<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>持久化 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/database-series/3.%E9%94%AE%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E6%8C%81%E4%B9%85%E5%8C%96/</link><atom:link href="https://ng-tech.icu/books/database-series/3.%E9%94%AE%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E6%8C%81%E4%B9%85%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><description>持久化</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>持久化</title><link>https://ng-tech.icu/books/database-series/3.%E9%94%AE%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E6%8C%81%E4%B9%85%E5%8C%96/</link></image><item><title>持久化</title><link>https://ng-tech.icu/books/database-series/3.%E9%94%AE%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E6%8C%81%E4%B9%85%E5%8C%96/%E6%8C%81%E4%B9%85%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-series/3.%E9%94%AE%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E6%8C%81%E4%B9%85%E5%8C%96/%E6%8C%81%E4%B9%85%E5%8C%96/</guid><description>&lt;h1 id="持久化备份与迁移">持久化备份与迁移&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>持久化方式&lt;/strong>&lt;/th>
&lt;th>&lt;strong>原理&lt;/strong>&lt;/th>
&lt;th>&lt;strong>特点&lt;/strong>&lt;/th>
&lt;th>&lt;strong>启用方式&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>RDB(快照持久化)&lt;/td>
&lt;td>当符合快照条件时，会自动将内存中的所有数据进行快照并且存储到硬盘上&lt;/td>
&lt;td>针对热数据，记录和恢复效率高，恢复不完整&lt;/td>
&lt;td>默认启用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>AOF(追加持久化)&lt;/td>
&lt;td>将发送到服务端的每一条请求都记录下来,并且保存在硬盘的 AOF 文件中&lt;/td>
&lt;td>针对所有请求，记录和恢复效率低，恢复完整&lt;/td>
&lt;td>配置文件&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Redis 提供了多种不同级别的持久化方式:一种是 RDB,另一种是 AOF。&lt;/p>
&lt;ul>
&lt;li>RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照(point-in-time snapshot)。&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。Redis 还可以在后台对 AOF 文件进行重写(rewrite)，使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。Redis 还可以同时使用 AOF 持久化和 RDB 持久化。在这种情况下，当 Redis 重启时，它会优先使用 AOF 文件来还原数据集，因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在。&lt;/li>
&lt;/ul>
&lt;p>一般来说,如果想达到足以媲美 PostgreSQL 的数据安全性，你应该同时使用两种持久化功能。如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化，但我们并不推荐这种方式: 因为定时生成 RDB 快照(snapshot)非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。因为以上提到的种种原因，未来我们可能会将 AOF 和 RDB 整合成单个持久化模型。(这是一个长期计划。)&lt;/p>
&lt;pre tabindex="0">&lt;code># The filename where to dump the DB
dbfilename dump.rdb
# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the &amp;#39;dbfilename&amp;#39; configuration directive.
#
# Also the Append Only File will be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir /var/lib/redis
&lt;/code>&lt;/pre>&lt;h3 id="rdb">RDB&lt;/h3>
&lt;p>RDB 的优点:&lt;/p>
&lt;p>RDB&lt;/p>
&lt;p>是一个非常紧凑(compact)的文件，它保存了 Redis 在某个时间点上的数据集。这种文件非常适合用于进行备份: 比如说，你可以在最近的&lt;/p>
&lt;p>24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。&lt;/p>
&lt;p>这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于灾难恢复(disaster&lt;/p>
&lt;p>recovery)：它只有一个文件，并且内容都非常紧凑，可以(在加密后)将它传送到别的数据中心，或者亚马逊 S3 中。RDB 可以最大化&lt;/p>
&lt;p>Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork&lt;/p>
&lt;p>出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 IO 操作。RDB 在恢复大数据集时的速度比 AOF&lt;/p>
&lt;p>的恢复速度要快。&lt;/p>
&lt;p>RDB 的缺点:&lt;/p>
&lt;p>如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。虽然 Redis 允许你设置不同的保存点(save point)来控制保存&lt;/p>
&lt;p>RDB 文件的频率，但是，因为 RDB 文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。因此你可能会至少 5 分钟才保存一次&lt;/p>
&lt;p>RDB 文件。在这种情况下，一旦发生故障停机，你就可能会丢失好几分钟的数据。每次保存 RDB 的时候，Redis 都要 fork()&lt;/p>
&lt;p>出一个子进程，并由子进程来进行实际的持久化工作。在数据集比较庞大时，fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；&lt;/p>
&lt;p>如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。虽然 AOF 重写也需要进行 fork()&lt;/p>
&lt;p>，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。&lt;/p>
&lt;p>RDB 快照:&lt;/p>
&lt;p>在默认情况下，Redis&lt;/p>
&lt;p>将数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置，让它在“ N 秒内数据集至少有 M&lt;/p>
&lt;p>个改动”这一条件被满足时，自动保存一次数据集。你也可以通过调用 SAVE 或者 BGSAVE，手动让 Redis&lt;/p>
&lt;p>进行数据集保存操作。比如说，以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时，自动保存一次数据集：&lt;/p>
&lt;p>save 60 1000&lt;/p>
&lt;p>这种持久化方式被称为快照(snapshot)。&lt;/p>
&lt;p>快照的运作方式:&lt;/p>
&lt;p>当 Redis 需要保存 dump.rdb 文件时，服务器执行以下操作：&lt;/p>
&lt;p>Redis 调用 fork()，同时拥有父进程和子进程。&lt;/p>
&lt;p>子进程将数据集写入到一个临时 RDB 文件中。&lt;/p>
&lt;p>当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。&lt;/p>
&lt;p>这种工作方式使得 Redis 可以从写时复制(copy-on-write)机制中获益。&lt;/p>
&lt;p>只进行追加操作的文件(append-only file，AOF)&lt;/p>
&lt;p>快照功能并不是非常耐久(durable): 如果 Redis 因为某些原因而造成故障停机，&lt;/p>
&lt;p>那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。尽管对于某些程序来说，数据的耐久性并不是最重要的考虑因素，&lt;/p>
&lt;p>但是对于那些追求完全耐久能力(full durability)的程序来说，快照功能就不太适用了。&lt;/p>
&lt;p>从 1.1 版本开始，Redis 增加了一种完全耐久的持久化方式: AOF 持久化。&lt;/p>
&lt;p>你可以通过修改配置文件来打开 AOF 功能：&lt;/p>
&lt;p>appendonly yes&lt;/p>
&lt;p>从现在开始，每当 Redis 执行一个改变数据集的命令时(比如 SET)，这个命令就会被追加到 AOF 文件的末尾。&lt;/p>
&lt;p>这样的话，当 Redis 重新启时，程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。&lt;/p>
&lt;h3 id="arf">ARF&lt;/h3>
&lt;p>AOF 的优点:&lt;/p>
&lt;p>使用 AOF 持久化会让 Redis&lt;/p>
&lt;p>变得非常耐久(much more durable)：你可以设置不同的 fsync 策略，比如无 fsync，每秒钟一次 fsync&lt;/p>
&lt;p>，或者每次执行写入命令时 fsync。AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis&lt;/p>
&lt;p>仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据( fsync&lt;/p>
&lt;p>会在后台线程执行，所以主线程可以继续努力地处理命令请求)。AOF 文件是一个只进行追加操作的日志文件(append only log)，因此对&lt;/p>
&lt;p>AOF 文件的写入不需要进行 seek，即使日志因为某些原因而包含了未写入完整的命令(比如写入时磁盘已满，写入中途停机，等等)，&lt;/p>
&lt;p>redis-check-aof 工具也可以轻易地修复这种问题。&lt;/p>
&lt;p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF&lt;/p>
&lt;p>进行重写: 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为 Redis 在创建新 AOF&lt;/p>
&lt;p>文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。而一旦新 AOF&lt;/p>
&lt;p>文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF&lt;/p>
&lt;p>文件有序地保存了对数据库执行的所有写入操作，这些写入操作以 Redis 协议的格式保存，因此 AOF 文件的内容非常容易被人读懂，&lt;/p>
&lt;p>对文件进行分析(parse)也很轻松。导出(export) AOF 文件也非常简单: 举个例子，如果你不小心执行了 FLUSHALL 命令，&lt;/p>
&lt;p>但只要 AOF 文件未被重写，那么只要停止服务器，移除 AOF 文件末尾的 FLUSHALL 命令，并重启 Redis，&lt;/p>
&lt;p>就可以将数据集恢复到 FLUSHALL 执行之前的状态。&lt;/p>
&lt;p>AOF 的缺点:&lt;/p>
&lt;p>对于相同的数据集来说，AOF&lt;/p>
&lt;p>文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。在一般情况下，每秒&lt;/p>
&lt;p>fsync 的性能依然非常高，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快，即使在高负荷之下也是如此。&lt;/p>
&lt;p>不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间(latency)。AOF 在过去曾经发生过这样的 bug&lt;/p>
&lt;p>因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。(举个例子，阻塞命令 BRPOPLPUSH&lt;/p>
&lt;p>就曾经引起过这样的 bug。) 测试套件里为这种情况添加了测试: 它们会自动生成随机的、复杂的数据集，并通过重新载入这些数据来确保一切正常。&lt;/p>
&lt;p>虽然这种 bug 在 AOF 文件中并不常见，但是对比来说，RDB 几乎是不可能出现这种 bug 的。&lt;/p>
&lt;p>AOF 重写:&lt;/p>
&lt;p>因为 AOF&lt;/p>
&lt;p>的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF 文件的体积也会变得越来越大。举个例子，&lt;/p>
&lt;p>如果你对一个计数器调用了 100 次 INCR，那么仅仅是为了保存这个计数器的当前值，AOF 文件就需要使用 100&lt;/p>
&lt;p>条记录(entry)。然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99&lt;/p>
&lt;p>条记录实际上都是多余的。为了处理这种情况，Redis 支持一种有趣的特性: 可以在不打断服务客户端的情况下，对 AOF&lt;/p>
&lt;p>文件进行重建(rebuild)。执行 BGREWRITEAOF 命令，Redis 将生成一个新的 AOF 文件，&lt;/p>
&lt;p>这个文件包含重建当前数据集所需的最少命令。&lt;/p>
&lt;p>AOF 有多耐久？&lt;/p>
&lt;p>你可以配置 Redis 多久才将数据 fsync 到磁盘一次。&lt;/p>
&lt;p>有三个选项：&lt;/p>
&lt;p>每次有新命令追加到 AOF 文件时就执行一次 fsync：非常慢，也非常安全。&lt;/p>
&lt;p>每秒 fsync 一次：足够快(和使用 RDB 持久化差不多)，并且在故障时只会丢失 1 秒钟的数据。&lt;/p>
&lt;p>从不 fsync：将数据交给操作系统来处理。更快，也更不安全的选择。&lt;/p>
&lt;p>推荐(并且也是默认)的措施为每秒 fsync 一次，这种 fsync 策略可以兼顾速度和安全性。&lt;/p>
&lt;p>总是 fsync 的策略在实际使用中非常慢，即使在 Redis 2.0 对相关的程序进行了改进之后仍是如此：频繁调用 fsync 注定了这种策略不可能快得起来。&lt;/p>
&lt;p>如果 AOF 文件出错了，怎么办？&lt;/p>
&lt;p>服务器可能在程序正在对 AOF 文件进行写入时停机，如果停机造成了 AOF 文件出错(corrupt)，那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏。&lt;/p>
&lt;p>当发生这种情况时，可以用以下方法来修复出错的 AOF 文件：&lt;/p>
&lt;p>为现有的 AOF 文件创建一个备份。&lt;/p>
&lt;p>使用 Redis 附带的 redis-check-aof 程序，对原来的 AOF 文件进行修复。&lt;/p>
&lt;p>$ redis-check-aof &amp;ndash;fix&lt;/p>
&lt;p>(可选)使用 diff -u 对比修复后的 AOF 文件和原始 AOF 文件的备份，查看两个文件之间的不同之处。&lt;/p>
&lt;p>重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复。&lt;/p>
&lt;p>AOF 的运作方式&lt;/p>
&lt;p>AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制。&lt;/p>
&lt;p>以下是 AOF 重写的执行步骤:&lt;/p>
&lt;p>Redis 执行 fork()，现在同时拥有父进程和子进程。&lt;/p>
&lt;p>子进程开始将新 AOF 文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有&lt;/p>
&lt;p>AOF 文件的末尾: 这样即使在重写的中途发生停机，现有的 AOF&lt;/p>
&lt;p>文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF&lt;/p>
&lt;p>文件的末尾。现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。&lt;/p>
&lt;p>为最新的 dump.rdb 文件创建一个备份。&lt;/p>
&lt;p>将备份放到一个安全的地方。&lt;/p>
&lt;p>执行以下两条命令：&lt;/p>
&lt;p>redis-cli&amp;gt; CONFIG SET appendonly yes&lt;/p>
&lt;p>redis-cli&amp;gt; CONFIG SET save &amp;quot;&amp;quot;&lt;/p>
&lt;p>确保命令执行之后，数据库的键的数量没有改变。&lt;/p>
&lt;p>确保写命令会被正确地追加到 AOF 文件的末尾。&lt;/p>
&lt;p>步骤 3 执行的第一条命令开启了 AOF 功能: Redis 会阻塞直到初始 AOF 文件创建完成为止，之后 Redis 会继续处理命令请求，并开始将写入命令追加到 AOF 文件末尾。&lt;/p>
&lt;p>步骤 3 执行的第二条命令用于关闭 RDB 功能。这一步是可选的，如果你愿意的话，也可以同时使用 RDB 和 AOF 这两种持久化功能。&lt;/p>
&lt;p>别忘了在 redis.conf 中打开 AOF 功能！ 否则的话，服务器重启之后，之前通过 CONFIG SET 设置的配置就会被遗忘，程序会按原来的配置来启动服务器。&lt;/p>
&lt;p>&lt;a href="http://www.bitstech.net/2016/03/03/redis-migration/" target="_blank" rel="noopener">redis-migration：独创的 redis 在线数据迁移工具&lt;/a>&lt;/p>
&lt;p>最近需要把一个 redis 服务从一台服务器上迁移到另外一台上，所以找了一下迁移的方案，有说在第一台 把数据 Dump 完然后复制数据文件过去，之后在新机器上起来 redis 实例，但是这样 redis 将会有一段无法 使用的时间。&lt;/p>
&lt;p>后来发现使用 redis 的 &lt;a href="http://redis.io/topics/replication" target="_blank" rel="noopener">replication&lt;/a> 可以极其简单的实现 redis 从一个地方到另外一个地方的迁移。&lt;/p>
&lt;h2 id="1-在新服务器上启动一个-redis-实例">1. 在新服务器上启动一个 redis 实例&lt;/h2>
&lt;p>首先我们先在需要迁移到的服务器上启动一个新的 redis 实例，配置没有什么特别的地方，值得注意的是，从 redis2.6 以后，redis 的 slave 默认变得不再接受写操作，所以我们需要修改 conf 中的&lt;/p>
&lt;pre tabindex="0">&lt;code>#slave-read-only yes
slave-read-only no
&lt;/code>&lt;/pre>&lt;p>这样 slave 才能正常的接受写操作，不然之后写的时候会报错。&lt;/p>
&lt;h2 id="2-使新的-redis-服务成为-slave">2. 使新的 redis 服务成为 slave&lt;/h2>
&lt;p>当新的 redis 起来后，我们使用 redis-cli 连进去，然后使用 &lt;a href="http://redis.io/commands/slaveof" target="_blank" rel="noopener">slaveof&lt;/a> 命令使这个 redis 成为我们的旧 redis 的 slave:&lt;/p>
&lt;pre tabindex="0">&lt;code>redis 127.0.0.1:6379&amp;gt; SLAVEOF 192.168.1.100 6379
OK
&lt;/code>&lt;/pre>&lt;p>在这之后，这两个 redis 会自动开始同步，如果需要查看同步的状态，可以使用 info 命令。&lt;/p>
&lt;h2 id="3-完成迁移">3. 完成迁移&lt;/h2>
&lt;p>等 master 和 slave 之间的同步完成后，我们就可以修改我们的应用，让它们使用新的 redis server 地址了。把地址全部修改完以后，在新的 redis 上执行&lt;/p>
&lt;pre tabindex="0">&lt;code>redis 127.0.0.1:6379&amp;gt; SLAVEOF no one
&lt;/code>&lt;/pre>&lt;p>让它重新变成老大，这样整个迁移就完成了。之后关闭调旧的 redis 旧 ok 了&lt;/p></description></item></channel></rss>
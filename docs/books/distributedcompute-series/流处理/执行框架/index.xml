<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>执行框架 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/</link><atom:link href="https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/index.xml" rel="self" type="application/rss+xml"/><description>执行框架</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>执行框架</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/</link></image><item><title>反压</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%8F%8D%E5%8E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%8F%8D%E5%8E%8B/</guid><description>&lt;h1 id="反压">反压&lt;/h1></description></item><item><title>分布式快照</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BF%AB%E7%85%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BF%AB%E7%85%A7/</guid><description>&lt;h1 id="分布式快照">分布式快照&lt;/h1>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/44454670" target="_blank" rel="noopener">简单解释: 分布式快照(Chandy-Lamport 算法)&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://zhuanlan.zhihu.com/p/43536305" target="_blank" rel="noopener">(十)简单解释: 分布式数据流的异步快照(Flink 的核心)&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>流式连接</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E6%B5%81%E5%BC%8F%E8%BF%9E%E6%8E%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E6%B5%81%E5%BC%8F%E8%BF%9E%E6%8E%A5/</guid><description>&lt;h1 id="流式连接">流式连接&lt;/h1>
&lt;p>我们讨论了批处理作业如何通过键来连接数据集，以及这种连接是如何成为数据管道的重要组成部分的。由于流处理将数据管道泛化为对无限数据集进行增量处理，因此对流进行连接的需求也是完全相同的。然而，新事件随时可能出现在一个流中，这使得流连接要比批处理连接更具挑战性。为了更好地理解情况，让我们先来区分三种不同类型的连接：流-流连接，流-表连接，与表-表连接。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>流流连接：两个输入流都由活动事件组成，而连接算子在某个时间窗口内搜索相关的事件。例如，它可能会将同一个用户 30 分钟内进行的两个活动联系在一起。如果你想要找出一个流内的相关事件，连接的两侧输入可能实际上都是同一个流（自连接（self-join））。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>流表连接：一个输入流由活动事件组成，另一个输入流是数据库变更日志。变更日志保证了数据库的本地副本是最新的。对于每个活动事件，连接算子将查询数据库，并输出一个扩展的活动事件。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>表表连接：两个输入流都是数据库变更日志。在这种情况下，一侧的每一个变化都与另一侧的最新状态相连接。结果是两表连接所得物化视图的变更流。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="流流连接窗口连接">流流连接（窗口连接）&lt;/h1>
&lt;p>假设你的网站上有搜索功能，而你想要找出搜索 URL 的近期趋势。每当有人键入搜索查询时，都会记录下一个包含查询与其返回结果的事件。每当有人点击其中一个搜索结果时，就会记录另一个记录点击事件。为了计算搜索结果中每个 URL 的点击率，你需要将搜索动作与点击动作的事件连在一起，这些事件通过相同的会话 ID 进行连接。广告系统中需要类似的分析。&lt;/p>
&lt;p>如果用户丢弃了搜索结果，点击可能永远不会发生，即使它出现了，搜索与点击之间的时间可能是高度可变的：在很多情况下，它可能是几秒钟，但也可能长达几天或几周（如果用户执行搜索，忘掉了这个浏览器页面，过了一段时间后重新回到这个浏览器页面上，并点击了一个结果）。由于可变的网络延迟，点击事件甚至可能先于搜索事件到达。你可以选择合适的连接窗口，例如，如果点击与搜索之间的时间间隔在一小时内，你可能会选择连接两者。&lt;/p>
&lt;p>请注意，在点击事件中嵌入搜索详情与事件连接并不一样：这样做的话，只有当用户点击了一个搜索结果时你才能知道，而那些没有点击的搜索就无能为力了。为了衡量搜索质量，你需要准确的点击率，为此搜索事件和点击事件两者都是必要的。为了实现这种类型的连接，流处理器需要维护状态：例如，按会话 ID 索引最近一小时内发生的所有事件。无论何时发生搜索事件或点击事件，都会被添加到合适的索引中，而流处理器也会检查另一个索引是否有具有相同会话 ID 的事件到达。如果有匹配事件就会发出一个表示搜索结果被点击的事件；如果搜索事件直到过期都没看见有匹配的点击事件，就会发出一个表示搜索结果未被点击的事件。&lt;/p>
&lt;h1 id="流表连接流扩展">流表连接（流扩展）&lt;/h1>
&lt;p>一般的用户活动事件分析中，我们看到了连接两个数据集的批处理作业示例：一组用户活动事件和一个用户档案数据库。将用户活动事件视为流，并在流处理器中连续执行相同的连接是很自然的想法：输入是包含用户 ID 的活动事件流，而输出还是活动事件流，但其中用户 ID 已经被扩展为用户的档案信息。这个过程有时被称为 使用数据库的信息来扩充（enriching）活动事件。要执行此联接，流处理器需要一次处理一个活动事件，在数据库中查找事件的用户 ID，并将档案信息添加到活动事件中。数据库查询可以通过查询远程数据库来实现。不过，此类远程查询可能会很慢，并且有可能导致数据库过载。&lt;/p>
&lt;p>另一种方法是将数据库副本加载到流处理器中，以便在本地进行查询而无需网络往返。这种技术与我们在“Map 端连接”中讨论的哈希连接非常相似：如果数据库的本地副本足够小，则可以是内存中的哈希表，比较大的话也可以是本地磁盘上的索引。与批处理作业的区别在于，批处理作业使用数据库的时间点快照作为输入，而流处理器是长时间运行的，且数据库的内容可能随时间而改变，所以流处理器数据库的本地副本需要保持更新。这个问题可以通过变更数据捕获来解决：流处理器可以订阅用户档案数据库的更新日志，如同活跃事件流一样。当增添或修改档案时，流处理器会更新其本地副本。因此，我们有了两个流之间的连接：活动事件和档案更新。&lt;/p>
&lt;p>流表连接实际上非常类似于流流连接；最大的区别在于对于表的变更日志流，连接使用了一个可以回溯到“时间起点”的窗口（概念上是无限的窗口），新版本的记录会覆盖更早的版本。对于输入的流，连接可能压根儿就没有维护窗口。&lt;/p>
&lt;h1 id="表表连接维护物化视图">表表连接（维护物化视图）&lt;/h1>
&lt;p>譬如在推特时间线中，当用户想要查看他们的主页时间线时，迭代用户所关注人群的推文并合并它们是一个开销巨大的操作。相反，我们需要一个时间线缓存：一种每个用户的“收件箱”，在发送推文的时候写入这些信息，因而读取时间线时只需要简单地查询即可。物化与维护这个缓存需要处理以下事件：&lt;/p>
&lt;ul>
&lt;li>当用户 u 发送新的推文时，它将被添加到每个关注用户 u 的时间线上。&lt;/li>
&lt;li>用户删除推文时，推文将从所有用户的时间表中删除。&lt;/li>
&lt;li>当用户$u_1$开始关注用户$u_2$时，$u_2$最近的推文将被添加到$u_1$的时间线上。&lt;/li>
&lt;li>当用户$u_1$取消关注用户$u_2$时，$u_2$的推文将从$u_1$的时间线中移除。&lt;/li>
&lt;/ul>
&lt;p>要在流处理器中实现这种缓存维护，你需要推文事件流（发送与删除）和关注关系事件流（关注与取消关注）。流处理需要为维护一个数据库，包含每个用户的粉丝集合。以便知道当一条新推文到达时，需要更新哪些时间线。观察这个流处理过程的另一种视角是：它维护了一个连接了两个表（推文与关注）的物化视图，如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">SELECT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">follows&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">follower_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">timeline_id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">array_agg&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tweets&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">ORDER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">BY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">tweets&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">timestamp&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DESC&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">tweets&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">JOIN&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">follows&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">ON&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">follows&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">followee_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">tweets&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">sender_id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">GROUP&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">BY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">follows&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">follower_id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>流连接直接对应于这个查询中的表连接。时间线实际上是这个查询结果的缓存，每当基础表发生变化时都会更新。&lt;/p>
&lt;h1 id="连接的时间依赖性">连接的时间依赖性&lt;/h1>
&lt;p>这里描述的三种连接（流流，流表，表表）有很多共通之处：它们都需要流处理器维护连接一侧的一些状态（搜索与点击事件，用户档案，关注列表），然后当连接另一侧的消息到达时查询该状态。用于维护状态的事件顺序是很重要的（先关注然后取消关注，或者其他类似操作）。在分区日志中，单个分区内的事件顺序是保留下来的。但典型情况下是没有跨流或跨分区的顺序保证的。&lt;/p>
&lt;p>这就产生了一个问题：如果不同流中的事件发生在近似的时间范围内，则应该按照什么样的顺序进行处理？在流表连接的例子中，如果用户更新了它们的档案，哪些活动事件与旧档案连接（在档案更新前处理），哪些又与新档案连接（在档案更新之后处理）？换句话说：你需要对一些状态做连接，如果状态会随着时间推移而变化，那应当使用什么时间点来连接呢？&lt;/p>
&lt;p>这种时序依赖可能出现在很多地方。例如销售东西需要对发票应用适当的税率，这取决于所处的国家/州，产品类型，销售日期（因为税率会随时变化）。当连接销售额与税率表时，你可能期望的是使用销售时的税率参与连接。如果你正在重新处理历史数据，销售时的税率可能和现在的税率有所不同。如果跨越流的事件顺序是未定的，则连接会变为不确定性的，这意味着你在同样输入上重跑相同的作业未必会得到相同的结果：当你重跑任务时，输入流上的事件可能会以不同的方式交织。&lt;/p>
&lt;p>在数据仓库中，这个问题被称为缓慢变化的维度（slowly changing dimension, SCD），通常通过对特定版本的记录使用唯一的标识符来解决：例如，每当税率改变时都会获得一个新的标识符，而发票在销售时会带有税率的标识符。这种变化使连接变为确定性的，但也会导致日志压缩无法进行：表中所有的记录版本都需要保留。&lt;/p></description></item><item><title>容错</title><link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%AE%B9%E9%94%99/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/%E6%89%A7%E8%A1%8C%E6%A1%86%E6%9E%B6/%E5%AE%B9%E9%94%99/</guid><description>&lt;h1 id="容错">容错&lt;/h1>
&lt;p>批处理框架可以很容易地容错：如果 MapReduce 作业中的任务失败，可以简单地在另一台机器上再次启动，并且丢弃失败任务的输出。这种透明的重试是可能的，因为输入文件是不可变的，每个任务都将其输出写入到 HDFS 上的独立文件中，而输出仅当任务成功完成后可见。特别是，批处理容错方法可确保批处理作业的输出与没有出错的情况相同，即使实际上某些任务失败了。看起来好像每条输入记录都被处理了恰好一次，没有记录被跳过，而且没有记录被处理两次。尽管重启任务意味着实际上可能会多次处理记录，但输出中的可见效果看上去就像只处理过一次。这个原则被称为恰好一次语义（exactly-once semantics），尽管有效一次（effectively-once）可能会是一个更写实的术语。&lt;/p>
&lt;p>在流处理中也出现了同样的容错问题，但是处理起来没有那么直观：等待某个任务完成之后再使其输出可见并不是一个可行选项，因为你永远无法处理完一个无限的流。&lt;/p>
&lt;h1 id="微批量与存档点">微批量与存档点&lt;/h1>
&lt;p>一个解决方案是将流分解成小块，并像微型批处理一样处理每个块。这种方法被称为微批次（microbatching），它被用于 Spark Streaming。批次的大小通常约为 1 秒，这是对性能妥协的结果：较小的批次会导致更大的调度与协调开销，而较大的批次意味着流处理器结果可见之前的延迟要更长。微批次也隐式提供了一个与批次大小相等的滚动窗口（按处理时间而不是事件时间戳分窗）。任何需要更大窗口的作业都需要显式地将状态从一个微批次转移到下一个微批次。&lt;/p>
&lt;p>Apache Flink 则使用不同的方法，它会定期生成状态的滚动存档点并将其写入持久存储。如果流算子崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出。存档点会由消息流中的 壁障（barrier）触发，类似于微批次之间的边界，但不会强制一个特定的窗口大小。在流处理框架的范围内，微批次与存档点方法提供了与批处理一样的恰好一次语义。但是，只要输出离开流处理器（例如，写入数据库，向外部消息代理发送消息，或发送电子邮件），框架就无法抛弃失败批次的输出了。在这种情况下，重启失败任务会导致外部副作用发生两次，只有微批次或存档点不足以阻止这一问题。&lt;/p>
&lt;h1 id="原子提交再现">原子提交再现&lt;/h1>
&lt;p>为了在出现故障时表现出恰好处理一次的样子，我们需要确保事件处理的所有输出和副作用当且仅当处理成功时才会生效。这些影响包括发送给下游算子或外部消息传递系统（包括电子邮件或推送通知）的任何消息，任何数据库写入，对算子状态的任何变更，以及对输入消息的任何确认（包括在基于日志的消息代理中将消费者偏移量前移）。&lt;/p>
&lt;p>这些事情要么都原子地发生，要么都不发生，但是它们不应当失去同步，该方法很类似于分布式事务与两阶段提交。&lt;/p>
&lt;h1 id="幂等性">幂等性&lt;/h1>
&lt;p>我们的目标是丢弃任何失败任务的部分输出，以便能安全地重试，而不会生效两次。分布式事务是实现这个目标的一种方式，而另一种方式是依赖幂等性（idempotence）。幂等操作是多次重复执行与单次执行效果相同的操作。例如，将键值存储中的某个键设置为某个特定值是幂等的（再次写入该值，只是用同样的值替代），而递增一个计数器不是幂等的（再次执行递增意味着该值递增两次）。&lt;/p>
&lt;p>即使一个操作不是天生幂等的，往往可以通过一些额外的元数据做成幂等的。例如，在使用来自 Kafka 的消息时，每条消息都有一个持久的，单调递增的偏移量。将值写入外部数据库时可以将这个偏移量带上，这样你就可以判断一条更新是不是已经执行过了，因而避免重复执行。Storm 的 Trident 基于类似的想法来处理状态。依赖幂等性意味着隐含了一些假设：重启一个失败的任务必须以相同的顺序重放相同的消息（基于日志的消息代理能做这些事），处理必须是确定性的，没有其他节点能同时更新相同的值。&lt;/p>
&lt;p>当从一个处理节点故障切换到另一个节点时，可能需要进行防护（fencing），以防止被假死节点干扰。尽管有这么多注意事项，幂等操作是一种实现恰好一次语义的有效方式，仅需很小的额外开销。&lt;/p>
&lt;h1 id="失败后重建状态">失败后重建状态&lt;/h1>
&lt;p>任何需要状态的流处理，例如，任何窗口聚合（例如计数器，平均值和直方图）以及任何用于连接的表和索引，都必须确保在失败之后能恢复其状态。一种选择是将状态保存在远程数据存储中，并进行复制，然而正如在“流表连接”中所述，每个消息都要查询远程数据库可能会很慢。另一种方法是在流处理器本地保存状态，并定期复制。然后当流处理器从故障中恢复时，新任务可以读取状态副本，恢复处理而不丢失数据。例如，Flink 定期捕获算子状态的快照，并将它们写入 HDFS 等持久存储中。Samza 和 Kafka Streams 通过将状态变更发送到具有日志压缩功能的专用 Kafka 主题来复制状态变更，这与变更数据捕获类似。VoltDB 通过在多个节点上对每个输入消息进行冗余处理来复制状态。&lt;/p>
&lt;p>在某些情况下，甚至可能都不需要复制状态，因为它可以从输入流重建。例如，如果状态是从相当短的窗口中聚合而成，则简单地重放该窗口中的输入事件可能是足够快的。如果状态是通过变更数据捕获来维护的数据库的本地副本，那么也可以从日志压缩的变更流中重建数据库。然而，所有这些权衡取决于底层基础架构的性能特征：在某些系统中，网络延迟可能低于磁盘访问延迟，网络带宽可能与磁盘带宽相当。没有针对所有情况的普世理想权衡，随着存储和网络技术的发展，本地状态与远程状态的优点也可能会互换。&lt;/p></description></item></channel></rss>
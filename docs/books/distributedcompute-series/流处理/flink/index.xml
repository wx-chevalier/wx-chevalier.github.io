<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Flink | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/</link>
      <atom:link href="https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/index.xml" rel="self" type="application/rss+xml" />
    <description>Flink</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>Flink</title>
      <link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/</link>
    </image>
    
    <item>
      <title>Table API</title>
      <link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/table-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/table-api/</guid>
      <description>&lt;p&gt;近年来，开源的分布式流处理系统层出不穷，引起了广泛的关注与讨论。其中的先行者，譬如 &lt;a href=&#34;https://storm.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Storm&lt;/a&gt;提供了低延迟的流式处理功能，但是受限于 at-least-once 的投递保证，背压等不太良好的处理以及相对而言的开放 API 的底层化。不过 Storm 也起到了抛砖引玉的作用，自此之后，很多新的流处理系统在不同的维度上大放光彩。今日，Apache Flink 或者 &lt;a href=&#34;https://beam.incubator.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Beam&lt;/a&gt;的使用者能够使用流式的 Scala 或者 Java APIs 来进行流处理任务，同时保证了 exactly-once 的投递机制以及高吞吐情况下的的低延迟响应。与此同时，流处理也在产界得到了应用，从 Apache Kafka 与 Apache Flink 在流处理的基础设施领域的大规模部署也折射除了流处理在产界的快速发展。与日俱增的实时数据流催生了开发人员或者分析人员对流数据进行分析以及实时展现的需求。不过，流数据分析也需要一些必备的技能与知识储备，譬如无限流的基本特性、窗口、时间以及状态等等，这些概念都会在利用 Java 或者 Scala API 来完成一个流分析的任务时候起到很大的作用。
大概六个月之前，Apache Flink 社区着手为流数据分析系统引入一个 SQL 交互功能。众所周知，SQL 是访问与处理数据的标准语言，基本上每个用过数据库的或者进行或数据分析的都对 SQL 不陌生。鉴于此，为流处理系统添加一个 SQL 交互接口能够有效地扩大该技术的受用面，让更多的人可以熟悉并且使用。除此之外，引入 SQL 的支持还能满足于一些需要实时交互地用户场景，大大简化一些需要进行流操作或者转化的应用代码。这篇文章中，我们会从现有的状态、架构的设计以及未来 Apache Flink 社区准备添加 SQL 支持的计划这几个方面进行讨论。&lt;/p&gt;
&lt;h2 id=&#34;从何开始先来回顾下已有的-table-api&#34;&gt;从何开始，先来回顾下已有的 Table API&lt;/h2&gt;
&lt;p&gt;在 &lt;a href=&#34;http://flink.apache.org/news/2015/04/13/release-0.9.0-milestone1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;0.9.0-milestone1&lt;/a&gt; 发布之后，Apache Flink 添加了所谓的 Table API 来提供类似于 SQL 的表达式用于对关系型数据进行处理。这系列 API 的操作对象就是抽象而言的能够进行关系型操作的结构化数据或者流。Table API 一般与 DataSet 或者 DataStream 紧密关联，可以从 DataSet 或者 DataStream 来方便地创建一个 Table 对象，也可以用如下的操作将一个 Table 转化回一个 DataSet 或者 DataStream 对象：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;execEnv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ExecutionEnvironment&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getExecutionEnvironment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tableEnv&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;TableEnvironment&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getTableEnvironment&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;execEnv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// obtain a DataSet from somewhere
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tempData&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;DataSet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;String&lt;/span&gt;, &lt;span class=&#34;kt&#34;&gt;Long&lt;/span&gt;, &lt;span class=&#34;kt&#34;&gt;Double&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;=&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// convert the DataSet to a Table
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tempTable&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tempData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toTable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tableEnv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;location&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;time&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;tempF&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// compute your result
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;avgTempCTable&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;Table&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tempTable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;location&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;like&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;room%&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;time &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3600&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;24&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &amp;#39;day&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &amp;#39;Location &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &amp;#39;room&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&amp;#39;tempF &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.556&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &amp;#39;tempC
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;groupBy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;day&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;room&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;select&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&amp;#39;day&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;room&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &amp;#39;tempC&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;avg&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &amp;#39;avgTempC&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// convert result Table back into a DataSet and print it
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;avgTempCTable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toDataSet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;Row&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面这坨代码是 Scala 的，不过你可以简单地用 Java 版本的 Table API 进行实现，下面这张图就展示了 Table API 的原始的结构：

















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://flink.apache.org/img/blog/stream-sql/old-table-api.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;
在我们从 DataSet 或者 DataStream 创建了 Table 之后，可以利用类似于&lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;join&lt;/code&gt;, 或者 &lt;code&gt;select&lt;/code&gt;关系型转化操作来转化为一个新的 Table 对象。而从内部实现上来说，所有应用于 Table 的转化操作都会变成一棵逻辑表操作树，在 Table 对象被转化回 DataSet 或者 DataStream 之后，专门的转化器会将这棵逻辑操作符树转化为对等的 DataSet 或者 DataStream 操作符。譬如&lt;code&gt;&#39;location.like(&amp;quot;room%&amp;quot;)&lt;/code&gt;这样的表达式会经由代码生成编译为 Flink 中的函数。
不过，老版本的 Table API 还是有很多的限制的。首先，Table API 并不能单独使用，而必须嵌入到 DataSet 或者 DataStream 的程序中，对于批处理表的查询并不支持外连接、排序以及其他很多在 SQL 中经常使用的扩展操作。而流处理表中只支持譬如 filters、union 以及 projections，不能支持 aggregations 以及 joins。并且，这个转化处理过程并不能有查询优化，你要优化的话还是要去参考那些对于 DataSet 操作的优化。&lt;/p&gt;
&lt;h2 id=&#34;table-api-joining-forces-with-sql&#34;&gt;Table API joining forces with SQL&lt;/h2&gt;
&lt;p&gt;关于是否需要添加 SQL 支持的讨论之前就在 Flink 社区中发生过几次，Flink 0.9 发布之后，Table API、关系表达式的代码生成工具以及运行时的操作符等都预示着添加 SQL 支持的很多基础已经具备，可以考虑进行添加了。不过另一方面，在整个 Hadoop 生态链里已经存在了大量的所谓“SQL-on-Hadoop”的解决方案，譬如&lt;a href=&#34;https://hive.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&#34;https://drill.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Drill&lt;/a&gt;, &lt;a href=&#34;http://impala.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&#34;https://tajo.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Tajo&lt;/a&gt;，在已经有了这么多的可选方案的情况下，我们觉得应该优先提升 Flink 其他方面的特性，于是就暂时搁置了 SQL-on-Hadoop 的开发。
不过，随着流处理系统的日渐火热以及 Flink 受到的越来越广泛地应用，我们发现有必要为用户提供一个更简单的可以用于数据分析的接口。大概半年前，我们决定要改造下 Table API，扩展其对于流处理的能力并且最终完成在流处理上的 SQL 支持。不过我们也不打算重复造轮子，因此打算基于&lt;a href=&#34;https://calcite.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache Calcite&lt;/a&gt;这个非常流行的 SQL 解析器进行重构操作。Calcite 在其他很多开源项目里也都应用到了，譬如 Apache Hive, Apache Drill, Cascading, and many &lt;a href=&#34;https://calcite.apache.org/docs/powered_by.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;more&lt;/a&gt;。此外，Calcite 社区本身也有将&lt;a href=&#34;https://calcite.apache.org/docs/stream.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL on streams&lt;/a&gt;列入到它们的路线图中，因此我们一拍即合。Calcite 在新的架构设计中的地位大概如下所示:

















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://flink.apache.org/img/blog/stream-sql/new-table-api.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;
新的架构主要是将 Table API 与 SQL 集成起来，用这两货的 API 构建的查询最终都会转化到 Calcite 的所谓的 logicl plans 表述。转化之后的流查询与批查询基本上差不多，然后 Calcite 的优化器会基于转化和优化规则来优化这些 logical plans，针对数据源(流还是静态数据)的不同我们会应用不同的规则。最后，经过优化的 logical plan 会转化为一个普通的 Flink DataStream 或者 DataSet 对象，即还是利用代码生成来将关系型表达式编译为 Flink 的函数。
新的架构继续提供了 Table API 并且在此基础上进行了很大的提升，它为流数据与关系型数据提供了统一的查询接口。另外，我们利用了 Calcite 的查询优化框架与 SQL 解释器来进行了查询优化。不过，因为这些设计都还是基于 Flink 的已有的 API，譬如 DataStream API 提供的低延迟、高吞吐以及 exactly-once 投递的功能，以及 DataSet API 通过的健壮与高效的内存级别的操作器与管道式的数据交换，任何对于 Flink 核心 API 的提升都能够自动地提升 Table API 或者 SQL 查询的效率。
在这些工作之后，Flink 就已经具备了同时对于流数据与静态数据的 SQL 支持。不过，我们并不想把这个当成一个高效的 SQL-on-Hadoop 的解决方案，就像 Impala, Drill, 以及 Hive 那样的角色，我们更愿意把它当成为流处理提供便捷的交互接口的方案。另外，这套机制还能促进同时用了 Flink API 与 SQL 的应用的性能。&lt;/p&gt;
&lt;h2 id=&#34;how-will-flinks-sql-on-streams-look-like&#34;&gt;How will Flink’s SQL on streams look like?&lt;/h2&gt;
&lt;p&gt;我们讨论了为啥要重构 Flink 的流 SQL 接口的原因以及大概怎么去完成这个任务，现在我们讨论下最终的 API 或者使用方式会是啥样的。新的 SQL 接口会集成到 Table API 中。DataStreams、DataSet 以及额外的数据源都会先在 TableEnvironment 中注册成一个 Table 然后再进行 SQL 操作。&lt;code&gt;TableEnvironment.sql()&lt;/code&gt;方法会允许你输入 SQL 查询语句然后执行返回一个新的 Table，下面这个例子就展示了一个完整的从 JSON 编码的 Kafka 主题中读取数据然后利用 SQL 查询进行处理最终写入另一个 Kafka 主题的模型。注意，这下面提到的 KafkaJsonSource 与 KafkaJsonSink 都还未发布，未来的话 TableSource 与 TableSinks 都会固定提供，这样可以减少很多的模板代码。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// get environments
val execEnv = StreamExecutionEnvironment.getExecutionEnvironment
val tableEnv = TableEnvironment.getTableEnvironment(execEnv)

// configure Kafka connection
val kafkaProps = ...
// define a JSON encoded Kafka topic as external table
val sensorSource = new KafkaJsonSource[(String, Long, Double)](
    &amp;#34;sensorTopic&amp;#34;,
    kafkaProps,
    (&amp;#34;location&amp;#34;, &amp;#34;time&amp;#34;, &amp;#34;tempF&amp;#34;))

// register external table
tableEnv.registerTableSource(&amp;#34;sensorData&amp;#34;, sensorSource)

// define query in external table
val roomSensors: Table = tableEnv.sql(
    &amp;#34;SELECT STREAM time, location AS room, (tempF - 32) * 0.556 AS tempC &amp;#34; +
    &amp;#34;FROM sensorData &amp;#34; +
    &amp;#34;WHERE location LIKE &amp;#39;room%&amp;#39;&amp;#34;
  )

// define a JSON encoded Kafka topic as external sink
val roomSensorSink = new KafkaJsonSink(...)

// define sink for room sensor data and execute query
roomSensors.toSink(roomSensorSink)
execEnv.execute()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;你可能会发现上面这个例子中没有体现流处理中两个重要的方面：基于窗口的聚合与关联。下面我就会解释下怎么在 SQL 中表达关于窗口的操作。Apache Calcite 社区关于这方面已经有所讨论：&lt;a href=&#34;https://calcite.apache.org/docs/stream.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SQL on streams&lt;/a&gt;。Calcite 的流 SQL 被认为是一个标准 SQL 的扩展，而不是另一个类似于 SQL 的语言。这会有几个方面的好处，首先，已经熟悉了标准 SQL 语法的同学就没必要花时间再学一波新的语法了，皆大欢喜。现在对于静态表与流数据的查询已经基本一致了，可以很方便地进行转换。Flink 一直主张的是批处理只是流处理的一个特殊情况，因此用户也可以同时在静态表与流上进行查询，譬如处理有限的流。最后，未来也会有很多工具支持进行标准的 SQL 进行数据分析。
尽管我们还没有完全地定义好在 Flink SQL 表达式与 Table API 中如何进行窗口等设置，下面这个简单的例子会指明如何在 SQL 与 Table API 中进行滚动窗口式查询：&lt;/p&gt;
&lt;h3 id=&#34;sql-following-the-syntax-proposal-of-calcites-streaming-sql-document&#34;&gt;SQL (following the syntax proposal of Calcite’s streaming SQL document)&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;SELECT STREAM
  TUMBLE_END(time, INTERVAL &amp;#39;1&amp;#39; DAY) AS day,
  location AS room,
  AVG((tempF - 32) * 0.556) AS avgTempC
FROM sensorData
WHERE location LIKE &amp;#39;room%&amp;#39;
GROUP BY TUMBLE(time, INTERVAL &amp;#39;1&amp;#39; DAY), location
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;table-api&#34;&gt;Table API&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;val avgRoomTemp: Table = tableEnv.ingest(&amp;#34;sensorData&amp;#34;)
  .where(&amp;#39;location.like(&amp;#34;room%&amp;#34;))
  .partitionBy(&amp;#39;location)
  .window(Tumbling every Days(1) on &amp;#39;time as &amp;#39;w)
  .select(&amp;#39;w.end, &amp;#39;location,, ((&amp;#39;tempF - 32) * 0.556).avg as &amp;#39;avgTempCs)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>代码开发</title>
      <link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91/</guid>
      <description>&lt;h1 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h1&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;最简单的引入 Flink 依赖项的方式就是利用 Maven 或者 Gradle:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;&amp;lt;!-- Use this dependency if you are using the DataStream API --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.flink&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;flink-streaming-java_2.10&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.1-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;&amp;lt;!-- Use this dependency if you are using the DataSet API --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.flink&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;flink-java&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.1-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.flink&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;flink-clients_2.10&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.1-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;不过需要注意的是，由于 Scala 2.11 编译版本与 2.10 版本无法兼容，因此在 Flink 的依赖项后面也加了个后缀来表示使用的 Scala 版本，你可以选择需要的 Scala 版本进行操作。&lt;/p&gt;
&lt;h2 id=&#34;wordcount&#34;&gt;WordCount&lt;/h2&gt;
&lt;p&gt;Flink 有个方便的地方就是能够直接在本地运行而不需要提交到集群上，下面的测试程序直接右键点击 Run 即可。&lt;/p&gt;
&lt;h3 id=&#34;stream&#34;&gt;Stream&lt;/h3&gt;
&lt;p&gt;这里展示的是基本的将&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;public class WordCount {

    //
    // Program
    //

    public static void main(String[] args) throws Exception {

        // set up the execution environment
        final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

        // get input data
        DataSet&amp;lt;String&amp;gt; text = env.fromElements(
                &amp;#34;To be, or not to be,--that is the question:--&amp;#34;,
                &amp;#34;Whether &amp;#39;tis nobler in the mind to suffer&amp;#34;,
                &amp;#34;The slings and arrows of outrageous fortune&amp;#34;,
                &amp;#34;Or to take arms against a sea of troubles,&amp;#34;
        );

        DataSet&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; counts =
                // split up the lines in pairs (2-tuples) containing: (word,1)
                text.flatMap(new LineSplitter())
                        // group by the tuple field &amp;#34;0&amp;#34; and sum up tuple field &amp;#34;1&amp;#34;
                        .groupBy(0)
                        .sum(1);

        // execute and print result
        counts.print();

    }

    /
     * @function 分词函数
     */
    public static final class LineSplitter implements FlatMapFunction&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; {

        @Override
        public void flatMap(String value, Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; out) {
            // normalize and split the line
            String[] tokens = value.toLowerCase().split(&amp;#34;\\W+&amp;#34;);

            // emit the pairs
            for (String token : tokens) {
                if (token.length() &amp;gt; 0) {
                    out.collect(new Tuple2&amp;lt;String, Integer&amp;gt;(token, 1));
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;window-word-count&#34;&gt;Window Word Count&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package wx;

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.util.Collector;

/
 * Created by apple on 16/5/27.
 */
public class WindowWordCount {

    public static void main(String[] args) throws Exception {

        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStream&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; dataStream = env
                .socketTextStream(&amp;#34;localhost&amp;#34;, 9999)
                .flatMap(new Splitter()) //将Sentence转化为Collector流
                .keyBy(0) //将Collector中的Tuple2按照word排序
                .timeWindow(Time.seconds(5))
                .sum(1); //进行求和操作

        dataStream.print();

        env.execute(&amp;#34;Window WordCount&amp;#34;);
    }

    /
     * @function 分词与映射器
     */
    public static class Splitter implements FlatMapFunction&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; {
        @Override
        public void flatMap(String sentence, Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; out) throws Exception {
            for (String word : sentence.split(&amp;#34; &amp;#34;)) {
                //每遇到1个词,将它设置加1
                out.collect(new Tuple2&amp;lt;String, Integer&amp;gt;(word, 1));
            }
        }
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;submit-jobs&#34;&gt;Submit Jobs&lt;/h2&gt;
&lt;h3 id=&#34;command-line-interface&#34;&gt;Command-Line Interface&lt;/h3&gt;
&lt;p&gt;笔者建议可以将 Flink 的命令添加到全局：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export FLINK_HOME=/Users/apple/Desktop/Tools/SDK/Flink/flink-1.0.3
export PATH=$PATH:$FLINK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;完整的参数列表列举如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Run example program with no arguments.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run ./examples/batch/WordCount.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program with arguments for input and result files&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run ./examples/batch/WordCount.jar \
                       file:///home/user/hamlet.txt file:///home/user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program with parallelism 16 and arguments for input and result files&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run -p 16 ./examples/batch/WordCount.jar \
                        file:///home/user/hamlet.txt file:///home/user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program with flink log output disabled&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    ./bin/flink run -q ./examples/batch/WordCount.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program in detached mode&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    ./bin/flink run -d ./examples/batch/WordCount.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program on a specific JobManager:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run -m myJMHost:6123 \
                       ./examples/batch/WordCount.jar \
                       file:///home/user/hamlet.txt file:///home/user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program with a specific class as an entry point:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run -c org.apache.flink.examples.java.wordcount.WordCount \
                       ./examples/batch/WordCount.jar \
                       file:///home/user/hamlet.txt file:///home/user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run example program using a &lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-master/setup/yarn_setup.html#run-a-single-flink-job-on-hadoop-yarn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;per-job YARN cluster&lt;/a&gt; with 2 TaskManagers:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink run -m yarn-cluster -yn 2 \
                       ./examples/batch/WordCount.jar \
                       hdfs:///user/hamlet.txt hdfs:///user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Display the optimized execution plan for the WordCount example program as JSON:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink info ./examples/batch/WordCount.jar \
                        file:///home/user/hamlet.txt file:///home/user/wordcount_out
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;List scheduled and running jobs (including their JobIDs):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;List scheduled jobs (including their JobIDs):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink list -s
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;List running jobs (including their JobIDs):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink list -r
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cancel a job:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink cancel &amp;lt;jobID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop a job (streaming jobs only):&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./bin/flink stop &amp;lt;jobID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;program貌似不可用api-变化了&#34;&gt;Program:貌似不可用，API 变化了&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;try {
    PackagedProgram program = new PackagedProgram(file, args);
    InetSocketAddress jobManagerAddress = RemoteExecutor.getInetFromHostport(&amp;#34;localhost:6123&amp;#34;);
    Configuration config = new Configuration();

    Client client = new Client(jobManagerAddress, config, program.getUserCodeClassLoader());

    // set the parallelism to 10 here
    client.run(program, 10, true);

} catch (ProgramInvocationException e) {
    e.printStackTrace();
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>快速开始</title>
      <link>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedcompute-series/%E6%B5%81%E5%A4%84%E7%90%86/flink/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/</guid>
      <description>&lt;h1 id=&#34;快速开始&#34;&gt;快速开始&lt;/h1&gt;
&lt;h1 id=&#34;环境配置&#34;&gt;环境配置&lt;/h1&gt;
&lt;h2 id=&#34;搭建本地实例&#34;&gt;搭建本地实例&lt;/h2&gt;
&lt;p&gt;Flink 本身可以单独部署，如果你需要读写 HDFS 中的数据，则需要选择对应的 Hadoop 版本了，在初学阶段笔者还是建议单独部署即可，到&lt;a href=&#34;http://flink.apache.org/downloads.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;下载一个编译好的版本，然后直接解压缩即可：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ cd ~/Downloads # Go to download directory
$ tar xzf flink-*.tgz # Unpack the downloaded archive
$ cd flink-1.0.3
$ bin/start-local.sh # Start Flink
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后转到 &lt;a href=&#34;http://localhost:8081/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:8081&lt;/a&gt; 就可以看到一个运行的 JobManager 实例，注意，这里也会提示你存在一个 TaskManager 实例，如下图所示：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.0/page/img/quickstart-setup/jobmanager-1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;运行示例&#34;&gt;运行示例&lt;/h2&gt;
&lt;p&gt;在搭建好了基本的运行环境之后，我们开始测试 &lt;a href=&#34;https://github.com/apache/flink/blob/release-1.0.0/flink-quickstart/flink-quickstart-java/src/main/resources/archetype-resources/src/main/java/SocketTextStreamWordCount.java&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SocketTextStreamWordCount example&lt;/a&gt;，即从 Socket 中读取数据然后统计出独立的单词数目，典型的 WordCounts。&lt;/p&gt;
&lt;p&gt;首先，使用 nc 来启动一个本地的 Server&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ nc -l -p 9000
// mac 下是 nc -l 9000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将任务的 Jar 包提交到 Flink:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ bin/flink run examples/streaming/SocketTextStreamWordCount.jar \
  --hostname localhost \
  --port 9000
Printing result to stdout. Use --output to specify output path.
03/08/2016 17:21:56 Job execution switched to status RUNNING.
03/08/2016 17:21:56 Source: Socket Stream -&amp;gt; Flat Map(1/1) switched to SCHEDULED
03/08/2016 17:21:56 Source: Socket Stream -&amp;gt; Flat Map(1/1) switched to DEPLOYING
03/08/2016 17:21:56 Keyed Aggregation -&amp;gt; Sink: Unnamed(1/1) switched to SCHEDULED
03/08/2016 17:21:56 Keyed Aggregation -&amp;gt; Sink: Unnamed(1/1) switched to DEPLOYING
03/08/2016 17:21:56 Source: Socket Stream -&amp;gt; Flat Map(1/1) switched to RUNNING
03/08/2016 17:21:56 Keyed Aggregation -&amp;gt; Sink: Unnamed(1/1) switched to RUNNING
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;该任务会连接到 Socket 然后等待输入，你可以在 Web 界面中判断任务是否正常运行：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.0/page/img/quickstart-setup/jobmanager-2.png&#34; alt=&#34;JobManager: Overview (cont&amp;amp;rsquo;d&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.0/page/img/quickstart-setup/jobmanager-3.png&#34; alt=&#34;JobManager: Running Job&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在刚才的 nc 终端里输入一些数据&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ nc -l -p 9000
lorem ipsum
ipsum ipsum ipsum
bye
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果会被直接统计出来&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ tail -f log/flink-*-jobmanager-*.out
(lorem,1)
(ipsum,1)
(ipsum,2)
(ipsum,3)
(ipsum,4)
(bye,1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你要停止 Flink 集群&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ bin/stop-local.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.0/page/img/quickstart-setup/setup.gif&#34; alt=&#34;Quickstart: Setu&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

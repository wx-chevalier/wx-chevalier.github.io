<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>特征编码 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/</link>
      <atom:link href="https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/index.xml" rel="self" type="application/rss+xml" />
    <description>特征编码</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>特征编码</title>
      <link>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/</link>
    </image>
    
    <item>
      <title>README.old</title>
      <link>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/readme.old/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/readme.old/</guid>
      <description>&lt;h1 id=&#34;数据变换&#34;&gt;数据变换&lt;/h1&gt;
&lt;p&gt;数据变换包括对数据进行规范化，离散化，稀疏化处理，达到适用于挖掘的目的。&lt;/p&gt;
&lt;h1 id=&#34;规范化处理&#34;&gt;规范化处理&lt;/h1&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/007DFXDhgy1g5urbccl78j30tz0v5q70.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&#34;离散化处理&#34;&gt;离散化处理&lt;/h1&gt;
&lt;p&gt;数据离散化是指将连续的数据进行分段，使其变为一段段离散化的区间。分段的原则有基于等距离、等频率或优化的方法。数据离散化的原因主要有以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;模型需要：比如决策树、朴素贝叶斯等算法，都是基于离散型的数据展开的。如果要使用该类算法，必须将离散型的数据进行。有效的离散化能减小算法的时间和空间开销，提高系统对样本的分类聚类能力和抗噪声能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;离散化的特征相对于连续型特征更易理解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以有效的克服数据中隐藏的缺陷，使模型结果更加稳定。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等频法：使得每个箱中的样本数量相等，例如总样本 n=100，分成 k=5 个箱，则分箱原则是保证落入每个箱的样本量=20。&lt;/p&gt;
&lt;p&gt;等宽法：使得属性的箱宽度相等，例如年龄变量（0-100 之间），可分成 [0,20]，[20,40]，[40,60]，[60,80]，[80,100]五个等宽的箱。&lt;/p&gt;
&lt;p&gt;聚类法：根据聚类出来的簇，每个簇中的数据为一个箱，簇的数量模型给定。&lt;/p&gt;
&lt;h1 id=&#34;稀疏化处理&#34;&gt;稀疏化处理&lt;/h1&gt;
&lt;p&gt;针对离散型且标称变量，无法进行有序的 LabelEncoder 时，通常考虑将变量做 0，1 哑变量的稀疏化处理，例如动物类型变量中含有猫，狗，猪，羊四个不同值，将该变量转换成 is&lt;em&gt;猪，is&lt;/em&gt;猫，is&lt;em&gt;狗，is&lt;/em&gt;羊四个哑变量。若是变量的不同值较多，则根据频数，将出现次数较少的值统一归为一类&amp;rsquo;rare&amp;rsquo;。稀疏化处理既有利于模型快速收敛，又能提升模型的抗噪能力。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TF-IDF</title>
      <link>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/tf-idf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/tf-idf/</guid>
      <description>&lt;h1 id=&#34;tf-idf&#34;&gt;TF-IDF&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>归一化</title>
      <link>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/%E5%BD%92%E4%B8%80%E5%8C%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-series/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81/%E5%BD%92%E4%B8%80%E5%8C%96/</guid>
      <description>&lt;h1 id=&#34;normalization&#34;&gt;Normalization&lt;/h1&gt;
&lt;p&gt;数据标准化(归一化)处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。以下是两种常用的归一化方法：&lt;/p&gt;
&lt;h1 id=&#34;min-max-标准化min-max-normalization&#34;&gt;min-max 标准化(Min-Max Normalization)&lt;/h1&gt;
&lt;p&gt;也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://images.cnitblog.com/blog/407700/201307/31105200-6bd5002661114e40ba1ee5d7d3377015.gif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://images.cnitblog.com/blog/407700/201307/31105200-fa4ecf7c8f7f4960a1cc47c349979c45.gif&#34; alt=&#34;clip_image002&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中 max 为样本数据的最大值，min 为样本数据的最小值。这种方法有个缺陷就是当有新数据加入时，可能导致 max 和 min 的变化，需要重新定义。&lt;/p&gt;
&lt;h1 id=&#34;z-score-标准化方法&#34;&gt;Z-score 标准化方法&lt;/h1&gt;
&lt;p&gt;这种方法给予原始数据的均值(mean)和标准差(standard deviation)进行数据的标准化。经过处理的数据符合标准正态分布，即均值为 0，标准差为 1，转化函数为：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://images.cnitblog.com/blog/407700/201307/31105201-a6fe07c7a6764af0ac554988a3468917.gif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://images.cnitblog.com/blog/407700/201307/31105201-fa88e179a3ed46e99372f1804a914c4f.gif&#34; alt=&#34;clip_image004&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;a href=&#34;http://images.cnitblog.com/blog/407700/201307/31105201-9d0fa14ece1946f38e3888c5549eb5d9.gif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://images.cnitblog.com/blog/407700/201307/31105201-d56ab5212c974bc7816b147c6051f54f.gif&#34; alt=&#34;clip_image006&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/a&gt;为所有样本数据的均值，&lt;a href=&#34;http://images.cnitblog.com/blog/407700/201307/31105202-75fa8d217dcb462d81166b034ba7b400.gif&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://images.cnitblog.com/blog/407700/201307/31105202-56805481fe2f4c10804c5c5d83be27b1.gif&#34; alt=&#34;clip_image008&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/a&gt;为所有样本数据的标准差。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>程序指标 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/</link><atom:link href="https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/index.xml" rel="self" type="application/rss+xml"/><description>程序指标</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>程序指标</title><link>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/</link></image><item><title>服务吞吐量</title><link>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E6%9C%8D%E5%8A%A1%E5%90%9E%E5%90%90%E9%87%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E6%9C%8D%E5%8A%A1%E5%90%9E%E5%90%90%E9%87%8F/</guid><description>&lt;h1 id="吞吐量">吞吐量&lt;/h1>
&lt;p>流量指标可以指系统层面的网络和磁盘 IO，服务层面的 QpS、PV 和 UV 等数据。流量和突增或突减都可能预示着系统可能出现问题（攻击事件、系统故障等）。以下为流量主要关注的方面：&lt;/p>
&lt;ul>
&lt;li>基础监控：磁盘和网卡 IO；&lt;/li>
&lt;li>业务监控：核心功能流量，例如通过 QpS/PV/UV 等通常能够代表 Web 服务的流量，而 ElasticSearch 的流量可用索引创建速率、搜索速率表示。&lt;/li>
&lt;/ul>
&lt;p>我们通常说的网站流量(traffic)就是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的网页数量等指标，常用的统计指标包括网站的独立用户数量、总用户数量(含重复访问者)、网页浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。&lt;/p>
&lt;p>网站访问量的衡量标准一个是 IP，另一个是 PV，常以日为标准,即日独立 IP 和 PV 来计算.&lt;/p>
&lt;ul>
&lt;li>访问数(IP)：即 Internet Protocol,指独立 IP 数。00:00-24:00 内相同 IP 地址只被计算一次。&lt;/li>
&lt;li>综合浏览量(PV)：即 Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次。&lt;/li>
&lt;/ul>
&lt;p>二者的联系与区别：PV 高不一定代表来访者多；PV 与来访者的数量成正比，但是 PV 并不直接决定页面的真实来访者数量。比如一个网站就你一个人进来，通过不断的刷新页面，也可以制造出非常高的 PV。IP 是一个反映网络虚拟地址对象的概念，独立用户是一个反映实际使用者的概念，每个独立用户相对于每个 IP，更加准确地对应一个实际的浏览者。使用独立用户作为统计量，可以更加准确的了解单位时间内实际上有多少个访问者来到了相应的页面。&lt;/p>
&lt;p>一个独立 IP 可以产生多个 PV,所以 PV 个数&amp;gt;=IP 个数。&lt;/p>
&lt;ul>
&lt;li>PV(Page View)值：是指一定时间范围内所有浏览该网站的访问者请求的页面数量之合。(例如：该网站一天有 500 个访问者，每个访问者浏览的页面数量平均为 8 页，则每天的 PV 是 500×8=4000)&lt;/li>
&lt;li>Hits 值：是指对每个页面元素的请求数量。(一个页面中任何一个图片或者 flash 文件都算是一个页面元素)&lt;/li>
&lt;li>日浏览字节数：即日流量，是指一天内，访问者请求的所有页面元素的字节数之和。&lt;/li>
&lt;/ul>
&lt;h1 id="访问量指标">访问量指标&lt;/h1>
&lt;ul>
&lt;li>PV 即 page view，页面浏览量 用户每一次对网站中的每个页面访问均被记录 1 次。用户对同一页面的多次刷新，访问量累计。&lt;/li>
&lt;li>UV 即 Unique visitor，独立访客 通过客户端的 cookies 实现。即同一页面，客户端多次点击只计算一次，访问量不累计。&lt;/li>
&lt;li>IP 即 Internet Protocol，本意本是指网络协议，在数据统计这块指通过 ip 的访问量。即同一页面，客户端使用同一个 IP 访问多次只计算一次，访问量不累计。&lt;/li>
&lt;/ul>
&lt;h1 id="qps--tps--rps">QPS &amp;amp; TPS &amp;amp; RPS&lt;/h1>
&lt;p>TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS 包括一条消息入和一条消息出，加上一次用户数据库访问。（业务 TPS = CAPS × 每个呼叫平均 TPS）。TPS 是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的 TPS 值。&lt;/p>
&lt;p>QPS：每秒查询率 QPS 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。&lt;/p>
&lt;p>对应 fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。&lt;/p>
&lt;ul>
&lt;li>并发连接数（The number of concurrent connections）：某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。&lt;/li>
&lt;li>并发用户数（The number of concurrent users，Concurrency Level）：要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。&lt;/li>
&lt;/ul>
&lt;p>QPS(Queries Per Second)每秒能处理查询数目。是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。QPS 是每秒钟处理完请求的次数。这里的请求不是指一个查询或者数据库查询，是包括一个业务逻辑的整个流程，也就是说每秒钟响应的请求次数。&lt;/p>
&lt;p>TPS(Transactions Per Second)指每秒处理的事务数目；事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。TPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端，客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。&lt;/p>
&lt;p>RPS(Requests Per Second) | 吞吐率: 服务器并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。&lt;/p>
&lt;h1 id="饱和度">饱和度&lt;/h1>
&lt;p>饱和度可以理解为服务的利用率，可以代表系统承受的压力。所以饱和度与流量息息相关，流量的上升一般也会导致饱和度的上升。通常情况下，每种业务系统都应该有各自的饱和度指标。在很多业务系统中，消息队列长度是一个比较重要的饱和度指标，除此之外 CPU、内存、磁盘、网络等系统资源利用率也可以作为饱和度的一种体现方式。&lt;/p>
&lt;p>基础监控自然包含 CPU、内存、磁盘和网络利用率、内存堆栈利用率、文件句柄数、TCP 连接数等；业务监控：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>基础功能单元使用率，大多数系统对其基础的功能单元都有其处理能力的上限，接近或达到该上限时可能会导致服务的错误、延迟增大。例如 HDFS 的 Block 数量上升会导致 NameNode 堆内存使用率上升，Kafka 的 Topics 和 Partitions 的数量、Zookeeper 的 node 数的上升都会对系统产生压力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>消息队列长度，不少系统采用消息队列存放待处理数据，所以消息队列长度在一定程度上可以代表系统的繁忙程度。如 ElasticSearch、HDFS 等都有队列长度相关指标可供采集。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="links">Links&lt;/h1></description></item><item><title>响应时延</title><link>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E5%93%8D%E5%BA%94%E6%97%B6%E5%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E5%93%8D%E5%BA%94%E6%97%B6%E5%BB%B6/</guid><description>&lt;h1 id="延迟与响应指标">延迟与响应指标&lt;/h1>
&lt;h1 id="延迟">延迟&lt;/h1>
&lt;p>延迟（latency）和 响应时间（response time）经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（服务时间（service time））之外，还包括网络延迟和排队延迟。延迟是某个请求等待处理的持续时长，在此期间它处于 休眠（latent）状态，并等待服务。从客户端来看，延迟就是从发送请求到接收响应的整体耗时，包括：请求的网络耗时，请求在服务端的处理耗时以及响应的网络耗时。吞吐量则是服务在一定的并发下，每秒可以处理的请求数。服务延迟的上升不仅仅体现在用户体验的下降，也有可能会导致请求堆积并最终演变为整个业务系统的雪崩。以下为延迟指标的主要关注点：&lt;/p>
&lt;ul>
&lt;li>基础监控：IO 等待、网络延迟；&lt;/li>
&lt;li>业务监控：业务相关指标主要需要关注核心功能的响应时长。比如 Zookeeper 的延迟指标 zk_avg_latency，ElasticSearch 的索引、搜索延迟和慢查询。&lt;/li>
&lt;/ul>
&lt;p>与错误指标类似，白盒延迟指标通常仅能代表系统内部延迟，建议为主要功能或接口添加黑盒监控来采集端到端的延迟指标。&lt;/p>
&lt;h2 id="中位数">中位数&lt;/h2>
&lt;p>每个灰条表代表一次对服务的请求，其高度表示请求花费了多长时间。大多数请求是相当快的，但偶尔会出现需要更长的时间的异常值。这也许是因为缓慢的请求实质上开销更大，例如它们可能会处理更多的数据。但即使（你认为）所有请求都花费相同时间的情况下，随机的附加延迟也会导致结果变化，例如：上下文切换到后台进程，网络数据包丢失与 TCP 重传，垃圾收集暂停，强制从磁盘读取的页面错误，服务器机架中的震动等。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/02/1tgSAA.md.png" alt="展示了一个服务100次请求响应时间的均值与百分位数" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>通常报表都会展示服务的平均响应时间，但平均值并不是一个非常好的指标，因为它不能告诉你有多少用户实际上经历了这个延迟。通常使用百分位点（percentiles）会更好。如果将响应时间列表按最快到最慢排序，那么中位数（median）就在正中间：举个例子，如果你的响应时间中位数是 200 毫秒，这意味着一半请求的返回时间少于 200 毫秒，另一半比这个要长。&lt;/p>
&lt;p>如果想知道典型场景下用户需要等待多长时间，那么中位数是一个好的度量标准：一半用户请求的响应时间少于响应时间的中位数，另一半服务时间比中位数长。中位数也被称为第 50 百分位点，有时缩写为 p50。注意中位数是关于单个请求的；如果用户同时发出几个请求（在一个会话过程中，或者由于一个页面中包含了多个资源），则至少一个请求比中位数慢的概率远大于 50％。&lt;/p>
&lt;h2 id="百分点位">百分点位&lt;/h2>
&lt;p>为了弄清异常值有多糟糕，可以看看更高的百分位点，例如第 95、99 和 99.9 百分位点（缩写为 p95，p99 和 p999）。它们意味着 95％，99％或 99.9％的请求响应时间要比该阈值快，例如：如果第 95 百分位点响应时间是 1.5 秒，则意味着 100 个请求中的 95 个响应时间快于 1.5 秒，而 100 个请求中的 5 个响应时间超过 1.5 秒。&lt;/p>
&lt;p>响应时间的高百分位点（也称为尾部延迟（tail latencies））非常重要，因为它们直接影响用户的服务体验。例如亚马逊在描述内部服务的响应时间要求时以 99.9 百分位点为准，即使它只影响一千个请求中的一个。另一方面，优化第 99.99 百分位点（一万个请求中最慢的一个）被认为太昂贵了，不能为亚马逊的目标带来足够好处。减小高百分位点处的响应时间相当困难，因为它很容易受到随机事件的影响，这超出了控制范围，而且效益也很小。&lt;/p>
&lt;p>百分位点通常用于服务级别目标（SLO, service level objectives）和服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同 SLA 可能会声明，如果服务响应时间的中位数小于 200 毫秒，且 99.9 百分位点低于 1 秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在 SLA 未达标的情况下要求退款。&lt;/p>
&lt;p>排队延迟（queueing delay）通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 头部阻塞（head-of-line blocking）。即使后续请求在服务器上处理的非常迅速，由于需要等待先前请求完成，客户端最终看到的是缓慢的总体响应时间。因为存在这种效应，测量客户端的响应时间非常重要。&lt;/p>
&lt;p>为测试系统的可扩展性而人为产生负载时，产生负载的客户端要独立于响应时间不断发送请求。如果客户端在发送下一个请求之前等待先前的请求完成，这种行为会产生人为排队的效果，使得测试时的队列比现实情况更短，使测量结果产生偏差。&lt;/p>
&lt;h2 id="微服务中的百分点位">微服务中的百分点位&lt;/h2>
&lt;p>在多重调用的后端服务里，高百分位数变得特别重要。即使并行调用，最终用户请求仍然需要等待最慢的并行调用完成。如下图所示，只需要一个缓慢的调用就可以使整个最终用户请求变慢。即使只有一小部分后端调用速度较慢，如果最终用户请求需要多个后端调用，则获得较慢调用的机会也会增加，因此较高比例的最终用户请求速度会变慢（效果称为尾部延迟放大）。&lt;/p>
&lt;p>如果您想将响应时间百分点添加到您的服务的监视仪表板，则需要持续有效地计算它们。例如，您可能希望在最近 10 分钟内保持请求响应时间的滚动窗口。每一分钟，您都会计算出该窗口中的中值和各种百分数，并将这些度量值绘制在图上。&lt;/p>
&lt;p>简单的实现是在时间窗口内保存所有请求的响应时间列表，并且每分钟对列表进行排序。如果对你来说效率太低，那么有一些算法能够以最小的 CPU 和内存成本（如前向衰减，t-digest 或 HdrHistogram）来计算百分位数的近似值。请注意，平均百分比（例如，减少时间分辨率或合并来自多台机器的数据）在数学上没有意义 - 聚合响应时间数据的正确方法是添加直方图。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/02/1t2VxK.md.png" alt="当一个请求需要多个后端请求时，单个后端慢请求就会拖慢整个终端用户的请求" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="rt--响应时间">RT | 响应时间&lt;/h1>
&lt;p>响应时间即 RT，处理一次请求所需要的平均处理时间。对于 RT，客户端和服务端是大不相同的，因为请求从客户端到服务端，需要经过广域网，所以客户端 RT 往往远大于服务端 RT，同时客户端的 RT 往往决定着用户的真实体验，服务端 RT 往往是评估我们系统好坏的一个关键因素。&lt;/p>
&lt;p>假设我们的服务端只有一个线程，那么所有的请求都是串行执行，我们可以很简单的算出系统的 QPS，也就是：QPS = 1000ms/RT。假设一个 RT 过程中 CPU 计算的时间为 49ms，CPU Wait Time 为 200ms，那么 QPS 就为 1000/49+200 = 4.01。CPU Time 就是一次请求中，实际用到计算资源。CPU Time 的消耗是全流程的，涉及到请求到应用服务器，再从应用服务器返回的全过程。实际上这取决于你的计算的复杂度。&lt;/p>
&lt;p>CPU Wait Time 是一次请求过程中对于 IO 的操作，CPU 这段时间可以理解为空闲的，那么此时要尽量利用这些空闲时间，也就是增加线程数。CPU 利用率是业务系统利用到 CPU 的比率，因为往往一个系统上会有一些其他的线程，这些线程会和 CPU 竞争计算资源，那么此时留给业务的计算资源比例就会下降，典型的像，GC 线程的 GC 过程、锁的竞争过程都是消耗 CPU 的过程。甚至一些 IO 的瓶颈，也会导致 CPU 利用率下降(CPU 都在 Wait IO，利用率当然不高)。&lt;/p>
&lt;p>用户平均请求等待时间（Time per request）计算公式：处理完成所有请求数所花费的时间/（总请求数 / 并发用户数），即
Time per request = Time taken for tests /（Complete requests / Concurrency Level）&lt;/p>
&lt;p>服务器平均请求等待时间（Time per request: across all concurrent requests），计算公式：处理完成所有请求数所花费的时间 / 总请求数，即 Time taken for / testsComplete requests 可以看到，它是吞吐率的倒数。同时，它也等于用户平均请求等待时间/并发用户数，即 Time per request / Concurrency Level&lt;/p></description></item><item><title>应用</title><link>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E5%BA%94%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/devops-notes/03.%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87/%E7%A8%8B%E5%BA%8F%E6%8C%87%E6%A0%87/%E5%BA%94%E7%94%A8/</guid><description>&lt;h1 id="应用性能监控">应用性能监控&lt;/h1>
&lt;h1 id="java">Java&lt;/h1>
&lt;blockquote>
&lt;p>本部分参阅 &lt;a href="https://github.com/wx-chevalier/Java-Notes" target="_blank" rel="noopener">Java 应用性能监控&lt;/a>一节。&lt;/p>
&lt;/blockquote></description></item></channel></rss>
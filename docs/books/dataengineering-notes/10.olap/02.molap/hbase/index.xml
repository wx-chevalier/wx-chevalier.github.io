<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HBase | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/</link>
      <atom:link href="https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/index.xml" rel="self" type="application/rss+xml" />
    <description>HBase</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>HBase</title>
      <link>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/</link>
    </image>
    
    <item>
      <title>CRUD</title>
      <link>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/crud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/crud/</guid>
      <description>&lt;h1 id=&#34;filter&#34;&gt;Filter&lt;/h1&gt;
&lt;p&gt;基础 API 中的查询操作在面对大量数据的时候是非常苍白的，这里 Hbase 提供了高级的查询方法：Filter。Filter 可以根据簇、列、版本等更多的条件来对数据进行过滤，基于 Hbase 本身提供的三维有序(主键有序、列有序、版本有序)，这些 Filter 可以高效的完成查询过滤的任务。带有 Filter 条件的 RPC 查询请求会把 Filter 分发到各个 RegionServer，是一个服务器端(Server-side )的过滤器，这样也可以降低网络传输的压力。要完成一个过滤的操作，至少需要两个参数。一个是抽象的操作符，Hbase 提供了枚举类型的变量来表示这些抽象的操作符：LESS/LESS_OR_EQUAL/EQUAL/NOT_EUQAL 等；另外一个就是具体的比较器(Comparator )，代表具体的比较逻辑，如果可以提高字节级的比较、字符串级的比较等。有了这两个参数，我们就可以清晰的定义筛选的条件，过滤数据。CompareFilter ( CompareOp compareOp，WritableByteArrayComparable valueComparator )&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; CompareFilter是高层的抽象类，下面我们将看到它的实现类和实现类代表的各种过滤条件。这里实现类实际上代表的是参数中的过滤器过滤的内容，可以使主键、簇名、列值等，这就是由CompareFilter决定了。
行过滤器(RowFilter)
行过滤器的比较对象是行主键
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Scan scan = new Scan(); Filter filter1 = new RowFilter(CompareFIlter.CompareOp.LESS_OR_EUQAL, new BinaryComparator(Bytes.toBytes(&amp;ldquo;hello&amp;rdquo;))); scan.setFilter(filter1); scan.close();&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;例中的Filter会将所有的小于等于“Hello”的主键过滤出来。
簇过滤器(FamilyFilter)
簇过滤器过滤的是簇的名字。
列过滤器(QualifierFilter)
列过滤器过滤的是列的名字。
值过滤器(ValueFilter)
值过滤器过滤的是扫描对象的值。
单值过滤器(SingleColumnValueFilter)
单值过滤器是以特定列的值为过滤内容，与值过滤器不同的是，这里是特定的列，而值过滤器比较的是行内的所有列。所有在使用单值过滤器的时候要指定比较的列的坐标。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;SingleColumnValueFilter(byte[] family, byte[] qualifier, CompareOp compareOp, WritableByteArrayComparable comparator)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;对于找不到该列的行，可以有特殊的处理
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;void setFilterIfMissing(boolean filterIfMissing)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;默认缺省行将被包含进过滤的结果集中。
前缀过滤器(PrefixFilter)
前缀过滤器将会过滤掉不匹配的记录，过滤的对象是主键的值。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PrefixFilter(byte[] prefix)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 页过滤器(PageFilter)
页过滤器可以根据主键有序返回固定数量的记录，这需要客户端在遍历的时候记住页开始的地方，配合scan的startkey一起使用。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PageFilter(int size)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 键过滤器(KeyOnlyFilter)
键过滤器可以简单的设置过滤的结果集中只包含键而忽略值，这里有一个选项可以把结果集的值保存为值的长度。
FirstKeyOnlyFilter
在键过滤器的基础上，根据列有序，只包含第一个满足的键。
ColumnPrefixFilter
这里过滤的对象是列的值。
TimestampsFilter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;TimestampsFilter(List&lt;Long&gt; times)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这里参数是一个集合，只有包含在集合中的版本才会包含在结果集中。
包装类过滤器，此类过滤器要通过包装其他的过滤器才有意义，是其他过滤器的一种加强。
SkipFilter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;SkipFilter(Filter filter)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;过滤器集合(FilterList)
Hbase的过滤器设计遵照于设计模式中的组合模式，以上的所有过滤器都可以叠加起来共同作用于一次查询。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;计数器&#34;&gt;计数器&lt;/h2&gt;
&lt;p&gt;Hbase 提供一个计数器工具可以方便快速的进行计数的操作，而免去了加锁等保证原子性的操作。但是实质上，计数器还是列，有自己的簇和列名。值得注意的是，维护计数器的值最好是用 Hbase 提供的 API，直接操作更新很容易引起数据的混乱。计数器的增量可以是正数负数，正数代表加，负数代表减。&lt;/p&gt;
&lt;p&gt;long icrementColumnValue(byte[] row, byte[] famuly, byte[] qualifier, long amount) Result increment(Increment increment)&lt;/p&gt;
&lt;h2 id=&#34;协处理器coprocessor-&#34;&gt;协处理器(Coprocessor )&lt;/h2&gt;
&lt;p&gt;协处理器的思想是把处理的复杂代码分发到各个 RegionServer，使大部分的计算可以在服务器端，或者扫描的时候完成，提高处理的效率。形式上比较类似 RDBMS 中的存储过程，不同的是，存储过程的原理是在服务器端进行预处理等优化，而协处理器仅仅只是服务器处理，这里又有点类似于 Map-Reduce 中的 Map 阶段。协处理器 (Coprocesssor) 有两种，一种是观察者(Obsever )另外一种是 Endpoint(LZ 跪了，实在不知道翻译成啥)。每个协处理器都有一个优先级，优先级分为 USER/SYSTEM，优先级决定处理器的执行顺序，SYSTEM 级别的处理器永远先于 USER。每个处理器都有自己的执行环境 (CoprocessorEnvironment)，这个环境包含当前集群和请求的状态等信息，是处理中重要的一部分，以构造函数参数的形式被传入到处理器。另外就是 CoprocessorHost，这是 Hbase 管理协处理器的类，用来维护所有的处理器和其环境。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;协处理器的加载有两种方式，一种是通过配置文件，在配置文件中指定加载路径、类名等，通过这种方式加载的处理器都是SYSTEM级别的，会作用于所有的请求，所有的表；另一种方式是通过在创建表的时候在表中指定，这种方式既可以创建全局的SYSTEM级别的处理器，也可以创建USER级别的处理器，USER级别的处理器是针对表的。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Path path = new Paht(&amp;ldquo;test.jar&amp;rdquo;); HTableDescriptor htd = new HTableDescriptor(&amp;ldquo;test&amp;rdquo;); htd.addFamily(new HColumnDescriptor(&amp;ldquo;family1&amp;rdquo;)); htd.setValue(&amp;ldquo;Coprocessor$1&amp;rdquo;, path.toString + &amp;ldquo;|&amp;rdquo; + className + &amp;ldquo;|&amp;rdquo; + Coprocessor.Priority.USER); HBaseAdmin admin = new HBaseAdmin(conf); admin.createTable(htd);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这里setValue方法有两个参数，第一个参数是协处理器的名字，$后面跟的是影响执行顺序的序号；第二个参数是&amp;lt;path&amp;gt;|&amp;lt;classname&amp;gt;|&amp;lt;priority&amp;gt;。
Observer
这是第一种处理器，观察者，观察者有三种，分别用来监听RegionServerObserver、MasterServerObserver、WALObserver。
RegionServer监听的是Region Server上的操作，如在Region Server上的Get、Put等。操作被赋予生命周期：Pending open--open--Pending close
监听器是可以监听生命周期中的各个阶段，并对其做出处理。
每一个监听的方法都有一个上下文参数(Context)，通过Context参数可以直接的操作请求的声明周期。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;void bypass(); void complete(); MasterObserver 监听的是 Master Server 上的操作，有点类似 RDBMS 中的 DDL 的操作如表操作、列操作等。具体的操作和 RegionServer 比较类似。Endpoint 这是第二种处理器，Endpoint 相当于被分发到各个 RegionServer 上的存储过程，可以在客户端远程调用的方法。Endpoint 的存在使我们可以进行一些服务器端的计算，如服务器聚集、求和等运算，弥补了查询 API 的不足。服务器端计算的优势是显而易见的，它可以降低网络传输的数据量，合理利用服务器资源。从功能上可以看出 Endpoint 是一个基于 RPC 调用的模块，所以在实现自己的 Endpoint 时候需要定义我们自己的通信协议。在 Hbase 中，通信协议被抽象为 CoprocessorProtocol 接口，要实现我们的协议，我们要创建协议接口继承自 CoprocessorProtocol 接口，然后再实现我们的协议类。&lt;br&gt;
public interface MyProtocol extends CoprocessorProtocol { public int work(); } 协议类本身也是处理器，所以还要继承 BaseEndpointCoprocessor 类。&lt;/p&gt;
&lt;p&gt;public class MyEndpoint extends BaseEndpointCoprocessor implements MyProtocol { public int work() { Sytem.out.println(&amp;ldquo;hello&amp;rdquo;); } } 在抽象的父类 BaseEndpointCoprocessor 中还提供了一些有用的方法，如我们可以拿到对应的环境类。&lt;br&gt;
RegionCoprocessorEnvironment getEnvironment()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;配置好Endpoint重启集群环境以后，我们的实现类会被分发到各个RegionServer，通过HTable实例的方法我们可以调用到Endpoint。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;lt;T extends CoprocessorProtocol, R&amp;gt; Map&amp;lt;byte[], R&amp;gt; coprocessorExec(Class&lt;T&gt; protocol, byte[] startKey, byte[] endKey, Batch.Call&amp;lt;T, R&amp;gt; callable);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;startKey和endKey用于确定哪些RegionServer将执行Endpoint，Batch中的内部类将决定协议中方法的调用。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;四、HTablePool 连接池 在 Hbase 中，创建一个代表表的 HTable 实例是一个耗时且很占资源的操作，类似操作数据库，我们也需要建立我们自己的连接池，于是有了代表连接池的抽象类：HTable。&lt;/p&gt;
&lt;p&gt;HTablePool(Configuaration conf, int maxSize) HTablePool(Configuaration conf, int maxSize, HTableInterfaceFactory factory)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 创建HTable需要配置文件的实例，连接池的最大连接数也在构造方法中设置。另外，如果想要自己控制HTable被创建的过程，则需要实现自己的工厂方法。在连接池中，最大连接数(maxSize)的含义是，连接池管理的最大的连接数，当所需要的连接数超过最大值时，会临时的创建连接来满足需求，但是这些连接在使用完毕之后会被直接释放且丢弃而不会进入连接池被管理，所以最大连接数代表的是连接池中最大被管理的连接数，而不是使用连接池最大可使用的连接数。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HTableInterface getTable(String tableName) HTableInterface getTable(byte[] tableName) void putTable(HTableInterface table)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 需要注意的是，使用完连接以后需要手动的调用putTable方法将连接放回池中。
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>部署与使用</title>
      <link>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Hbase 是运行在 Hadoop 上的 NoSQL 数据库，它是一个分布式的和可扩展的大数据仓库，也就是说 HBase 能够利用 HDFS 的分布式处理模式，并 从 Hadoop 的 MapReduce 程序模型中获益。这意味着在一组商业硬件上存储许多具有数十亿行和上百万列的大表。除去 Hadoop 的优 势，HBase 本身就是十分强大的数据库，它能够融合 key/value 存储模式带来实时查询的能力，以及通过 MapReduce 进行离线处理或者批处理 的能力。总的来说，Hbase 能够让你在大量的数据中查询记录，也可以从中获得综合分析报告。HBase 的发展历史进程简介如下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2006.11 G release paper on BigTable&lt;/li&gt;
&lt;li&gt;2007.2 inital HBase prototype created as Hadoop contrib&lt;/li&gt;
&lt;li&gt;2007.10 First useable Hbase&lt;/li&gt;
&lt;li&gt;2008.1 Hadoop become Apache top-level project and Hbase becomes subproject&lt;/li&gt;
&lt;li&gt;2008.10 Hbase 0.18,0.19 released&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HBase 中的表一般有如下特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大：一个表可以有上亿行，上百万列&lt;/li&gt;
&lt;li&gt;面向列 : 面向列 ( 族 ) 的存储和权限控制，列 ( 族 ) 独立检索。&lt;/li&gt;
&lt;li&gt;稀疏 : 对于为空 (null) 的列，并不占用存储空间，因此，表可以设计的非常稀疏。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;logical-view-逻辑视图&#34;&gt;Logical View: 逻辑视图&lt;/h2&gt;
&lt;p&gt;HBase 介于 NoSQL 和 RDBMS 之间，仅能通过主键 (row key) 和主键的 range 来检索数据，仅支持单行事务 ( 可通过 hive 支持来实现多表 join 等复杂操作 )。主要用来存储非结构化和半结构化的松散数据。HBase 实际上定义了一个四维数据模型，下面就是每一维度的定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行键：每行都有唯一的行键，行键没有数据类型，它内部被认为是一个字节数组。&lt;/li&gt;
&lt;li&gt;列簇：数据在行中被组织成列簇，每行有相同的列簇，但是在行之间，相同的列簇不需要有相同的列修饰符。在引擎中，HBase 将列簇存储在它自己的数据文件中，所以，它们需要事先被定义，此外，改变列簇并不容易。&lt;/li&gt;
&lt;li&gt;列修饰符：列簇定义真实的列，被称之为列修饰符，你可以认为列修饰符就是列本身。&lt;/li&gt;
&lt;li&gt;版本：每列都可以有一个可配置的版本数量，你可以通过列修饰符的制定版本获取数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://jbcdn2.b0.upaiyun.com/2015/01/6cca4d757d9b5e1e0d40cd07b679d6e3.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt; 如上图所示，通过行键获取一个指定的行，它由一个或多个列簇构成，每个列簇有一个或多个列修饰符(也被称为列)，每列又可以有一个或多个版本。为了获取指定数据，你 需要知道它的行键、列簇、列修饰符以及版本。当设计 HBase 数据模型时，对考虑数据是如何被获取是十分有帮助的。你可以通过以下两种方式获得 HBase 数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过他们的行键，或者一系列行键的表扫描。&lt;/li&gt;
&lt;li&gt;使用 map-reduce 进行批操作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://www.uml.org.cn/zjjs/images/2012111322.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;row-key&#34;&gt;Row Key&lt;/h3&gt;
&lt;p&gt;Row key 行键 (Row key) 可以是任意字符串 ( 最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在 hbase 内部，row key 保存为字节数组。存储时，数据按照 Row key 的字典序 (byte order) 排序存储。设计 key 时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。( 位置相关性 ) 注意：字典序对 int 排序的结果是 1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。要保持整形的自然序，行键必须用 0 作左填充。行的一次读写是原子操作 ( 不论一次读写多少列 )。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。&lt;/p&gt;
&lt;h3 id=&#34;列簇&#34;&gt;列簇&lt;/h3&gt;
&lt;p&gt;HBase 表中的每个列，都归属与某个列簇。列簇是表的 Schema 的一部分 ( 而列不是 )，必须在使用表之前定义。列名都以列簇作为前缀。例如 courses:history，courses:math 都属于 courses 这个列簇。访问控制、磁盘和内存的使用统计都是在列簇层面进行的。实际应用中，列簇上的控制权限能帮助我们管理不同类型的应用：我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据(甚至可能因为隐私的原因不能浏览所有数据)。&lt;/p&gt;
&lt;h3 id=&#34;时间戳&#34;&gt;时间戳&lt;/h3&gt;
&lt;p&gt;HBase 中通过 row 和 columns 确定的为一个存贮单元称为 cell。每个 cell 都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64 位整型。时间戳可以由 hbase( 在数据写入时自动 ) 赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个 cell 中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理 ( 包括存贮和索引 ) 负担，hbase 提供了两种数据版本回收方式。一是保存数据的最后 n 个版本，二是保存最近一段时间内的版本(比如最近七天)。用户可以针对每个列族进行设置。&lt;/p&gt;
&lt;h3 id=&#34;cell&#34;&gt;Cell&lt;/h3&gt;
&lt;p&gt;由 {row key, column(= + ), version} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。&lt;/p&gt;
&lt;h1 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h1&gt;
&lt;h2 id=&#34;installation-安装&#34;&gt;Installation: 安装&lt;/h2&gt;
&lt;p&gt;让我们开始用命令行操作 HBase，在 HBase bin 目录下执行下面命令：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;./hbase shell
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;你应该看到如下类似的输出：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;HBase Shell; enter &amp;#39;help&amp;lt;RETURN&amp;gt;&amp;#39; for list of supported commands.
Type &amp;#34;exit&amp;lt;RETURN&amp;gt;&amp;#34; to leave the HBase Shell
Version 0.98.5-hadoop2, rUnknown, Mon Aug  4 23:58:06 PDT 2014
hbase(main):001:0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;表创建&#34;&gt;表创建&lt;/h2&gt;
&lt;p&gt;创建一个名为 PageViews 的表，并具有名为 info 的列簇：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):002:0&amp;gt; create &amp;#39;PageViews&amp;#39;, &amp;#39;info&amp;#39;
0 row(s) in 5.3160 seconds
=&amp;gt; Hbase::Table - PageViews
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每张表至少要有一个列簇，因此我们创建了 info，现在，看看我们的表，执行下面 list 命令：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):002:0&amp;gt; list

TABLE

PageViews

1 row(s) in 0.0350 seconds

=&amp;gt; [&amp;#34;PageViews&amp;#34;]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如你所见，list 命令返回一个名为 PageViews 的表，我们可以通过 describe 命令得到表的更多信息：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):003:0&amp;gt; describe &amp;#39;PageViews&amp;#39;

DESCRIPTION                                                                                                                                         ENABLED

&amp;#39;PageViews&amp;#39;, {NAME =&amp;gt; &amp;#39;info&amp;#39;, DATA_BLOCK_ENCODING =&amp;gt; &amp;#39;NONE&amp;#39;, BLOOMFILTER =&amp;gt; &amp;#39;ROW&amp;#39;,

REPLICATION_SCOPE =&amp;gt; &amp;#39;0&amp;#39;, VERSIONS =&amp;gt; &amp;#39;1&amp;#39;, COMPRESSION =&amp;gt; &amp;#39;NONE true

&amp;#39;, MIN_VERSIONS =&amp;gt; &amp;#39;0&amp;#39;, TTL =&amp;gt; &amp;#39;FOREVER&amp;#39;, KEEP_DELETED_CELLS =&amp;gt; &amp;#39;false&amp;#39;,

BLOCKSIZE =&amp;gt; &amp;#39;65536&amp;#39;, IN_MEMORY =&amp;gt; &amp;#39;false&amp;#39;, BLOCKCACHE =&amp;gt; &amp;#39;true&amp;#39;}

1 row(s) in 0.0480 seconds
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Describe 命令返回表的详细信息，包括列簇的列表，这里我们创建的仅有一个：info。&lt;/p&gt;
&lt;h2 id=&#34;数据插入&#34;&gt;数据插入&lt;/h2&gt;
&lt;p&gt;现在为表添加以下数据，下面命令是在 info 中添加新的行：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):004:0&amp;amp;gt; put &amp;#34;;PageViews&amp;#34;, &amp;#34;;rowkey1&amp;#34;, &amp;#34;;info:page&amp;#34;, &amp;#34;;/mypage&amp;#34;
0 row(s) in 0.0850 seconds
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Put 命令插入一条行键为 rowkey1 的新纪录，指定在 info 下的 page 列，插入值为 /mypage 的记录，我们随后可以通过 get 命令通过行键 rowkey1 查询到这条记录：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):005:0&amp;gt; get &amp;#39;PageViews&amp;#39;, &amp;#39;rowkey1&amp;#39;

COLUMN                                                     CELL

 info:page                                                 timestamp=1410374788088, value=/mypage

1 row(s) in 0.0250 seconds
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;数据查询&#34;&gt;数据查询&lt;/h2&gt;
&lt;p&gt;让我们查询出 PageViews 表的所有记录：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):007:0&amp;gt; scan &amp;#39;PageViews&amp;#39;

ROW                                                        COLUMN+CELL

 rowkey1                                                   column=info:page, timestamp=1410374788088, value=/mypage

 rowkey2                                                   column=info:page, timestamp=1410374823590, value=/myotherpage

2 row(s) in 0.0350 seconds
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如前面所提到的，我们不能查询本身，但是我们可以对表进行 scan 操作，如果你执行 scan table 命令，它会返回表中所有行，这很有可能不是你想要做的。你可以给出行的范围来限制返回的结果，让我们插入一带有 s 开头行键的新记录：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hbase(main):012:0&amp;gt; put &amp;#39;PageViews&amp;#39;, &amp;#39;srowkey2&amp;#39;, &amp;#39;info:page&amp;#39;, &amp;#39;/myotherpage&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在，如果我增加点限制，想查询行键在 r 和 s 之间的记录，可以使用如下结构：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hbase&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;main&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:014:0&amp;gt; scan &lt;span class=&#34;s1&#34;&gt;&amp;#39;PageViews&amp;#39;&lt;/span&gt;, &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;STARTROW&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;, &lt;span class=&#34;nv&#34;&gt;ENDROW&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;s&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ROW                                                        COLUMN+CELL
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rowkey1                                                   &lt;span class=&#34;nv&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;info:page, &lt;span class=&#34;nv&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1410374788088, &lt;span class=&#34;nv&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/mypage
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rowkey2                                                   &lt;span class=&#34;nv&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;info:page, &lt;span class=&#34;nv&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1410374823590, &lt;span class=&#34;nv&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/myotherpage
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; row&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; in 0.0080 seconds
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个 scan 返回了仅有 s 开头的记录，这个类比是基于全行键上的，所以 rowkey1 比 r 大，所有它被返回了。另外，scan 的结果包含了所指范围的 STARTROW，但不包含 ENDROW，注意，ENDROW 不是必须指定的，如果我们执行相同查询只给出了 STARTROW，那么我们会得到行键比 r 大 的所有记录。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hbase&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;main&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:013:0&amp;gt; scan &lt;span class=&#34;s1&#34;&gt;&amp;#39;PageViews&amp;#39;&lt;/span&gt;, &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;STARTROW&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ROW                                                        COLUMN+CELL
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rowkey1                                                   &lt;span class=&#34;nv&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;info:page, &lt;span class=&#34;nv&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1410374788088, &lt;span class=&#34;nv&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/mypage
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rowkey2                                                   &lt;span class=&#34;nv&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;info:page, &lt;span class=&#34;nv&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1410374823590, &lt;span class=&#34;nv&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/myotherpage
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;srowkey2                                                  &lt;span class=&#34;nv&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;info:page, &lt;span class=&#34;nv&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1410375975965, &lt;span class=&#34;nv&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/myotherpage
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; row&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;s&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; in 0.0120 seconds
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>架构分析</title>
      <link>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/dataengineering-notes/10.olap/02.molap/hbase/%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      <description>&lt;h1 id=&#34;hbase-architecture&#34;&gt;HBase Architecture&lt;/h1&gt;
&lt;p&gt;HBase 采用 Master/Slave 架构搭建集群，它隶属于 Hadoop 生态系统，由一下类型节点组成：HMaster 节点、HRegionServer 节点、ZooKeeper 集群，而在底层，它将数据存储于 HDFS 中，因而涉及到 HDFS 的 NameNode、DataNode 等，总体结构如下: 
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://www.blogjava.net/images/blogjava_net/dlevin/HBaseArch1.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt; 其中&lt;strong&gt;HMaster 节点&lt;/strong&gt;用于：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;管理HRegionServer，实现其负载均衡。
管理和分配HRegion，比如在HRegion split时分配新的HRegion；在HRegionServer退出时迁移其内的HRegion到其他HRegionServer上。
实现DDL操作(Data Definition
Language，namespace和table的增删改，column
familiy的增删改等)。
管理namespace和table的元数据(实际存储在HDFS上)。
权限控制(ACL)。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;HRegionServer 节点&lt;/strong&gt;用于：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;存放和管理本地HRegion。
读写HDFS，管理Table中的数据。
Client直接通过HRegionServer读写数据(从HMaster中获取元数据，找到RowKey所在的HRegion/HRegionServer后)。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper 集群是协调系统&lt;/strong&gt;，用于：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;存放整个
HBase集群的元数据以及集群的状态信息。
实现HMaster主从节点的failover。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HBase Client 通过 RPC 方式和 HMaster、HRegionServer 通信；一个 HRegionServer 可以存放 1000 个 HRegion；底层 Table 数据存储于 HDFS 中，而 HRegion 所处理的数据尽量和数据所在的 DataNode 在一起，实现数据的本地化；数据本地化并不是总能实现，比如在 HRegion 移动 ( 如因 Split) 时，需要等下一次 Compact 才能继续回到本地化。&lt;/p&gt;
&lt;h1 id=&#34;hfile&#34;&gt;HFile&lt;/h1&gt;
&lt;p&gt;HFile 数据格式中的 Data 字段用于存储实际的 KeyValue 数据，MetaIndex 字段用于 Meta 块的起始点，Magic 字段用于存储随机数，防止数据被破坏。而 HFile 中的 KeyValue 数据格式中的 Key 应该是 byte[] 数组，Value 部分是二进制数据。&lt;/p&gt;
&lt;h1 id=&#34;预分区&#34;&gt;预分区&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;HBase中，表会被划分为1...n个Region，被托管在RegionServer中。Region二个重要的属性:StartKey与 EndKey表示这个Region维护的rowKey范围，当我们要读/写数据时，如果rowKey落在某个start-end key范围内，那么就会定位到目标region并且读/写到相关的数据。简单地说，有那么一点点类似人群划分，1-15岁为小朋友,16-39岁为年轻 人，40-64为中年人,65岁以上为老年人。(这些数值都是拍脑袋出来的，只是举例，非真实),然后某人找队伍，然后根据年龄，处于哪个范围，就找到它 所属的队伍。: ( 有点废话了。。。。
然后，默认地，当我们只是通过HBaseAdmin指定TableDescriptor来创建一张表时，只有一个region,正处于混沌时 期，start-end key无边界,可谓海纳百川。啥样的rowKey都可以接受，都往这个region里装，然而，当数据越来越多，region的size越来越大时，大到 一定的阀值，hbase认为再往这个region里塞数据已经不合适了，就会找到一个midKey将region一分为二，成为2个region,这个过 程称为分裂(region-split).而midKey则为这二个region的临界，左为N无下界，右为M无上界。&amp;lt; midKey则为阴被塞到N区，&amp;gt; midKey则会被塞到M区。
如何找到midKey?涉及的内容比较多，暂且不去讨论，最简单的可以认为是region的总行数 / 2 的那一行数据的rowKey.虽然实际上比它会稍复杂点。
如果我们就这样默认地，建表，表里不断地Put数据，更严重的是我们的rowkey还是顺序增大的，是比较可怕的。存在的缺点比较明显。
首先是热点写，我们总是会往最大的start-key所在的region写东西，因为我们的rowkey总是会比之前的大，并且hbase的是按升序方式排序的。所以写操作总是被定位到无上界的那个region中。
其次，由于写热点，我们总是往最大start-key的region写记录，之前分裂出来的region不会再被写数据，有点被打进冷宫的赶脚，它们都处于半满状态，这样的分布也是不利的。
如果在写比较频率的场景下，数据增长快，split的次数也会增多，由于split是比较耗时耗资源的，所以我们并不希望这种事情经常发生。
............
看到这些缺点，我们知道，在集群的环境中，为了得到更好的并行性，我们希望有好的load blance，让每个节点提供的请求处理都是均等的。我们也希望，region不要经常split，因为split会使server有一段时间的停顿，如何能做到呢？
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;随机哈希与预分区。二者结合起来，是比较完美的，预分区一开始就预建好了一部分 region, 这些 region 都维护着自已的 start-end keys，再配合上随机哈希，写数据能均等地命中这些预建的 region，就能解决上面的那些缺点，大大地提高了性能。提供 2 种思路 : hash 与 partition. 一、hash 就是 rowkey 前面由一串随机字符串组成, 随机字符串生成方式可以由 SHA 或者 MD5 等方式生成，只要 region 所管理的 start-end keys 范围比较随机，那么就可以解决写热点问题。long currentId = 1L; byte [] rowkey = Bytes.add(MD5Hash.getMD5AsHex(Bytes.toBytes(currentId)).substring(0, 8).getBytes(), Bytes.toBytes(currentId));&lt;/p&gt;
&lt;p&gt;假设 rowKey 原本是自增长的 long 型，可以将 rowkey 转为 hash 再转为 bytes，加上本身 id 转为 bytes, 组成 rowkey，这样就生成随便的 rowkey。那么对于这种方式的 rowkey 设计，如何去进行预分区呢？1. 取样，先随机生成一定数量的 rowkey, 将取样数据按升序排序放到一个集合里 2. 根据预分区的 region 个数，对整个集合平均分割，即是相关的 splitKeys. 3.HBaseAdmin.createTable(HTableDescriptor tableDescriptor,byte[][] splitkeys) 可以指定预分区的 splitKey，即是指定 region 间的 rowkey 临界值 .&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   以上，就已经按hash方式，预建好了分区，以后在插入数据的时候，也要按照此rowkeyGenerator的方式生成rowkey,有兴趣的话，也可以做些试验，插入些数据，看看数据的分布。

   二、partition故名思义，就是分区式，这种分区有点类似于mapreduce中的partitioner,将区域用长整数(Long)作为分区号，每个region管理着相应的区域数据，在rowKey生成时，将id取模后，然后拼上id整体作为rowKey.这个比较简单，不需要取 样，splitKeys也非常简单，直接是分区号即可。直接上代码吧：
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;calcSplitKeys 方法比较单纯，splitKey 就是 partition 的编号, 我们看看测试类 : Java 代码 收藏代码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   通过partition实现的loadblance写的话，当然生成rowkey方式也要结合当前的region数目取模而求得，大家同样也可以做些实验，看看数据插入后的分布。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这里也顺提一下，如果是顺序的增长型原 id, 可以将 id 保存到一个数据库，传统的也好 ,redis 的也好，每次取的时候，将数值设大 1000 左右，以后 id 可以在内存内增长，当内存数量已经超过 1000 的话，再去 load 下一个，有点类似于 oracle 中的 sqeuence.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    随机分布加预分区也不是一劳永逸的。因为数据是不断地增长的，随着时间不断地推移，已经分好的区域，或许已经装不住更多的数据，当然就要进一步进行 split了，同样也会出现性能损耗问题，所以我们还是要规划好数据增长速率，观察好数据定期维护，按需分析是否要进一步分行手工将分区再分好，也或者是 更严重的是新建表，做好更大的预分区然后进行数据迁移。
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>

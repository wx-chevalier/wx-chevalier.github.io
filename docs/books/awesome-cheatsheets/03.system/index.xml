<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>03.System | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/</link><atom:link href="https://ng-tech.icu/books/awesome-cheatsheets/03.system/index.xml" rel="self" type="application/rss+xml"/><description>03.System</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>03.System</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/</link></image><item><title>Cache-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/cache-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/cache-cheatsheet/</guid><description>&lt;h1 id="web-架构缓存概览从-cpu-到浏览器">Web 架构缓存概览：从 CPU 到浏览器&lt;/h1>
&lt;p>Web caches sit between the user and the application server, where they save and serve copies of certain responses. In the diagram below, we can see three users fetching the same resource one after the other:&lt;/p>
&lt;p>Caching is intended to speed up page loads by reducing latency, and also reduce load on the application server. Some companies host their own cache using software like Varnish, and others opt to rely on a Content Delivery Network (CDN) like Cloudflare, with caches scattered across geographical locations. Also, some popular web applications and frameworks like Drupal have a built-in cache.&lt;/p>
&lt;p>There are also other types of cache, such as client-side browser caches and DNS caches, but they&amp;rsquo;re not the focus of this research.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550368.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="cpu-cache">CPU Cache&lt;/h1>
&lt;p>由于内存的访问速度与 CPU 中寄存器的访问速度相去甚远，当我们需要对同一批数据(譬如数组或循环计数变量)进行多次操作时，CPU 会自动将值放到 CPU 缓存而不是内存中。CPU 缓存的访问速度仅次于 CPU 寄存器。其容量远小于内存，但速度却可以接近处理器的频率。当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在(命中)，则不经访问内存直接返回该数据；如果不存在(失效)，则要先把内存中的相应数据载入缓存，再将其返回处理器。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550400.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>随着多核的发展，CPU 缓存又被细分为了 L1, L2, L3 这三个级别，级别越小越接近于 CPU，并且容量越小；一般来说，每个核上都会包含用于存放数据的 L1d Cache 与存放指令的 L1i Cache，以及独立的 L2 Cache，而往往同一个 CPU 插槽之间的核会共享 L3 Cache。在 Linux 设备上 &lt;code>cat /proc/cpuinfo&lt;/code> 或者 &lt;code>lscpu&lt;/code> 查看 CPU 情况。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>存储单元&lt;/th>
&lt;th>体积&lt;/th>
&lt;th>访问所需 CPU 周期&lt;/th>
&lt;th>访问所需时间&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>寄存器&lt;/td>
&lt;td>&lt;/td>
&lt;td>1 cycle&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>L1 Cache&lt;/td>
&lt;td>2KB~64KB&lt;/td>
&lt;td>~3-4 cycles&lt;/td>
&lt;td>~0.5-1 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>L2 Cache&lt;/td>
&lt;td>256KB~512KB&lt;/td>
&lt;td>~10-20 cycles&lt;/td>
&lt;td>~3-7 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>L3 Cache&lt;/td>
&lt;td>1MB~8MB&lt;/td>
&lt;td>~40-45 cycles&lt;/td>
&lt;td>~15 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>跨槽传输&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>~20 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>内存&lt;/td>
&lt;td>&lt;/td>
&lt;td>~120-240 cycles&lt;/td>
&lt;td>~60-120ns&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>结构上，一个直接映射(Direct Mapped)缓存由若干缓存块(Cache Block，或 Cache Line)构成。每个缓存块存储具有连续内存地址的若干个存储单元。在 32 位计算机上这通常是一个双字(dword)，即四个字节。因此，每个双字具有唯一的块内偏移量。每个缓存块有一个索引(Index)，它一般是内存地址的低端部分，但不含块内偏移和字节偏移所占的最低若干位。一个数据总量为 4KB、缓存块大小为 16B 的直接映射缓存一共有 256 个缓存块，其索引范围为 0 到 255。在 Linux 设备上我们可以查看机器缓存行的大小：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="m">64&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="缓存策略">缓存策略&lt;/h1>
&lt;h1 id="cdn">CDN&lt;/h1>
&lt;p>CDN 的全称是 Content Delivery Network，即内容分发网络。其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN 系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet 网络拥挤的状况，提高用户访问网站的响应速度。&lt;/p>
&lt;p>客户端浏览器先检查是否有本地缓存是否过期，如果过期，则向 CDN 边缘节点发起请求，CDN 边缘节点会检测用户请求数据的缓存是否过期，如果没有过期，则直接响应用户请求，此时一个完成 http 请求结束；如果数据已经过期，那么 CDN 还需要向源站发出回源请求（back to the source request）,来拉取最新的数据。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550420.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>CDN 系统中，直接面向用户，负责给用户提供内容服务的的 Cache 设备都部署在整个 CDN 网络的边缘位置，所以将这一层称为边缘层。CDN 系统中，中心层负责全局的管理和控制，同时也保存了最多的内容 Cache。在边缘层设备未能命中 Cache 时，需要向中心层设备请求；而中心层未能命中时，则需要向源站请求。不同的 CDN 系统设计存在差异，中心层可能具备用户服务的能力，也可能只会向下一层提供服务。如果 CDN 系统比较庞大，边缘层向中心层请求内容太多，会造成中心层负载压力太大。此时，需要在中心层和边缘层之间部署一个区域层，负责一个区域的管理和控制，也可以提供一些内容 Cache 供边缘层访问。&lt;/p>
&lt;p>常规的 CDN 都是回源的。即：当有用户访问某一个 URL 的时候，如果被解析到的那个 CDN 节点没有缓存响应的内容，或者是缓存已经到期，就会回源站去获取。如果没有人访问，那么 CDN 节点不会主动去源站拿的；源站内容有更新的时候，源站主动把内容推送到 CDN 节点。回源域名一般是 cdn 领域的专业术语，通常情况下，是直接用 ip 进行回源的，但是如果客户源站有多个 ip，并且 ip 地址会经常变化，对于 cdn 厂商来说，为了避免经常更改配置（回源 ip），会采用回源域名方式进行回源，这样即使源站的 ip 变化了，也不影响原有的配置。CDN 本来是给我们的网站加速的，但是有时会因为不合适的回源策略给服务器带来负担，只有选择正确的策略才能给自己的网站带来更高的访问效率。&lt;/p>
&lt;h1 id="微服务缓存">微服务缓存&lt;/h1>
&lt;p>① 非本地缓存的工作机制&lt;/p>
&lt;p>② 本地缓存的工作机制：Key 预加载/更新&lt;/p>
&lt;p>③ 本地缓存的工作机制：Set/Delete 操作&lt;/p>
&lt;p>④ 本地缓存的工作机制：Get 操作&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550436.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550458.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550474.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/202304181550491.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p></description></item><item><title>Kara-SystemDesign-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/kara-systemdesign-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/kara-systemdesign-cheatsheet/</guid><description>&lt;h1 id="system-design-course">System Design Course&lt;/h1>
&lt;p>Hey, welcome to the course. I hope this course provides a great learning experience.&lt;/p>
&lt;p>&lt;em>This course is also available on my &lt;a href="https://karanpratapsingh.com/courses/system-design" target="_blank" rel="noopener">website&lt;/a> and as an ebook on &lt;a href="https://leanpub.com/systemdesign" target="_blank" rel="noopener">leanpub&lt;/a>. Please leave a ⭐ as motivation if this was helpful!&lt;/em>&lt;/p>
&lt;h1 id="table-of-contents">Table of contents&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Getting Started&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#what-is-system-design">What is system design?&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Chapter I&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#ip">IP&lt;/a>&lt;/li>
&lt;li>&lt;a href="#osi-model">OSI Model&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tcp-and-udp">TCP and UDP&lt;/a>&lt;/li>
&lt;li>&lt;a href="#domain-name-system-dns">Domain Name System (DNS)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#load-balancing">Load Balancing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clustering">Clustering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#caching">Caching&lt;/a>&lt;/li>
&lt;li>&lt;a href="#content-delivery-network-cdn">Content Delivery Network (CDN)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#proxy">Proxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="#availability">Availability&lt;/a>&lt;/li>
&lt;li>&lt;a href="#scalability">Scalability&lt;/a>&lt;/li>
&lt;li>&lt;a href="#storage">Storage&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Chapter II&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#databases-and-dbms">Databases and DBMS&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sql-databases">SQL databases&lt;/a>&lt;/li>
&lt;li>&lt;a href="#nosql-databases">NoSQL databases&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sql-vs-nosql-databases">SQL vs NoSQL databases&lt;/a>&lt;/li>
&lt;li>&lt;a href="#database-replication">Database Replication&lt;/a>&lt;/li>
&lt;li>&lt;a href="#indexes">Indexes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#normalization-and-denormalization">Normalization and Denormalization&lt;/a>&lt;/li>
&lt;li>&lt;a href="#acid-and-base-consistency-models">ACID and BASE consistency models&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cap-theorem">CAP theorem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pacelc-theorem">PACELC Theorem&lt;/a>&lt;/li>
&lt;li>&lt;a href="#transactions">Transactions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#distributed-transactions">Distributed Transactions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sharding">Sharding&lt;/a>&lt;/li>
&lt;li>&lt;a href="#consistent-hashing">Consistent Hashing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#database-federation">Database Federation&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Chapter III&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#n-tier-architecture">N-tier architecture&lt;/a>&lt;/li>
&lt;li>&lt;a href="#message-brokers">Message Brokers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#message-queues">Message Queues&lt;/a>&lt;/li>
&lt;li>&lt;a href="#publish-subscribe">Publish-Subscribe&lt;/a>&lt;/li>
&lt;li>&lt;a href="#enterprise-service-bus-esb">Enterprise Service Bus (ESB)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#monoliths-and-microservices">Monoliths and Microservices&lt;/a>&lt;/li>
&lt;li>&lt;a href="#event-driven-architecture-eda">Event-Driven Architecture (EDA)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#event-sourcing">Event Sourcing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#command-and-query-responsibility-segregation-cqrs">Command and Query Responsibility Segregation (CQRS)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#api-gateway">API Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="#rest-graphql-grpc">REST, GraphQL, gRPC&lt;/a>&lt;/li>
&lt;li>&lt;a href="#long-polling-websockets-server-sent-events-sse">Long polling, WebSockets, Server-Sent Events (SSE)&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Chapter IV&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#geohashing-and-quadtrees">Geohashing and Quadtrees&lt;/a>&lt;/li>
&lt;li>&lt;a href="#circuit-breaker">Circuit breaker&lt;/a>&lt;/li>
&lt;li>&lt;a href="#rate-limiting">Rate Limiting&lt;/a>&lt;/li>
&lt;li>&lt;a href="#service-discovery">Service Discovery&lt;/a>&lt;/li>
&lt;li>&lt;a href="#sla-slo-sli">SLA, SLO, SLI&lt;/a>&lt;/li>
&lt;li>&lt;a href="#disaster-recovery">Disaster recovery&lt;/a>&lt;/li>
&lt;li>&lt;a href="#virtual-machines-vms-and-containers">Virtual Machines (VMs) and Containers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#oauth-20-and-openid-connect-oidc">OAuth 2.0 and OpenID Connect (OIDC)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#single-sign-on-sso">Single Sign-On (SSO)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#ssl-tls-mtls">SSL, TLS, mTLS&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Chapter V&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#system-design-interviews">System Design Interviews&lt;/a>&lt;/li>
&lt;li>&lt;a href="#url-shortener">URL Shortener&lt;/a>&lt;/li>
&lt;li>&lt;a href="#whatsapp">WhatsApp&lt;/a>&lt;/li>
&lt;li>&lt;a href="#twitter">Twitter&lt;/a>&lt;/li>
&lt;li>&lt;a href="#netflix">Netflix&lt;/a>&lt;/li>
&lt;li>&lt;a href="#uber">Uber&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Appendix&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#next-steps">Next Steps&lt;/a>&lt;/li>
&lt;li>&lt;a href="#references">References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="what-is-system-design">What is system design?&lt;/h1>
&lt;p>Before we start this course, let&amp;rsquo;s talk about what even is system design.&lt;/p>
&lt;p>System design is the process of defining the architecture, interfaces, and data
for a system that satisfies specific requirements. System design meets the needs
of your business or organization through coherent and efficient systems. It requires
a systematic approach to building and engineering systems. A good system design requires
us to think about everything, from infrastructure all the way down to the data and how it&amp;rsquo;s stored.&lt;/p>
&lt;h2 id="why-is-system-design-so-important">Why is System Design so important?&lt;/h2>
&lt;p>System design helps us define a solution that meets the business requirements. It is
one of the earliest decisions we can make when building a system. Often it is essential
to think from a high level as these decisions are very difficult to correct later. It
also makes it easier to reason about and manage architectural changes as the system evolves.&lt;/p>
&lt;h1 id="ip">IP&lt;/h1>
&lt;p>An IP address is a unique address that identifies a device on the internet or a local network. IP stands for &lt;em>&amp;ldquo;Internet Protocol&amp;rdquo;&lt;/em>, which is the set of rules governing the format of data sent via the internet or local network.&lt;/p>
&lt;p>In essence, IP addresses are the identifier that allows information to be sent between devices on a network. They contain location information and make devices accessible for communication. The internet needs a way to differentiate between different computers, routers, and websites. IP addresses provide a way of doing so and form an essential part of how the internet works.&lt;/p>
&lt;h2 id="versions">Versions&lt;/h2>
&lt;p>Now, let&amp;rsquo;s learn about the different versions of IP addresses:&lt;/p>
&lt;h3 id="ipv4">IPv4&lt;/h3>
&lt;p>The original Internet Protocol is IPv4 which uses a 32-bit numeric dot-decimal notation that only allows for around 4 billion IP addresses. Initially, it was more than enough but as internet adoption grew, we needed something better.&lt;/p>
&lt;p>&lt;em>Example: &lt;code>102.22.192.181&lt;/code>&lt;/em>&lt;/p>
&lt;h3 id="ipv6">IPv6&lt;/h3>
&lt;p>IPv6 is a new protocol that was introduced in 1998. Deployment commenced in the mid-2000s and since the internet users have grown exponentially, it is still ongoing.&lt;/p>
&lt;p>This new protocol uses 128-bit alphanumeric hexadecimal notation. This means that IPv6 can provide about ~340e+36 IP addresses. That&amp;rsquo;s more than enough to meet the growing demand for years to come.&lt;/p>
&lt;p>&lt;em>Example: &lt;code>2001:0db8:85a3:0000:0000:8a2e:0370:7334&lt;/code>&lt;/em>&lt;/p>
&lt;h2 id="types">Types&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss types of IP addresses:&lt;/p>
&lt;h3 id="public">Public&lt;/h3>
&lt;p>A public IP address is an address where one primary address is associated with your whole network. In this type of IP address, each of the connected devices has the same IP address.&lt;/p>
&lt;p>&lt;em>Example: IP address provided to your router by the ISP.&lt;/em>&lt;/p>
&lt;h3 id="private">Private&lt;/h3>
&lt;p>A private IP address is a unique IP number assigned to every device that connects to your internet network, which includes devices like computers, tablets, and smartphones, which are used in your household.&lt;/p>
&lt;p>&lt;em>Example: IP addresses generated by your home router for your devices.&lt;/em>&lt;/p>
&lt;h3 id="static">Static&lt;/h3>
&lt;p>A static IP address does not change and is one that was manually created, as opposed to having been assigned. These addresses are usually more expensive but are more reliable.&lt;/p>
&lt;p>&lt;em>Example: They are usually used for important things like reliable geo-location services, remote access, server hosting, etc.&lt;/em>&lt;/p>
&lt;h3 id="dynamic">Dynamic&lt;/h3>
&lt;p>A dynamic IP address changes from time to time and is not always the same. It has been assigned by a &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol" target="_blank" rel="noopener">Dynamic Host Configuration Protocol (DHCP)&lt;/a> server. Dynamic IP addresses are the most common type of internet protocol address. They are cheaper to deploy and allow us to reuse IP addresses within a network as needed.&lt;/p>
&lt;p>&lt;em>Example: They are more commonly used for consumer equipment and personal use.&lt;/em>&lt;/p>
&lt;h1 id="osi-model">OSI Model&lt;/h1>
&lt;p>The OSI Model is a logical and conceptual model that defines network communication used by systems open to interconnection and communication with other systems. The Open System Interconnection (OSI Model) also defines a logical network and effectively describes computer packet transfer by using various layers of protocols.&lt;/p>
&lt;p>The OSI Model can be seen as a universal language for computer networking. It&amp;rsquo;s based on the concept of splitting up a communication system into seven abstract layers, each one stacked upon the last.&lt;/p>
&lt;h2 id="why-does-the-osi-model-matter">Why does the OSI model matter?&lt;/h2>
&lt;p>The Open System Interconnection (OSI) model has defined the common terminology used in networking discussions and documentation. This allows us to take a very complex communications process apart and evaluate its components.&lt;/p>
&lt;p>While this model is not directly implemented in the TCP/IP networks that are most common today, it can still help us do so much more, such as:&lt;/p>
&lt;ul>
&lt;li>Make troubleshooting easier and help identify threats across the entire stack.&lt;/li>
&lt;li>Encourage hardware manufacturers to create networking products that can communicate with each other over the network.&lt;/li>
&lt;li>Essential for developing a security-first mindset.&lt;/li>
&lt;li>Separate a complex function into simpler components.&lt;/li>
&lt;/ul>
&lt;h2 id="layers">Layers&lt;/h2>
&lt;p>The seven abstraction layers of the OSI model can be defined as follows, from top to bottom:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png" alt="osi-model" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="application">Application&lt;/h3>
&lt;p>This is the only layer that directly interacts with data from the user. Software applications like web browsers and email clients rely on the application layer to initiate communication. But it should be made clear that client software applications are not part of the application layer, rather the application layer is responsible for the protocols and data manipulation that the software relies on to present meaningful data to the user. Application layer protocols include HTTP as well as SMTP.&lt;/p>
&lt;h3 id="presentation">Presentation&lt;/h3>
&lt;p>The presentation layer is also called the Translation layer. The data from the application layer is extracted here and manipulated as per the required format to transmit over the network. The functions of the presentation layer are translation, encryption/decryption, and compression.&lt;/p>
&lt;h3 id="session">Session&lt;/h3>
&lt;p>This is the layer responsible for opening and closing communication between the two devices. The time between when the communication is opened and closed is known as the session. The session layer ensures that the session stays open long enough to transfer all the data being exchanged, and then promptly closes the session in order to avoid wasting resources. The session layer also synchronizes data transfer with checkpoints.&lt;/p>
&lt;h3 id="transport">Transport&lt;/h3>
&lt;p>The transport layer (also known as layer 4) is responsible for end-to-end communication between the two devices. This includes taking data from the session layer and breaking it up into chunks called segments before sending it to the Network layer (layer 3). It is also responsible for reassembling the segments on the receiving device into data the session layer can consume.&lt;/p>
&lt;h3 id="network">Network&lt;/h3>
&lt;p>The network layer is responsible for facilitating data transfer between two different networks. The network layer breaks up segments from the transport layer into smaller units, called packets, on the sender&amp;rsquo;s device, and reassembles these packets on the receiving device. The network layer also finds the best physical path for the data to reach its destination this is known as routing. If the two devices communicating are on the same network, then the network layer is unnecessary.&lt;/p>
&lt;h3 id="data-link">Data Link&lt;/h3>
&lt;p>The data link layer is very similar to the network layer, except the data link layer facilitates data transfer between two devices on the same network. The data link layer takes packets from the network layer and breaks them into smaller pieces called frames.&lt;/p>
&lt;h3 id="physical">Physical&lt;/h3>
&lt;p>This layer includes the physical equipment involved in the data transfer, such as the cables and switches. This is also the layer where the data gets converted into a bit stream, which is a string of 1s and 0s. The physical layer of both devices must also agree on a signal convention so that the 1s can be distinguished from the 0s on both devices.&lt;/p>
&lt;h1 id="tcp-and-udp">TCP and UDP&lt;/h1>
&lt;h2 id="tcp">TCP&lt;/h2>
&lt;p>Transmission Control Protocol (TCP) is connection-oriented, meaning once a connection has been established, data can be transmitted in both directions. TCP has built-in systems to check for errors and to guarantee data will be delivered in the order it was sent, making it the perfect protocol for transferring information like still images, data files, and web pages.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png" alt="tcp" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>But while TCP is instinctively reliable, its feedback mechanisms also result in a larger overhead, translating to greater use of the available bandwidth on the network.&lt;/p>
&lt;h2 id="udp">UDP&lt;/h2>
&lt;p>User Datagram Protocol (UDP) is a simpler, connectionless internet protocol in which error-checking and recovery services are not required. With UDP, there is no overhead for opening a connection, maintaining a connection, or terminating a connection. Data is continuously sent to the recipient, whether or not they receive it.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png" alt="udp" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>It is largely preferred for real-time communications like broadcast or multicast network transmission. We should use UDP over TCP when we need the lowest latency and late data is worse than the loss of data.&lt;/p>
&lt;h2 id="tcp-vs-udp">TCP vs UDP&lt;/h2>
&lt;p>TCP is a connection-oriented protocol, whereas UDP is a connectionless protocol. A key difference between TCP and UDP is speed, as TCP is comparatively slower than UDP. Overall, UDP is a much faster, simpler, and more efficient protocol, however, retransmission of lost data packets is only possible with TCP.&lt;/p>
&lt;p>TCP provides ordered delivery of data from user to server (and vice versa), whereas UDP is not dedicated to end-to-end communications, nor does it check the readiness of the receiver.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Feature&lt;/th>
&lt;th>TCP&lt;/th>
&lt;th>UDP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Connection&lt;/td>
&lt;td>Requires an established connection&lt;/td>
&lt;td>Connectionless protocol&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Guaranteed delivery&lt;/td>
&lt;td>Can guarantee delivery of data&lt;/td>
&lt;td>Cannot guarantee delivery of data&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Re-transmission&lt;/td>
&lt;td>Re-transmission of lost packets is possible&lt;/td>
&lt;td>No re-transmission of lost packets&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Speed&lt;/td>
&lt;td>Slower than UDP&lt;/td>
&lt;td>Faster than TCP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Broadcasting&lt;/td>
&lt;td>Does not support broadcasting&lt;/td>
&lt;td>Supports broadcasting&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Use cases&lt;/td>
&lt;td>HTTPS, HTTP, SMTP, POP, FTP, etc&lt;/td>
&lt;td>Video streaming, DNS, VoIP, etc&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="domain-name-system-dns">Domain Name System (DNS)&lt;/h1>
&lt;p>Earlier we learned about IP addresses that enable every machine to connect with other machines. But as we know humans are more comfortable with names than numbers. It&amp;rsquo;s easier to remember a name like &lt;code>google.com&lt;/code> than something like &lt;code>122.250.192.232&lt;/code>.&lt;/p>
&lt;p>This brings us to Domain Name System (DNS) which is a hierarchical and decentralized naming system used for translating human-readable domain names to IP addresses.&lt;/p>
&lt;h2 id="how-dns-works">How DNS works&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png" alt="how-dns-works" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>DNS lookup involves the following eight steps:&lt;/p>
&lt;ol>
&lt;li>A client types &lt;a href="http://example.com" target="_blank" rel="noopener">example.com&lt;/a> into a web browser, the query travels to the internet and is received by a DNS resolver.&lt;/li>
&lt;li>The resolver then recursively queries a DNS root nameserver.&lt;/li>
&lt;li>The root server responds to the resolver with the address of a Top-Level Domain (TLD).&lt;/li>
&lt;li>The resolver then makes a request to the &lt;code>.com&lt;/code> TLD.&lt;/li>
&lt;li>The TLD server then responds with the IP address of the domain&amp;rsquo;s nameserver, &lt;a href="http://example.com" target="_blank" rel="noopener">example.com&lt;/a>.&lt;/li>
&lt;li>Lastly, the recursive resolver sends a query to the domain&amp;rsquo;s nameserver.&lt;/li>
&lt;li>The IP address for &lt;a href="http://example.com" target="_blank" rel="noopener">example.com&lt;/a> is then returned to the resolver from the nameserver.&lt;/li>
&lt;li>The DNS resolver then responds to the web browser with the IP address of the domain requested initially.&lt;/li>
&lt;/ol>
&lt;p>Once the IP address has been resolved, the client should be able to request content from the resolved IP address. For example, the resolved IP may return a webpage to be rendered in the browser.&lt;/p>
&lt;h2 id="server-types">Server types&lt;/h2>
&lt;p>Now, let&amp;rsquo;s look at the four key groups of servers that make up the DNS infrastructure.&lt;/p>
&lt;h3 id="dns-resolver">DNS Resolver&lt;/h3>
&lt;p>A DNS resolver (also known as a DNS recursive resolver) is the first stop in a DNS query. The recursive resolver acts as a middleman between a client and a DNS nameserver. After receiving a DNS query from a web client, a recursive resolver will either respond with cached data, or send a request to a root nameserver, followed by another request to a TLD nameserver, and then one last request to an authoritative nameserver. After receiving a response from the authoritative nameserver containing the requested IP address, the recursive resolver then sends a response to the client.&lt;/p>
&lt;h3 id="dns-root-server">DNS root server&lt;/h3>
&lt;p>A root server accepts a recursive resolver&amp;rsquo;s query which includes a domain name, and the root nameserver responds by directing the recursive resolver to a TLD nameserver, based on the extension of that domain (&lt;code>.com&lt;/code>, &lt;code>.net&lt;/code>, &lt;code>.org&lt;/code>, etc.). The root nameservers are overseen by a nonprofit called the &lt;a href="https://www.icann.org" target="_blank" rel="noopener">Internet Corporation for Assigned Names and Numbers (ICANN)&lt;/a>.&lt;/p>
&lt;p>There are 13 DNS root nameservers known to every recursive resolver. Note that while there are 13 root nameservers, that doesn&amp;rsquo;t mean that there are only 13 machines in the root nameserver system. There are 13 types of root nameservers, but there are multiple copies of each one all over the world, which use &lt;a href="https://en.wikipedia.org/wiki/Anycast" target="_blank" rel="noopener">Anycast routing&lt;/a> to provide speedy responses.&lt;/p>
&lt;h3 id="tld-nameserver">TLD nameserver&lt;/h3>
&lt;p>A TLD nameserver maintains information for all the domain names that share a common domain extension, such as &lt;code>.com&lt;/code>, &lt;code>.net&lt;/code>, or whatever comes after the last dot in a URL.&lt;/p>
&lt;p>Management of TLD nameservers is handled by the &lt;a href="https://www.iana.org" target="_blank" rel="noopener">Internet Assigned Numbers Authority (IANA)&lt;/a>, which is a branch of &lt;a href="https://www.icann.org" target="_blank" rel="noopener">ICANN&lt;/a>. The IANA breaks up the TLD servers into two main groups:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Generic top-level domains&lt;/strong>: These are domains like &lt;code>.com&lt;/code>, &lt;code>.org&lt;/code>, &lt;code>.net&lt;/code>, &lt;code>.edu&lt;/code>, and &lt;code>.gov&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Country code top-level domains&lt;/strong>: These include any domains that are specific to a country or state. Examples include &lt;code>.uk&lt;/code>, &lt;code>.us&lt;/code>, &lt;code>.ru&lt;/code>, and &lt;code>.jp&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h3 id="authoritative-dns-server">Authoritative DNS server&lt;/h3>
&lt;p>The authoritative nameserver is usually the resolver&amp;rsquo;s last step in the journey for an IP address. The authoritative nameserver contains information specific to the domain name it serves (e.g. &lt;a href="http://google.com" target="_blank" rel="noopener">google.com&lt;/a>) and it can provide a recursive resolver with the IP address of that server found in the DNS A record, or if the domain has a CNAME record (alias) it will provide the recursive resolver with an alias domain, at which point the recursive resolver will have to perform a whole new DNS lookup to procure a record from an authoritative nameserver (often an A record containing an IP address). If it cannot find the domain, returns the NXDOMAIN message.&lt;/p>
&lt;h2 id="query-types">Query Types&lt;/h2>
&lt;p>There are three types of queries in a DNS system:&lt;/p>
&lt;h3 id="recursive">Recursive&lt;/h3>
&lt;p>In a recursive query, a DNS client requires that a DNS server (typically a DNS recursive resolver) will respond to the client with either the requested resource record or an error message if the resolver can&amp;rsquo;t find the record.&lt;/p>
&lt;h3 id="iterative">Iterative&lt;/h3>
&lt;p>In an iterative query, a DNS client provides a hostname, and the DNS Resolver returns the best answer it can. If the DNS resolver has the relevant DNS records in its cache, it returns them. If not, it refers the DNS client to the Root Server or another Authoritative Name Server that is nearest to the required DNS zone. The DNS client must then repeat the query directly against the DNS server it was referred.&lt;/p>
&lt;h3 id="non-recursive">Non-recursive&lt;/h3>
&lt;p>A non-recursive query is a query in which the DNS Resolver already knows the answer. It either immediately returns a DNS record because it already stores it in a local cache, or queries a DNS Name Server which is authoritative for the record, meaning it definitely holds the correct IP for that hostname. In both cases, there is no need for additional rounds of queries (like in recursive or iterative queries). Rather, a response is immediately returned to the client.&lt;/p>
&lt;h2 id="record-types">Record Types&lt;/h2>
&lt;p>DNS records (aka zone files) are instructions that live in authoritative DNS servers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain.&lt;/p>
&lt;p>These records consist of a series of text files written in what is known as &lt;em>DNS syntax&lt;/em>. DNS syntax is just a string of characters used as commands that tell the DNS server what to do. All DNS records also have a &lt;em>&amp;ldquo;TTL&amp;rdquo;&lt;/em>, which stands for time-to-live, and indicates how often a DNS server will refresh that record.&lt;/p>
&lt;p>There are more record types but for now, let&amp;rsquo;s look at some of the most commonly used ones:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>A (Address record)&lt;/strong>: This is the record that holds the IP address of a domain.&lt;/li>
&lt;li>&lt;strong>AAAA (IP Version 6 Address record)&lt;/strong>: The record that contains the IPv6 address for a domain (as opposed to A records, which stores the IPv4 address).&lt;/li>
&lt;li>&lt;strong>CNAME (Canonical Name record)&lt;/strong>: Forwards one domain or subdomain to another domain, does NOT provide an IP address.&lt;/li>
&lt;li>&lt;strong>MX (Mail exchanger record)&lt;/strong>: Directs mail to an email server.&lt;/li>
&lt;li>&lt;strong>TXT (Text Record)&lt;/strong>: This record lets an admin store text notes in the record. These records are often used for email security.&lt;/li>
&lt;li>&lt;strong>NS (Name Server records)&lt;/strong>: Stores the name server for a DNS entry.&lt;/li>
&lt;li>&lt;strong>SOA (Start of Authority)&lt;/strong>: Stores admin information about a domain.&lt;/li>
&lt;li>&lt;strong>SRV (Service Location record)&lt;/strong>: Specifies a port for specific services.&lt;/li>
&lt;li>&lt;strong>PTR (Reverse-lookup Pointer records)&lt;/strong>: Provides a domain name in reverse lookups.&lt;/li>
&lt;li>&lt;strong>CERT (Certificate record)&lt;/strong>: Stores public key certificates.&lt;/li>
&lt;/ul>
&lt;h2 id="subdomains">Subdomains&lt;/h2>
&lt;p>A subdomain is an additional part of our main domain name. It is commonly used to logically separate a website into sections. We can create multiple subdomains or child domains on the main domain.&lt;/p>
&lt;p>For example, &lt;code>blog.example.com&lt;/code> where &lt;code>blog&lt;/code> is the subdomain, &lt;code>example&lt;/code> is the primary domain and &lt;code>.com&lt;/code> is the top-level domain (TLD). Similar examples can be &lt;code>support.example.com&lt;/code> or &lt;code>careers.example.com&lt;/code>.&lt;/p>
&lt;h2 id="dns-zones">DNS Zones&lt;/h2>
&lt;p>A DNS zone is a distinct part of the domain namespace which is delegated to a legal entity like a person, organization, or company, who is responsible for maintaining the DNS zone. A DNS zone is also an administrative function, allowing for granular control of DNS components, such as authoritative name servers.&lt;/p>
&lt;h2 id="dns-caching">DNS Caching&lt;/h2>
&lt;p>A DNS cache (sometimes called a DNS resolver cache) is a temporary database, maintained by a computer&amp;rsquo;s operating system, that contains records of all the recent visits and attempted visits to websites and other internet domains. In other words, a DNS cache is just a memory of recent DNS lookups that our computer can quickly refer to when it&amp;rsquo;s trying to figure out how to load a website.&lt;/p>
&lt;p>The Domain Name System implements a time-to-live (TTL) on every DNS record. TTL specifies the number of seconds the record can be cached by a DNS client or server. When the record is stored in a cache, whatever TTL value came with it gets stored as well. The server continues to update the TTL of the record stored in the cache, counting down every second. When it hits zero, the record is deleted or purged from the cache. At that point, if a query for that record is received, the DNS server has to start the resolution process.&lt;/p>
&lt;h2 id="reverse-dns">Reverse DNS&lt;/h2>
&lt;p>A reverse DNS lookup is a DNS query for the domain name associated with a given IP address. This accomplishes the opposite of the more commonly used forward DNS lookup, in which the DNS system is queried to return an IP address. The process of reverse resolving an IP address uses PTR records. If the server does not have a PTR record, it cannot resolve a reverse lookup.&lt;/p>
&lt;p>Reverse lookups are commonly used by email servers. Email servers check and see if an email message came from a valid server before bringing it onto their network. Many email servers will reject messages from any server that does not support reverse lookups or from a server that is highly unlikely to be legitimate.&lt;/p>
&lt;p>&lt;em>Note: Reverse DNS lookups are not universally adopted as they are not critical to the normal function of the internet.&lt;/em>&lt;/p>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>These are some widely used managed DNS solutions:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/route53" target="_blank" rel="noopener">Route53&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cloudflare.com/dns" target="_blank" rel="noopener">Cloudflare DNS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/dns" target="_blank" rel="noopener">Google Cloud DNS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://azure.microsoft.com/en-in/services/dns" target="_blank" rel="noopener">Azure DNS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ns1.com/products/managed-dns" target="_blank" rel="noopener">NS1&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="load-balancing">Load Balancing&lt;/h1>
&lt;p>Load balancing lets us distribute incoming network traffic across multiple resources ensuring high availability and reliability by sending requests only to resources that are online. This provides the flexibility to add or subtract resources as demand dictates.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png" alt="load-balancing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>For additional scalability and redundancy, we can try to load balance at each layer of our system:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png" alt="load-balancing-layers" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="but-why">But why?&lt;/h2>
&lt;p>Modern high-traffic websites must serve hundreds of thousands, if not millions, of concurrent requests from users or clients. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers.&lt;/p>
&lt;p>A load balancer can sit in front of the servers and route client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization. This ensures that no single server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts sending requests to it.&lt;/p>
&lt;h2 id="workload-distribution">Workload distribution&lt;/h2>
&lt;p>This is the core functionality provided by a load balancer and has several common variations:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Host-based&lt;/strong>: Distributes requests based on the requested hostname.&lt;/li>
&lt;li>&lt;strong>Path-based&lt;/strong>: Using the entire URL to distribute requests as opposed to just the hostname.&lt;/li>
&lt;li>&lt;strong>Content-based&lt;/strong>: Inspects the message content of a request. This allows distribution based on content such as the value of a parameter.&lt;/li>
&lt;/ul>
&lt;h2 id="layers-1">Layers&lt;/h2>
&lt;p>Generally speaking, load balancers operate at one of the two levels:&lt;/p>
&lt;h3 id="network-layer">Network layer&lt;/h3>
&lt;p>This is the load balancer that works at the network&amp;rsquo;s transport layer, also known as layer 4. This performs routing based on networking information such as IP addresses and is not able to perform content-based routing. These are often dedicated hardware devices that can operate at high speed.&lt;/p>
&lt;h3 id="application-layer">Application layer&lt;/h3>
&lt;p>This is the load balancer that operates at the application layer, also known as layer 7. Load balancers can read requests in their entirety and perform content-based routing. This allows the management of load based on a full understanding of traffic.&lt;/p>
&lt;h2 id="types-1">Types&lt;/h2>
&lt;p>Let&amp;rsquo;s look at different types of load balancers:&lt;/p>
&lt;h3 id="software">Software&lt;/h3>
&lt;p>Software load balancers usually are easier to deploy than hardware versions. They also tend to be more cost-effective and flexible, and they are used in conjunction with software development environments. The software approach gives us the flexibility of configuring the load balancer to our environment&amp;rsquo;s specific needs. The boost in flexibility may come at the cost of having to do more work to set up the load balancer. Compared to hardware versions, which offer more of a closed-box approach, software balancers give us more freedom to make changes and upgrades.&lt;/p>
&lt;p>Software load balancers are widely used and are available either as installable solutions that require configuration and management or as a managed cloud service.&lt;/p>
&lt;h3 id="hardware">Hardware&lt;/h3>
&lt;p>As the name implies, a hardware load balancer relies on physical, on-premises hardware to distribute application and network traffic. These devices can handle a large volume of traffic but often carry a hefty price tag and are fairly limited in terms of flexibility.&lt;/p>
&lt;p>Hardware load balancers include proprietary firmware that requires maintenance and updates as new versions, and security patches are released.&lt;/p>
&lt;h3 id="dns">DNS&lt;/h3>
&lt;p>DNS load balancing is the practice of configuring a domain in the Domain Name System (DNS) such that client requests to the domain are distributed across a group of server machines.&lt;/p>
&lt;p>Unfortunately, DNS load balancing has inherent problems limiting its reliability and efficiency. Most significantly, DNS does not check for server and network outages, or errors. It always returns the same set of IP addresses for a domain even if servers are down or inaccessible.&lt;/p>
&lt;h2 id="routing-algorithms">Routing Algorithms&lt;/h2>
&lt;p>Now, let&amp;rsquo;s discuss commonly used routing algorithms:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Round-robin&lt;/strong>: Requests are distributed to application servers in rotation.&lt;/li>
&lt;li>&lt;strong>Weighted Round-robin&lt;/strong>: Builds on the simple Round-robin technique to account for differing server characteristics such as compute and traffic handling capacity using weights that can be assigned via DNS records by the administrator.&lt;/li>
&lt;li>&lt;strong>Least Connections&lt;/strong>: A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections.&lt;/li>
&lt;li>&lt;strong>Least Response Time&lt;/strong>: Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections.&lt;/li>
&lt;li>&lt;strong>Least Bandwidth&lt;/strong>: This method measures traffic in megabits per second (Mbps), sending client requests to the server with the least Mbps of traffic.&lt;/li>
&lt;li>&lt;strong>Hashing&lt;/strong>: Distributes requests based on a key we define, such as the client IP address or the request URL.&lt;/li>
&lt;/ul>
&lt;h2 id="advantages">Advantages&lt;/h2>
&lt;p>Load balancing also plays a key role in preventing downtime, other advantages of load balancing include the following:&lt;/p>
&lt;ul>
&lt;li>Scalability&lt;/li>
&lt;li>Redundancy&lt;/li>
&lt;li>Flexibility&lt;/li>
&lt;li>Efficiency&lt;/li>
&lt;/ul>
&lt;h2 id="redundant-load-balancers">Redundant load balancers&lt;/h2>
&lt;p>As you must&amp;rsquo;ve already guessed, the load balancer itself can be a single point of failure. To overcome this, a second or &lt;code>N&lt;/code> number of load balancers can be used in a cluster mode.&lt;/p>
&lt;p>And, if there&amp;rsquo;s a failure detection and the &lt;em>active&lt;/em> load balancer fails, another &lt;em>passive&lt;/em> load balancer can take over which will make our system more fault-tolerant.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png" alt="redundant-load-balancing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="features">Features&lt;/h2>
&lt;p>Here are some commonly desired features of load balancers:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Autoscaling&lt;/strong>: Starting up and shutting down resources in response to demand conditions.&lt;/li>
&lt;li>&lt;strong>Sticky sessions&lt;/strong>: The ability to assign the same user or device to the same resource in order to maintain the session state on the resource.&lt;/li>
&lt;li>&lt;strong>Healthchecks&lt;/strong>: The ability to determine if a resource is down or performing poorly in order to remove the resource from the load balancing pool.&lt;/li>
&lt;li>&lt;strong>Persistence connections&lt;/strong>: Allowing a server to open a persistent connection with a client such as a WebSocket.&lt;/li>
&lt;li>&lt;strong>Encryption&lt;/strong>: Handling encrypted connections such as TLS and SSL.&lt;/li>
&lt;li>&lt;strong>Certificates&lt;/strong>: Presenting certificates to a client and authentication of client certificates.&lt;/li>
&lt;li>&lt;strong>Compression&lt;/strong>: Compression of responses.&lt;/li>
&lt;li>&lt;strong>Caching&lt;/strong>: An application-layer load balancer may offer the ability to cache responses.&lt;/li>
&lt;li>&lt;strong>Logging&lt;/strong>: Logging of request and response metadata can serve as an important audit trail or source for analytics data.&lt;/li>
&lt;li>&lt;strong>Request tracing&lt;/strong>: Assigning each request a unique id for the purposes of logging, monitoring, and troubleshooting.&lt;/li>
&lt;li>&lt;strong>Redirects&lt;/strong>: The ability to redirect an incoming request based on factors such as the requested path.&lt;/li>
&lt;li>&lt;strong>Fixed response&lt;/strong>: Returning a static response for a request such as an error message.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-1">Examples&lt;/h2>
&lt;p>Following are some of the load balancing solutions commonly used in the industry:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/elasticloadbalancing" target="_blank" rel="noopener">Amazon Elastic Load Balancing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://azure.microsoft.com/en-in/services/load-balancer" target="_blank" rel="noopener">Azure Load Balancing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/load-balancing" target="_blank" rel="noopener">GCP Load Balancing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.digitalocean.com/products/load-balancer" target="_blank" rel="noopener">DigitalOcean Load Balancer&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.nginx.com" target="_blank" rel="noopener">Nginx&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.haproxy.org" target="_blank" rel="noopener">HAProxy&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="clustering">Clustering&lt;/h1>
&lt;p>At a high level, a computer cluster is a group of two or more computers, or nodes, that run in parallel to achieve a common goal. This allows workloads consisting of a high number of individual, parallelizable tasks to be distributed among the nodes in the cluster. As a result, these tasks can leverage the combined memory and processing power of each computer to increase overall performance.&lt;/p>
&lt;p>To build a computer cluster, the individual nodes should be connected to a network to enable internode communication. The software can then be used to join the nodes together and form a cluster. It may have a shared storage device and/or local storage on each node.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png" alt="cluster" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Typically, at least one node is designated as the leader node and acts as the entry point to the cluster. The leader node may be responsible for delegating incoming work to the other nodes and, if necessary, aggregating the results and returning a response to the user.&lt;/p>
&lt;p>Ideally, a cluster functions as if it were a single system. A user accessing the cluster should not need to know whether the system is a cluster or an individual machine. Furthermore, a cluster should be designed to minimize latency and prevent bottlenecks in node-to-node communication.&lt;/p>
&lt;h2 id="types-2">Types&lt;/h2>
&lt;p>Computer clusters can generally be categorized into three types:&lt;/p>
&lt;ul>
&lt;li>Highly available or fail-over&lt;/li>
&lt;li>Load balancing&lt;/li>
&lt;li>High-performance computing&lt;/li>
&lt;/ul>
&lt;h2 id="configurations">Configurations&lt;/h2>
&lt;p>The two most commonly used high availability (HA) clustering configurations are active-active and active-passive.&lt;/p>
&lt;h3 id="active-active">Active-Active&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png" alt="active-active" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>An active-active cluster is typically made up of at least two nodes, both actively running the same kind of service simultaneously. The main purpose of an active-active cluster is to achieve load balancing. A load balancer distributes workloads across all nodes to prevent any single node from getting overloaded. Because there are more nodes available to serve, there will also be an improvement in throughput and response times.&lt;/p>
&lt;h3 id="active-passive">Active-Passive&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png" alt="active-passive" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Like the active-active cluster configuration, an active-passive cluster also consists of at least two nodes. However, as the name &lt;em>active-passive&lt;/em> implies, not all nodes are going to be active. For example, in the case of two nodes, if the first node is already active, then the second node must be passive or on standby.&lt;/p>
&lt;h2 id="advantages-1">Advantages&lt;/h2>
&lt;p>Four key advantages of cluster computing are as follows:&lt;/p>
&lt;ul>
&lt;li>High availability&lt;/li>
&lt;li>Scalability&lt;/li>
&lt;li>Performance&lt;/li>
&lt;li>Cost-effective&lt;/li>
&lt;/ul>
&lt;h2 id="load-balancing-vs-clustering">Load balancing vs Clustering&lt;/h2>
&lt;p>Load balancing shares some common traits with clustering, but they are different processes. Clustering provides redundancy and boosts capacity and availability. Servers in a cluster are aware of each other and work together toward a common purpose. But with load balancing, servers are not aware of each other. Instead, they react to the requests they receive from the load balancer.&lt;/p>
&lt;p>We can employ load balancing in conjunction with clustering, but it also is applicable in cases involving independent servers that share a common purpose such as to run a website, business application, web service, or some other IT resource.&lt;/p>
&lt;h2 id="challenges">Challenges&lt;/h2>
&lt;p>The most obvious challenge clustering presents is the increased complexity of installation and maintenance. An operating system, the application, and its dependencies must each be installed and updated on every node.&lt;/p>
&lt;p>This becomes even more complicated if the nodes in the cluster are not homogeneous. Resource utilization for each node must also be closely monitored, and logs should be aggregated to ensure that the software is behaving correctly.&lt;/p>
&lt;p>Additionally, storage becomes more difficult to manage, a shared storage device must prevent nodes from overwriting one another and distributed data stores have to be kept in sync.&lt;/p>
&lt;h2 id="examples-2">Examples&lt;/h2>
&lt;p>Clustering is commonly used in the industry, and often many technologies offer some sort of clustering mode. For example:&lt;/p>
&lt;ul>
&lt;li>Containers (e.g. &lt;a href="https://kubernetes.io" target="_blank" rel="noopener">Kubernetes&lt;/a>, &lt;a href="https://aws.amazon.com/ecs" target="_blank" rel="noopener">Amazon ECS&lt;/a>)&lt;/li>
&lt;li>Databases (e.g. &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Cassandra&lt;/a>, &lt;a href="https://www.mongodb.com" target="_blank" rel="noopener">MongoDB&lt;/a>)&lt;/li>
&lt;li>Cache (e.g. &lt;a href="https://redis.io/docs/manual/scaling" target="_blank" rel="noopener">Redis&lt;/a>)&lt;/li>
&lt;/ul>
&lt;h1 id="caching">Caching&lt;/h1>
&lt;p>&lt;em>&amp;ldquo;There are only two hard things in Computer Science: cache invalidation and naming things.&amp;rdquo; - Phil Karlton&lt;/em>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png" alt="caching" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>A cache&amp;rsquo;s primary purpose is to increase data retrieval performance by reducing the need to access the underlying slower storage layer. Trading off capacity for speed, a cache typically stores a subset of data transiently, in contrast to databases whose data is usually complete and durable.&lt;/p>
&lt;p>Caches take advantage of the locality of reference principle &lt;em>&amp;ldquo;recently requested data is likely to be requested again&amp;rdquo;.&lt;/em>&lt;/p>
&lt;h2 id="caching-and-memory">Caching and Memory&lt;/h2>
&lt;p>Like a computer&amp;rsquo;s memory, a cache is a compact, fast-performing memory that stores data in a hierarchy of levels, starting at level one, and progressing from there sequentially. They are labeled as L1, L2, L3, and so on. A cache also gets written if requested, such as when there has been an update and new content needs to be saved to the cache, replacing the older content that was saved.&lt;/p>
&lt;p>No matter whether the cache is read or written, it&amp;rsquo;s done one block at a time. Each block also has a tag that includes the location where the data was stored in the cache. When data is requested from the cache, a search occurs through the tags to find the specific content that&amp;rsquo;s needed in level one (L1) of the memory. If the correct data isn&amp;rsquo;t found, more searches are conducted in L2.&lt;/p>
&lt;p>If the data isn&amp;rsquo;t found there, searches are continued in L3, then L4, and so on until it has been found, then, it&amp;rsquo;s read and loaded. If the data isn&amp;rsquo;t found in the cache at all, then it&amp;rsquo;s written into it for quick retrieval the next time.&lt;/p>
&lt;h2 id="cache-hit-and-cache-miss">Cache hit and Cache miss&lt;/h2>
&lt;h3 id="cache-hit">Cache hit&lt;/h3>
&lt;p>A cache hit describes the situation where content is successfully served from the cache. The tags are searched in the memory rapidly, and when the data is found and read, it&amp;rsquo;s considered a cache hit.&lt;/p>
&lt;p>&lt;strong>Cold, Warm, and Hot Caches&lt;/strong>&lt;/p>
&lt;p>A cache hit can also be described as cold, warm, or hot. In each of these, the speed at which the data is read is described.&lt;/p>
&lt;p>A hot cache is an instance where data was read from the memory at the &lt;em>fastest&lt;/em> possible rate. This happens when the data is retrieved from L1.&lt;/p>
&lt;p>A cold cache is the &lt;em>slowest&lt;/em> possible rate for data to be read, though, it&amp;rsquo;s still successful so it&amp;rsquo;s still considered a cache hit. The data is just found lower in the memory hierarchy such as in L3, or lower.&lt;/p>
&lt;p>A warm cache is used to describe data that&amp;rsquo;s found in L2 or L3. It&amp;rsquo;s not as fast as a hot cache, but it&amp;rsquo;s still faster than a cold cache. Generally, calling a cache warm is used to express that it&amp;rsquo;s slower and closer to a cold cache than a hot one.&lt;/p>
&lt;h3 id="cache-miss">Cache miss&lt;/h3>
&lt;p>A cache miss refers to the instance when the memory is searched, and the data isn&amp;rsquo;t found. When this happens, the content is transferred and written into the cache.&lt;/p>
&lt;h2 id="cache-invalidation">Cache Invalidation&lt;/h2>
&lt;p>Cache invalidation is a process where the computer system declares the cache entries as invalid and removes or replaces them. If the data is modified, it should be invalidated in the cache, if not, this can cause inconsistent application behavior. There are three kinds of caching systems:&lt;/p>
&lt;h3 id="write-through-cache">Write-through cache&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png" alt="write-through-cache" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Data is written into the cache and the corresponding database simultaneously.&lt;/p>
&lt;p>&lt;strong>Pro&lt;/strong>: Fast retrieval, complete data consistency between cache and storage.&lt;/p>
&lt;p>&lt;strong>Con&lt;/strong>: Higher latency for write operations.&lt;/p>
&lt;h3 id="write-around-cache">Write-around cache&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png" alt="write-around-cache" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Where write directly goes to the database or permanent storage, bypassing the cache.&lt;/p>
&lt;p>&lt;strong>Pro&lt;/strong>: This may reduce latency.&lt;/p>
&lt;p>&lt;strong>Con&lt;/strong>: It increases cache misses because the cache system has to read the information from the database in case of a cache miss. As a result, this can lead to higher read latency in the case of applications that write and re-read the information quickly. Read happen from slower back-end storage and experiences higher latency.&lt;/p>
&lt;h3 id="write-back-cache">Write-back cache&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png" alt="write-back-cache" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Where the write is only done to the caching layer and the write is confirmed as soon as the write to the cache completes. The cache then asynchronously syncs this write to the database.&lt;/p>
&lt;p>&lt;strong>Pro&lt;/strong>: This would lead to reduced latency and high throughput for write-intensive applications.&lt;/p>
&lt;p>&lt;strong>Con&lt;/strong>: There is a risk of data loss in case the caching layer crashes. We can improve this by having more than one replica acknowledging the write in the cache.&lt;/p>
&lt;h2 id="eviction-policies">Eviction policies&lt;/h2>
&lt;p>Following are some of the most common cache eviction policies:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>First In First Out (FIFO)&lt;/strong>: The cache evicts the first block accessed first without any regard to how often or how many times it was accessed before.&lt;/li>
&lt;li>&lt;strong>Last In First Out (LIFO)&lt;/strong>: The cache evicts the block accessed most recently first without any regard to how often or how many times it was accessed before.&lt;/li>
&lt;li>&lt;strong>Least Recently Used (LRU)&lt;/strong>: Discards the least recently used items first.&lt;/li>
&lt;li>&lt;strong>Most Recently Used (MRU)&lt;/strong>: Discards, in contrast to LRU, the most recently used items first.&lt;/li>
&lt;li>&lt;strong>Least Frequently Used (LFU)&lt;/strong>: Counts how often an item is needed. Those that are used least often are discarded first.&lt;/li>
&lt;li>&lt;strong>Random Replacement (RR)&lt;/strong>: Randomly selects a candidate item and discards it to make space when necessary.&lt;/li>
&lt;/ul>
&lt;h2 id="distributed-cache">Distributed Cache&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png" alt="distributed-cache" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>A distributed cache is a system that pools together the random-access memory (RAM) of multiple networked computers into a single in-memory data store used as a data cache to provide fast access to data. While most caches are traditionally in one physical server or hardware component, a distributed cache can grow beyond the memory limits of a single computer by linking together multiple computers.&lt;/p>
&lt;h2 id="global-cache">Global Cache&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png" alt="global-cache" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>As the name suggests, we will have a single shared cache that all the application nodes will use. When the requested data is not found in the global cache, it&amp;rsquo;s the responsibility of the cache to find out the missing piece of data from the underlying data store.&lt;/p>
&lt;h2 id="use-cases">Use cases&lt;/h2>
&lt;p>Caching can have many real-world use cases such as:&lt;/p>
&lt;ul>
&lt;li>Database Caching&lt;/li>
&lt;li>Content Delivery Network (CDN)&lt;/li>
&lt;li>Domain Name System (DNS) Caching&lt;/li>
&lt;li>API Caching&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>When not to use caching?&lt;/strong>&lt;/p>
&lt;p>Let&amp;rsquo;s also look at some scenarios where we should not use cache:&lt;/p>
&lt;ul>
&lt;li>Caching isn&amp;rsquo;t helpful when it takes just as long to access the cache as it does to access the primary data store.&lt;/li>
&lt;li>Caching doesn&amp;rsquo;t work as well when requests have low repetition (higher randomness), because caching performance comes from repeated memory access patterns.&lt;/li>
&lt;li>Caching isn&amp;rsquo;t helpful when the data changes frequently, as the cached version gets out of sync, and the primary data store must be accessed every time.&lt;/li>
&lt;/ul>
&lt;p>&lt;em>It&amp;rsquo;s important to note that a cache should not be used as permanent data storage. They are almost always implemented in volatile memory because it is faster, and thus should be considered transient.&lt;/em>&lt;/p>
&lt;h2 id="advantages-2">Advantages&lt;/h2>
&lt;p>Below are some advantages of caching:&lt;/p>
&lt;ul>
&lt;li>Improves performance&lt;/li>
&lt;li>Reduce latency&lt;/li>
&lt;li>Reduce load on the database&lt;/li>
&lt;li>Reduce network cost&lt;/li>
&lt;li>Increase Read Throughput&lt;/li>
&lt;/ul>
&lt;h2 id="examples-3">Examples&lt;/h2>
&lt;p>Here are some commonly used technologies for caching:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/elasticache" target="_blank" rel="noopener">Amazon Elasticache&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aerospike.com" target="_blank" rel="noopener">Aerospike&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="content-delivery-network-cdn">Content Delivery Network (CDN)&lt;/h1>
&lt;p>A content delivery network (CDN) is a geographically distributed group of servers that work together to provide fast delivery of internet content. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png" alt="cdn-map" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="why-use-a-cdn">Why use a CDN?&lt;/h2>
&lt;p>Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs and improving security. Serving content from CDNs can significantly improve performance as users receive content from data centers close to them and our servers do not have to serve requests that the CDN fulfills.&lt;/p>
&lt;h2 id="how-does-a-cdn-work">How does a CDN work?&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png" alt="cdn" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>In a CDN, the origin server contains the original versions of the content while the edge servers are numerous and distributed across various locations around the world.&lt;/p>
&lt;p>To minimize the distance between the visitors and the website&amp;rsquo;s server, a CDN stores a cached version of its content in multiple geographical locations known as edge locations. Each edge location contains several caching servers responsible for content delivery to visitors within its proximity.&lt;/p>
&lt;p>Once the static assets are cached on all the CDN servers for a particular location, all subsequent website visitor requests for static assets will be delivered from these edge servers instead of the origin, thus reducing the origin load and improving scalability.&lt;/p>
&lt;p>For example, when someone in the UK requests our website which might be hosted in the USA, they will be served from the closest edge location such as the London edge location. This is much quicker than having the visitor make a complete request to the origin server which will increase the latency.&lt;/p>
&lt;h2 id="types-3">Types&lt;/h2>
&lt;p>CDNs are generally divided into two types:&lt;/p>
&lt;h3 id="push-cdns">Push CDNs&lt;/h3>
&lt;p>Push CDNs receive new content whenever changes occur on the server. We take full responsibility for providing content, uploading directly to the CDN, and rewriting URLs to point to the CDN. We can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p>
&lt;p>Sites with a small amount of traffic or sites with content that isn&amp;rsquo;t often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p>
&lt;h3 id="pull-cdns">Pull CDNs&lt;/h3>
&lt;p>In a Pull CDN situation, the cache is updated based on request. When the client sends a request that requires static assets to be fetched from the CDN if the CDN doesn&amp;rsquo;t have it, then it will fetch the newly updated assets from the origin server and populate its cache with this new asset, and then send this new cached asset to the user.&lt;/p>
&lt;p>Contrary to the Push CDN, this requires less maintenance because cache updates on CDN nodes are performed based on requests from the client to the origin server. Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p>
&lt;h2 id="disadvantages">Disadvantages&lt;/h2>
&lt;p>As we all know good things come with extra costs, so let&amp;rsquo;s discuss some disadvantages of CDNs:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Extra charges&lt;/strong>: It can be expensive to use a CDN, especially for high-traffic services.&lt;/li>
&lt;li>&lt;strong>Restrictions&lt;/strong>: Some organizations and countries have blocked the domains or IP addresses of popular CDNs.&lt;/li>
&lt;li>&lt;strong>Location&lt;/strong>: If most of our audience is located in a country where the CDN has no servers, the data on our website may have to travel further than without using any CDN.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-4">Examples&lt;/h2>
&lt;p>Here are some widely used CDNs:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/cloudfront" target="_blank" rel="noopener">Amazon CloudFront&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/cdn" target="_blank" rel="noopener">Google Cloud CDN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cloudflare.com/cdn" target="_blank" rel="noopener">Cloudflare CDN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.fastly.com/products/cdn" target="_blank" rel="noopener">Fastly&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="proxy">Proxy&lt;/h1>
&lt;p>A proxy server is an intermediary piece of hardware/software sitting between the client and the backend server. It receives requests from clients and relays them to the origin servers. Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compression).&lt;/p>
&lt;h2 id="types-4">Types&lt;/h2>
&lt;p>There are two types of proxies:&lt;/p>
&lt;h3 id="forward-proxy">Forward Proxy&lt;/h3>
&lt;p>A forward proxy, often called a proxy, proxy server, or web proxy is a server that sits in front of a group of client machines. When those computers make requests to sites and services on the internet, the proxy server intercepts those requests and then communicates with web servers on behalf of those clients, like a middleman.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png" alt="forward-proxy" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;p>Here are some advantages of a forward proxy:&lt;/p>
&lt;ul>
&lt;li>Block access to certain content&lt;/li>
&lt;li>Allows access to &lt;a href="https://en.wikipedia.org/wiki/Geo-blocking" target="_blank" rel="noopener">geo-restricted&lt;/a> content&lt;/li>
&lt;li>Provides anonymity&lt;/li>
&lt;li>Avoid other browsing restrictions&lt;/li>
&lt;/ul>
&lt;p>Although proxies provide the benefits of anonymity, they can still track our personal information. Setup and maintenance of a proxy server can be costly and requires configurations.&lt;/p>
&lt;h3 id="reverse-proxy">Reverse Proxy&lt;/h3>
&lt;p>A reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients. When clients send requests to the origin server of a website, those requests are intercepted by the reverse proxy server.&lt;/p>
&lt;p>The difference between a forward and reverse proxy is subtle but important. A simplified way to sum it up would be to say that a forward proxy sits in front of a client and ensures that no origin server ever communicates directly with that specific client. On the other hand, a reverse proxy sits in front of an origin server and ensures that no client ever communicates directly with that origin server.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png" alt="reverse-proxy" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Introducing reverse proxy results in increased complexity. A single reverse proxy is a single point of failure, configuring multiple reverse proxies (i.e. a failover) further increases complexity.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;p>Here are some advantages of using a reverse proxy:&lt;/p>
&lt;ul>
&lt;li>Improved security&lt;/li>
&lt;li>Caching&lt;/li>
&lt;li>SSL encryption&lt;/li>
&lt;li>Load balancing&lt;/li>
&lt;li>Scalability and flexibility&lt;/li>
&lt;/ul>
&lt;h2 id="load-balancer-vs-reverse-proxy">Load balancer vs Reverse Proxy&lt;/h2>
&lt;p>Wait, isn&amp;rsquo;t reverse proxy similar to a load balancer? Well, no as a load balancer is useful when we have multiple servers. Often, load balancers route traffic to a set of servers serving the same function, while reverse proxies can be useful even with just one web server or application server. A reverse proxy can also act as a load balancer but not the other way around.&lt;/p>
&lt;h2 id="examples-5">Examples&lt;/h2>
&lt;p>Below are some commonly used proxy technologies:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.nginx.com" target="_blank" rel="noopener">Nginx&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.haproxy.org" target="_blank" rel="noopener">HAProxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://doc.traefik.io/traefik" target="_blank" rel="noopener">Traefik&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.envoyproxy.io" target="_blank" rel="noopener">Envoy&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="availability">Availability&lt;/h1>
&lt;p>Availability is the time a system remains operational to perform its required function in a specific period. It is a simple measure of the percentage of time that a system, service, or machine remains operational under normal conditions.&lt;/p>
&lt;h2 id="the-nines-of-availability">The Nine&amp;rsquo;s of availability&lt;/h2>
&lt;p>Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. It is generally measured in the number of 9s.&lt;/p>
&lt;p>$$
Availability = \frac{Uptime}{(Uptime + Downtime)}
$$&lt;/p>
&lt;p>If availability is 99.00% available, it is said to have &amp;ldquo;2 nines&amp;rdquo; of availability, and if it is 99.9%, it is called &amp;ldquo;3 nines&amp;rdquo;, and so on.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Availability (Percent)&lt;/th>
&lt;th>Downtime (Year)&lt;/th>
&lt;th>Downtime (Month)&lt;/th>
&lt;th>Downtime (Week)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>90% (one nine)&lt;/td>
&lt;td>36.53 days&lt;/td>
&lt;td>72 hours&lt;/td>
&lt;td>16.8 hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99% (two nines)&lt;/td>
&lt;td>3.65 days&lt;/td>
&lt;td>7.20 hours&lt;/td>
&lt;td>1.68 hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.9% (three nines)&lt;/td>
&lt;td>8.77 hours&lt;/td>
&lt;td>43.8 minutes&lt;/td>
&lt;td>10.1 minutes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.99% (four nines)&lt;/td>
&lt;td>52.6 minutes&lt;/td>
&lt;td>4.32 minutes&lt;/td>
&lt;td>1.01 minutes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.999% (five nines)&lt;/td>
&lt;td>5.25 minutes&lt;/td>
&lt;td>25.9 seconds&lt;/td>
&lt;td>6.05 seconds&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.9999% (six nines)&lt;/td>
&lt;td>31.56 seconds&lt;/td>
&lt;td>2.59 seconds&lt;/td>
&lt;td>604.8 milliseconds&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.99999% (seven nines)&lt;/td>
&lt;td>3.15 seconds&lt;/td>
&lt;td>263 milliseconds&lt;/td>
&lt;td>60.5 milliseconds&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.999999% (eight nines)&lt;/td>
&lt;td>315.6 milliseconds&lt;/td>
&lt;td>26.3 milliseconds&lt;/td>
&lt;td>6 milliseconds&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.9999999% (nine nines)&lt;/td>
&lt;td>31.6 milliseconds&lt;/td>
&lt;td>2.6 milliseconds&lt;/td>
&lt;td>0.6 milliseconds&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="availability-in-sequence-vs-parallel">Availability in Sequence vs Parallel&lt;/h2>
&lt;p>If a service consists of multiple components prone to failure, the service&amp;rsquo;s overall availability depends on whether the components are in sequence or in parallel.&lt;/p>
&lt;h3 id="sequence">Sequence&lt;/h3>
&lt;p>Overall availability decreases when two components are in sequence.&lt;/p>
&lt;p>$$
Availability \space (Total) = Availability \space (Foo) * Availability \space (Bar)
$$&lt;/p>
&lt;p>For example, if both &lt;code>Foo&lt;/code> and &lt;code>Bar&lt;/code> each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p>
&lt;h3 id="parallel">Parallel&lt;/h3>
&lt;p>Overall availability increases when two components are in parallel.&lt;/p>
&lt;p>$$
Availability \space (Total) = 1 - (1 - Availability \space (Foo)) * (1 - Availability \space (Bar))
$$&lt;/p>
&lt;p>For example, if both &lt;code>Foo&lt;/code> and &lt;code>Bar&lt;/code> each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p>
&lt;h2 id="availability-vs-reliability">Availability vs Reliability&lt;/h2>
&lt;p>If a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve high availability even with an unreliable system.&lt;/p>
&lt;h2 id="high-availability-vs-fault-tolerance">High availability vs Fault Tolerance&lt;/h2>
&lt;p>Both high availability and fault tolerance apply to methods for providing high uptime levels. However, they accomplish the objective differently.&lt;/p>
&lt;p>A fault-tolerant system has no service interruption but a significantly higher cost, while a highly available system has minimal service interruption. Fault-tolerance requires full hardware redundancy as if the main system fails, with no loss in uptime, another system should take over.&lt;/p>
&lt;h1 id="scalability">Scalability&lt;/h1>
&lt;p>Scalability is the measure of how well a system responds to changes by adding or removing resources to meet demands.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png" alt="scalability" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let&amp;rsquo;s discuss different types of scaling:&lt;/p>
&lt;h2 id="vertical-scaling">Vertical scaling&lt;/h2>
&lt;p>Vertical scaling (also known as scaling up) expands a system&amp;rsquo;s scalability by adding more power to an existing machine. In other words, vertical scaling refers to improving an application&amp;rsquo;s capability via increasing hardware capacity.&lt;/p>
&lt;h3 id="advantages-3">Advantages&lt;/h3>
&lt;ul>
&lt;li>Simple to implement&lt;/li>
&lt;li>Easier to manage&lt;/li>
&lt;li>Data consistent&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-1">Disadvantages&lt;/h3>
&lt;ul>
&lt;li>Risk of high downtime&lt;/li>
&lt;li>Harder to upgrade&lt;/li>
&lt;li>Can be a single point of failure&lt;/li>
&lt;/ul>
&lt;h2 id="horizontal-scaling">Horizontal scaling&lt;/h2>
&lt;p>Horizontal scaling (also known as scaling out) expands a system&amp;rsquo;s scale by adding more machines. It improves the performance of the server by adding more instances to the existing pool of servers, allowing the load to be distributed more evenly.&lt;/p>
&lt;h3 id="advantages-4">Advantages&lt;/h3>
&lt;ul>
&lt;li>Increased redundancy&lt;/li>
&lt;li>Better fault tolerance&lt;/li>
&lt;li>Flexible and efficient&lt;/li>
&lt;li>Easier to upgrade&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-2">Disadvantages&lt;/h3>
&lt;ul>
&lt;li>Increased complexity&lt;/li>
&lt;li>Data inconsistency&lt;/li>
&lt;li>Increased load on downstream services&lt;/li>
&lt;/ul>
&lt;h1 id="storage">Storage&lt;/h1>
&lt;p>Storage is a mechanism that enables a system to retain data, either temporarily or permanently. This topic is mostly skipped over in the context of system design, however, it is important to have a basic understanding of some common types of storage techniques that can help us fine-tune our storage components. Let&amp;rsquo;s discuss some important storage concepts:&lt;/p>
&lt;h2 id="raid">RAID&lt;/h2>
&lt;p>RAID (Redundant Array of Independent Disks) is a way of storing the same data on multiple hard disks or solid-state drives (SSDs) to protect data in the case of a drive failure.&lt;/p>
&lt;p>There are different RAID levels, however, and not all have the goal of providing redundancy. Let&amp;rsquo;s discuss some commonly used RAID levels:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>RAID 0&lt;/strong>: Also known as striping, data is split evenly across all the drives in the array.&lt;/li>
&lt;li>&lt;strong>RAID 1&lt;/strong>: Also known as mirroring, at least two drives contains the exact copy of a set of data. If a drive fails, others will still work.&lt;/li>
&lt;li>&lt;strong>RAID 5&lt;/strong>: Striping with parity. Requires the use of at least 3 drives, striping the data across multiple drives like RAID 0, but also has a parity distributed across the drives.&lt;/li>
&lt;li>&lt;strong>RAID 6&lt;/strong>: Striping with double parity. RAID 6 is like RAID 5, but the parity data are written to two drives.&lt;/li>
&lt;li>&lt;strong>RAID 10&lt;/strong>: Combines striping plus mirroring from RAID 0 and RAID 1. It provides security by mirroring all data on secondary drives while using striping across each set of drives to speed up data transfers.&lt;/li>
&lt;/ul>
&lt;h3 id="comparison">Comparison&lt;/h3>
&lt;p>Let&amp;rsquo;s compare all the features of different RAID levels:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Features&lt;/th>
&lt;th>RAID 0&lt;/th>
&lt;th>RAID 1&lt;/th>
&lt;th>RAID 5&lt;/th>
&lt;th>RAID 6&lt;/th>
&lt;th>RAID 10&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Description&lt;/td>
&lt;td>Striping&lt;/td>
&lt;td>Mirroring&lt;/td>
&lt;td>Striping with Parity&lt;/td>
&lt;td>Striping with double parity&lt;/td>
&lt;td>Striping and Mirroring&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Minimum Disks&lt;/td>
&lt;td>2&lt;/td>
&lt;td>2&lt;/td>
&lt;td>3&lt;/td>
&lt;td>4&lt;/td>
&lt;td>4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Read Performance&lt;/td>
&lt;td>High&lt;/td>
&lt;td>High&lt;/td>
&lt;td>High&lt;/td>
&lt;td>High&lt;/td>
&lt;td>High&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Write Performance&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Medium&lt;/td>
&lt;td>High&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Medium&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Cost&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>High&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Fault Tolerance&lt;/td>
&lt;td>None&lt;/td>
&lt;td>Single-drive failure&lt;/td>
&lt;td>Single-drive failure&lt;/td>
&lt;td>Two-drive failure&lt;/td>
&lt;td>Up to one disk failure in each sub-array&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Capacity Utilization&lt;/td>
&lt;td>100%&lt;/td>
&lt;td>50%&lt;/td>
&lt;td>67%-94%&lt;/td>
&lt;td>50%-80%&lt;/td>
&lt;td>50%&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="volumes">Volumes&lt;/h2>
&lt;p>Volume is a fixed amount of storage on a disk or tape. The term volume is often used as a synonym for the storage itself, but it is possible for a single disk to contain more than one volume or a volume to span more than one disk.&lt;/p>
&lt;h2 id="file-storage">File storage&lt;/h2>
&lt;p>File storage is a solution to store data as files and present it to its final users as a hierarchical directories structure. The main advantage is to provide a user-friendly solution to store and retrieve files. To locate a file in file storage, the complete path of the file is required. It is economical and easily structured and is usually found on hard drives, which means that they appear exactly the same for the user and on the hard drive.&lt;/p>
&lt;p>Example: &lt;a href="https://aws.amazon.com/efs" target="_blank" rel="noopener">Amazon EFS&lt;/a>, &lt;a href="https://azure.microsoft.com/en-in/services/storage/files" target="_blank" rel="noopener">Azure files&lt;/a>, &lt;a href="https://cloud.google.com/filestore" target="_blank" rel="noopener">Google Cloud Filestore&lt;/a>, etc.&lt;/p>
&lt;h2 id="block-storage">Block storage&lt;/h2>
&lt;p>Block storage divides data into blocks (chunks) and stores them as separate pieces. Each block of data is given a unique identifier, which allows a storage system to place the smaller pieces of data wherever it is most convenient.&lt;/p>
&lt;p>Block storage also decouples data from user environments, allowing that data to be spread across multiple environments. This creates multiple paths to the data and allows the user to retrieve it quickly. When a user or application requests data from a block storage system, the underlying storage system reassembles the data blocks and presents the data to the user or application&lt;/p>
&lt;p>Example: &lt;a href="https://aws.amazon.com/ebs" target="_blank" rel="noopener">Amazon EBS&lt;/a>.&lt;/p>
&lt;h2 id="object-storage">Object Storage&lt;/h2>
&lt;p>Object storage, which is also known as object-based storage, breaks data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems.&lt;/p>
&lt;p>Example: &lt;a href="https://aws.amazon.com/s3" target="_blank" rel="noopener">Amazon S3&lt;/a>, &lt;a href="https://azure.microsoft.com/en-in/services/storage/blobs" target="_blank" rel="noopener">Azure Blob Storage&lt;/a>, &lt;a href="https://cloud.google.com/storage" target="_blank" rel="noopener">Google Cloud Storage&lt;/a>, etc.&lt;/p>
&lt;h2 id="nas">NAS&lt;/h2>
&lt;p>A NAS (Network Attached Storage) is a storage device connected to a network that allows storage and retrieval of data from a central location for authorized network users. NAS devices are flexible, meaning that as we need additional storage, we can add to what we have. It&amp;rsquo;s faster, less expensive, and provides all the benefits of a public cloud on-site, giving us complete control.&lt;/p>
&lt;h2 id="hdfs">HDFS&lt;/h2>
&lt;p>The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. It has many similarities with existing distributed file systems.&lt;/p>
&lt;p>HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks, all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance.&lt;/p>
&lt;h1 id="databases-and-dbms">Databases and DBMS&lt;/h1>
&lt;h2 id="what-is-a-database">What is a Database?&lt;/h2>
&lt;p>A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a Database Management System (DBMS). Together, the data and the DBMS, along with the applications that are associated with them, are referred to as a database system, often shortened to just database.&lt;/p>
&lt;h2 id="what-is-dbms">What is DBMS?&lt;/h2>
&lt;p>A database typically requires a comprehensive database software program known as a Database Management System (DBMS). A DBMS serves as an interface between the database and its end-users or programs, allowing users to retrieve, update, and manage how the information is organized and optimized. A DBMS also facilitates oversight and control of databases, enabling a variety of administrative operations such as performance monitoring, tuning, and backup and recovery.&lt;/p>
&lt;h2 id="components">Components&lt;/h2>
&lt;p>Here are some common components found across different databases:&lt;/p>
&lt;h3 id="schema">Schema&lt;/h3>
&lt;p>The role of a schema is to define the shape of a data structure, and specify what kinds of data can go where. Schemas can be strictly enforced across the entire database, loosely enforced on part of the database, or they might not exist at all.&lt;/p>
&lt;h3 id="table">Table&lt;/h3>
&lt;p>Each table contains various columns just like in a spreadsheet. A table can have as meager as two columns and upwards of a hundred or more columns, depending upon the kind of information being put in the table.&lt;/p>
&lt;h3 id="column">Column&lt;/h3>
&lt;p>A column contains a set of data values of a particular type, one value for each row of the database. A column may contain text values, numbers, enums, timestamps, etc.&lt;/p>
&lt;h3 id="row">Row&lt;/h3>
&lt;p>Data in a table is recorded in rows. There can be thousands or millions of rows in a table having any particular information.&lt;/p>
&lt;h2 id="types-5">Types&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png" alt="database-types" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Below are different types of databases:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://karanpratapsingh.com/courses/system-design/sql-databases" target="_blank" rel="noopener">SQL&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://karanpratapsingh.com/courses/system-design/nosql-databases" target="_blank" rel="noopener">NoSQL&lt;/a>&lt;/strong>
&lt;ul>
&lt;li>Document&lt;/li>
&lt;li>Key-value&lt;/li>
&lt;li>Graph&lt;/li>
&lt;li>Timeseries&lt;/li>
&lt;li>Wide column&lt;/li>
&lt;li>Multi-model&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>SQL and NoSQL databases are broad topics and will be discussed separately in &lt;a href="https://karanpratapsingh.com/courses/system-design/sql-databases" target="_blank" rel="noopener">SQL databases&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/nosql-databases" target="_blank" rel="noopener">NoSQL databases&lt;/a>. Learn how they compare to each other in &lt;a href="https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases" target="_blank" rel="noopener">SQL vs NoSQL databases&lt;/a>.&lt;/p>
&lt;h2 id="challenges-1">Challenges&lt;/h2>
&lt;p>Some common challenges faced while running databases at scale:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Absorbing significant increases in data volume&lt;/strong>: The explosion of data coming in from sensors, connected machines, and dozens of other sources.&lt;/li>
&lt;li>&lt;strong>Ensuring data security&lt;/strong>: Data breaches are happening everywhere these days, it&amp;rsquo;s more important than ever to ensure that data is secure but also easily accessible to users.&lt;/li>
&lt;li>&lt;strong>Keeping up with demand&lt;/strong>: Companies need real-time access to their data to support timely decision-making and to take advantage of new opportunities.&lt;/li>
&lt;li>&lt;strong>Managing and maintaining the database and infrastructure&lt;/strong>: As databases become more complex and data volumes grow, companies are faced with the expense of hiring additional talent to manage their databases.&lt;/li>
&lt;li>&lt;strong>Removing limits on scalability&lt;/strong>: A business needs to grow if it&amp;rsquo;s going to survive, and its data management must grow along with it. But it&amp;rsquo;s very difficult to predict how much capacity the company will need, particularly with on-premises databases.&lt;/li>
&lt;li>&lt;strong>Ensuring data residency, data sovereignty, or latency requirements&lt;/strong>: Some organizations have use cases that are better suited to run on-premises. In those cases, engineered systems that are pre-configured and pre-optimized for running the database are ideal.&lt;/li>
&lt;/ul>
&lt;h1 id="sql-databases">SQL databases&lt;/h1>
&lt;p>A SQL (or relational) database is a collection of data items with pre-defined relationships between them. These items are organized as a set of tables with columns and rows. Tables are used to hold information about the objects to be represented in the database. Each column in a table holds a certain kind of data and a field stores the actual value of an attribute. The rows in the table represent a collection of related values of one object or entity.&lt;/p>
&lt;p>Each row in a table could be marked with a unique identifier called a primary key, and rows among multiple tables can be made related using foreign keys. This data can be accessed in many different ways without re-organizing the database tables themselves. SQL databases usually follow the &lt;a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid" target="_blank" rel="noopener">ACID consistency model&lt;/a>.&lt;/p>
&lt;h2 id="materialized-views">Materialized views&lt;/h2>
&lt;p>A materialized view is a pre-computed data set derived from a query specification and stored for later use. Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view. This performance difference can be significant when a query is run frequently or is sufficiently complex.&lt;/p>
&lt;p>It also enables data subsetting and improves the performance of complex queries that run on large data sets which reduces network loads. There are other uses of materialized views, but they are mostly used for performance and replication.&lt;/p>
&lt;h2 id="n1-query-problem">N+1 query problem&lt;/h2>
&lt;p>The N+1 query problem happens when the data access layer executes N additional SQL statements to fetch the same data that could have been retrieved when executing the primary SQL query. The larger the value of N, the more queries will be executed, the larger the performance impact.&lt;/p>
&lt;p>This is commonly seen in GraphQL and ORM (Object-Relational Mapping) tools and can be addressed by optimizing the SQL query or using a dataloader that batches consecutive requests and makes a single data request under the hood.&lt;/p>
&lt;h2 id="advantages-5">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some advantages of using relational databases:&lt;/p>
&lt;ul>
&lt;li>Simple and accurate&lt;/li>
&lt;li>Accessibility&lt;/li>
&lt;li>Data consistency&lt;/li>
&lt;li>Flexibility&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-3">Disadvantages&lt;/h2>
&lt;p>Below are the disadvantages of relational databases:&lt;/p>
&lt;ul>
&lt;li>Expensive to maintain&lt;/li>
&lt;li>Difficult schema evolution&lt;/li>
&lt;li>Performance hits (join, denormalization, etc.)&lt;/li>
&lt;li>Difficult to scale due to poor horizontal scalability&lt;/li>
&lt;/ul>
&lt;h2 id="examples-6">Examples&lt;/h2>
&lt;p>Here are some commonly used relational databases:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.mysql.com" target="_blank" rel="noopener">MySQL&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mariadb.org" target="_blank" rel="noopener">MariaDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/rds/aurora" target="_blank" rel="noopener">Amazon Aurora&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="nosql-databases">NoSQL databases&lt;/h1>
&lt;p>NoSQL is a broad category that includes any database that doesn&amp;rsquo;t use SQL as its primary data access language. These types of databases are also sometimes referred to as non-relational databases. Unlike in relational databases, data in a NoSQL database doesn&amp;rsquo;t have to conform to a pre-defined schema. NoSQL databases follow &lt;a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base" target="_blank" rel="noopener">BASE consistency model&lt;/a>.&lt;/p>
&lt;p>Below are different types of NoSQL databases:&lt;/p>
&lt;h3 id="document">Document&lt;/h3>
&lt;p>A document database (also known as a document-oriented database or a document store) is a database that stores information in documents. They are general-purpose databases that serve a variety of use cases for both transactional and analytical applications.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Intuitive and flexible&lt;/li>
&lt;li>Easy horizontal scaling&lt;/li>
&lt;li>Schemaless&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Disadvantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Schemaless&lt;/li>
&lt;li>Non-relational&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.mongodb.com" target="_blank" rel="noopener">MongoDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/documentdb" target="_blank" rel="noopener">Amazon DocumentDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://couchdb.apache.org" target="_blank" rel="noopener">CouchDB&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="key-value">Key-value&lt;/h3>
&lt;p>One of the simplest types of NoSQL databases, key-value databases save data as a group of key-value pairs made up of two data items each. They&amp;rsquo;re also sometimes referred to as a key-value store.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Simple and performant&lt;/li>
&lt;li>Highly scalable for high volumes of traffic&lt;/li>
&lt;li>Session management&lt;/li>
&lt;li>Optimized lookups&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Disadvantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Basic CRUD&lt;/li>
&lt;li>Values can&amp;rsquo;t be filtered&lt;/li>
&lt;li>Lacks indexing and scanning capabilities&lt;/li>
&lt;li>Not optimized for complex queries&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/dynamodb" target="_blank" rel="noopener">Amazon DynamoDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aerospike.com" target="_blank" rel="noopener">Aerospike&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="graph">Graph&lt;/h3>
&lt;p>A graph database is a NoSQL database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data instead of tables or documents.&lt;/p>
&lt;p>The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Query speed&lt;/li>
&lt;li>Agile and flexible&lt;/li>
&lt;li>Explicit data representation&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Disadvantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Complex&lt;/li>
&lt;li>No standardized query language&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Use cases&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Fraud detection&lt;/li>
&lt;li>Recommendation engines&lt;/li>
&lt;li>Social networks&lt;/li>
&lt;li>Network mapping&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://neo4j.com" target="_blank" rel="noopener">Neo4j&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.arangodb.com" target="_blank" rel="noopener">ArangoDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/neptune" target="_blank" rel="noopener">Amazon Neptune&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://janusgraph.org" target="_blank" rel="noopener">JanusGraph&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="time-series">Time series&lt;/h3>
&lt;p>A time-series database is a database optimized for time-stamped, or time series, data.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Fast insertion and retrieval&lt;/li>
&lt;li>Efficient data storage&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Use cases&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>IoT data&lt;/li>
&lt;li>Metrics analysis&lt;/li>
&lt;li>Application monitoring&lt;/li>
&lt;li>Understand financial trends&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.influxdata.com" target="_blank" rel="noopener">InfluxDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://druid.apache.org" target="_blank" rel="noopener">Apache Druid&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="wide-column">Wide column&lt;/h3>
&lt;p>Wide column databases, also known as wide column stores, are schema-agnostic. Data is stored in column families, rather than in rows and columns.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Highly scalable, can handle petabytes of data&lt;/li>
&lt;li>Ideal for real-time big data applications&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Disadvantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Expensive&lt;/li>
&lt;li>Increased write time&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Use cases&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Business analytics&lt;/li>
&lt;li>Attribute-based data storage&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://cloud.google.com/bigtable" target="_blank" rel="noopener">BigTable&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cassandra.apache.org" target="_blank" rel="noopener">Apache Cassandra&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.scylladb.com" target="_blank" rel="noopener">ScyllaDB&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="multi-model">Multi-model&lt;/h3>
&lt;p>Multi-model databases combine different database models (i.e. relational, graph, key-value, document, etc.) into a single, integrated backend. This means they can accommodate various data types, indexes, queries, and store data in more than one model.&lt;/p>
&lt;p>&lt;strong>Advantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Flexibility&lt;/li>
&lt;li>Suitable for complex projects&lt;/li>
&lt;li>Data consistent&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Disadvantages&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Complex&lt;/li>
&lt;li>Less mature&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Examples&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.arangodb.com" target="_blank" rel="noopener">ArangoDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://azure.microsoft.com/en-in/services/cosmos-db" target="_blank" rel="noopener">Azure Cosmos DB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.couchbase.com" target="_blank" rel="noopener">Couchbase&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="sql-vs-nosql-databases">SQL vs NoSQL databases&lt;/h1>
&lt;p>In the world of databases, there are two main types of solutions, SQL (relational) and NoSQL (non-relational) databases. Both of them differ in the way they were built, the kind of information they store, and how they store it. Relational databases are structured and have predefined schemas while non-relational databases are unstructured, distributed, and have a dynamic schema.&lt;/p>
&lt;h2 id="high-level-differences">High-level differences&lt;/h2>
&lt;p>Here are some high-level differences between SQL and NoSQL:&lt;/p>
&lt;h3 id="storage-1">Storage&lt;/h3>
&lt;p>SQL stores data in tables, where each row represents an entity and each column represents a data point about that entity.&lt;/p>
&lt;p>NoSQL databases have different data storage models such as key-value, graph, document, etc.&lt;/p>
&lt;h3 id="schema-1">Schema&lt;/h3>
&lt;p>In SQL, each record conforms to a fixed schema, meaning the columns must be decided and chosen before data entry and each row must have data for each column. The schema can be altered later, but it involves modifying the database using migrations.&lt;/p>
&lt;p>Whereas in NoSQL, schemas are dynamic. Fields can be added on the fly, and each &lt;em>record&lt;/em> (or equivalent) doesn&amp;rsquo;t have to contain data for each &lt;em>field&lt;/em>.&lt;/p>
&lt;h3 id="querying">Querying&lt;/h3>
&lt;p>SQL databases use SQL (structured query language) for defining and manipulating the data, which is very powerful.&lt;/p>
&lt;p>In a NoSQL database, queries are focused on a collection of documents. Different databases have different syntax for querying.&lt;/p>
&lt;h3 id="scalability-1">Scalability&lt;/h3>
&lt;p>In most common situations, SQL databases are vertically scalable, which can get very expensive. It is possible to scale a relational database across multiple servers, but this is a challenging and time-consuming process.&lt;/p>
&lt;p>On the other hand, NoSQL databases are horizontally scalable, meaning we can add more servers easily to our NoSQL database infrastructure to handle large traffic. Any cheap commodity hardware or cloud instances can host NoSQL databases, thus making it a lot more cost-effective than vertical scaling. A lot of NoSQL technologies also distribute data across servers automatically.&lt;/p>
&lt;h3 id="reliability">Reliability&lt;/h3>
&lt;p>The vast majority of relational databases are ACID compliant. So, when it comes to data reliability and a safe guarantee of performing transactions, SQL databases are still the better bet.&lt;/p>
&lt;p>Most of the NoSQL solutions sacrifice ACID compliance for performance and scalability.&lt;/p>
&lt;h2 id="reasons">Reasons&lt;/h2>
&lt;p>As always we should always pick the technology that fits the requirements better. So, let&amp;rsquo;s look at some reasons for picking SQL or NoSQL based database:&lt;/p>
&lt;p>&lt;strong>For SQL&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Structured data with strict schema&lt;/li>
&lt;li>Relational data&lt;/li>
&lt;li>Need for complex joins&lt;/li>
&lt;li>Transactions&lt;/li>
&lt;li>Lookups by index are very fast&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>For NoSQL&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Dynamic or flexible schema&lt;/li>
&lt;li>Non-relational data&lt;/li>
&lt;li>No need for complex joins&lt;/li>
&lt;li>Very data-intensive workload&lt;/li>
&lt;li>Very high throughput for IOPS&lt;/li>
&lt;/ul>
&lt;h1 id="database-replication">Database Replication&lt;/h1>
&lt;p>Replication is a process that involves sharing information to ensure consistency between redundant resources such as multiple databases, to improve reliability, fault-tolerance, or accessibility.&lt;/p>
&lt;h2 id="master-slave-replication">Master-Slave Replication&lt;/h2>
&lt;p>The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png" alt="master-slave-replication" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="advantages-6">Advantages&lt;/h3>
&lt;ul>
&lt;li>Backups of the entire database of relatively no impact on the master.&lt;/li>
&lt;li>Applications can read from the slave(s) without impacting the master.&lt;/li>
&lt;li>Slaves can be taken offline and synced back to the master without any downtime.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-4">Disadvantages&lt;/h3>
&lt;ul>
&lt;li>Replication adds more hardware and additional complexity.&lt;/li>
&lt;li>Downtime and possibly loss of data when a master fails.&lt;/li>
&lt;li>All writes also have to be made to the master in a master-slave architecture.&lt;/li>
&lt;li>The more read slaves, the more we have to replicate, which will increase replication lag.&lt;/li>
&lt;/ul>
&lt;h2 id="master-master-replication">Master-Master Replication&lt;/h2>
&lt;p>Both masters serve reads/writes and coordinate with each other. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png" alt="master-master-replication" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="advantages-7">Advantages&lt;/h3>
&lt;ul>
&lt;li>Applications can read from both masters.&lt;/li>
&lt;li>Distributes write load across both master nodes.&lt;/li>
&lt;li>Simple, automatic, and quick failover.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-5">Disadvantages&lt;/h3>
&lt;ul>
&lt;li>Not as simple as master-slave to configure and deploy.&lt;/li>
&lt;li>Either loosely consistent or have increased write latency due to synchronization.&lt;/li>
&lt;li>Conflict resolution comes into play as more write nodes are added and as latency increases.&lt;/li>
&lt;/ul>
&lt;h2 id="synchronous-vs-asynchronous-replication">Synchronous vs Asynchronous replication&lt;/h2>
&lt;p>The primary difference between synchronous and asynchronous replication is how the data is written to the replica. In synchronous replication, data is written to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized.&lt;/p>
&lt;p>In contrast, asynchronous replication copies the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis and it is more cost-effective.&lt;/p>
&lt;h1 id="indexes">Indexes&lt;/h1>
&lt;p>Indexes are well known when it comes to databases, they are used to improve the speed of data retrieval operations on the data store. An index makes the trade-offs of increased storage overhead, and slower writes (since we not only have to write the data but also have to update the index) for the benefit of faster reads. Indexes are used to quickly locate data without having to examine every row in a database table. Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access to ordered records.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png" alt="indexes" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>An index is a data structure that can be perceived as a table of contents that points us to the location where actual data lives. So when we create an index on a column of a table, we store that column and a pointer to the whole row in the index. Indexes are also used to create different views of the same data. For large data sets, this is an excellent way to specify different filters or sorting schemes without resorting to creating multiple additional copies of the data.&lt;/p>
&lt;p>One quality that database indexes can have is that they can be &lt;strong>dense&lt;/strong> or &lt;strong>sparse&lt;/strong>. Each of these index qualities comes with its own trade-offs. Let&amp;rsquo;s look at how each index type would work:&lt;/p>
&lt;h2 id="dense-index">Dense Index&lt;/h2>
&lt;p>In a dense index, an index record is created for every row of the table. Records can be located directly as each record of the index holds the search key value and the pointer to the actual record.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png" alt="dense-index" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Dense indexes require more maintenance than sparse indexes at write-time. Since every row must have an entry, the database must maintain the index on inserts, updates, and deletes. Having an entry for every row also means that dense indexes will require more memory. The benefit of a dense index is that values can be quickly found with just a binary search. Dense indexes also do not impose any ordering requirements on the data.&lt;/p>
&lt;h2 id="sparse-index">Sparse Index&lt;/h2>
&lt;p>In a sparse index, records are created only for some of the records.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png" alt="sparse-index" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Sparse indexes require less maintenance than dense indexes at write-time since they only contain a subset of the values. This lighter maintenance burden means that inserts, updates, and deletes will be faster. Having fewer entries also means that the index will use less memory. Finding data is slower since a scan across the page typically follows the binary search. Sparse indexes are also optional when working with ordered data.&lt;/p>
&lt;h1 id="normalization-and-denormalization">Normalization and Denormalization&lt;/h1>
&lt;h2 id="terms">Terms&lt;/h2>
&lt;p>Before we go any further, let&amp;rsquo;s look at some commonly used terms in normalization and denormalization.&lt;/p>
&lt;h3 id="keys">Keys&lt;/h3>
&lt;p>&lt;strong>Primary key&lt;/strong>: Column or group of columns that can be used to uniquely identify every row of the table.&lt;/p>
&lt;p>&lt;strong>Composite key&lt;/strong>: A primary key made up of multiple columns.&lt;/p>
&lt;p>&lt;strong>Super key&lt;/strong>: Set of all keys that can uniquely identify all the rows present in a table.&lt;/p>
&lt;p>&lt;strong>Candidate key&lt;/strong>: Attributes that identify rows uniquely in a table.&lt;/p>
&lt;p>&lt;strong>Foreign key&lt;/strong>: It is a reference to a primary key of another table.&lt;/p>
&lt;p>&lt;strong>Alternate key&lt;/strong>: Keys that are not primary keys are known as alternate keys.&lt;/p>
&lt;p>&lt;strong>Surrogate key&lt;/strong>: A system-generated value that uniquely identifies each entry in a table when no other column was able to hold properties of a primary key.&lt;/p>
&lt;h3 id="dependencies">Dependencies&lt;/h3>
&lt;p>&lt;strong>Partial dependency&lt;/strong>: Occurs when the primary key determines some other attributes.&lt;/p>
&lt;p>&lt;strong>Functional dependency&lt;/strong>: It is a relationship that exists between two attributes, typically between the primary key and non-key attribute within a table.&lt;/p>
&lt;p>&lt;strong>Transitive functional dependency&lt;/strong>: Occurs when some non-key attribute determines some other attribute.&lt;/p>
&lt;h3 id="anomalies">Anomalies&lt;/h3>
&lt;p>Database anomaly happens when there is a flaw in the database due to incorrect planning or storing everything in a flat database. This is generally addressed by the process of normalization.&lt;/p>
&lt;p>There are three types of database anomalies:&lt;/p>
&lt;p>&lt;strong>Insertion anomaly&lt;/strong>: Occurs when we are not able to insert certain attributes in the database without the presence of other attributes.&lt;/p>
&lt;p>&lt;strong>Update anomaly&lt;/strong>: Occurs in case of data redundancy and partial update. In other words, a correct update of the database needs other actions such as addition, deletion, or both.&lt;/p>
&lt;p>&lt;strong>Deletion anomaly&lt;/strong>: Occurs where deletion of some data requires deletion of other data.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>&lt;/p>
&lt;p>Let&amp;rsquo;s consider the following table which is not normalized:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>ID&lt;/th>
&lt;th>Name&lt;/th>
&lt;th>Role&lt;/th>
&lt;th>Team&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>Peter&lt;/td>
&lt;td>Software Engineer&lt;/td>
&lt;td>A&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>Brian&lt;/td>
&lt;td>DevOps Engineer&lt;/td>
&lt;td>B&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>Hailey&lt;/td>
&lt;td>Product Manager&lt;/td>
&lt;td>C&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>Hailey&lt;/td>
&lt;td>Product Manager&lt;/td>
&lt;td>C&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>Steve&lt;/td>
&lt;td>Frontend Engineer&lt;/td>
&lt;td>D&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Let&amp;rsquo;s imagine, we hired a new person &amp;ldquo;John&amp;rdquo; but they might not be assigned a team immediately. This will cause an &lt;em>insertion anomaly&lt;/em> as the team attribute is not yet present.&lt;/p>
&lt;p>Next, let&amp;rsquo;s say Hailey from Team C got promoted, to reflect that change in the database, we will need to update 2 rows to maintain consistency which can cause an &lt;em>update anomaly&lt;/em>.&lt;/p>
&lt;p>Finally, we would like to remove Team B but to do that we will also need to remove additional information such as name and role, this is an example of a &lt;em>deletion anomaly&lt;/em>.&lt;/p>
&lt;h2 id="normalization">Normalization&lt;/h2>
&lt;p>Normalization is the process of organizing data in a database. This includes creating tables and establishing relationships between those tables according to rules designed both to protect the data and to make the database more flexible by eliminating redundancy and inconsistent dependency.&lt;/p>
&lt;h3 id="why-do-we-need-normalization">Why do we need normalization?&lt;/h3>
&lt;p>The goal of normalization is to eliminate redundant data and ensure data is consistent. A fully normalized database allows its structure to be extended to accommodate new types of data without changing the existing structure too much. As a result, applications interacting with the database are minimally affected.&lt;/p>
&lt;h3 id="normal-forms">Normal forms&lt;/h3>
&lt;p>Normal forms are a series of guidelines to ensure that the database is normalized. Let&amp;rsquo;s discuss some essential normal forms:&lt;/p>
&lt;p>&lt;strong>1NF&lt;/strong>&lt;/p>
&lt;p>For a table to be in the first normal form (1NF), it should follow the following rules:&lt;/p>
&lt;ul>
&lt;li>Repeating groups are not permitted.&lt;/li>
&lt;li>Identify each set of related data with a primary key.&lt;/li>
&lt;li>Set of related data should have a separate table.&lt;/li>
&lt;li>Mixing data types in the same column is not permitted.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>2NF&lt;/strong>&lt;/p>
&lt;p>For a table to be in the second normal form (2NF), it should follow the following rules:&lt;/p>
&lt;ul>
&lt;li>Satisfies the first normal form (1NF).&lt;/li>
&lt;li>Should not have any partial dependency.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>3NF&lt;/strong>&lt;/p>
&lt;p>For a table to be in the third normal form (3NF), it should follow the following rules:&lt;/p>
&lt;ul>
&lt;li>Satisfies the second normal form (2NF).&lt;/li>
&lt;li>Transitive functional dependencies are not permitted.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>BCNF&lt;/strong>&lt;/p>
&lt;p>Boyce-Codd normal form (or BCNF) is a slightly stronger version of the third normal form (3NF) used to address certain types of anomalies not dealt with by 3NF as originally defined. Sometimes it is also known as the 3.5 normal form (3.5NF).&lt;/p>
&lt;p>For a table to be in the Boyce-Codd normal form (BCNF), it should follow the following rules:&lt;/p>
&lt;ul>
&lt;li>Satisfied the third normal form (3NF).&lt;/li>
&lt;li>For every functional dependency X → Y, X should be the super key.&lt;/li>
&lt;/ul>
&lt;p>&lt;em>There are more normal forms such as 4NF, 5NF, and 6NF but we won&amp;rsquo;t discuss them here. Check out this &lt;a href="https://www.youtube.com/watch?v=GFQaEYEc8_8" target="_blank" rel="noopener">amazing video&lt;/a> that goes into detail.&lt;/em>&lt;/p>
&lt;p>In a relational database, a relation is often described as &lt;em>&amp;ldquo;normalized&amp;rdquo;&lt;/em> if it meets the third normal form. Most 3NF relations are free of insertion, update, and deletion anomalies.&lt;/p>
&lt;p>As with many formal rules and specifications, real-world scenarios do not always allow for perfect compliance. If you decide to violate one of the first three rules of normalization, make sure that your application anticipates any problems that could occur, such as redundant data and inconsistent dependencies.&lt;/p>
&lt;h3 id="advantages-8">Advantages&lt;/h3>
&lt;p>Here are some advantages of normalization:&lt;/p>
&lt;ul>
&lt;li>Reduces data redundancy.&lt;/li>
&lt;li>Better data design.&lt;/li>
&lt;li>Increases data consistency.&lt;/li>
&lt;li>Enforces referential integrity.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-6">Disadvantages&lt;/h3>
&lt;p>Let&amp;rsquo;s look at some disadvantages of normalization:&lt;/p>
&lt;ul>
&lt;li>Data design is complex.&lt;/li>
&lt;li>Slower performance.&lt;/li>
&lt;li>Maintenance overhead.&lt;/li>
&lt;li>Require more joins.&lt;/li>
&lt;/ul>
&lt;h2 id="denormalization">Denormalization&lt;/h2>
&lt;p>Denormalization is a database optimization technique in which we add redundant data to one or more tables. This can help us avoid costly joins in a relational database. It attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins.&lt;/p>
&lt;p>Once data becomes distributed with techniques such as federation and sharding, managing joins across the network further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p>
&lt;p>&lt;em>Note: Denormalization does not mean reversing normalization.&lt;/em>&lt;/p>
&lt;h3 id="advantages-9">Advantages&lt;/h3>
&lt;p>Let&amp;rsquo;s look at some advantages of denormalization:&lt;/p>
&lt;ul>
&lt;li>Retrieving data is faster.&lt;/li>
&lt;li>Writing queries is easier.&lt;/li>
&lt;li>Reduction in number of tables.&lt;/li>
&lt;li>Convenient to manage.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-7">Disadvantages&lt;/h3>
&lt;p>Below are some disadvantages of denormalization:&lt;/p>
&lt;ul>
&lt;li>Expensive inserts and updates.&lt;/li>
&lt;li>Increases complexity of database design.&lt;/li>
&lt;li>Increases data redundancy.&lt;/li>
&lt;li>More chances of data inconsistency.&lt;/li>
&lt;/ul>
&lt;h1 id="acid-and-base-consistency-models">ACID and BASE consistency models&lt;/h1>
&lt;p>Let&amp;rsquo;s discuss the ACID and BASE consistency models.&lt;/p>
&lt;h2 id="acid">ACID&lt;/h2>
&lt;p>The term ACID stands for Atomicity, Consistency, Isolation, and Durability. ACID properties are used for maintaining data integrity during transaction processing.&lt;/p>
&lt;p>In order to maintain consistency before and after a transaction relational databases follow ACID properties. Let us understand these terms:&lt;/p>
&lt;h3 id="atomic">Atomic&lt;/h3>
&lt;p>All operations in a transaction succeed or every operation is rolled back.&lt;/p>
&lt;h3 id="consistent">Consistent&lt;/h3>
&lt;p>On the completion of a transaction, the database is structurally sound.&lt;/p>
&lt;h3 id="isolated">Isolated&lt;/h3>
&lt;p>Transactions do not contend with one another. Contentious access to data is moderated by the database so that transactions appear to run sequentially.&lt;/p>
&lt;h3 id="durable">Durable&lt;/h3>
&lt;p>Once the transaction has been completed and the writes and updates have been written to the disk, it will remain in the system even if a system failure occurs.&lt;/p>
&lt;h2 id="base">BASE&lt;/h2>
&lt;p>With the increasing amount of data and high availability requirements, the approach to database design has also changed dramatically. To increase the ability to scale and at the same time be highly available, we move the logic from the database to separate servers. In this way, the database becomes more independent and focused on the actual process of storing data.&lt;/p>
&lt;p>In the NoSQL database world, ACID transactions are less common as some databases have loosened the requirements for immediate consistency, data freshness, and accuracy in order to gain other benefits, like scale and resilience.&lt;/p>
&lt;p>BASE properties are much looser than ACID guarantees, but there isn&amp;rsquo;t a direct one-for-one mapping between the two consistency models. Let us understand these terms:&lt;/p>
&lt;h3 id="basic-availability">Basic Availability&lt;/h3>
&lt;p>The database appears to work most of the time.&lt;/p>
&lt;h3 id="soft-state">Soft-state&lt;/h3>
&lt;p>Stores don&amp;rsquo;t have to be write-consistent, nor do different replicas have to be mutually consistent all the time.&lt;/p>
&lt;h3 id="eventual-consistency">Eventual consistency&lt;/h3>
&lt;p>The data might not be consistent immediately but eventually, it becomes consistent. Reads in the system are still possible even though they may not give the correct response due to inconsistency.&lt;/p>
&lt;h2 id="acid-vs-base-trade-offs">ACID vs BASE Trade-offs&lt;/h2>
&lt;p>There&amp;rsquo;s no right answer to whether our application needs an ACID or a BASE consistency model. Both the models have been designed to satisfy different requirements. While choosing a database we need to keep the properties of both the models and the requirements of our application in mind.&lt;/p>
&lt;p>Given BASE&amp;rsquo;s loose consistency, developers need to be more knowledgeable and rigorous about consistent data if they choose a BASE store for their application. It&amp;rsquo;s essential to be familiar with the BASE behavior of the chosen database and work within those constraints.&lt;/p>
&lt;p>On the other hand, planning around BASE limitations can sometimes be a major disadvantage when compared to the simplicity of ACID transactions. A fully ACID database is the perfect fit for use cases where data reliability and consistency are essential.&lt;/p>
&lt;h1 id="cap-theorem">CAP Theorem&lt;/h1>
&lt;p>CAP theorem states that a distributed system can deliver only two of the three desired characteristics Consistency, Availability, and Partition tolerance (CAP).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png" alt="cap-theorem" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let&amp;rsquo;s take a detailed look at the three distributed system characteristics to which the CAP theorem refers.&lt;/p>
&lt;h3 id="consistency">Consistency&lt;/h3>
&lt;p>Consistency means that all clients see the same data at the same time, no matter which node they connect to. For this to happen, whenever data is written to one node, it must be instantly forwarded or replicated across all the nodes in the system before the write is deemed &amp;ldquo;successful&amp;rdquo;.&lt;/p>
&lt;h3 id="availability-1">Availability&lt;/h3>
&lt;p>Availability means that any client making a request for data gets a response, even if one or more nodes are down.&lt;/p>
&lt;h3 id="partition-tolerance">Partition tolerance&lt;/h3>
&lt;p>Partition tolerance means the system continues to work despite message loss or partial failure. A system that is partition-tolerant can sustain any amount of network failure that doesn&amp;rsquo;t result in a failure of the entire network. Data is sufficiently replicated across combinations of nodes and networks to keep the system up through intermittent outages.&lt;/p>
&lt;h2 id="consistency-availability-tradeoff">Consistency-Availability Tradeoff&lt;/h2>
&lt;p>We live in a physical world and can&amp;rsquo;t guarantee the stability of a network, so distributed databases must choose Partition Tolerance (P). This implies a tradeoff between Consistency (C) and Availability (A).&lt;/p>
&lt;h3 id="ca-database">CA database&lt;/h3>
&lt;p>A CA database delivers consistency and availability across all nodes. It can&amp;rsquo;t do this if there is a partition between any two nodes in the system, and therefore can&amp;rsquo;t deliver fault tolerance.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>: &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a>, &lt;a href="https://mariadb.org" target="_blank" rel="noopener">MariaDB&lt;/a>.&lt;/p>
&lt;h3 id="cp-database">CP database&lt;/h3>
&lt;p>A CP database delivers consistency and partition tolerance at the expense of availability. When a partition occurs between any two nodes, the system has to shut down the non-consistent node until the partition is resolved.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>: &lt;a href="https://www.mongodb.com" target="_blank" rel="noopener">MongoDB&lt;/a>, &lt;a href="https://hbase.apache.org" target="_blank" rel="noopener">Apache HBase&lt;/a>.&lt;/p>
&lt;h3 id="ap-database">AP database&lt;/h3>
&lt;p>An AP database delivers availability and partition tolerance at the expense of consistency. When a partition occurs, all nodes remain available but those at the wrong end of a partition might return an older version of data than others. When the partition is resolved, the AP databases typically re-syncs the nodes to repair all inconsistencies in the system.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>: &lt;a href="https://cassandra.apache.org" target="_blank" rel="noopener">Apache Cassandra&lt;/a>, &lt;a href="https://couchdb.apache.org" target="_blank" rel="noopener">CouchDB&lt;/a>.&lt;/p>
&lt;h1 id="pacelc-theorem">PACELC Theorem&lt;/h1>
&lt;p>The PACELC theorem is an extension of the CAP theorem. The CAP theorem states that in the case of network partitioning (P) in a distributed system, one has to choose between Availability (A) and Consistency (C).&lt;/p>
&lt;p>PACELC extends the CAP theorem by introducing latency (L) as an additional attribute of a distributed system. The theorem states that else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).&lt;/p>
&lt;p>&lt;em>The PACELC theorem was first described by &lt;a href="https://scholar.google.com/citations?user=zxeEF2gAAAAJ" target="_blank" rel="noopener">Daniel J. Abadi&lt;/a>.&lt;/em>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png" alt="pacelc-theorem" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>PACELC theorem was developed to address a key limitation of the CAP theorem as it makes no provision for performance or latency.&lt;/p>
&lt;p>For example, according to the CAP theorem, a database can be considered Available if a query returns a response after 30 days. Obviously, such latency would be unacceptable for any real-world application.&lt;/p>
&lt;h1 id="transactions">Transactions&lt;/h1>
&lt;p>A transaction is a series of database operations that are considered to be a &lt;em>&amp;ldquo;single unit of work&amp;rdquo;&lt;/em>. The operations in a transaction either all succeed, or they all fail. In this way, the notion of a transaction supports data integrity when part of a system fails. Not all databases choose to support ACID transactions, usually because they are prioritizing other optimizations that are hard or theoretically impossible to implement together.&lt;/p>
&lt;p>&lt;em>Usually, relational databases support ACID transactions, and non-relational databases don&amp;rsquo;t (there are exceptions).&lt;/em>&lt;/p>
&lt;h2 id="states">States&lt;/h2>
&lt;p>A transaction in a database can be in one of the following states:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png" alt="transaction-states" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="active">Active&lt;/h3>
&lt;p>In this state, the transaction is being executed. This is the initial state of every transaction.&lt;/p>
&lt;h3 id="partially-committed">Partially Committed&lt;/h3>
&lt;p>When a transaction executes its final operation, it is said to be in a partially committed state.&lt;/p>
&lt;h3 id="committed">Committed&lt;/h3>
&lt;p>If a transaction executes all its operations successfully, it is said to be committed. All its effects are now permanently established on the database system.&lt;/p>
&lt;h3 id="failed">Failed&lt;/h3>
&lt;p>The transaction is said to be in a failed state if any of the checks made by the database recovery system fails. A failed transaction can no longer proceed further.&lt;/p>
&lt;h3 id="aborted">Aborted&lt;/h3>
&lt;p>If any of the checks fail and the transaction has reached a failed state, then the recovery manager rolls back all its write operations on the database to bring the database back to its original state where it was prior to the execution of the transaction. Transactions in this state are aborted.&lt;/p>
&lt;p>The database recovery module can select one of the two operations after a transaction aborts:&lt;/p>
&lt;ul>
&lt;li>Restart the transaction&lt;/li>
&lt;li>Kill the transaction&lt;/li>
&lt;/ul>
&lt;h3 id="terminated">Terminated&lt;/h3>
&lt;p>If there isn&amp;rsquo;t any roll-back or the transaction comes from the &lt;em>committed state&lt;/em>, then the system is consistent and ready for a new transaction and the old transaction is terminated.&lt;/p>
&lt;h1 id="distributed-transactions">Distributed Transactions&lt;/h1>
&lt;p>A distributed transaction is a set of operations on data that is performed across two or more databases. It is typically coordinated across separate nodes connected by a network, but may also span multiple databases on a single server.&lt;/p>
&lt;h2 id="why-do-we-need-distributed-transactions">Why do we need distributed transactions?&lt;/h2>
&lt;p>Unlike an ACID transaction on a single database, a distributed transaction involves altering data on multiple databases. Consequently, distributed transaction processing is more complicated, because the database must coordinate the committing or rollback of the changes in a transaction as a self-contained unit.&lt;/p>
&lt;p>In other words, all the nodes must commit, or all must abort and the entire transaction rolls back. This is why we need distributed transactions.&lt;/p>
&lt;p>Now, let&amp;rsquo;s look at some popular solutions for distributed transactions:&lt;/p>
&lt;h2 id="two-phase-commit">Two-Phase commit&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png" alt="two-phase-commit" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The two-phase commit (2PC) protocol is a distributed algorithm that coordinates all the processes that participate in a distributed transaction on whether to commit or abort (roll back) the transaction.&lt;/p>
&lt;p>This protocol achieves its goal even in many cases of temporary system failure and is thus widely used. However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome.&lt;/p>
&lt;p>This protocol requires a coordinator node, which basically coordinates and oversees the transaction across different nodes. The coordinator tries to establish the consensus among a set of processes in two phases, hence the name.&lt;/p>
&lt;h3 id="phases">Phases&lt;/h3>
&lt;p>Two-phase commit consists of the following phases:&lt;/p>
&lt;p>&lt;strong>Prepare phase&lt;/strong>&lt;/p>
&lt;p>The prepare phase involves the coordinator node collecting consensus from each of the participant nodes. The transaction will be aborted unless each of the nodes responds that they&amp;rsquo;re &lt;em>prepared&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Commit phase&lt;/strong>&lt;/p>
&lt;p>If all participants respond to the coordinator that they are &lt;em>prepared&lt;/em>, then the coordinator asks all the nodes to commit the transaction. If a failure occurs, the transaction will be rolled back.&lt;/p>
&lt;h3 id="problems">Problems&lt;/h3>
&lt;p>Following problems may arise in the two-phase commit protocol:&lt;/p>
&lt;ul>
&lt;li>What if one of the nodes crashes?&lt;/li>
&lt;li>What if the coordinator itself crashes?&lt;/li>
&lt;li>It is a blocking protocol.&lt;/li>
&lt;/ul>
&lt;h2 id="three-phase-commit">Three-phase commit&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png" alt="three-phase-commit" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Three-phase commit (3PC) is an extension of the two-phase commit where the commit phase is split into two phases. This helps with the blocking problem that occurs in the two-phase commit protocol.&lt;/p>
&lt;h3 id="phases-1">Phases&lt;/h3>
&lt;p>Three-phase commit consists of the following phases:&lt;/p>
&lt;p>&lt;strong>Prepare phase&lt;/strong>&lt;/p>
&lt;p>This phase is the same as the two-phase commit.&lt;/p>
&lt;p>&lt;strong>Pre-commit phase&lt;/strong>&lt;/p>
&lt;p>Coordinator issues the pre-commit message and all the participating nodes must acknowledge it. If a participant fails to receive this message in time, then the transaction is aborted.&lt;/p>
&lt;p>&lt;strong>Commit phase&lt;/strong>&lt;/p>
&lt;p>This step is also similar to the two-phase commit protocol.&lt;/p>
&lt;h3 id="why-is-the-pre-commit-phase-helpful">Why is the Pre-commit phase helpful?&lt;/h3>
&lt;p>The pre-commit phase accomplishes the following:&lt;/p>
&lt;ul>
&lt;li>If the participant nodes are found in this phase, that means that &lt;em>every&lt;/em> participant has completed the first phase. The completion of prepare phase is guaranteed.&lt;/li>
&lt;li>Every phase can now time out and avoid indefinite waits.&lt;/li>
&lt;/ul>
&lt;h2 id="sagas">Sagas&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png" alt="sagas" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.&lt;/p>
&lt;h3 id="coordination">Coordination&lt;/h3>
&lt;p>There are two common implementation approaches:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Choreography&lt;/strong>: Each local transaction publishes domain events that trigger local transactions in other services.&lt;/li>
&lt;li>&lt;strong>Orchestration&lt;/strong>: An orchestrator tells the participants what local transactions to execute.&lt;/li>
&lt;/ul>
&lt;h3 id="problems-1">Problems&lt;/h3>
&lt;ul>
&lt;li>The Saga pattern is particularly hard to debug.&lt;/li>
&lt;li>There&amp;rsquo;s a risk of cyclic dependency between saga participants.&lt;/li>
&lt;li>Lack of participant data isolation imposes durability challenges.&lt;/li>
&lt;li>Testing is difficult because all services must be running to simulate a transaction.&lt;/li>
&lt;/ul>
&lt;h1 id="sharding">Sharding&lt;/h1>
&lt;p>Before we discuss sharding, let&amp;rsquo;s talk about data partitioning:&lt;/p>
&lt;h2 id="data-partitioning">Data Partitioning&lt;/h2>
&lt;p>Data partitioning is a technique to break up a database into many smaller parts. It is the process of splitting up a database or a table across multiple machines to improve the manageability, performance, and availability of a database.&lt;/p>
&lt;h3 id="methods">Methods&lt;/h3>
&lt;p>There are many different ways one could use to decide how to break up an application database into multiple smaller DBs. Below are three of the most popular methods used by various large-scale applications:&lt;/p>
&lt;p>&lt;strong>Horizontal Partitioning (or Sharding)&lt;/strong>&lt;/p>
&lt;p>In this strategy, we split the table data horizontally based on the range of values defined by the &lt;em>partition key&lt;/em>. It is also referred to as &lt;strong>&lt;em>database sharding&lt;/em>&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Vertical Partitioning&lt;/strong>&lt;/p>
&lt;p>In vertical partitioning, we partition the data vertically based on columns. We divide tables into relatively smaller tables with few elements, and each part is present in a separate partition.&lt;/p>
&lt;p>In this tutorial, we will specifically focus on sharding.&lt;/p>
&lt;h2 id="what-is-sharding">What is sharding?&lt;/h2>
&lt;p>Sharding is a database architecture pattern related to &lt;em>horizontal partitioning&lt;/em>, which is the practice of separating one table&amp;rsquo;s rows into multiple different tables, known as &lt;em>partitions&lt;/em> or &lt;em>shards&lt;/em>. Each partition has the same schema and columns, but also a subset of the shared data. Likewise, the data held in each is unique and independent of the data held in other partitions.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png" alt="sharding" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The justification for data sharding is that, after a certain point, it is cheaper and more feasible to scale horizontally by adding more machines than to scale it vertically by adding powerful servers. Sharding can be implemented at both application or the database level.&lt;/p>
&lt;h2 id="partitioning-criteria">Partitioning criteria&lt;/h2>
&lt;p>There are a large number of criteria available for data partitioning. Some most commonly used criteria are:&lt;/p>
&lt;h3 id="hash-based">Hash-Based&lt;/h3>
&lt;p>This strategy divides the rows into different partitions based on a hashing algorithm rather than grouping database rows based on continuous indexes.&lt;/p>
&lt;p>The disadvantage of this method is that dynamically adding/removing database servers becomes expensive.&lt;/p>
&lt;h3 id="list-based">List-Based&lt;/h3>
&lt;p>In list-based partitioning, each partition is defined and selected based on the list of values on a column rather than a set of contiguous ranges of values.&lt;/p>
&lt;h3 id="range-based">Range Based&lt;/h3>
&lt;p>Range partitioning maps data to various partitions based on ranges of values of the partitioning key. In other words, we partition the table in such a way that each partition contains rows within a given range defined by the partition key.&lt;/p>
&lt;p>Ranges should be contiguous but not overlapping, where each range specifies a non-inclusive lower and upper bound for a partition. Any partitioning key values equal to or higher than the upper bound of the range are added to the next partition.&lt;/p>
&lt;h3 id="composite">Composite&lt;/h3>
&lt;p>As the name suggests, composite partitioning partitions the data based on two or more partitioning techniques. Here we first partition the data using one technique, and then each partition is further subdivided into sub-partitions using the same or some other method.&lt;/p>
&lt;h2 id="advantages-10">Advantages&lt;/h2>
&lt;p>But why do we need sharding? Here are some advantages:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Availability&lt;/strong>: Provides logical independence to the partitioned database, ensuring the high availability of our application. Here individual partitions can be managed independently.&lt;/li>
&lt;li>&lt;strong>Scalability&lt;/strong>: Proves to increase scalability by distributing the data across multiple partitions.&lt;/li>
&lt;li>&lt;strong>Security&lt;/strong>: Helps improve the system&amp;rsquo;s security by storing sensitive and non-sensitive data in different partitions. This could provide better manageability and security to sensitive data.&lt;/li>
&lt;li>&lt;strong>Query Performance&lt;/strong>: Improves the performance of the system. Instead of querying the whole database, now the system has to query only a smaller partition.&lt;/li>
&lt;li>&lt;strong>Data Manageability&lt;/strong>: Divides tables and indexes into smaller and more manageable units.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-8">Disadvantages&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Complexity&lt;/strong>: Sharding increases the complexity of the system in general.&lt;/li>
&lt;li>&lt;strong>Joins across shards&lt;/strong>: Once a database is partitioned and spread across multiple machines it is often not feasible to perform joins that span multiple database shards. Such joins will not be performance efficient since data has to be retrieved from multiple servers.&lt;/li>
&lt;li>&lt;strong>Rebalancing&lt;/strong>: If the data distribution is not uniform or there is a lot of load on a single shard, in such cases we have to rebalance our shards so that the requests are as equally distributed among the shards as possible.&lt;/li>
&lt;/ul>
&lt;h2 id="when-to-use-sharding">When to use sharding?&lt;/h2>
&lt;p>Here are some reasons where sharding might be the right choice:&lt;/p>
&lt;ul>
&lt;li>Leveraging existing hardware instead of high-end machines.&lt;/li>
&lt;li>Maintain data in distinct geographic regions.&lt;/li>
&lt;li>Quickly scale by adding more shards.&lt;/li>
&lt;li>Better performance as each machine is under less load.&lt;/li>
&lt;li>When more concurrent connections are required.&lt;/li>
&lt;/ul>
&lt;h1 id="consistent-hashing">Consistent Hashing&lt;/h1>
&lt;p>Let&amp;rsquo;s first understand the problem we&amp;rsquo;re trying to solve.&lt;/p>
&lt;h2 id="why-do-we-need-this">Why do we need this?&lt;/h2>
&lt;p>In traditional hashing-based distribution methods, we use a hash function to hash our partition keys (i.e. request ID or IP). Then if we use the modulo against the total number of nodes (server or databases). This will give us the node where we want to route our request.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png" alt="simple-hashing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>$$
\begin{align*}
&amp;amp; Hash(key_1) \to H_1 \bmod N = Node_0 \
&amp;amp; Hash(key_2) \to H_2 \bmod N = Node_1 \
&amp;amp; Hash(key_3) \to H_3 \bmod N = Node_2 \
&amp;amp; &amp;hellip; \
&amp;amp; Hash(key_n) \to H_n \bmod N = Node_{n-1}
\end{align*}
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>key&lt;/code>: Request ID or IP.&lt;/p>
&lt;p>&lt;code>H&lt;/code>: Hash function result.&lt;/p>
&lt;p>&lt;code>N&lt;/code>: Total number of nodes.&lt;/p>
&lt;p>&lt;code>Node&lt;/code>: The node where the request will be routed.&lt;/p>
&lt;p>The problem with this is if we add or remove a node, it will cause &lt;code>N&lt;/code> to change, meaning our mapping strategy will break as the same requests will now map to a different server. As a consequence, the majority of requests will need to be redistributed which is very inefficient.&lt;/p>
&lt;p>We want to uniformly distribute requests among different nodes such that we should be able to add or remove nodes with minimal effort. Hence, we need a distribution scheme that does not depend directly on the number of nodes (or servers), so that, when adding or removing nodes, the number of keys that need to be relocated is minimized.&lt;/p>
&lt;p>Consistent hashing solves this horizontal scalability problem by ensuring that every time we scale up or down, we do not have to re-arrange all the keys or touch all the servers.&lt;/p>
&lt;p>Now that we understand the problem, let&amp;rsquo;s discuss consistent hashing in detail.&lt;/p>
&lt;h2 id="how-does-it-work">How does it work&lt;/h2>
&lt;p>Consistent Hashing is a distributed hashing scheme that operates independently of the number of nodes in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png" alt="consistent-hashing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Using consistent hashing, only &lt;code>K/N&lt;/code> data would require re-distributing.&lt;/p>
&lt;p>$$
R = K/N
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>R&lt;/code>: Data that would require re-distribution.&lt;/p>
&lt;p>&lt;code>K&lt;/code>: Number of partition keys.&lt;/p>
&lt;p>&lt;code>N&lt;/code>: Number of nodes.&lt;/p>
&lt;p>The output of the hash function is a range let&amp;rsquo;s say &lt;code>0...m-1&lt;/code> which we can represent on our hash ring. We hash the requests and distribute them on the ring depending on what the output was. Similarly, we also hash the node and distribute them on the same ring as well.&lt;/p>
&lt;p>$$
\begin{align*}
&amp;amp; Hash(key_1) = P_1 \
&amp;amp; Hash(key_2) = P_2 \
&amp;amp; Hash(key_3) = P_3 \
&amp;amp; &amp;hellip; \
&amp;amp; Hash(key_n) = P_{m-1}
\end{align*}
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>key&lt;/code>: Request/Node ID or IP.&lt;/p>
&lt;p>&lt;code>P&lt;/code>: Position on the hash ring.&lt;/p>
&lt;p>&lt;code>m&lt;/code>: Total range of the hash ring.&lt;/p>
&lt;p>Now, when the request comes in we can simply route it to the closest node in a clockwise (can be counterclockwise as well) manner. This means that if a new node is added or removed, we can use the nearest node and only a &lt;em>fraction&lt;/em> of the requests need to be re-routed.&lt;/p>
&lt;p>In theory, consistent hashing should distribute the load evenly however it doesn&amp;rsquo;t happen in practice. Usually, the load distribution is uneven and one server may end up handling the majority of the request becoming a &lt;em>hotspot&lt;/em>, essentially a bottleneck for the system. We can fix this by adding extra nodes but that can be expensive.&lt;/p>
&lt;p>Let&amp;rsquo;s see how we can address these issues.&lt;/p>
&lt;h2 id="virtual-nodes">Virtual Nodes&lt;/h2>
&lt;p>In order to ensure a more evenly distributed load, we can introduce the idea of a virtual node, sometimes also referred to as a VNode.&lt;/p>
&lt;p>Instead of assigning a single position to a node, the hash range is divided into multiple smaller ranges, and each physical node is assigned several of these smaller ranges. Each of these subranges is considered a VNode. Hence, virtual nodes are basically existing physical nodes mapped multiple times across the hash ring to minimize changes to a node&amp;rsquo;s assigned range.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png" alt="virtual-nodes" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>For this, we can use &lt;code>k&lt;/code> number of hash functions.&lt;/p>
&lt;p>$$
\begin{align*}
&amp;amp; Hash_1(key_1) = P_1 \
&amp;amp; Hash_2(key_2) = P_2 \
&amp;amp; Hash_3(key_3) = P_3 \
&amp;amp; . . . \
&amp;amp; Hash_k(key_n) = P_{m-1}
\end{align*}
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>key&lt;/code>: Request/Node ID or IP.&lt;/p>
&lt;p>&lt;code>k&lt;/code>: Number of hash functions.&lt;/p>
&lt;p>&lt;code>P&lt;/code>: Position on the hash ring.&lt;/p>
&lt;p>&lt;code>m&lt;/code>: Total range of the hash ring.&lt;/p>
&lt;p>As VNodes help spread the load more evenly across the physical nodes on the cluster by diving the hash ranges into smaller subranges, this speeds up the re-balancing process after adding or removing nodes. This also helps us reduce the probability of hotspots.&lt;/p>
&lt;h2 id="data-replication">Data replication&lt;/h2>
&lt;p>To ensure high availability and durability, consistent hashing replicates each data item on multiple &lt;code>N&lt;/code> nodes in the system where the value &lt;code>N&lt;/code> is equivalent to the &lt;em>replication factor&lt;/em>.&lt;/p>
&lt;p>The replication factor is the number of nodes that will receive the copy of the same data. In eventually consistent systems, this is done asynchronously.&lt;/p>
&lt;h2 id="advantages-11">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some advantages of consistent hashing:&lt;/p>
&lt;ul>
&lt;li>Makes rapid scaling up and down more predictable.&lt;/li>
&lt;li>Facilitates partitioning and replication across nodes.&lt;/li>
&lt;li>Enables scalability and availability.&lt;/li>
&lt;li>Reduces hotspots.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-9">Disadvantages&lt;/h2>
&lt;p>Below are some disadvantages of consistent hashing:&lt;/p>
&lt;ul>
&lt;li>Increases complexity.&lt;/li>
&lt;li>Cascading failures.&lt;/li>
&lt;li>Load distribution can still be uneven.&lt;/li>
&lt;li>Key management can be expensive when nodes transiently fail.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-7">Examples&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some examples where consistent hashing is used:&lt;/p>
&lt;ul>
&lt;li>Data partitioning in &lt;a href="https://cassandra.apache.org" target="_blank" rel="noopener">Apache Cassandra&lt;/a>.&lt;/li>
&lt;li>Load distribution across multiple storage hosts in &lt;a href="https://aws.amazon.com/dynamodb" target="_blank" rel="noopener">Amazon DynamoDB&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h1 id="database-federation">Database Federation&lt;/h1>
&lt;p>Federation (or functional partitioning) splits up databases by function. The federation architecture makes several distinct physical databases appear as one logical database to end-users.&lt;/p>
&lt;p>All of the components in a federation are tied together by one or more federal schemas that express the commonality of data throughout the federation. These federated schemas are used to specify the information that can be shared by the federation components and to provide a common basis for communication among them.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png" alt="database-federation" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Federation also provides a cohesive, unified view of data derived from multiple sources. The data sources for federated systems can include databases and various other forms of structured and unstructured data.&lt;/p>
&lt;h2 id="characteristics">Characteristics&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some key characteristics of a federated database:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Transparency&lt;/strong>: Federated database masks user differences and implementations of underlying data sources. Therefore, the users do not need to be aware of where the data is stored.&lt;/li>
&lt;li>&lt;strong>Heterogeneity&lt;/strong>: Data sources can differ in many ways. A federated database system can handle different hardware, network protocols, data models, etc.&lt;/li>
&lt;li>&lt;strong>Extensibility&lt;/strong>: New sources may be needed to meet the changing needs of the business. A good federated database system needs to make it easy to add new sources.&lt;/li>
&lt;li>&lt;strong>Autonomy&lt;/strong>: A Federated database does not change existing data sources, interfaces should remain the same.&lt;/li>
&lt;li>&lt;strong>Data integration&lt;/strong>: A federated database can integrate data from different protocols, database management systems, etc.&lt;/li>
&lt;/ul>
&lt;h2 id="advantages-12">Advantages&lt;/h2>
&lt;p>Here are some advantages of federated databases:&lt;/p>
&lt;ul>
&lt;li>Flexible data sharing.&lt;/li>
&lt;li>Autonomy among the database components.&lt;/li>
&lt;li>Access heterogeneous data in a unified way.&lt;/li>
&lt;li>No tight coupling of applications with legacy databases.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-10">Disadvantages&lt;/h2>
&lt;p>Below are some disadvantages of federated databases:&lt;/p>
&lt;ul>
&lt;li>Adds more hardware and additional complexity.&lt;/li>
&lt;li>Joining data from two databases is complex.&lt;/li>
&lt;li>Dependence on autonomous data sources.&lt;/li>
&lt;li>Query performance and scalability.&lt;/li>
&lt;/ul>
&lt;h1 id="n-tier-architecture">N-tier architecture&lt;/h1>
&lt;p>N-tier architecture divides an application into logical layers and physical tiers. Layers are a way to separate responsibilities and manage dependencies. Each layer has a specific responsibility. A higher layer can use services in a lower layer, but not the other way around.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png" alt="n-tier-architecture" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Tiers are physically separated, running on separate machines. A tier can call to another tier directly, or use asynchronous messaging. Although each layer might be hosted in its own tier, that&amp;rsquo;s not required. Several layers might be hosted on the same tier. Physically separating the tiers improves scalability and resiliency and adds latency from the additional network communication.&lt;/p>
&lt;p>An N-tier architecture can be of two types:&lt;/p>
&lt;ul>
&lt;li>In a closed layer architecture, a layer can only call the next layer immediately down.&lt;/li>
&lt;li>In an open layer architecture, a layer can call any of the layers below it.&lt;/li>
&lt;/ul>
&lt;p>A closed-layer architecture limits the dependencies between layers. However, it might create unnecessary network traffic, if one layer simply passes requests along to the next layer.&lt;/p>
&lt;h2 id="types-of-n-tier-architectures">Types of N-Tier architectures&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some examples of N-Tier architecture:&lt;/p>
&lt;h3 id="3-tier-architecture">3-Tier architecture&lt;/h3>
&lt;p>3-Tier is widely used and consists of the following different layers:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Presentation layer&lt;/strong>: Handles user interactions with the application.&lt;/li>
&lt;li>&lt;strong>Business Logic layer&lt;/strong>: Accepts the data from the application layer, validates it as per business logic and passes it to the data layer.&lt;/li>
&lt;li>&lt;strong>Data Access layer&lt;/strong>: Receives the data from the business layer and performs the necessary operation on the database.&lt;/li>
&lt;/ul>
&lt;h3 id="2-tier-architecture">2-Tier architecture&lt;/h3>
&lt;p>In this architecture, the presentation layer runs on the client and communicates with a data store. There is no business logic layer or immediate layer between client and server.&lt;/p>
&lt;h3 id="single-tier-or-1-tier-architecture">Single Tier or 1-Tier architecture&lt;/h3>
&lt;p>It is the simplest one as it is equivalent to running the application on a personal computer. All of the required components for an application to run are on a single application or server.&lt;/p>
&lt;h2 id="advantages-13">Advantages&lt;/h2>
&lt;p>Here are some advantages of using N-tier architecture:&lt;/p>
&lt;ul>
&lt;li>Can improve availability.&lt;/li>
&lt;li>Better security as layers can behave like a firewall.&lt;/li>
&lt;li>Separate tiers allow us to scale them as needed.&lt;/li>
&lt;li>Improve maintenance as different people can manage different tiers.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-11">Disadvantages&lt;/h2>
&lt;p>Below are some disadvantages of N-tier architecture:&lt;/p>
&lt;ul>
&lt;li>Increased complexity of the system as a whole.&lt;/li>
&lt;li>Increased network latency as the number of tiers increases.&lt;/li>
&lt;li>Expensive as every tier will have its own hardware cost.&lt;/li>
&lt;li>Difficult to manage network security.&lt;/li>
&lt;/ul>
&lt;h1 id="message-brokers">Message Brokers&lt;/h1>
&lt;p>A message broker is a software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to &lt;em>&amp;ldquo;talk&amp;rdquo;&lt;/em> with one another directly, even if they were written in different languages or implemented on different platforms.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png" alt="message-broker" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Message brokers can validate, store, route, and deliver messages to the appropriate destinations. They serve as intermediaries between other applications, allowing senders to issue messages without knowing where the receivers are, whether or not they are active, or how many of them there are. This facilitates the decoupling of processes and services within systems.&lt;/p>
&lt;h2 id="models">Models&lt;/h2>
&lt;p>Message brokers offer two basic message distribution patterns or messaging styles:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://karanpratapsingh.com/courses/system-design/message-queues" target="_blank" rel="noopener">Point-to-Point messaging&lt;/a>&lt;/strong>: This is the distribution pattern utilized in message queues with a one-to-one relationship between the message&amp;rsquo;s sender and receiver.&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" target="_blank" rel="noopener">Publish-subscribe messaging&lt;/a>&lt;/strong>: In this message distribution pattern, often referred to as &lt;em>&amp;ldquo;pub/sub&amp;rdquo;&lt;/em>, the producer of each message publishes it to a topic, and multiple message consumers subscribe to topics from which they want to receive messages.&lt;/li>
&lt;/ul>
&lt;p>&lt;em>We will discuss these messaging patterns in detail in the later tutorials.&lt;/em>&lt;/p>
&lt;h2 id="message-brokers-vs-event-streaming">Message brokers vs Event streaming&lt;/h2>
&lt;p>Message brokers can support two or more messaging patterns, including message queues and pub/sub, while event streaming platforms only offer pub/sub-style distribution patterns. Designed for use with high volumes of messages, event streaming platforms are readily scalable. They&amp;rsquo;re capable of ordering streams of records into categories called &lt;em>topics&lt;/em> and storing them for a predetermined amount of time. Unlike message brokers, however, event streaming platforms cannot guarantee message delivery or track which consumers have received the messages.&lt;/p>
&lt;p>Event streaming platforms offer more scalability than message brokers but fewer features that ensure fault tolerance like message resending, as well as more limited message routing and queueing capabilities.&lt;/p>
&lt;h2 id="message-brokers-vs-enterprise-service-bus-esb">Message brokers vs Enterprise Service Bus (ESB)&lt;/h2>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/enterprise-service-bus" target="_blank" rel="noopener">Enterprise Service Bus (ESB)&lt;/a> infrastructure is complex and can be challenging to integrate and expensive to maintain. It&amp;rsquo;s difficult to troubleshoot them when problems occur in production environments, they&amp;rsquo;re not easy to scale, and updating is tedious.&lt;/p>
&lt;p>Whereas message brokers are a &lt;em>&amp;ldquo;lightweight&amp;rdquo;&lt;/em> alternative to ESBs that provide similar functionality, a mechanism for inter-service communication, at a lower cost. They&amp;rsquo;re well-suited for use in the &lt;a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" target="_blank" rel="noopener">microservices architectures&lt;/a> that have become more prevalent as ESBs have fallen out of favor.&lt;/p>
&lt;h2 id="examples-8">Examples&lt;/h2>
&lt;p>Here are some commonly used message brokers:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://nats.io" target="_blank" rel="noopener">NATS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.rabbitmq.com" target="_blank" rel="noopener">RabbitMQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://activemq.apache.org" target="_blank" rel="noopener">ActiveMQ&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="message-queues">Message Queues&lt;/h1>
&lt;p>A message queue is a form of service-to-service communication that facilitates asynchronous communication. It asynchronously receives messages from producers and sends them to consumers.&lt;/p>
&lt;p>Queues are used to effectively manage requests in large-scale distributed systems. In small systems with minimal processing loads and small databases, writes can be predictably fast. However, in more complex and large systems writes can take an almost non-deterministic amount of time.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png" alt="message-queue" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="working">Working&lt;/h2>
&lt;p>Messages are stored in the queue until they are processed and deleted. Each message is processed only once by a single consumer. Here&amp;rsquo;s how it works:&lt;/p>
&lt;ul>
&lt;li>A producer publishes a job to the queue, then notifies the user of the job status.&lt;/li>
&lt;li>A consumer picks up the job from the queue, processes it, then signals that the job is complete.&lt;/li>
&lt;/ul>
&lt;h2 id="advantages-14">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some advantages of using a message queue:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Scalability&lt;/strong>: Message queues make it possible to scale precisely where we need to. When workloads peak, multiple instances of our application can add all requests to the queue without the risk of collision.&lt;/li>
&lt;li>&lt;strong>Decoupling&lt;/strong>: Message queues remove dependencies between components and significantly simplify the implementation of decoupled applications.&lt;/li>
&lt;li>&lt;strong>Performance&lt;/strong>: Message queues enable asynchronous communication, which means that the endpoints that are producing and consuming messages interact with the queue, not each other. Producers can add requests to the queue without waiting for them to be processed.&lt;/li>
&lt;li>&lt;strong>Reliability&lt;/strong>: Queues make our data persistent, and reduce the errors that happen when different parts of our system go offline.&lt;/li>
&lt;/ul>
&lt;h2 id="features-1">Features&lt;/h2>
&lt;p>Now, let&amp;rsquo;s discuss some desired features of message queues:&lt;/p>
&lt;h3 id="push-or-pull-delivery">Push or Pull Delivery&lt;/h3>
&lt;p>Most message queues provide both push and pull options for retrieving messages. Pull means continuously querying the queue for new messages. Push means that a consumer is notified when a message is available. We can also use long-polling to allow pulls to wait a specified amount of time for new messages to arrive.&lt;/p>
&lt;h3 id="fifo-first-in-first-out-queues">FIFO (First-In-First-Out) Queues&lt;/h3>
&lt;p>In these queues, the oldest (or first) entry, sometimes called the &lt;em>&amp;ldquo;head&amp;rdquo;&lt;/em> of the queue, is processed first.&lt;/p>
&lt;h3 id="schedule-or-delay-delivery">Schedule or Delay Delivery&lt;/h3>
&lt;p>Many message queues support setting a specific delivery time for a message. If we need to have a common delay for all messages, we can set up a delay queue.&lt;/p>
&lt;h3 id="at-least-once-delivery">At-Least-Once Delivery&lt;/h3>
&lt;p>Message queues may store multiple copies of messages for redundancy and high availability, and resend messages in the event of communication failures or errors to ensure they are delivered at least once.&lt;/p>
&lt;h3 id="exactly-once-delivery">Exactly-Once Delivery&lt;/h3>
&lt;p>When duplicates can&amp;rsquo;t be tolerated, FIFO (first-in-first-out) message queues will make sure that each message is delivered exactly once (and only once) by filtering out duplicates automatically.&lt;/p>
&lt;h3 id="dead-letter-queues">Dead-letter Queues&lt;/h3>
&lt;p>A dead-letter queue is a queue to which other queues can send messages that can&amp;rsquo;t be processed successfully. This makes it easy to set them aside for further inspection without blocking the queue processing or spending CPU cycles on a message that might never be consumed successfully.&lt;/p>
&lt;h3 id="ordering">Ordering&lt;/h3>
&lt;p>Most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they&amp;rsquo;re sent and that a message is delivered at least once.&lt;/p>
&lt;h3 id="poison-pill-messages">Poison-pill Messages&lt;/h3>
&lt;p>Poison pills are special messages that can be received, but not processed. They are a mechanism used in order to signal a consumer to end its work so it is no longer waiting for new inputs, and are similar to closing a socket in a client/server model.&lt;/p>
&lt;h3 id="security">Security&lt;/h3>
&lt;p>Message queues will authenticate applications that try to access the queue, this allows us to encrypt messages over the network as well as in the queue itself.&lt;/p>
&lt;h3 id="task-queues">Task Queues&lt;/h3>
&lt;p>Tasks queues receive tasks and their related data, run them, then deliver their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p>
&lt;h2 id="backpressure">Backpressure&lt;/h2>
&lt;p>If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. Backpressure can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff" target="_blank" rel="noopener">exponential backoff&lt;/a> strategy.&lt;/p>
&lt;h2 id="examples-9">Examples&lt;/h2>
&lt;p>Following are some widely used message queues:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/sqs" target="_blank" rel="noopener">Amazon SQS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.rabbitmq.com" target="_blank" rel="noopener">RabbitMQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://activemq.apache.org" target="_blank" rel="noopener">ActiveMQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zeromq.org" target="_blank" rel="noopener">ZeroMQ&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="publish-subscribe">Publish-Subscribe&lt;/h1>
&lt;p>Similar to a message queue, publish-subscribe is also a form of service-to-service communication that facilitates asynchronous communication. In a pub/sub model, any message published to a topic is pushed immediately to all the subscribers of the topic.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png" alt="publish-subscribe" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The subscribers to the message topic often perform different functions, and can each do something different with the message in parallel. The publisher doesn&amp;rsquo;t need to know who is using the information that it is broadcasting, and the subscribers don&amp;rsquo;t need to know where the message comes from. This style of messaging is a bit different than message queues, where the component that sends the message often knows the destination it is sending to.&lt;/p>
&lt;h2 id="working-1">Working&lt;/h2>
&lt;p>Unlike message queues, which batch messages until they are retrieved, message topics transfer messages with little or no queuing and push them out immediately to all subscribers. Here&amp;rsquo;s how it works:&lt;/p>
&lt;ul>
&lt;li>A message topic provides a lightweight mechanism to broadcast asynchronous event notifications and endpoints that allow software components to connect to the topic in order to send and receive those messages.&lt;/li>
&lt;li>To broadcast a message, a component called a &lt;em>publisher&lt;/em> simply pushes a message to the topic.&lt;/li>
&lt;li>All components that subscribe to the topic (known as &lt;em>subscribers&lt;/em>) will receive every message that was broadcasted.&lt;/li>
&lt;/ul>
&lt;h2 id="advantages-15">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some advantages of using publish-subscribe:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Eliminate Polling&lt;/strong>: Message topics allow instantaneous, push-based delivery, eliminating the need for message consumers to periodically check or &lt;em>&amp;ldquo;poll&amp;rdquo;&lt;/em> for new information and updates. This promotes faster response time and reduces the delivery latency which can be particularly problematic in systems where delays cannot be tolerated.&lt;/li>
&lt;li>&lt;strong>Dynamic Targeting&lt;/strong>: Pub/Sub makes the discovery of services easier, more natural, and less error-prone. Instead of maintaining a roster of peers where an application can send messages, a publisher will simply post messages to a topic. Then, any interested party will subscribe its endpoint to the topic, and start receiving these messages. Subscribers can change, upgrade, multiply or disappear and the system dynamically adjusts.&lt;/li>
&lt;li>&lt;strong>Decoupled and Independent Scaling&lt;/strong>: Publishers and subscribers are decoupled and work independently from each other, which allows us to develop and scale them independently.&lt;/li>
&lt;li>&lt;strong>Simplify Communication&lt;/strong>: The Publish-Subscribe model reduces complexity by removing all the point-to-point connections with a single connection to a message topic, which will manage subscriptions and decide what messages should be delivered to which endpoints.&lt;/li>
&lt;/ul>
&lt;h2 id="features-2">Features&lt;/h2>
&lt;p>Now, let&amp;rsquo;s discuss some desired features of publish-subscribe:&lt;/p>
&lt;h3 id="push-delivery">Push Delivery&lt;/h3>
&lt;p>Pub/Sub messaging instantly pushes asynchronous event notifications when messages are published to the message topic. Subscribers are notified when a message is available.&lt;/p>
&lt;h3 id="multiple-delivery-protocols">Multiple Delivery Protocols&lt;/h3>
&lt;p>In the Publish-Subscribe model, topics can typically connect to multiple types of endpoints, such as message queues, serverless functions, HTTP servers, etc.&lt;/p>
&lt;h3 id="fanout">Fanout&lt;/h3>
&lt;p>This scenario happens when a message is sent to a topic and then replicated and pushed to multiple endpoints. Fanout provides asynchronous event notifications which in turn allows for parallel processing.&lt;/p>
&lt;h3 id="filtering">Filtering&lt;/h3>
&lt;p>This feature empowers the subscriber to create a message filtering policy so that it will only get the notifications it is interested in, as opposed to receiving every single message posted to the topic.&lt;/p>
&lt;h3 id="durability">Durability&lt;/h3>
&lt;p>Pub/Sub messaging services often provide very high durability, and at least once delivery, by storing copies of the same message on multiple servers.&lt;/p>
&lt;h3 id="security-1">Security&lt;/h3>
&lt;p>Message topics authenticate applications that try to publish content, this allows us to use encrypted endpoints and encrypt messages in transit over the network.&lt;/p>
&lt;h2 id="examples-10">Examples&lt;/h2>
&lt;p>Here are some technologies commonly used for publish-subscribe:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/sns" target="_blank" rel="noopener">Amazon SNS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/pubsub" target="_blank" rel="noopener">Google Pub/Sub&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="enterprise-service-bus-esb">Enterprise Service Bus (ESB)&lt;/h1>
&lt;p>An Enterprise Service Bus (ESB) is an architectural pattern whereby a centralized software component performs integrations between applications. It performs transformations of data models, handles connectivity, performs message routing, converts communication protocols, and potentially manages the composition of multiple requests. The ESB can make these integrations and transformations available as a service interface for reuse by new applications.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png" alt="enterprise-service-bus" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="advantages-16">Advantages&lt;/h2>
&lt;p>In theory, a centralized ESB offers the potential to standardize and dramatically simplify communication, messaging, and integration between services across the enterprise. Here are some advantages of using an ESB:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Improved developer productivity&lt;/strong>: Enables developers to incorporate new technologies into one part of an application without touching the rest of the application.&lt;/li>
&lt;li>&lt;strong>Simpler, more cost-effective scalability&lt;/strong>: Components can be scaled independently of others.&lt;/li>
&lt;li>&lt;strong>Greater resilience&lt;/strong>: Failure of one component does not impact the others, and each microservice can adhere to its own availability requirements without risking the availability of other components in the system.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-12">Disadvantages&lt;/h2>
&lt;p>While ESBs were deployed successfully in many organizations, in many other organizations the ESB came to be seen as a bottleneck. Here are some disadvantages of using an ESB:&lt;/p>
&lt;ul>
&lt;li>Making changes or enhancements to one integration could destabilize others who use that same integration.&lt;/li>
&lt;li>A single point of failure can bring down all communications.&lt;/li>
&lt;li>Updates to the ESB often impact existing integrations, so there is significant testing required to perform any update.&lt;/li>
&lt;li>ESB is centrally managed which makes cross-team collaboration challenging.&lt;/li>
&lt;li>High configuration and maintenance complexity.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-11">Examples&lt;/h2>
&lt;p>Below are some widely used Enterprise Service Bus (ESB) technologies:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://azure.microsoft.com/en-in/services/service-bus" target="_blank" rel="noopener">Azure Service Bus&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.ibm.com/in-en/cloud/app-connect" target="_blank" rel="noopener">IBM App Connect&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://camel.apache.org" target="_blank" rel="noopener">Apache Camel&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/fuse" target="_blank" rel="noopener">Fuse ESB&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="monoliths-and-microservices">Monoliths and Microservices&lt;/h1>
&lt;h2 id="monoliths">Monoliths&lt;/h2>
&lt;p>A monolith is a self-contained and independent application. It is built as a single unit and is responsible for not just a particular task, but can perform every step needed to satisfy a business need.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png" alt="monolith" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="advantages-17">Advantages&lt;/h3>
&lt;p>Following are some advantages of monoliths:&lt;/p>
&lt;ul>
&lt;li>Simple to develop or debug.&lt;/li>
&lt;li>Fast and reliable communication.&lt;/li>
&lt;li>Easy monitoring and testing.&lt;/li>
&lt;li>Supports ACID transactions.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-13">Disadvantages&lt;/h3>
&lt;p>Some common disadvantages of monoliths are:&lt;/p>
&lt;ul>
&lt;li>Maintenance becomes hard as the codebase grows.&lt;/li>
&lt;li>Tightly coupled application, hard to extend.&lt;/li>
&lt;li>Requires commitment to a particular technology stack.&lt;/li>
&lt;li>On each update, the entire application is redeployed.&lt;/li>
&lt;li>Reduced reliability as a single bug can bring down the entire system.&lt;/li>
&lt;li>Difficult to scale or adopt new technologies.&lt;/li>
&lt;/ul>
&lt;h2 id="modular-monoliths">Modular monoliths&lt;/h2>
&lt;p>A Modular Monolith is an approach where we build and deploy a single application (that&amp;rsquo;s the &lt;em>Monolith&lt;/em> part), but we build it in a way that breaks up the code into independent modules for each of the features needed in our application.&lt;/p>
&lt;p>This approach reduces the dependencies of a module in such as way that we can enhance or change a module without affecting other modules. When done right, this can be really beneficial in the long term as it reduces the complexity that comes with maintaining a monolith as the system grows.&lt;/p>
&lt;h2 id="microservices">Microservices&lt;/h2>
&lt;p>A microservices architecture consists of a collection of small, autonomous services where each service is self-contained and should implement a single business capability within a bounded context. A bounded context is a natural division of business logic that provides an explicit boundary within which a domain model exists.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png" alt="microservices" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Each service has a separate codebase, which can be managed by a small development team. Services can be deployed independently and a team can update an existing service without rebuilding and redeploying the entire application.&lt;/p>
&lt;p>Services are responsible for persisting their own data or external state (database per service). This differs from the traditional model, where a separate data layer handles data persistence.&lt;/p>
&lt;h3 id="characteristics-1">Characteristics&lt;/h3>
&lt;p>The microservices architecture style has the following characteristics:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Loosely coupled&lt;/strong>: Services should be loosely coupled so that they can be independently deployed and scaled. This will lead to the decentralization of development teams and thus, enabling them to develop and deploy faster with minimal constraints and operational dependencies.&lt;/li>
&lt;li>&lt;strong>Small but focused&lt;/strong>: It&amp;rsquo;s about scope and responsibilities and not size, a service should be focused on a specific problem. Basically, &lt;em>&amp;ldquo;It does one thing and does it well&amp;rdquo;&lt;/em>. Ideally, they can be independent of the underlying architecture.&lt;/li>
&lt;li>&lt;strong>Built for businesses&lt;/strong>: The microservices architecture is usually organized around business capabilities and priorities.&lt;/li>
&lt;li>&lt;strong>Resilience &amp;amp; Fault tolerance&lt;/strong>: Services should be designed in such a way that they still function in case of failure or errors. In environments with independently deployable services, failure tolerance is of the highest importance.&lt;/li>
&lt;li>&lt;strong>Highly maintainable&lt;/strong>: Service should be easy to maintain and test because services that cannot be maintained will be rewritten.&lt;/li>
&lt;/ul>
&lt;h3 id="advantages-18">Advantages&lt;/h3>
&lt;p>Here are some advantages of microservices architecture:&lt;/p>
&lt;ul>
&lt;li>Loosely coupled services.&lt;/li>
&lt;li>Services can be deployed independently.&lt;/li>
&lt;li>Highly agile for multiple development teams.&lt;/li>
&lt;li>Improves fault tolerance and data isolation.&lt;/li>
&lt;li>Better scalability as each service can be scaled independently.&lt;/li>
&lt;li>Eliminates any long-term commitment to a particular technology stack.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-14">Disadvantages&lt;/h3>
&lt;p>Microservices architecture brings its own set of challenges:&lt;/p>
&lt;ul>
&lt;li>Complexity of a distributed system.&lt;/li>
&lt;li>Testing is more difficult.&lt;/li>
&lt;li>Expensive to maintain (individual servers, databases, etc.).&lt;/li>
&lt;li>Inter-service communication has its own challenges.&lt;/li>
&lt;li>Data integrity and consistency.&lt;/li>
&lt;li>Network congestion and latency.&lt;/li>
&lt;/ul>
&lt;h3 id="best-practices">Best practices&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some microservices best practices:&lt;/p>
&lt;ul>
&lt;li>Model services around the business domain.&lt;/li>
&lt;li>Services should have loose coupling and high functional cohesion.&lt;/li>
&lt;li>Isolate failures and use resiliency strategies to prevent failures within a service from cascading.&lt;/li>
&lt;li>Services should only communicate through well-designed APIs. Avoid leaking implementation details.&lt;/li>
&lt;li>Data storage should be private to the service that owns the data&lt;/li>
&lt;li>Avoid coupling between services. Causes of coupling include shared database schemas and rigid communication protocols.&lt;/li>
&lt;li>Decentralize everything. Individual teams are responsible for designing and building services. Avoid sharing code or data schemas.&lt;/li>
&lt;li>Fail fast by using a &lt;a href="https://karanpratapsingh.com/courses/system-design/circuit-breaker" target="_blank" rel="noopener">circuit breaker&lt;/a> to achieve fault tolerance.&lt;/li>
&lt;li>Ensure that the API changes are backward compatible.&lt;/li>
&lt;/ul>
&lt;h3 id="pitfalls">Pitfalls&lt;/h3>
&lt;p>Below are some common pitfalls of microservices architecture:&lt;/p>
&lt;ul>
&lt;li>Service boundaries are not based on the business domain.&lt;/li>
&lt;li>Underestimating how hard is to build a distributed system.&lt;/li>
&lt;li>Shared database or common dependencies between services.&lt;/li>
&lt;li>Lack of Business Alignment.&lt;/li>
&lt;li>Lack of clear ownership.&lt;/li>
&lt;li>Lack of idempotency.&lt;/li>
&lt;li>Trying to do everything &lt;a href="https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models" target="_blank" rel="noopener">ACID instead of BASE&lt;/a>.&lt;/li>
&lt;li>Lack of design for fault tolerance may result in cascading failures.&lt;/li>
&lt;/ul>
&lt;h2 id="beware-of-the-distributed-monolith">Beware of the distributed monolith&lt;/h2>
&lt;p>Distributed Monolith is a system that resembles the microservices architecture but is tightly coupled within itself like a monolithic application. Adopting microservices architecture comes with a lot of advantages. But while making one, there are good chances that we might end up with a distributed monolith.&lt;/p>
&lt;p>Our microservices are just a distributed monolith if any of these apply to it:&lt;/p>
&lt;ul>
&lt;li>Requires low latency communication.&lt;/li>
&lt;li>Services don&amp;rsquo;t scale easily.&lt;/li>
&lt;li>Dependency between services.&lt;/li>
&lt;li>Sharing the same resources such as databases.&lt;/li>
&lt;li>Tightly coupled systems.&lt;/li>
&lt;/ul>
&lt;p>One of the primary reasons to build an application using microservices architecture is to have scalability. Therefore, microservices should have loosely coupled services which enable every service to be independent. The distributed monolith architecture takes this away and causes most components to depend on one another, increasing design complexity.&lt;/p>
&lt;h2 id="microservices-vs-service-oriented-architecture-soa">Microservices vs Service-oriented architecture (SOA)&lt;/h2>
&lt;p>You might have seen &lt;em>Service-oriented architecture (SOA)&lt;/em> mentioned around the internet, sometimes even interchangeably with microservices, but they are different from each other and the main distinction between the two approaches comes down to &lt;em>scope&lt;/em>.&lt;/p>
&lt;p>Service-oriented architecture (SOA) defines a way to make software components reusable via service interfaces. These interfaces utilize common communication standards and focus on maximizing application service reusability whereas microservices are built as a collection of various smallest independent service units focused on team autonomy and decoupling.&lt;/p>
&lt;h2 id="why-you-dont-need-microservices">Why you don&amp;rsquo;t need microservices&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png" alt="architecture-range" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>So, you might be wondering, monoliths seem like a bad idea to begin with, why would anyone use that?&lt;/p>
&lt;p>Well, it depends. While each approach has its own advantages and disadvantages, it is advised to start with a monolith when building a new system. It is important to understand, that microservices are not a silver bullet, instead, they solve an organizational problem. Microservices architecture is about your organizational priorities and team as much as it&amp;rsquo;s about technology.&lt;/p>
&lt;p>Before making the decision to move to microservices architecture, you need to ask yourself questions like:&lt;/p>
&lt;ul>
&lt;li>&lt;em>&amp;ldquo;Is the team too large to work effectively on a shared codebase?&amp;rdquo;&lt;/em>&lt;/li>
&lt;li>&lt;em>&amp;ldquo;Are teams blocked on other teams?&amp;rdquo;&lt;/em>&lt;/li>
&lt;li>&lt;em>&amp;ldquo;Does microservices deliver clear business value for us?&amp;rdquo;&lt;/em>&lt;/li>
&lt;li>&lt;em>&amp;ldquo;Is my business mature enough to use microservices?&amp;rdquo;&lt;/em>&lt;/li>
&lt;li>&lt;em>&amp;ldquo;Is our current architecture limiting us with communication overhead?&amp;rdquo;&lt;/em>&lt;/li>
&lt;/ul>
&lt;p>If your application does not require to be broken down into microservices, you don&amp;rsquo;t need this. There is no absolute necessity that all applications should be broken down into microservices.&lt;/p>
&lt;p>We frequently draw inspiration from companies such as Netflix and their use of microservices, but we overlook the fact that we are not Netflix. They went through a lot of iterations and models before they had a market-ready solution, and this architecture became acceptable for them when they identified and solved the problem they were trying to tackle.&lt;/p>
&lt;p>That&amp;rsquo;s why it&amp;rsquo;s essential to understand in-depth if your business &lt;em>actually&lt;/em> needs microservices. What I&amp;rsquo;m trying to say is microservices are solutions to complex concerns and if your business doesn&amp;rsquo;t have complex issues, you don&amp;rsquo;t need them.&lt;/p>
&lt;h1 id="event-driven-architecture-eda">Event-Driven Architecture (EDA)&lt;/h1>
&lt;p>Event-Driven Architecture (EDA) is about using events as a way to communicate within a system. Generally, leveraging a message broker to publish and consume events asynchronously. The publisher is unaware of who is consuming an event and the consumers are unaware of each other. Event-Driven Architecture is simply a way of achieving loose coupling between services within a system.&lt;/p>
&lt;h2 id="what-is-an-event">What is an event?&lt;/h2>
&lt;p>An event is a data point that represents state changes in a system. It doesn&amp;rsquo;t specify what should happen and how the change should modify the system, it only notifies the system of a particular state change. When a user makes an action, they trigger an event.&lt;/p>
&lt;h2 id="components-1">Components&lt;/h2>
&lt;p>Event-driven architectures have three key components:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Event producers&lt;/strong>: Publishes an event to the router.&lt;/li>
&lt;li>&lt;strong>Event routers&lt;/strong>: Filters and pushes the events to consumers.&lt;/li>
&lt;li>&lt;strong>Event consumers&lt;/strong>: Uses events to reflect changes in the system.&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png" alt="event-driven-architecture" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>&lt;em>Note: Dots in the diagram represents different events in the system.&lt;/em>&lt;/p>
&lt;h2 id="patterns">Patterns&lt;/h2>
&lt;p>There are several ways to implement the event-driven architecture, and which method we use depends on the use case but here are some common examples:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas" target="_blank" rel="noopener">Sagas&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" target="_blank" rel="noopener">Publish-Subscribe&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/event-sourcing" target="_blank" rel="noopener">Event Sourcing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation" target="_blank" rel="noopener">Command and Query Responsibility Segregation (CQRS)&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;em>Note: Each of these methods is discussed separately.&lt;/em>&lt;/p>
&lt;h2 id="advantages-19">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some advantages:&lt;/p>
&lt;ul>
&lt;li>Decoupled producers and consumers.&lt;/li>
&lt;li>Highly scalable and distributed.&lt;/li>
&lt;li>Easy to add new consumers.&lt;/li>
&lt;li>Improves agility.&lt;/li>
&lt;/ul>
&lt;h2 id="challenges-2">Challenges&lt;/h2>
&lt;p>Here are some challenges of event-drive architecture:&lt;/p>
&lt;ul>
&lt;li>Guaranteed delivery.&lt;/li>
&lt;li>Error handling is difficult.&lt;/li>
&lt;li>Event-driven systems are complex in general.&lt;/li>
&lt;li>Exactly once, in-order processing of events.&lt;/li>
&lt;/ul>
&lt;h2 id="use-cases-1">Use cases&lt;/h2>
&lt;p>Below are some common use cases where event-driven architectures are beneficial:&lt;/p>
&lt;ul>
&lt;li>Metadata and metrics.&lt;/li>
&lt;li>Server and security logs.&lt;/li>
&lt;li>Integrating heterogeneous systems.&lt;/li>
&lt;li>Fanout and parallel processing.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-12">Examples&lt;/h2>
&lt;p>Here are some widely used technologies for implementing event-driven architectures:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://nats.io" target="_blank" rel="noopener">NATS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/eventbridge" target="_blank" rel="noopener">Amazon EventBridge&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/sns" target="_blank" rel="noopener">Amazon SNS&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/pubsub" target="_blank" rel="noopener">Google PubSub&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="event-sourcing">Event Sourcing&lt;/h1>
&lt;p>Instead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png" alt="event-sourcing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.&lt;/p>
&lt;h2 id="event-sourcing-vs-event-driven-architecture-eda">Event sourcing vs Event-Driven Architecture (EDA)&lt;/h2>
&lt;p>Event sourcing is seemingly constantly being confused with &lt;a href="https://karanpratapsingh.com/courses/system-design/event-driven-architecture" target="_blank" rel="noopener">Event-driven Architecture (EDA)&lt;/a>. Event-driven architecture is about using events to communicate between service boundaries. Generally, leveraging a message broker to publish and consume events asynchronously within other boundaries.&lt;/p>
&lt;p>Whereas, event sourcing is about using events as a state, which is a different approach to storing data. Rather than storing the current state, we&amp;rsquo;re instead going to be storing events. Also, event sourcing is one of the several patterns to implement an event-driven architecture.&lt;/p>
&lt;h2 id="advantages-20">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some advantages of using event sourcing:&lt;/p>
&lt;ul>
&lt;li>Excellent for real-time data reporting.&lt;/li>
&lt;li>Great for fail-safety, data can be reconstituted from the event store.&lt;/li>
&lt;li>Extremely flexible, any type of message can be stored.&lt;/li>
&lt;li>Preferred way of achieving audit logs functionality for high compliance systems.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-15">Disadvantages&lt;/h2>
&lt;p>Following are the disadvantages of event sourcing:&lt;/p>
&lt;ul>
&lt;li>Requires an extremely efficient network infrastructure.&lt;/li>
&lt;li>Requires a reliable way to control message formats, such as a schema registry.&lt;/li>
&lt;li>Different events will contain different payloads.&lt;/li>
&lt;/ul>
&lt;h1 id="command-and-query-responsibility-segregation-cqrs">Command and Query Responsibility Segregation (CQRS)&lt;/h1>
&lt;p>Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system&amp;rsquo;s actions into commands and queries. It was first described by &lt;a href="https://twitter.com/gregyoung" target="_blank" rel="noopener">Greg Young&lt;/a>.&lt;/p>
&lt;p>In CQRS, a &lt;em>command&lt;/em> is an instruction, a directive to perform a specific task. It is an intention to change something and doesn&amp;rsquo;t return a value, only an indication of success or failure. And, a &lt;em>query&lt;/em> is a request for information that doesn&amp;rsquo;t change the system&amp;rsquo;s state or cause any side effects.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png" alt="command-and-query-responsibility-segregation" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.&lt;/p>
&lt;h2 id="cqrs-with-event-sourcing">CQRS with Event Sourcing&lt;/h2>
&lt;p>The CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.&lt;/p>
&lt;p>When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.&lt;/p>
&lt;h2 id="advantages-21">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some advantages of CQRS:&lt;/p>
&lt;ul>
&lt;li>Allows independent scaling of read and write workloads.&lt;/li>
&lt;li>Easier scaling, optimizations, and architectural changes.&lt;/li>
&lt;li>Closer to business logic with loose coupling.&lt;/li>
&lt;li>The application can avoid complex joins when querying.&lt;/li>
&lt;li>Clear boundaries between the system behavior.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-16">Disadvantages&lt;/h2>
&lt;p>Below are some disadvantages of CQRS:&lt;/p>
&lt;ul>
&lt;li>More complex application design.&lt;/li>
&lt;li>Message failures or duplicate messages can occur.&lt;/li>
&lt;li>Dealing with eventual consistency is a challenge.&lt;/li>
&lt;li>Increased system maintenance efforts.&lt;/li>
&lt;/ul>
&lt;h2 id="use-cases-2">Use cases&lt;/h2>
&lt;p>Here are some scenarios where CQRS will be helpful:&lt;/p>
&lt;ul>
&lt;li>The performance of data reads must be fine-tuned separately from the performance of data writes.&lt;/li>
&lt;li>The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly.&lt;/li>
&lt;li>Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn&amp;rsquo;t affect the availability of the others.&lt;/li>
&lt;li>Better security to ensure that only the right domain entities are performing writes on the data.&lt;/li>
&lt;/ul>
&lt;h1 id="api-gateway">API Gateway&lt;/h1>
&lt;p>The API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png" alt="api-gateway" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="why-do-we-need-an-api-gateway">Why do we need an API Gateway?&lt;/h2>
&lt;p>The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management.&lt;/p>
&lt;h2 id="features-3">Features&lt;/h2>
&lt;p>Below are some desired features of an API Gateway:&lt;/p>
&lt;ul>
&lt;li>Authentication and Authorization&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/service-discovery" target="_blank" rel="noopener">Service discovery&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy" target="_blank" rel="noopener">Reverse Proxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">Caching&lt;/a>&lt;/li>
&lt;li>Security&lt;/li>
&lt;li>Retry and &lt;a href="https://karanpratapsingh.com/courses/system-design/circuit-breaker" target="_blank" rel="noopener">Circuit breaking&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">Load balancing&lt;/a>&lt;/li>
&lt;li>Logging, Tracing&lt;/li>
&lt;li>API composition&lt;/li>
&lt;li>&lt;a href="https://karanpratapsingh.com/courses/system-design/rate-limiting" target="_blank" rel="noopener">Rate limiting&lt;/a> and throttling&lt;/li>
&lt;li>Versioning&lt;/li>
&lt;li>Routing&lt;/li>
&lt;li>IP whitelisting or blacklisting&lt;/li>
&lt;/ul>
&lt;h2 id="advantages-22">Advantages&lt;/h2>
&lt;p>Let&amp;rsquo;s look at some advantages of using an API Gateway:&lt;/p>
&lt;ul>
&lt;li>Encapsulates the internal structure of an API.&lt;/li>
&lt;li>Provides a centralized view of the API.&lt;/li>
&lt;li>Simplifies the client code.&lt;/li>
&lt;li>Monitoring, analytics, tracing, and other such features.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-17">Disadvantages&lt;/h2>
&lt;p>Here are some possible disadvantages of an API Gateway:&lt;/p>
&lt;ul>
&lt;li>Possible single point of failure.&lt;/li>
&lt;li>Might impact performance.&lt;/li>
&lt;li>Can become a bottleneck if not scaled properly.&lt;/li>
&lt;li>Configuration can be challenging.&lt;/li>
&lt;/ul>
&lt;h2 id="backend-for-frontend-bff-pattern">Backend For Frontend (BFF) pattern&lt;/h2>
&lt;p>In the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by &lt;a href="https://samnewman.io" target="_blank" rel="noopener">Sam Newman&lt;/a>.&lt;/p>
&lt;p>Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png" alt="backend-for-frontend" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.&lt;/p>
&lt;p>&lt;em>&lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql" target="_blank" rel="noopener">GraphQL&lt;/a> performs really well as a backend for frontend (BFF).&lt;/em>&lt;/p>
&lt;h3 id="when-to-use-this-pattern">When to use this pattern?&lt;/h3>
&lt;p>We should consider using a Backend For Frontend (BFF) pattern when:&lt;/p>
&lt;ul>
&lt;li>A shared or general purpose backend service must be maintained with significant development overhead.&lt;/li>
&lt;li>We want to optimize the backend for the requirements of a specific client.&lt;/li>
&lt;li>Customizations are made to a general-purpose backend to accommodate multiple interfaces.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-13">Examples&lt;/h2>
&lt;p>Following are some widely used gateways technologies:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aws.amazon.com/api-gateway" target="_blank" rel="noopener">Amazon API Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/apigee" target="_blank" rel="noopener">Apigee API Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://azure.microsoft.com/en-in/services/api-management" target="_blank" rel="noopener">Azure API Gateway&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://konghq.com/kong" target="_blank" rel="noopener">Kong API Gateway&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="rest-graphql-grpc">REST, GraphQL, gRPC&lt;/h1>
&lt;p>A good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC.&lt;/p>
&lt;h2 id="whats-an-api">What&amp;rsquo;s an API?&lt;/h2>
&lt;p>Before we even get into API technologies, let&amp;rsquo;s first understand what is an API.&lt;/p>
&lt;p>API stands for Application Programming Interface. It is a set of definitions and protocols for building and integrating application software. It&amp;rsquo;s sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.&lt;/p>
&lt;p>In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.&lt;/p>
&lt;h2 id="rest">REST&lt;/h2>
&lt;p>A &lt;a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm" target="_blank" rel="noopener">REST API&lt;/a> (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by &lt;a href="https://roy.gbiv.com" target="_blank" rel="noopener">Roy Fielding&lt;/a> in the year 2000.&lt;/p>
&lt;p>&lt;em>In REST API, the fundamental unit is a resource.&lt;/em>&lt;/p>
&lt;h3 id="concepts">Concepts&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some concepts of a RESTful API.&lt;/p>
&lt;p>&lt;strong>Constraints&lt;/strong>&lt;/p>
&lt;p>In order for an API to be considered &lt;em>RESTful&lt;/em>, it has to conform to these architectural constraints:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Uniform Interface&lt;/strong>: There should be a uniform way of interacting with a given server.&lt;/li>
&lt;li>&lt;strong>Client-Server&lt;/strong>: A client-server architecture managed through HTTP.&lt;/li>
&lt;li>&lt;strong>Stateless&lt;/strong>: No client context shall be stored on the server between requests.&lt;/li>
&lt;li>&lt;strong>Cacheable&lt;/strong>: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side.&lt;/li>
&lt;li>&lt;strong>Layered system&lt;/strong>: An application architecture needs to be composed of multiple layers.&lt;/li>
&lt;li>&lt;strong>Code on demand&lt;/strong>: Return executable code to support a part of your application. &lt;em>(optional)&lt;/em>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>HTTP Verbs&lt;/strong>&lt;/p>
&lt;p>HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as &lt;em>HTTP verbs&lt;/em>. Each of them implements a different semantic, but some common features are shared by a group of them.&lt;/p>
&lt;p>Below are some commonly used HTTP verbs:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GET&lt;/strong>: Request a representation of the specified resource.&lt;/li>
&lt;li>&lt;strong>HEAD&lt;/strong>: Response is identical to a &lt;code>GET&lt;/code> request, but without the response body.&lt;/li>
&lt;li>&lt;strong>POST&lt;/strong>: Submits an entity to the specified resource, often causing a change in state or side effects on the server.&lt;/li>
&lt;li>&lt;strong>PUT&lt;/strong>: Replaces all current representations of the target resource with the request payload.&lt;/li>
&lt;li>&lt;strong>DELETE&lt;/strong>: Deletes the specified resource.&lt;/li>
&lt;li>&lt;strong>PATCH&lt;/strong>: Applies partial modifications to a resource.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>HTTP response codes&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes" target="_blank" rel="noopener">HTTP response status codes&lt;/a> indicate whether a specific HTTP request has been successfully completed.&lt;/p>
&lt;p>There are five classes defined by the standard:&lt;/p>
&lt;ul>
&lt;li>1xx - Informational responses.&lt;/li>
&lt;li>2xx - Successful responses.&lt;/li>
&lt;li>3xx - Redirection responses.&lt;/li>
&lt;li>4xx - Client error responses.&lt;/li>
&lt;li>5xx - Server error responses.&lt;/li>
&lt;/ul>
&lt;p>For example, HTTP 200 means that the request was successful.&lt;/p>
&lt;h3 id="advantages-23">Advantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some advantages of REST API:&lt;/p>
&lt;ul>
&lt;li>Simple and easy to understand.&lt;/li>
&lt;li>Flexible and portable.&lt;/li>
&lt;li>Good caching support.&lt;/li>
&lt;li>Client and server are decoupled.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-18">Disadvantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some disadvantages of REST API:&lt;/p>
&lt;ul>
&lt;li>Over-fetching of data.&lt;/li>
&lt;li>Sometimes multiple round trips to the server are required.&lt;/li>
&lt;/ul>
&lt;h3 id="use-cases-3">Use cases&lt;/h3>
&lt;p>REST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios.&lt;/p>
&lt;h3 id="example">Example&lt;/h3>
&lt;p>Here&amp;rsquo;s an example usage of a REST API that operates on a &lt;strong>users&lt;/strong> resource.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>URI&lt;/th>
&lt;th>HTTP verb&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>/users&lt;/td>
&lt;td>GET&lt;/td>
&lt;td>Get all users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>/users/{id}&lt;/td>
&lt;td>GET&lt;/td>
&lt;td>Get a user by id&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>/users&lt;/td>
&lt;td>POST&lt;/td>
&lt;td>Add a new user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>/users/{id}&lt;/td>
&lt;td>PATCH&lt;/td>
&lt;td>Update a user by id&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>/users/{id}&lt;/td>
&lt;td>DELETE&lt;/td>
&lt;td>Delete a user by id&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;em>There is so much more to learn when it comes to REST APIs, I will highly recommend looking into &lt;a href="https://en.wikipedia.org/wiki/HATEOAS" target="_blank" rel="noopener">Hypermedia as the Engine of Application State (HATEOAS)&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="graphql">GraphQL&lt;/h2>
&lt;p>&lt;a href="https://graphql.org" target="_blank" rel="noopener">GraphQL&lt;/a> is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by &lt;a href="https://engineering.fb.com" target="_blank" rel="noopener">Facebook&lt;/a> and later open-sourced in 2015.&lt;/p>
&lt;p>GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.&lt;/p>
&lt;p>&lt;em>In GraphQL, the fundamental unit is a query.&lt;/em>&lt;/p>
&lt;h3 id="concepts-1">Concepts&lt;/h3>
&lt;p>Let&amp;rsquo;s briefly discuss some key concepts in GraphQL:&lt;/p>
&lt;p>&lt;strong>Schema&lt;/strong>&lt;/p>
&lt;p>A GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.&lt;/p>
&lt;p>&lt;strong>Queries&lt;/strong>&lt;/p>
&lt;p>A query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a &lt;a href="https://graphql.org/learn/queries/#mutations" target="_blank" rel="noopener">mutation&lt;/a> which provides a way to modify server-side data.&lt;/p>
&lt;p>&lt;strong>Resolvers&lt;/strong>&lt;/p>
&lt;p>Resolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.&lt;/p>
&lt;h3 id="advantages-24">Advantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some advantages of GraphQL:&lt;/p>
&lt;ul>
&lt;li>Eliminates over-fetching of data.&lt;/li>
&lt;li>Strongly defined schema.&lt;/li>
&lt;li>Code generation support.&lt;/li>
&lt;li>Payload optimization.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-19">Disadvantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some disadvantages of GraphQL:&lt;/p>
&lt;ul>
&lt;li>Shifts complexity to server-side.&lt;/li>
&lt;li>Caching becomes hard.&lt;/li>
&lt;li>Versioning is ambiguous.&lt;/li>
&lt;li>N+1 problem.&lt;/li>
&lt;/ul>
&lt;h3 id="use-cases-4">Use cases&lt;/h3>
&lt;p>GraphQL proves to be essential in the following scenarios:&lt;/p>
&lt;ul>
&lt;li>Reducing app bandwidth usage as we can query multiple resources in a single query.&lt;/li>
&lt;li>Rapid prototyping for complex systems.&lt;/li>
&lt;li>When we are working with a graph-like data model.&lt;/li>
&lt;/ul>
&lt;h3 id="example-1">Example&lt;/h3>
&lt;p>Here&amp;rsquo;s a GraphQL schema that defines a &lt;code>User&lt;/code> type and a &lt;code>Query&lt;/code> type.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-graphql" data-lang="graphql">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">Query&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">getUser&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kd">type&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">id&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">ID&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">city&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">state&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nc">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-graphql" data-lang="graphql">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">getUser&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">name&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="py">city&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will give the following response to the client.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;getUser&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">123&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Karan&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;city&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;San Francisco&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>Learn more about GraphQL at &lt;a href="https://graphql.org" target="_blank" rel="noopener">graphql.org&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="grpc">gRPC&lt;/h2>
&lt;p>&lt;a href="https://grpc.io" target="_blank" rel="noopener">gRPC&lt;/a> is a modern open-source high-performance &lt;a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="noopener">Remote Procedure Call (RPC)&lt;/a> framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more.&lt;/p>
&lt;h3 id="concepts-2">Concepts&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some key concepts of gRPC.&lt;/p>
&lt;p>&lt;strong>Protocol buffers&lt;/strong>&lt;/p>
&lt;p>Protocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It&amp;rsquo;s like JSON, except it&amp;rsquo;s smaller and faster, and it generates native language bindings.&lt;/p>
&lt;p>&lt;strong>Service definition&lt;/strong>&lt;/p>
&lt;p>Like many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the &lt;a href="https://en.wikipedia.org/wiki/Interface_description_language" target="_blank" rel="noopener">Interface Definition Language (IDL)&lt;/a> for describing both the service interface and the structure of the payload messages.&lt;/p>
&lt;h3 id="advantages-25">Advantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some advantages of gRPC:&lt;/p>
&lt;ul>
&lt;li>Lightweight and efficient.&lt;/li>
&lt;li>High performance.&lt;/li>
&lt;li>Built-in code generation support.&lt;/li>
&lt;li>Bi-directional streaming.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-20">Disadvantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some disadvantages of gRPC:&lt;/p>
&lt;ul>
&lt;li>Relatively new compared to REST and GraphQL.&lt;/li>
&lt;li>Limited browser support.&lt;/li>
&lt;li>Steeper learning curve.&lt;/li>
&lt;li>Not human readable.&lt;/li>
&lt;/ul>
&lt;h3 id="use-cases-5">Use cases&lt;/h3>
&lt;p>Below are some good use cases for gRPC:&lt;/p>
&lt;ul>
&lt;li>Real-time communication via bi-directional streaming.&lt;/li>
&lt;li>Efficient inter-service communication in microservices.&lt;/li>
&lt;li>Low latency and high throughput communication.&lt;/li>
&lt;li>Polyglot environments.&lt;/li>
&lt;/ul>
&lt;h3 id="example-2">Example&lt;/h3>
&lt;p>Here&amp;rsquo;s a basic example of a gRPC service defined in a &lt;code>*.proto&lt;/code> file. Using this definition, we can easily code generate the &lt;code>HelloService&lt;/code> service in the programming language of our choice.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-protobuf" data-lang="protobuf">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">service&lt;/span> &lt;span class="n">HelloService&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="k">rpc&lt;/span> &lt;span class="n">SayHello&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">HelloRequest&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">returns&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">HelloResponse&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="kd">message&lt;/span> &lt;span class="nc">HelloRequest&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">greeting&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="kd">message&lt;/span> &lt;span class="nc">HelloResponse&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="n">reply&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="rest-vs-graphql-vs-grpc">REST vs GraphQL vs gRPC&lt;/h2>
&lt;p>Now that we know how these API designing techniques work, let&amp;rsquo;s compare them based on the following parameters:&lt;/p>
&lt;ul>
&lt;li>Will it cause tight coupling?&lt;/li>
&lt;li>How &lt;em>chatty&lt;/em> (distinct API calls to get needed information) are the APIs?&lt;/li>
&lt;li>What&amp;rsquo;s the performance like?&lt;/li>
&lt;li>How complex is it to integrate?&lt;/li>
&lt;li>How well does the caching work?&lt;/li>
&lt;li>Built-in tooling and code generation?&lt;/li>
&lt;li>What&amp;rsquo;s API discoverability like?&lt;/li>
&lt;li>How easy is it to version APIs?&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Coupling&lt;/th>
&lt;th>Chattiness&lt;/th>
&lt;th>Performance&lt;/th>
&lt;th>Complexity&lt;/th>
&lt;th>Caching&lt;/th>
&lt;th>Codegen&lt;/th>
&lt;th>Discoverability&lt;/th>
&lt;th>Versioning&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>REST&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Good&lt;/td>
&lt;td>Medium&lt;/td>
&lt;td>Great&lt;/td>
&lt;td>Bad&lt;/td>
&lt;td>Good&lt;/td>
&lt;td>Easy&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GraphQL&lt;/td>
&lt;td>Medium&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>Good&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Custom&lt;/td>
&lt;td>Good&lt;/td>
&lt;td>Good&lt;/td>
&lt;td>Custom&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>gRPC&lt;/td>
&lt;td>High&lt;/td>
&lt;td>Medium&lt;/td>
&lt;td>Great&lt;/td>
&lt;td>Low&lt;/td>
&lt;td>Custom&lt;/td>
&lt;td>Great&lt;/td>
&lt;td>Bad&lt;/td>
&lt;td>Hard&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="which-api-technology-is-better">Which API technology is better?&lt;/h3>
&lt;p>Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API.&lt;/p>
&lt;h1 id="long-polling-websockets-server-sent-events-sse">Long polling, WebSockets, Server-Sent Events (SSE)&lt;/h1>
&lt;p>Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let&amp;rsquo;s discuss some approaches to overcome this problem.&lt;/p>
&lt;h2 id="long-polling">Long polling&lt;/h2>
&lt;p>HTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.&lt;/p>
&lt;p>In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png" alt="long-polling" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.&lt;/p>
&lt;h3 id="working-2">Working&lt;/h3>
&lt;p>Let&amp;rsquo;s understand how long polling works:&lt;/p>
&lt;ol>
&lt;li>The client makes an initial request and waits for a response.&lt;/li>
&lt;li>The server receives the request and delays sending anything until an update is available.&lt;/li>
&lt;li>Once an update is available, the response is sent to the client.&lt;/li>
&lt;li>The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.&lt;/li>
&lt;/ol>
&lt;h3 id="advantages-26">Advantages&lt;/h3>
&lt;p>Here are some advantages of long polling:&lt;/p>
&lt;ul>
&lt;li>Easy to implement, good for small-scale projects.&lt;/li>
&lt;li>Nearly universally supported.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-21">Disadvantages&lt;/h3>
&lt;p>A major downside of long polling is that it is usually not scalable. Below are some of the other reasons:&lt;/p>
&lt;ul>
&lt;li>Creates a new connection each time, which can be intensive on the server.&lt;/li>
&lt;li>Reliable message ordering can be an issue for multiple requests.&lt;/li>
&lt;li>Increased latency as the server needs to wait for a new request.&lt;/li>
&lt;/ul>
&lt;h2 id="websockets">WebSockets&lt;/h2>
&lt;p>WebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.&lt;/p>
&lt;p>The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png" alt="websockets" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.&lt;/p>
&lt;h3 id="working-3">Working&lt;/h3>
&lt;p>Let&amp;rsquo;s understand how WebSockets work:&lt;/p>
&lt;ol>
&lt;li>The client initiates a WebSocket handshake process by sending a request.&lt;/li>
&lt;li>The request also contains an &lt;a href="https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header" target="_blank" rel="noopener">HTTP Upgrade&lt;/a> header that allows the request to switch to the WebSocket protocol (&lt;code>ws://&lt;/code>).&lt;/li>
&lt;li>The server sends a response to the client, acknowledging the WebSocket handshake request.&lt;/li>
&lt;li>A WebSocket connection will be opened once the client receives a successful handshake response.&lt;/li>
&lt;li>Now the client and server can start sending data in both directions allowing real-time communication.&lt;/li>
&lt;li>The connection is closed once the server or the client decides to close the connection.&lt;/li>
&lt;/ol>
&lt;h3 id="advantages-27">Advantages&lt;/h3>
&lt;p>Below are some advantages of WebSockets:&lt;/p>
&lt;ul>
&lt;li>Full-duplex asynchronous messaging.&lt;/li>
&lt;li>Better origin-based security model.&lt;/li>
&lt;li>Lightweight for both client and server.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-22">Disadvantages&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some disadvantages of WebSockets:&lt;/p>
&lt;ul>
&lt;li>Terminated connections aren&amp;rsquo;t automatically recovered.&lt;/li>
&lt;li>Older browsers don&amp;rsquo;t support WebSockets (becoming less relevant).&lt;/li>
&lt;/ul>
&lt;h2 id="server-sent-events-sse">Server-Sent Events (SSE)&lt;/h2>
&lt;p>Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png" alt="server-sent-events" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.&lt;/p>
&lt;h3 id="working-4">Working&lt;/h3>
&lt;p>Let&amp;rsquo;s understand how server-sent events work:&lt;/p>
&lt;ol>
&lt;li>The client makes a request to the server.&lt;/li>
&lt;li>The connection between client and server is established and it remains open.&lt;/li>
&lt;li>The server sends responses or events to the client when new data is available.&lt;/li>
&lt;/ol>
&lt;h3 id="advantages-28">Advantages&lt;/h3>
&lt;ul>
&lt;li>Simple to implement and use for both client and server.&lt;/li>
&lt;li>Supported by most browsers.&lt;/li>
&lt;li>No trouble with firewalls.&lt;/li>
&lt;/ul>
&lt;h3 id="disadvantages-23">Disadvantages&lt;/h3>
&lt;ul>
&lt;li>Unidirectional nature can be limiting.&lt;/li>
&lt;li>Limitation for the maximum number of open connections.&lt;/li>
&lt;li>Does not support binary data.&lt;/li>
&lt;/ul>
&lt;h1 id="geohashing-and-quadtrees">Geohashing and Quadtrees&lt;/h1>
&lt;h2 id="geohashing">Geohashing&lt;/h2>
&lt;p>Geohashing is a &lt;a href="https://en.wikipedia.org/wiki/Address_geocoding" target="_blank" rel="noopener">geocoding&lt;/a> method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by &lt;a href="https://twitter.com/gniemeyer" target="_blank" rel="noopener">Gustavo Niemeyer&lt;/a> in 2008.&lt;/p>
&lt;p>For example, San Francisco with coordinates &lt;code>37.7564, -122.4016&lt;/code> can be represented in geohash as &lt;code>9q8yy9mf&lt;/code>.&lt;/p>
&lt;h3 id="how-does-geohashing-work">How does Geohashing work?&lt;/h3>
&lt;p>Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png" alt="geohashing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes &lt;code>9q8yy9mf&lt;/code> and &lt;code>9q8yy9vx&lt;/code> are spatially closer as they share the prefix &lt;code>9q8yy9&lt;/code>.&lt;/p>
&lt;p>Geohashing can also be used to provide a degree of anonymity as we don&amp;rsquo;t need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.&lt;/p>
&lt;p>The cell sizes of the geohashes of different lengths are as follows:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Geohash length&lt;/th>
&lt;th>Cell width&lt;/th>
&lt;th>Cell height&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>5000 km&lt;/td>
&lt;td>5000 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>1250 km&lt;/td>
&lt;td>1250 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>156 km&lt;/td>
&lt;td>156 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>39.1 km&lt;/td>
&lt;td>19.5 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>4.89 km&lt;/td>
&lt;td>4.89 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>1.22 km&lt;/td>
&lt;td>0.61 km&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>7&lt;/td>
&lt;td>153 m&lt;/td>
&lt;td>153 m&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>38.2 m&lt;/td>
&lt;td>19.1 m&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>9&lt;/td>
&lt;td>4.77 m&lt;/td>
&lt;td>4.77 m&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10&lt;/td>
&lt;td>1.19 m&lt;/td>
&lt;td>0.596 m&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>11&lt;/td>
&lt;td>149 mm&lt;/td>
&lt;td>149 mm&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>12&lt;/td>
&lt;td>37.2 mm&lt;/td>
&lt;td>18.6 mm&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="use-cases-6">Use cases&lt;/h3>
&lt;p>Here are some common use cases for Geohashing:&lt;/p>
&lt;ul>
&lt;li>It is a simple way to represent and store a location in a database.&lt;/li>
&lt;li>It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes.&lt;/li>
&lt;li>We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.&lt;/li>
&lt;/ul>
&lt;h3 id="examples-14">Examples&lt;/h3>
&lt;p>Geohashing is widely used and it is supported by popular databases.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.mysql.com" target="_blank" rel="noopener">MySQL&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://redis.io" target="_blank" rel="noopener">Redis&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/dynamodb" target="_blank" rel="noopener">Amazon DynamoDB&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/firestore" target="_blank" rel="noopener">Google Cloud Firestore&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="quadtrees">Quadtrees&lt;/h2>
&lt;p>A quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of &lt;a href="https://en.wikipedia.org/wiki/Octree" target="_blank" rel="noopener">Octrees&lt;/a> which are used to partition three-dimensional space.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png" alt="quadtree" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="types-of-quadtrees">Types of Quadtrees&lt;/h3>
&lt;p>Quadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees:&lt;/p>
&lt;ul>
&lt;li>Point quadtrees&lt;/li>
&lt;li>Point-region (PR) quadtrees&lt;/li>
&lt;li>Polygonal map (PM) quadtrees&lt;/li>
&lt;li>Compressed quadtrees&lt;/li>
&lt;li>Edge quadtrees&lt;/li>
&lt;/ul>
&lt;h3 id="why-do-we-need-quadtrees">Why do we need Quadtrees?&lt;/h3>
&lt;p>Aren&amp;rsquo;t latitudes and longitudes enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using &lt;a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank" rel="noopener">euclidean distance&lt;/a>, for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png" alt="quadtree-subdivision" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the &lt;a href="https://en.wikipedia.org/wiki/Hilbert_curve" target="_blank" rel="noopener">Hilbert curve&lt;/a>, we can easily improve range query performance.&lt;/p>
&lt;h3 id="use-cases-7">Use cases&lt;/h3>
&lt;p>Below are some common uses of quadtrees:&lt;/p>
&lt;ul>
&lt;li>Image representation, processing, and compression.&lt;/li>
&lt;li>Spacial indexing and range queries.&lt;/li>
&lt;li>Location-based services like Google Maps, Uber, etc.&lt;/li>
&lt;li>Mesh generation and computer graphics.&lt;/li>
&lt;li>Sparse data storage.&lt;/li>
&lt;/ul>
&lt;h1 id="circuit-breaker">Circuit breaker&lt;/h1>
&lt;p>The circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png" alt="circuit-breaker" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we&amp;rsquo;ll also want some kind of monitor alert if the circuit breaker trips.&lt;/p>
&lt;h2 id="why-do-we-need-circuit-breaking">Why do we need circuit breaking?&lt;/h2>
&lt;p>It&amp;rsquo;s common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What&amp;rsquo;s worse is if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems.&lt;/p>
&lt;h2 id="states-1">States&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss circuit breaker states:&lt;/p>
&lt;h3 id="closed">Closed&lt;/h3>
&lt;p>When everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state.&lt;/p>
&lt;h3 id="open">Open&lt;/h3>
&lt;p>In this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified.&lt;/p>
&lt;h3 id="half-open">Half-open&lt;/h3>
&lt;p>In this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state.&lt;/p>
&lt;h1 id="rate-limiting">Rate Limiting&lt;/h1>
&lt;p>Rate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png" alt="rate-limiting" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="why-do-we-need-rate-limiting">Why do we need Rate Limiting?&lt;/h2>
&lt;p>Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following:&lt;/p>
&lt;ul>
&lt;li>Avoid resource starvation as a result of Denial of Service (DoS) attacks.&lt;/li>
&lt;li>Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills.&lt;/li>
&lt;li>Rate limiting can be used as defense or mitigation against some common attacks.&lt;/li>
&lt;li>For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.&lt;/li>
&lt;/ul>
&lt;h2 id="algorithms">Algorithms&lt;/h2>
&lt;p>There are various algorithms for API rate limiting, each with its advantages and disadvantages. Let&amp;rsquo;s briefly discuss some of these algorithms:&lt;/p>
&lt;h3 id="leaky-bucket">Leaky Bucket&lt;/h3>
&lt;p>Leaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked).&lt;/p>
&lt;h3 id="token-bucket">Token Bucket&lt;/h3>
&lt;p>Here we use a concept of a &lt;em>bucket&lt;/em>. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period.&lt;/p>
&lt;h3 id="fixed-window">Fixed Window&lt;/h3>
&lt;p>The system uses a window size of &lt;code>n&lt;/code> seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold.&lt;/p>
&lt;h3 id="sliding-log">Sliding Log&lt;/h3>
&lt;p>Sliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.&lt;/p>
&lt;h3 id="sliding-window">Sliding Window&lt;/h3>
&lt;p>Sliding Window is a hybrid approach that combines the fixed window algorithm&amp;rsquo;s low processing cost and the sliding log&amp;rsquo;s improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window&amp;rsquo;s request rate based on the current timestamp to smooth out bursts of traffic.&lt;/p>
&lt;h2 id="rate-limiting-in-distributed-systems">Rate Limiting in Distributed Systems&lt;/h2>
&lt;p>Rate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:&lt;/p>
&lt;h3 id="inconsistencies">Inconsistencies&lt;/h3>
&lt;p>When using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.&lt;/p>
&lt;p>The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> but this will increase latency and cause race conditions.&lt;/p>
&lt;h3 id="race-conditions">Race Conditions&lt;/h3>
&lt;p>This issue happens when we use a naive &lt;em>&amp;ldquo;get-then-set&amp;rdquo;&lt;/em> approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model&amp;rsquo;s problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.&lt;/p>
&lt;p>One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a &lt;em>&amp;ldquo;set-then-get&amp;rdquo;&lt;/em> approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.&lt;/p>
&lt;h1 id="service-discovery">Service Discovery&lt;/h1>
&lt;p>Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.&lt;/p>
&lt;h2 id="why-do-we-need-service-discovery">Why do we need Service Discovery?&lt;/h2>
&lt;p>In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.&lt;/p>
&lt;h2 id="implementations">Implementations&lt;/h2>
&lt;p>There are two main service discovery patterns:&lt;/p>
&lt;h3 id="client-side-discovery">Client-side discovery&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png" alt="client-side-service-discovery" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.&lt;/p>
&lt;h3 id="server-side-discovery">Server-side discovery&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png" alt="server-side-service-discovery" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.&lt;/p>
&lt;h2 id="service-registry">Service Registry&lt;/h2>
&lt;p>A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.&lt;/p>
&lt;h2 id="service-registration">Service Registration&lt;/h2>
&lt;p>We also need a way to obtain service information, often known as service registration. Let&amp;rsquo;s look at two possible service registration approaches:&lt;/p>
&lt;h3 id="self-registration">Self-Registration&lt;/h3>
&lt;p>When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive.&lt;/p>
&lt;h3 id="third-party-registration">Third-party Registration&lt;/h3>
&lt;p>The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.&lt;/p>
&lt;h2 id="service-mesh">Service mesh&lt;/h2>
&lt;p>Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. &lt;a href="https://istio.io/latest/about/service-mesh" target="_blank" rel="noopener">Istio&lt;/a> and &lt;a href="https://www.envoyproxy.io" target="_blank" rel="noopener">envoy&lt;/a> are some of the most commonly used service mesh technologies.&lt;/p>
&lt;h2 id="examples-15">Examples&lt;/h2>
&lt;p>Here are some commonly used service discovery infrastructure tools:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://etcd.io" target="_blank" rel="noopener">etcd&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.consul.io" target="_blank" rel="noopener">Consul&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://thrift.apache.org" target="_blank" rel="noopener">Apache Thrift&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zookeeper.apache.org" target="_blank" rel="noopener">Apache Zookeeper&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="sla-slo-sli">SLA, SLO, SLI&lt;/h1>
&lt;p>Let&amp;rsquo;s briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.&lt;/p>
&lt;h2 id="why-are-they-important">Why are they important?&lt;/h2>
&lt;p>SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.&lt;/p>
&lt;h2 id="sla">SLA&lt;/h2>
&lt;p>An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.&lt;/p>
&lt;p>&lt;em>SLAs are often written by a company&amp;rsquo;s business or legal team.&lt;/em>&lt;/p>
&lt;h2 id="slo">SLO&lt;/h2>
&lt;p>An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.&lt;/p>
&lt;h2 id="sli">SLI&lt;/h2>
&lt;p>An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI&amp;rsquo;s value must always meet or exceed the value determined by the SLO.&lt;/p>
&lt;h1 id="disaster-recovery">Disaster recovery&lt;/h1>
&lt;p>Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.&lt;/p>
&lt;p>Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.&lt;/p>
&lt;p>&lt;em>Disaster Recovery is often not actively discussed during system design interviews but it&amp;rsquo;s important to have some basic understanding of this topic. You can learn more about disaster recovery from &lt;a href="https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html" target="_blank" rel="noopener">AWS Well-Architected Framework&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="why-is-disaster-recovery-important">Why is disaster recovery important?&lt;/h2>
&lt;p>Disaster recovery can have the following benefits:&lt;/p>
&lt;ul>
&lt;li>Minimize interruption and downtime&lt;/li>
&lt;li>Limit damages&lt;/li>
&lt;li>Fast restoration&lt;/li>
&lt;li>Better customer retention&lt;/li>
&lt;/ul>
&lt;h2 id="terms-1">Terms&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some important terms relevantly for disaster recovery:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png" alt="disaster-recovery" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="rto">RTO&lt;/h3>
&lt;p>Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.&lt;/p>
&lt;h3 id="rpo">RPO&lt;/h3>
&lt;p>Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.&lt;/p>
&lt;h2 id="strategies">Strategies&lt;/h2>
&lt;p>A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.&lt;/p>
&lt;h3 id="back-up">Back-up&lt;/h3>
&lt;p>This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.&lt;/p>
&lt;h3 id="cold-site">Cold Site&lt;/h3>
&lt;p>In this type of disaster recovery, an organization sets up basic infrastructure in a second site.&lt;/p>
&lt;h3 id="hot-site">Hot site&lt;/h3>
&lt;p>A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.&lt;/p>
&lt;h1 id="virtual-machines-vms-and-containers">Virtual Machines (VMs) and Containers&lt;/h1>
&lt;p>Before we discuss virtualization vs containerization, let&amp;rsquo;s learn what are virtual machines (VMs) and Containers.&lt;/p>
&lt;h2 id="virtual-machines-vm">Virtual Machines (VM)&lt;/h2>
&lt;p>A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine&amp;rsquo;s resources from the hardware and provisions them appropriately so they can be used by the VM.&lt;/p>
&lt;p>VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.&lt;/p>
&lt;h3 id="what-is-a-hypervisor">What is a Hypervisor?&lt;/h3>
&lt;p>A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.&lt;/p>
&lt;h3 id="why-use-a-virtual-machine">Why use a Virtual Machine?&lt;/h3>
&lt;p>Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.&lt;/p>
&lt;p>A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won&amp;rsquo;t interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.&lt;/p>
&lt;h2 id="containers">Containers&lt;/h2>
&lt;p>A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.&lt;/p>
&lt;h3 id="why-do-we-need-containers">Why do we need containers?&lt;/h3>
&lt;p>Let&amp;rsquo;s discuss some advantages of using containers:&lt;/p>
&lt;p>&lt;strong>Separation of responsibility&lt;/strong>&lt;/p>
&lt;p>Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.&lt;/p>
&lt;p>&lt;strong>Workload portability&lt;/strong>&lt;/p>
&lt;p>Containers can run virtually anywhere, greatly easing development and deployment.&lt;/p>
&lt;p>&lt;strong>Application isolation&lt;/strong>&lt;/p>
&lt;p>Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.&lt;/p>
&lt;p>&lt;strong>Agile development&lt;/strong>&lt;/p>
&lt;p>Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.&lt;/p>
&lt;p>&lt;strong>Efficient operations&lt;/strong>&lt;/p>
&lt;p>Containers are lightweight and allow us to use just the computing resources we need.&lt;/p>
&lt;h2 id="virtualization-vs-containerization">Virtualization vs Containerization&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png" alt="virtualization-vs-containerization" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.&lt;/p>
&lt;p>Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.&lt;/p>
&lt;h1 id="oauth-20-and-openid-connect-oidc">OAuth 2.0 and OpenID Connect (OIDC)&lt;/h1>
&lt;h2 id="oauth-20">OAuth 2.0&lt;/h2>
&lt;p>OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user&amp;rsquo;s credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user&amp;rsquo;s data.&lt;/p>
&lt;h3 id="concepts-3">Concepts&lt;/h3>
&lt;p>The OAuth 2.0 protocol defines the following entities:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Resource Owner&lt;/strong>: The user or system that owns the protected resources and can grant access to them.&lt;/li>
&lt;li>&lt;strong>Client&lt;/strong>: The client is the system that requires access to the protected resources.&lt;/li>
&lt;li>&lt;strong>Authorization Server&lt;/strong>: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.&lt;/li>
&lt;li>&lt;strong>Resource Server&lt;/strong>: A server that protects the user&amp;rsquo;s resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.&lt;/li>
&lt;li>&lt;strong>Scopes&lt;/strong>: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.&lt;/li>
&lt;li>&lt;strong>Access Token&lt;/strong>: A piece of data that represents the authorization to access resources on behalf of the end-user.&lt;/li>
&lt;/ul>
&lt;h3 id="how-does-oauth-20-work">How does OAuth 2.0 work?&lt;/h3>
&lt;p>Let&amp;rsquo;s learn how OAuth 2.0 works:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png" alt="oauth2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol>
&lt;li>The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.&lt;/li>
&lt;li>The Authorization Server authenticates the client and verifies that the requested scopes are permitted.&lt;/li>
&lt;li>The resource owner interacts with the authorization server to grant access.&lt;/li>
&lt;li>The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.&lt;/li>
&lt;li>With the Access Token, the client can request access to the resource from the Resource Server.&lt;/li>
&lt;/ol>
&lt;h3 id="disadvantages-24">Disadvantages&lt;/h3>
&lt;p>Here are the most common disadvantages of OAuth 2.0:&lt;/p>
&lt;ul>
&lt;li>Lacks built-in security features.&lt;/li>
&lt;li>No standard implementation.&lt;/li>
&lt;li>No common set of scopes.&lt;/li>
&lt;/ul>
&lt;h2 id="openid-connect">OpenID Connect&lt;/h2>
&lt;p>OAuth 2.0 is designed only for &lt;em>authorization&lt;/em>, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.&lt;/p>
&lt;p>When an Authorization Server supports OIDC, it is sometimes called an identity provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.&lt;/p>
&lt;h3 id="concepts-4">Concepts&lt;/h3>
&lt;p>The OpenID Connect (OIDC) protocol defines the following entities:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Relying Party&lt;/strong>: The current application.&lt;/li>
&lt;li>&lt;strong>OpenID Provider&lt;/strong>: This is essentially an intermediate service that provides a one-time code to the Relying Party.&lt;/li>
&lt;li>&lt;strong>Token Endpoint&lt;/strong>: A web server that accepts the One-Time Code (OTC) and provides an access code that&amp;rsquo;s valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).&lt;/li>
&lt;li>&lt;strong>UserInfo Endpoint&lt;/strong>: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user&lt;/li>
&lt;/ul>
&lt;p>Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.&lt;/p>
&lt;h1 id="single-sign-on-sso">Single Sign-On (SSO)&lt;/h1>
&lt;p>Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.&lt;/p>
&lt;p>The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.&lt;/p>
&lt;p>Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.&lt;/p>
&lt;h2 id="components-2">Components&lt;/h2>
&lt;p>Let&amp;rsquo;s discuss some key components of Single Sign-On (SSO).&lt;/p>
&lt;h3 id="identity-provider-idp">Identity Provider (IdP)&lt;/h3>
&lt;p>User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.&lt;/p>
&lt;p>The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user&amp;rsquo;s identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.&lt;/p>
&lt;h3 id="service-provider">Service Provider&lt;/h3>
&lt;p>A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.&lt;/p>
&lt;h3 id="identity-broker">Identity Broker&lt;/h3>
&lt;p>An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.&lt;/p>
&lt;h2 id="saml">SAML&lt;/h2>
&lt;p>Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.&lt;/p>
&lt;p>SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.&lt;/p>
&lt;h2 id="how-does-sso-work">How does SSO work?&lt;/h2>
&lt;p>Now, let&amp;rsquo;s discuss how Single Sign-On works:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png" alt="sso" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol>
&lt;li>The user requests a resource from their desired application.&lt;/li>
&lt;li>The application redirects the user to the Identity Provider (IdP) for authentication.&lt;/li>
&lt;li>The user signs in with their credentials (usually, username and password).&lt;/li>
&lt;li>Identity Provider (IdP) sends a Single Sign-On response back to the client application.&lt;/li>
&lt;li>The application grants access to the user.&lt;/li>
&lt;/ol>
&lt;h2 id="saml-vs-oauth-20-and-openid-connect-oidc">SAML vs OAuth 2.0 and OpenID Connect (OIDC)&lt;/h2>
&lt;p>There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.&lt;/p>
&lt;p>OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.&lt;/p>
&lt;p>OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.&lt;/p>
&lt;p>OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.&lt;/p>
&lt;p>&lt;em>Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience.&lt;/em>&lt;/p>
&lt;h2 id="advantages-29">Advantages&lt;/h2>
&lt;p>Following are the benefits of using Single Sign-On:&lt;/p>
&lt;ul>
&lt;li>Ease of use as users only need to remember one set of credentials.&lt;/li>
&lt;li>Ease of access without having to go through a lengthy authorization process.&lt;/li>
&lt;li>Enforced security and compliance to protect sensitive data.&lt;/li>
&lt;li>Simplifying the management with reduced IT support cost and admin time.&lt;/li>
&lt;/ul>
&lt;h2 id="disadvantages-25">Disadvantages&lt;/h2>
&lt;p>Here are some disadvantages of Single Sign-On:&lt;/p>
&lt;ul>
&lt;li>Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.&lt;/li>
&lt;li>The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.&lt;/li>
&lt;/ul>
&lt;h2 id="examples-16">Examples&lt;/h2>
&lt;p>These are some commonly used Identity Providers (IdP):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.okta.com" target="_blank" rel="noopener">Okta&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cloud.google.com/architecture/identity/single-sign-on" target="_blank" rel="noopener">Google&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://auth0.com" target="_blank" rel="noopener">Auth0&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.onelogin.com" target="_blank" rel="noopener">OneLogin&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="ssl-tls-mtls">SSL, TLS, mTLS&lt;/h1>
&lt;p>Let&amp;rsquo;s briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a &lt;em>&amp;ldquo;big picture&amp;rdquo;&lt;/em> system design perspective, this topic is not very important but still good to know about.&lt;/p>
&lt;h2 id="ssl">SSL&lt;/h2>
&lt;p>SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).&lt;/p>
&lt;h3 id="why-is-it-called-an-ssl-certificate-if-it-is-deprecated">Why is it called an SSL certificate if it is deprecated?&lt;/h3>
&lt;p>Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.&lt;/p>
&lt;h3 id="why-was-ssl-so-important">Why was SSL so important?&lt;/h3>
&lt;p>Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.&lt;/p>
&lt;h2 id="tls">TLS&lt;/h2>
&lt;p>Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.&lt;/p>
&lt;p>There are three main components to what the TLS protocol accomplishes:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Encryption&lt;/strong>: hides the data being transferred from third parties.&lt;/li>
&lt;li>&lt;strong>Authentication&lt;/strong>: ensures that the parties exchanging information are who they claim to be.&lt;/li>
&lt;li>&lt;strong>Integrity&lt;/strong>: verifies that the data has not been forged or tampered with.&lt;/li>
&lt;/ul>
&lt;h2 id="mtls">mTLS&lt;/h2>
&lt;p>Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.&lt;/p>
&lt;h3 id="why-use-mtls">Why use mTLS?&lt;/h3>
&lt;p>mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization&amp;rsquo;s network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.&lt;/p>
&lt;p>Nowadays, mTLS is commonly used by microservices or distributed systems in a &lt;a href="https://en.wikipedia.org/wiki/Zero_trust_security_model" target="_blank" rel="noopener">zero trust security model&lt;/a> to verify each other.&lt;/p>
&lt;h1 id="system-design-interviews">System Design Interviews&lt;/h1>
&lt;p>System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they&amp;rsquo;re not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.&lt;/p>
&lt;p>Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who&amp;rsquo;s new in the industry. As a result, it&amp;rsquo;s hard to come up with a single strategy that will help us stay organized during the interview.&lt;/p>
&lt;p>Let&amp;rsquo;s look at some common strategies for the system design interviews:&lt;/p>
&lt;h2 id="requirements-clarifications">Requirements clarifications&lt;/h2>
&lt;p>System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:&lt;/p>
&lt;h3 id="functional-requirements">Functional requirements&lt;/h3>
&lt;p>These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What are the features that we need to design for this system?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What are the edge cases we need to consider, if any, in our design?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements">Non-functional requirements&lt;/h3>
&lt;p>These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Each request should be processed with the minimum latency&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;System should be highly available&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements">Extended requirements&lt;/h3>
&lt;p>These are basically &amp;ldquo;nice to have&amp;rdquo; requirements that might be out of the scope of the system.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Our system should record metrics and analytics&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Service health and performance monitoring?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints">Estimation and Constraints&lt;/h2>
&lt;p>Estimate the scale of the system we&amp;rsquo;re going to design. It is important to ask questions such as:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What is the desired scale that this system will need to handle?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What is the read/write ratio of our system?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How many requests per second?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How much storage will be needed?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>These questions will help us scale our design later.&lt;/p>
&lt;h2 id="data-model-design">Data model design&lt;/h2>
&lt;p>Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them.&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What are the different entities in the system?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What are the relationships between these entities?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How many tables do we need?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Is NoSQL a better choice here?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h2 id="api-design">API design&lt;/h2>
&lt;p>Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don&amp;rsquo;t have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">createUser&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">name&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">email&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">User&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.&lt;/p>
&lt;h2 id="high-level-component-design">High-level component design&lt;/h2>
&lt;p>Now we have established our data model and API design, it&amp;rsquo;s time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system.&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Is it best to design a monolithic or a microservices architecture?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What type of database should we use?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client&amp;rsquo;s perspective.&lt;/p>
&lt;h2 id="detailed-design">Detailed design&lt;/h2>
&lt;p>Now it&amp;rsquo;s time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.&lt;/p>
&lt;p>Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional.&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;How should we partition our data?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What about load distribution?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Should we use cache?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we handle a sudden spike in traffic?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>Also, try not to be too opinionated about certain technologies, statements like &amp;ldquo;I believe that NoSQL databases are just better, SQL databases are not scalable&amp;rdquo; reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks">Identify and resolve bottlenecks&lt;/h2>
&lt;p>Finally, it&amp;rsquo;s time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Do we have enough database replicas?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Is there any single point of failure?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Is database sharding required?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we make our system more robust?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>Make sure to read the engineering blog of the company you&amp;rsquo;re interviewing with. This will help you get a sense of what technology stack they&amp;rsquo;re using and which problems are important to them.&lt;/p>
&lt;h1 id="url-shortener">URL Shortener&lt;/h1>
&lt;p>Let&amp;rsquo;s design a URL shortener, similar to services like &lt;a href="https://bitly.com" target="_blank" rel="noopener">Bitly&lt;/a>, &lt;a href="https://tinyurl.com/app" target="_blank" rel="noopener">TinyURL&lt;/a>.&lt;/p>
&lt;h2 id="what-is-a-url-shortener">What is a URL Shortener?&lt;/h2>
&lt;p>A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.&lt;/p>
&lt;p>For example, the following long URL can be changed to a shorter URL.&lt;/p>
&lt;p>&lt;strong>Long URL&lt;/strong>: &lt;a href="https://karanpratapsingh.com/courses/system-design/url-shortener" target="_blank" rel="noopener">https://karanpratapsingh.com/courses/system-design/url-shortener&lt;/a>&lt;/p>
&lt;p>&lt;strong>Short URL&lt;/strong>: &lt;a href="https://bit.ly/3I71d3o" target="_blank" rel="noopener">https://bit.ly/3I71d3o&lt;/a>&lt;/p>
&lt;h2 id="why-do-we-need-a-url-shortener">Why do we need a URL shortener?&lt;/h2>
&lt;p>URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.&lt;/p>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;p>Our URL shortening system should meet the following requirements:&lt;/p>
&lt;h3 id="functional-requirements-1">Functional requirements&lt;/h3>
&lt;ul>
&lt;li>Given a URL, our service should generate a &lt;em>shorter and unique&lt;/em> alias for it.&lt;/li>
&lt;li>Users should be redirected to the original URL when they visit the short link.&lt;/li>
&lt;li>Links should expire after a default timespan.&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements-1">Non-functional requirements&lt;/h3>
&lt;ul>
&lt;li>High availability with minimal latency.&lt;/li>
&lt;li>The system should be scalable and efficient.&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements-1">Extended requirements&lt;/h3>
&lt;ul>
&lt;li>Prevent abuse of services.&lt;/li>
&lt;li>Record analytics and metrics for redirections.&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints-1">Estimation and Constraints&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the estimation and constraints.&lt;/p>
&lt;p>&lt;em>Note: Make sure to check any scale or traffic related assumptions with your interviewer.&lt;/em>&lt;/p>
&lt;h3 id="traffic">Traffic&lt;/h3>
&lt;p>This will be a read-heavy system, so let&amp;rsquo;s assume a &lt;code>100:1&lt;/code> read/write ratio with 100 million links generated per month.&lt;/p>
&lt;p>&lt;strong>Reads/Writes Per month&lt;/strong>&lt;/p>
&lt;p>For reads per month:&lt;/p>
&lt;p>$$
100 \times 100 \space million = 10 \space billion/month
$$&lt;/p>
&lt;p>Similarly for writes:&lt;/p>
&lt;p>$$
1 \times 100 \space million = 100 \space million/month
$$&lt;/p>
&lt;p>&lt;strong>What would be Requests Per Second (RPS) for our system?&lt;/strong>&lt;/p>
&lt;p>100 million requests per month translate into 40 requests per second.&lt;/p>
&lt;p>$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$&lt;/p>
&lt;p>And with a &lt;code>100:1&lt;/code> read/write ratio, the number of redirections will be:&lt;/p>
&lt;p>$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$&lt;/p>
&lt;h3 id="bandwidth">Bandwidth&lt;/h3>
&lt;p>Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:&lt;/p>
&lt;p>$$
40 \times 500 \space bytes = 20 \space KB/second
$$&lt;/p>
&lt;p>Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:&lt;/p>
&lt;p>$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$&lt;/p>
&lt;h3 id="storage-2">Storage&lt;/h3>
&lt;p>For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:&lt;/p>
&lt;p>$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$&lt;/p>
&lt;p>Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:&lt;/p>
&lt;p>$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$&lt;/p>
&lt;h3 id="cache">Cache&lt;/h3>
&lt;p>For caching, we will follow the classic &lt;a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank" rel="noopener">Pareto principle&lt;/a> also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.&lt;/p>
&lt;p>Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.&lt;/p>
&lt;p>$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$&lt;/p>
&lt;p>Hence, we will need around 35GB of memory per day.&lt;/p>
&lt;p>$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$&lt;/p>
&lt;h3 id="high-level-estimate">High-level estimate&lt;/h3>
&lt;p>Here is our high-level estimate:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Estimate&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Writes (New URLs)&lt;/td>
&lt;td>40/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Reads (Redirection)&lt;/td>
&lt;td>4K/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth (Incoming)&lt;/td>
&lt;td>20 KB/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth (Outgoing)&lt;/td>
&lt;td>2 MB/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (10 years)&lt;/td>
&lt;td>6 TB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Memory (Caching)&lt;/td>
&lt;td>~35 GB/day&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="data-model-design-1">Data model design&lt;/h2>
&lt;p>Next, we will focus on the data model design. Here is our database schema:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png" alt="url-shortener-datamodel" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Initially, we can get started with just two tables:&lt;/p>
&lt;p>&lt;strong>users&lt;/strong>&lt;/p>
&lt;p>Stores user&amp;rsquo;s details such as &lt;code>name&lt;/code>, &lt;code>email&lt;/code>, &lt;code>createdAt&lt;/code>, etc.&lt;/p>
&lt;p>&lt;strong>urls&lt;/strong>&lt;/p>
&lt;p>Contains the new short URL&amp;rsquo;s properties such as &lt;code>expiration&lt;/code>, &lt;code>hash&lt;/code>, &lt;code>originalURL&lt;/code>, and &lt;code>userID&lt;/code> of the user who created the short URL. We can also use the &lt;code>hash&lt;/code> column as an &lt;a href="https://karanpratapsingh.com/courses/system-design/indexes" target="_blank" rel="noopener">index&lt;/a> to improve the query performance.&lt;/p>
&lt;h3 id="what-kind-of-database-should-we-use">What kind of database should we use?&lt;/h3>
&lt;p>Since the data is not strongly relational, NoSQL databases such as &lt;a href="https://aws.amazon.com/dynamodb" target="_blank" rel="noopener">Amazon DynamoDB&lt;/a>, &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Apache Cassandra&lt;/a>, or &lt;a href="https://www.mongodb.com" target="_blank" rel="noopener">MongoDB&lt;/a> will be a better choice here, if we do decide to use an SQL database then we can use something like &lt;a href="https://azure.microsoft.com/en-in/products/azure-sql/database" target="_blank" rel="noopener">Azure SQL Database&lt;/a> or &lt;a href="https://aws.amazon.com/rds" target="_blank" rel="noopener">Amazon RDS&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases" target="_blank" rel="noopener">SQL vs NoSQL&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="api-design-1">API design&lt;/h2>
&lt;p>Let us do a basic API design for our services:&lt;/p>
&lt;h3 id="create-url">Create URL&lt;/h3>
&lt;p>This API should create a new short URL in our system given an original URL.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">createURL&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">apiKey&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">originalURL&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">expiration?&lt;/span>: &lt;span class="kt">Date&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kt">string&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>API Key (&lt;code>string&lt;/code>): API key provided by the user.&lt;/p>
&lt;p>Original URL (&lt;code>string&lt;/code>): Original URL to be shortened.&lt;/p>
&lt;p>Expiration (&lt;code>Date&lt;/code>): Expiration date of the new URL &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Short URL (&lt;code>string&lt;/code>): New shortened URL.&lt;/p>
&lt;h3 id="get-url">Get URL&lt;/h3>
&lt;p>This API should retrieve the original URL from a given short URL.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">getURL&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">apiKey&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">shortURL&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kt">string&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>API Key (&lt;code>string&lt;/code>): API key provided by the user.&lt;/p>
&lt;p>Short URL (&lt;code>string&lt;/code>): Short URL mapped to the original URL.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Original URL (&lt;code>string&lt;/code>): Original URL to be retrieved.&lt;/p>
&lt;h3 id="delete-url">Delete URL&lt;/h3>
&lt;p>This API should delete a given shortURL from our system.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">deleteURL&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">apiKey&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">shortURL&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>API Key (&lt;code>string&lt;/code>): API key provided by the user.&lt;/p>
&lt;p>Short URL (&lt;code>string&lt;/code>): Short URL to be deleted.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="why-do-we-need-an-api-key">Why do we need an API key?&lt;/h3>
&lt;p>As you must&amp;rsquo;ve noticed, we&amp;rsquo;re using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.&lt;/p>
&lt;h2 id="high-level-design">High-level design&lt;/h2>
&lt;p>Now let us do a high-level design of our system.&lt;/p>
&lt;h3 id="url-encoding">URL Encoding&lt;/h3>
&lt;p>Our system&amp;rsquo;s primary goal is to shorten a given URL, let&amp;rsquo;s look at different approaches:&lt;/p>
&lt;p>&lt;strong>Base62 Approach&lt;/strong>&lt;/p>
&lt;p>In this approach, we can encode the original URL using &lt;a href="https://en.wikipedia.org/wiki/Base62" target="_blank" rel="noopener">Base62&lt;/a> which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.&lt;/p>
&lt;p>$$
Number \space of \space URLs = 62^N
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>N&lt;/code>: Number of characters in the generated URL.&lt;/p>
&lt;p>So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.&lt;/p>
&lt;p>$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \
62^6 = \sim 56.8 \space billion \space URLs \
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$&lt;/p>
&lt;p>This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.&lt;/p>
&lt;p>&lt;strong>MD5 Approach&lt;/strong>&lt;/p>
&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/MD5" target="_blank" rel="noopener">MD5 message-digest algorithm&lt;/a> is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.&lt;/p>
&lt;p>$$
MD5(original_url) \rightarrow base62encode \rightarrow hash
$$&lt;/p>
&lt;p>However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It&amp;rsquo;s better to look for more scalable approaches.&lt;/p>
&lt;p>&lt;strong>Counter Approach&lt;/strong>&lt;/p>
&lt;p>In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.&lt;/p>
&lt;p>$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$&lt;/p>
&lt;p>The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it&amp;rsquo;s essentially a distributed system.&lt;/p>
&lt;p>To solve this issue we can use a distributed system manager such as &lt;a href="https://zookeeper.apache.org" target="_blank" rel="noopener">Zookeeper&lt;/a> which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.&lt;/p>
&lt;p>$$
\begin{align*}
&amp;amp; Range \space 1: \space 1 \rightarrow 1,000,000 \
&amp;amp; Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \
&amp;amp; Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \
&amp;amp; &amp;hellip;
\end{align*}
$$&lt;/p>
&lt;p>Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.&lt;/p>
&lt;h3 id="key-generation-service-kgs">Key Generation Service (KGS)&lt;/h3>
&lt;p>As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.&lt;/p>
&lt;p>&lt;strong>How to handle concurrent access?&lt;/strong>&lt;/p>
&lt;p>Once the key is used, we can mark it in the database to make sure we don&amp;rsquo;t reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.&lt;/p>
&lt;p>The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.&lt;/p>
&lt;p>&lt;strong>KGS database estimations&lt;/strong>&lt;/p>
&lt;p>As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.&lt;/p>
&lt;p>$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$&lt;/p>
&lt;p>While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.&lt;/p>
&lt;h3 id="caching-1">Caching&lt;/h3>
&lt;p>Now, let&amp;rsquo;s talk about &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">caching&lt;/a>. As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> servers alongside our API server.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">caching&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="design">Design&lt;/h3>
&lt;p>Now that we have identified some core components, let&amp;rsquo;s do the first draft of our system design.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png" alt="url-shortener-basic-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Here&amp;rsquo;s how it works:&lt;/p>
&lt;p>&lt;strong>Creating a new URL&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).&lt;/li>
&lt;li>Key Generation Service provides a unique key to the API server and marks the key as used.&lt;/li>
&lt;li>API server writes the new URL entry to the database and cache.&lt;/li>
&lt;li>Our service returns an HTTP 201 (Created) response to the user.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Accessing a URL&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>When a client navigates to a certain short URL, the request is sent to the API servers.&lt;/li>
&lt;li>The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.&lt;/li>
&lt;li>If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.&lt;/li>
&lt;/ol>
&lt;h2 id="detailed-design-1">Detailed design&lt;/h2>
&lt;p>It&amp;rsquo;s time to discuss the finer details of our design.&lt;/p>
&lt;h3 id="data-partitioning-1">Data Partitioning&lt;/h3>
&lt;p>To scale out our databases we will need to partition our data. Horizontal partitioning (aka &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a>) can be a good first step. We can use partitions schemes such as:&lt;/p>
&lt;ul>
&lt;li>Hash-Based Partitioning&lt;/li>
&lt;li>List-Based Partitioning&lt;/li>
&lt;li>Range Based Partitioning&lt;/li>
&lt;li>Composite Partitioning&lt;/li>
&lt;/ul>
&lt;p>The above approaches can still cause uneven data and load distribution, we can solve this using &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent hashing&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent Hashing&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="database-cleanup">Database cleanup&lt;/h3>
&lt;p>This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:&lt;/p>
&lt;p>&lt;strong>Active cleanup&lt;/strong>&lt;/p>
&lt;p>In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a &lt;a href="https://en.wikipedia.org/wiki/Cron" target="_blank" rel="noopener">cron job&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Passive cleanup&lt;/strong>&lt;/p>
&lt;p>For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.&lt;/p>
&lt;h3 id="cache-1">Cache&lt;/h3>
&lt;p>Now let us talk about &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">caching&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Which cache eviction policy to use?&lt;/strong>&lt;/p>
&lt;p>As we discussed before, we can use solutions like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_%28LRU%29" target="_blank" rel="noopener">Least Recently Used (LRU)&lt;/a> can be a good policy for our system. In this policy, we discard the least recently used key first.&lt;/p>
&lt;p>&lt;strong>How to handle cache miss?&lt;/strong>&lt;/p>
&lt;p>Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.&lt;/p>
&lt;h3 id="metrics-and-analytics">Metrics and Analytics&lt;/h3>
&lt;p>Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor&amp;rsquo;s country, platform, the number of views, etc alongside the URL entry in our database.&lt;/p>
&lt;h3 id="security-2">Security&lt;/h3>
&lt;p>For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.&lt;/p>
&lt;p>We can also use an &lt;a href="https://karanpratapsingh.com/courses/system-design/api-gateway" target="_blank" rel="noopener">API Gateway&lt;/a> as they can support capabilities like authorization, rate limiting, and load balancing out of the box.&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks-1">Identify and resolve bottlenecks&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png" alt="url-shortener-advanced-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let us identify and resolve bottlenecks such as single points of failure in our design:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What if the API service or Key Generation Service crashes?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we distribute our traffic between our components?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce the load on our database?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;What if the key database used by KGS fails?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>To make our system more resilient we can do the following:&lt;/p>
&lt;ul>
&lt;li>Running multiple instances of our Servers and Key Generation Service.&lt;/li>
&lt;li>Introducing &lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">load balancers&lt;/a> between clients, servers, databases, and cache servers.&lt;/li>
&lt;li>Using multiple read replicas for our database as it&amp;rsquo;s a read-heavy system.&lt;/li>
&lt;li>Standby replica for our key database in case it fails.&lt;/li>
&lt;li>Multiple instances and replicas for our distributed cache.&lt;/li>
&lt;/ul>
&lt;h1 id="whatsapp">WhatsApp&lt;/h1>
&lt;p>Let&amp;rsquo;s design a &lt;a href="https://whatsapp.com" target="_blank" rel="noopener">WhatsApp&lt;/a> like instant messaging service, similar to services like &lt;a href="https://www.messenger.com" target="_blank" rel="noopener">Facebook Messenger&lt;/a>, and &lt;a href="https://www.wechat.com" target="_blank" rel="noopener">WeChat&lt;/a>.&lt;/p>
&lt;h2 id="what-is-whatsapp">What is WhatsApp?&lt;/h2>
&lt;p>WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.&lt;/p>
&lt;h2 id="requirements-1">Requirements&lt;/h2>
&lt;p>Our system should meet the following requirements:&lt;/p>
&lt;h3 id="functional-requirements-2">Functional requirements&lt;/h3>
&lt;ul>
&lt;li>Should support one-on-one chat.&lt;/li>
&lt;li>Group chats (max 100 people).&lt;/li>
&lt;li>Should support file sharing (image, video, etc.).&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements-2">Non-functional requirements&lt;/h3>
&lt;ul>
&lt;li>High availability with minimal latency.&lt;/li>
&lt;li>The system should be scalable and efficient.&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements-2">Extended requirements&lt;/h3>
&lt;ul>
&lt;li>Sent, Delivered, and Read receipts of the messages.&lt;/li>
&lt;li>Show the last seen time of users.&lt;/li>
&lt;li>Push notifications.&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints-2">Estimation and Constraints&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the estimation and constraints.&lt;/p>
&lt;p>&lt;em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.&lt;/em>&lt;/p>
&lt;h3 id="traffic-1">Traffic&lt;/h3>
&lt;p>Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 2 different people every day. This gives us 2 billion messages per day.&lt;/p>
&lt;p>$$
50 \space million \times 20 \space messages = 2 \space billion/day
$$&lt;/p>
&lt;p>Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 200 million files we would need to store.&lt;/p>
&lt;p>$$
5 \space percent \times 2 \space billion = 200 \space million/day
$$&lt;/p>
&lt;p>&lt;strong>What would be Requests Per Second (RPS) for our system?&lt;/strong>&lt;/p>
&lt;p>2 billion requests per day translate into 24K requests per second.&lt;/p>
&lt;p>$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$&lt;/p>
&lt;h3 id="storage-3">Storage&lt;/h3>
&lt;p>If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.&lt;/p>
&lt;p>$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$&lt;/p>
&lt;p>As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 50 KB on average, we will require 10 TB of storage every day.&lt;/p>
&lt;p>$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$&lt;/p>
&lt;p>And for 10 years, we will require about 38 PB of storage.&lt;/p>
&lt;p>$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$&lt;/p>
&lt;h3 id="bandwidth-1">Bandwidth&lt;/h3>
&lt;p>As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.&lt;/p>
&lt;p>$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$&lt;/p>
&lt;h3 id="high-level-estimate-1">High-level estimate&lt;/h3>
&lt;p>Here is our high-level estimate:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Estimate&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Daily active users (DAU)&lt;/td>
&lt;td>50 million&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Requests per second (RPS)&lt;/td>
&lt;td>24K/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (per day)&lt;/td>
&lt;td>~10.2 TB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (10 years)&lt;/td>
&lt;td>~38 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth&lt;/td>
&lt;td>~120 MB/s&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="data-model-design-2">Data model design&lt;/h2>
&lt;p>This is the general data model which reflects our requirements.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png" alt="whatsapp-datamodel" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>We have the following tables:&lt;/p>
&lt;p>&lt;strong>users&lt;/strong>&lt;/p>
&lt;p>This table will contain a user&amp;rsquo;s information such as &lt;code>name&lt;/code>, &lt;code>phoneNumber&lt;/code>, and other details.&lt;/p>
&lt;p>&lt;strong>messages&lt;/strong>&lt;/p>
&lt;p>As the name suggests, this table will store messages with properties such as &lt;code>type&lt;/code> (text, image, video, etc.), &lt;code>content&lt;/code>, and timestamps for message delivery. The message will also have a corresponding &lt;code>chatID&lt;/code> or &lt;code>groupID&lt;/code>.&lt;/p>
&lt;p>&lt;strong>chats&lt;/strong>&lt;/p>
&lt;p>This table basically represents a private chat between two users and can contain multiple messages.&lt;/p>
&lt;p>&lt;strong>users_chats&lt;/strong>&lt;/p>
&lt;p>This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.&lt;/p>
&lt;p>&lt;strong>groups&lt;/strong>&lt;/p>
&lt;p>This table represents a group made up of multiple users.&lt;/p>
&lt;p>&lt;strong>users_groups&lt;/strong>&lt;/p>
&lt;p>This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.&lt;/p>
&lt;h3 id="what-kind-of-database-should-we-use-1">What kind of database should we use?&lt;/h3>
&lt;p>While our data model seems quite relational, we don&amp;rsquo;t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.&lt;/p>
&lt;p>We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a> or a distributed NoSQL database such as &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Apache Cassandra&lt;/a> for our use case.&lt;/p>
&lt;h2 id="api-design-2">API design&lt;/h2>
&lt;p>Let us do a basic API design for our services:&lt;/p>
&lt;h3 id="get-all-chats-or-groups">Get all chats or groups&lt;/h3>
&lt;p>This API will get all chats or groups for a given &lt;code>userID&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">getAll&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">Chat&lt;/span>&lt;span class="p">[]&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="nx">Group&lt;/span>&lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the current user.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>Chat[] | Group[]&lt;/code>): All the chats and groups the user is a part of.&lt;/p>
&lt;h3 id="get-messages">Get messages&lt;/h3>
&lt;p>Get all messages for a user given the &lt;code>channelID&lt;/code> (chat or group id).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">getMessages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">channelID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">Message&lt;/span>&lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the current user.&lt;/p>
&lt;p>Channel ID (&lt;code>UUID&lt;/code>): ID of the channel (chat or group) from which messages need to be retrieved.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Messages (&lt;code>Message[]&lt;/code>): All the messages in a given chat or group.&lt;/p>
&lt;h3 id="send-message">Send message&lt;/h3>
&lt;p>Send a message from a user to a channel (chat or group).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">sendMessage&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">channelID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">message&lt;/span>: &lt;span class="kt">Message&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the current user.&lt;/p>
&lt;p>Channel ID (&lt;code>UUID&lt;/code>): ID of the channel (chat or group) user wants to send a message to.&lt;/p>
&lt;p>Message (&lt;code>Message&lt;/code>): The message (text, image, video, etc.) that the user wants to send.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="join-or-leave-a-group">Join or leave a group&lt;/h3>
&lt;p>Send a message from a user to a channel (chat or group).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">joinGroup&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">channelID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">leaveGroup&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">channelID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the current user.&lt;/p>
&lt;p>Channel ID (&lt;code>UUID&lt;/code>): ID of the channel (chat or group) the user wants to join or leave.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h2 id="high-level-design-1">High-level design&lt;/h2>
&lt;p>Now let us do a high-level design of our system.&lt;/p>
&lt;h3 id="architecture">Architecture&lt;/h3>
&lt;p>We will be using &lt;a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" target="_blank" rel="noopener">microservices architecture&lt;/a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let&amp;rsquo;s try to divide our system into some core services.&lt;/p>
&lt;p>&lt;strong>User Service&lt;/strong>&lt;/p>
&lt;p>This is an HTTP-based service that handles user-related concerns such as authentication and user information.&lt;/p>
&lt;p>&lt;strong>Chat Service&lt;/strong>&lt;/p>
&lt;p>The chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.&lt;/p>
&lt;p>&lt;strong>Notification Service&lt;/strong>&lt;/p>
&lt;p>This service will simply send push notifications to the users. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Presence Service&lt;/strong>&lt;/p>
&lt;p>The presence service will keep track of the &lt;em>last seen&lt;/em> status of all users. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Media service&lt;/strong>&lt;/p>
&lt;p>This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>What about inter-service communication and service discovery?&lt;/strong>&lt;/p>
&lt;p>Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" target="_blank" rel="noopener">gRPC&lt;/a> which is more lightweight and efficient.&lt;/p>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/service-discovery" target="_blank" rel="noopener">Service discovery&lt;/a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" target="_blank" rel="noopener">REST, GraphQL, gRPC&lt;/a> and how they compare with each other.&lt;/em>&lt;/p>
&lt;h3 id="real-time-messaging">Real-time messaging&lt;/h3>
&lt;p>How do we efficiently send and receive messages? We have two different options:&lt;/p>
&lt;p>&lt;strong>Pull model&lt;/strong>&lt;/p>
&lt;p>The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling" target="_blank" rel="noopener">Long polling&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Push model&lt;/strong>&lt;/p>
&lt;p>The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" target="_blank" rel="noopener">WebSockets&lt;/a> or &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" target="_blank" rel="noopener">Server-Sent Events (SSE)&lt;/a> for this.&lt;/p>
&lt;p>The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" target="_blank" rel="noopener">WebSockets&lt;/a> is a better choice because then we can push data to the client once it&amp;rsquo;s available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" target="_blank" rel="noopener">Server-Sent Events (SSE)&lt;/a> which are only unidirectional.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events" target="_blank" rel="noopener">Long polling, WebSockets, Server-Sent Events (SSE)&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="last-seen">Last seen&lt;/h3>
&lt;p>To implement the last seen functionality, we can use a &lt;a href="https://en.wikipedia.org/wiki/Heartbeat_%28computing%29" target="_blank" rel="noopener">heartbeat&lt;/a> mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Key&lt;/th>
&lt;th>Value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User A&lt;/td>
&lt;td>2022-07-01T14:32:50&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>User B&lt;/td>
&lt;td>2022-07-05T05:10:35&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>User C&lt;/td>
&lt;td>2022-07-10T04:33:25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>This will give us the last time the user was active. This functionality will be handled by the presence service combined with &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> as our cache.&lt;/p>
&lt;p>Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as &lt;em>&amp;ldquo;user hasn&amp;rsquo;t performed any action in the last 30 seconds&amp;rdquo;&lt;/em>, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.&lt;/p>
&lt;h3 id="notifications">Notifications&lt;/h3>
&lt;p>Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user&amp;rsquo;s active connection and last seen into consideration.&lt;/p>
&lt;p>If the recipient is not active, the chat service will add an event to a &lt;a href="https://karanpratapsingh.com/courses/system-design/message-queues" target="_blank" rel="noopener">message queue&lt;/a> with additional metadata such as the client&amp;rsquo;s device platform which will be used to route the notification to the correct platform later on.&lt;/p>
&lt;p>The notification service will then consume the event from the message queue and forward the request to &lt;a href="https://firebase.google.com/docs/cloud-messaging" target="_blank" rel="noopener">Firebase Cloud Messaging (FCM)&lt;/a> or &lt;a href="https://developer.apple.com/documentation/usernotifications" target="_blank" rel="noopener">Apple Push Notification Service (APNS)&lt;/a> based on the client&amp;rsquo;s device platform (Android, iOS, web, etc). We can also add support for email and SMS.&lt;/p>
&lt;p>&lt;strong>Why are we using a message queue?&lt;/strong>&lt;/p>
&lt;p>Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they&amp;rsquo;re sent and that a message is delivered at least once which is an important part of our service functionality.&lt;/p>
&lt;p>While this seems like a classic &lt;a href="https://karanpratapsingh.com/courses/system-design/publish-subscribe" target="_blank" rel="noopener">publish-subscribe&lt;/a> use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like &lt;a href="https://aws.amazon.com/sqs" target="_blank" rel="noopener">Amazon SQS&lt;/a> or &lt;a href="https://www.rabbitmq.com" target="_blank" rel="noopener">RabbitMQ&lt;/a> to support this functionality.&lt;/p>
&lt;h3 id="read-receipts">Read receipts&lt;/h3>
&lt;p>Handling read receipts can be tricky, for this use case we can wait for some sort of &lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_%28data_networks%29" target="_blank" rel="noopener">Acknowledgment (ACK)&lt;/a> from the client to determine if the message was delivered and update the corresponding &lt;code>deliveredAt&lt;/code> field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding &lt;code>seenAt&lt;/code> timestamp field.&lt;/p>
&lt;h3 id="design-1">Design&lt;/h3>
&lt;p>Now that we have identified some core components, let&amp;rsquo;s do the first draft of our system design.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png" alt="whatsapp-basic-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="detailed-design-2">Detailed design&lt;/h2>
&lt;p>It&amp;rsquo;s time to discuss our design decisions in detail.&lt;/p>
&lt;h3 id="data-partitioning-2">Data Partitioning&lt;/h3>
&lt;p>To scale out our databases we will need to partition our data. Horizontal partitioning (aka &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a>) can be a good first step. We can use partitions schemes such as:&lt;/p>
&lt;ul>
&lt;li>Hash-Based Partitioning&lt;/li>
&lt;li>List-Based Partitioning&lt;/li>
&lt;li>Range Based Partitioning&lt;/li>
&lt;li>Composite Partitioning&lt;/li>
&lt;/ul>
&lt;p>The above approaches can still cause uneven data and load distribution, we can solve this using &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent hashing&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent Hashing&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="caching-2">Caching&lt;/h3>
&lt;p>In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.&lt;/p>
&lt;p>Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won&amp;rsquo;t have to retrieve old messages unless requested.&lt;/p>
&lt;p>&lt;strong>Which cache eviction policy to use?&lt;/strong>&lt;/p>
&lt;p>We can use solutions like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_%28LRU%29" target="_blank" rel="noopener">Least Recently Used (LRU)&lt;/a> can be a good policy for our system. In this policy, we discard the least recently used key first.&lt;/p>
&lt;p>&lt;strong>How to handle cache miss?&lt;/strong>&lt;/p>
&lt;p>Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">Caching&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="media-access-and-storage">Media access and storage&lt;/h3>
&lt;p>As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.&lt;/p>
&lt;p>But where can we store files at scale? Well, &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" target="_blank" rel="noopener">object storage&lt;/a> is what we&amp;rsquo;re looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" target="_blank" rel="noopener">HDFS&lt;/a> or &lt;a href="https://www.gluster.org" target="_blank" rel="noopener">GlusterFS&lt;/a>.&lt;/p>
&lt;p>&lt;em>Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user.&lt;/em>&lt;/p>
&lt;p>We can use object stores like &lt;a href="https://aws.amazon.com/s3" target="_blank" rel="noopener">Amazon S3&lt;/a>, &lt;a href="https://azure.microsoft.com/en-in/services/storage/blobs" target="_blank" rel="noopener">Azure Blob Storage&lt;/a>, or &lt;a href="https://cloud.google.com/storage" target="_blank" rel="noopener">Google Cloud Storage&lt;/a> for this use case.&lt;/p>
&lt;h3 id="content-delivery-network-cdn-1">Content Delivery Network (CDN)&lt;/h3>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" target="_blank" rel="noopener">Content Delivery Network (CDN)&lt;/a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like &lt;a href="https://aws.amazon.com/cloudfront" target="_blank" rel="noopener">Amazon CloudFront&lt;/a> or &lt;a href="https://www.cloudflare.com/cdn" target="_blank" rel="noopener">Cloudflare CDN&lt;/a> for this use case.&lt;/p>
&lt;h3 id="api-gateway-1">API gateway&lt;/h3>
&lt;p>Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an &lt;a href="https://karanpratapsingh.com/courses/system-design/api-gateway" target="_blank" rel="noopener">API Gateway&lt;/a> that supports multiple protocols without any issues.&lt;/p>
&lt;p>API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.&lt;/p>
&lt;p>We can use services like &lt;a href="https://aws.amazon.com/api-gateway" target="_blank" rel="noopener">Amazon API Gateway&lt;/a> or &lt;a href="https://azure.microsoft.com/en-in/services/api-management" target="_blank" rel="noopener">Azure API Gateway&lt;/a> for this use case.&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks-2">Identify and resolve bottlenecks&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png" alt="whatsapp-advanced-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let us identify and resolve bottlenecks such as single points of failure in our design:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What if one of our services crashes?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we distribute our traffic between our components?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce the load on our database?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;Wouldn&amp;rsquo;t API Gateway be a single point of failure?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we make our notification system more robust?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce media storage costs&amp;rdquo;?&lt;/li>
&lt;li>&amp;ldquo;Does chat service has too much responsibility?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>To make our system more resilient we can do the following:&lt;/p>
&lt;ul>
&lt;li>Running multiple instances of each of our services.&lt;/li>
&lt;li>Introducing &lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">load balancers&lt;/a> between clients, servers, databases, and cache servers.&lt;/li>
&lt;li>Using multiple read replicas for our databases.&lt;/li>
&lt;li>Multiple instances and replicas for our distributed cache.&lt;/li>
&lt;li>We can have a standby replica of our API Gateway.&lt;/li>
&lt;li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated &lt;a href="https://karanpratapsingh.com/courses/system-design/message-brokers" target="_blank" rel="noopener">message broker&lt;/a> such as &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> or &lt;a href="https://nats.io" target="_blank" rel="noopener">NATS&lt;/a> to make our notification system more robust.&lt;/li>
&lt;li>We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.&lt;/li>
&lt;li>We can create a group service separate from the chat service to further decouple our services.&lt;/li>
&lt;/ul>
&lt;h1 id="twitter">Twitter&lt;/h1>
&lt;p>Let&amp;rsquo;s design a &lt;a href="https://twitter.com" target="_blank" rel="noopener">Twitter&lt;/a> like social media service, similar to services like &lt;a href="https://facebook.com" target="_blank" rel="noopener">Facebook&lt;/a>, &lt;a href="https://instagram.com" target="_blank" rel="noopener">Instagram&lt;/a>, etc.&lt;/p>
&lt;h2 id="what-is-twitter">What is Twitter?&lt;/h2>
&lt;p>Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.&lt;/p>
&lt;h2 id="requirements-2">Requirements&lt;/h2>
&lt;p>Our system should meet the following requirements:&lt;/p>
&lt;h3 id="functional-requirements-3">Functional requirements&lt;/h3>
&lt;ul>
&lt;li>Should be able to post new tweets (can be text, image, video, etc.).&lt;/li>
&lt;li>Should be able to follow other users.&lt;/li>
&lt;li>Should have a newsfeed feature consisting of tweets from the people the user is following.&lt;/li>
&lt;li>Should be able to search tweets.&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements-3">Non-Functional requirements&lt;/h3>
&lt;ul>
&lt;li>High availability with minimal latency.&lt;/li>
&lt;li>The system should be scalable and efficient.&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements-3">Extended requirements&lt;/h3>
&lt;ul>
&lt;li>Metrics and analytics.&lt;/li>
&lt;li>Retweet functionality.&lt;/li>
&lt;li>Favorite tweets.&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints-3">Estimation and Constraints&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the estimation and constraints.&lt;/p>
&lt;p>&lt;em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.&lt;/em>&lt;/p>
&lt;h3 id="traffic-2">Traffic&lt;/h3>
&lt;p>This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.&lt;/p>
&lt;p>$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$&lt;/p>
&lt;p>Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.&lt;/p>
&lt;p>$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$&lt;/p>
&lt;p>&lt;strong>What would be Requests Per Second (RPS) for our system?&lt;/strong>&lt;/p>
&lt;p>1 billion requests per day translate into 12K requests per second.&lt;/p>
&lt;p>$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$&lt;/p>
&lt;h3 id="storage-4">Storage&lt;/h3>
&lt;p>If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.&lt;/p>
&lt;p>$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$&lt;/p>
&lt;p>We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.&lt;/p>
&lt;p>$$
100 \space million \times 100 \space KB = 5 \space TB/day
$$&lt;/p>
&lt;p>And for 10 years, we will require about 19 PB of storage.&lt;/p>
&lt;p>$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$&lt;/p>
&lt;h3 id="bandwidth-2">Bandwidth&lt;/h3>
&lt;p>As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.&lt;/p>
&lt;p>$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$&lt;/p>
&lt;h3 id="high-level-estimate-2">High-level estimate&lt;/h3>
&lt;p>Here is our high-level estimate:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Estimate&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Daily active users (DAU)&lt;/td>
&lt;td>100 million&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Requests per second (RPS)&lt;/td>
&lt;td>12K/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (per day)&lt;/td>
&lt;td>~5.1 TB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (10 years)&lt;/td>
&lt;td>~19 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth&lt;/td>
&lt;td>~60 MB/s&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="data-model-design-3">Data model design&lt;/h2>
&lt;p>This is the general data model which reflects our requirements.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png" alt="twitter-datamodel" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>We have the following tables:&lt;/p>
&lt;p>&lt;strong>users&lt;/strong>&lt;/p>
&lt;p>This table will contain a user&amp;rsquo;s information such as &lt;code>name&lt;/code>, &lt;code>email&lt;/code>, &lt;code>dob&lt;/code>, and other details.&lt;/p>
&lt;p>&lt;strong>tweets&lt;/strong>&lt;/p>
&lt;p>As the name suggests, this table will store tweets and their properties such as &lt;code>type&lt;/code> (text, image, video, etc.), &lt;code>content&lt;/code>, etc. We will also store the corresponding &lt;code>userID&lt;/code>.&lt;/p>
&lt;p>&lt;strong>favorites&lt;/strong>&lt;/p>
&lt;p>This table maps tweets with users for the favorite tweets functionality in our application.&lt;/p>
&lt;p>&lt;strong>followers&lt;/strong>&lt;/p>
&lt;p>This table maps the followers and &lt;a href="https://en.wiktionary.org/wiki/followee" target="_blank" rel="noopener">followees&lt;/a> as users can follow each other (N:M relationship).&lt;/p>
&lt;p>&lt;strong>feeds&lt;/strong>&lt;/p>
&lt;p>This table stores feed properties with the corresponding &lt;code>userID&lt;/code>.&lt;/p>
&lt;p>&lt;strong>feeds_tweets&lt;/strong>&lt;/p>
&lt;p>This table maps tweets and feed (N:M relationship).&lt;/p>
&lt;h3 id="what-kind-of-database-should-we-use-2">What kind of database should we use?&lt;/h3>
&lt;p>While our data model seems quite relational, we don&amp;rsquo;t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.&lt;/p>
&lt;p>We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a> or a distributed NoSQL database such as &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Apache Cassandra&lt;/a> for our use case.&lt;/p>
&lt;h2 id="api-design-3">API design&lt;/h2>
&lt;p>Let us do a basic API design for our services:&lt;/p>
&lt;h3 id="post-a-tweet">Post a tweet&lt;/h3>
&lt;p>This API will allow the user to post a tweet on the platform.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">postTweet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">content&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">mediaURL?&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the user.&lt;/p>
&lt;p>Content (&lt;code>string&lt;/code>): Contents of the tweet.&lt;/p>
&lt;p>Media URL (&lt;code>string&lt;/code>): URL of the attached media &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="follow-or-unfollow-a-user">Follow or unfollow a user&lt;/h3>
&lt;p>This API will allow the user to follow or unfollow another user.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">follow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">followerID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">followeeID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">unfollow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">followerID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">followeeID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Follower ID (&lt;code>UUID&lt;/code>): ID of the current user.&lt;/p>
&lt;p>Followee ID (&lt;code>UUID&lt;/code>): ID of the user we want to follow or unfollow.&lt;/p>
&lt;p>Media URL (&lt;code>string&lt;/code>): URL of the attached media &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="get-newsfeed">Get newsfeed&lt;/h3>
&lt;p>This API will return all the tweets to be shown within a given newsfeed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">getNewsfeed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">Tweet&lt;/span>&lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>User ID (&lt;code>UUID&lt;/code>): ID of the user.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Tweets (&lt;code>Tweet[]&lt;/code>): All the tweets to be shown within a given newsfeed.&lt;/p>
&lt;h2 id="high-level-design-2">High-level design&lt;/h2>
&lt;p>Now let us do a high-level design of our system.&lt;/p>
&lt;h3 id="architecture-1">Architecture&lt;/h3>
&lt;p>We will be using &lt;a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" target="_blank" rel="noopener">microservices architecture&lt;/a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let&amp;rsquo;s try to divide our system into some core services.&lt;/p>
&lt;p>&lt;strong>User Service&lt;/strong>&lt;/p>
&lt;p>This service handles user-related concerns such as authentication and user information.&lt;/p>
&lt;p>&lt;strong>Newsfeed Service&lt;/strong>&lt;/p>
&lt;p>This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Tweet Service&lt;/strong>&lt;/p>
&lt;p>The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.&lt;/p>
&lt;p>&lt;strong>Search Service&lt;/strong>&lt;/p>
&lt;p>The service is responsible for handling search-related functionality. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Media service&lt;/strong>&lt;/p>
&lt;p>This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Notification Service&lt;/strong>&lt;/p>
&lt;p>This service will simply send push notifications to the users.&lt;/p>
&lt;p>&lt;strong>Analytics Service&lt;/strong>&lt;/p>
&lt;p>This service will be used for metrics and analytics use cases.&lt;/p>
&lt;p>&lt;strong>What about inter-service communication and service discovery?&lt;/strong>&lt;/p>
&lt;p>Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" target="_blank" rel="noopener">gRPC&lt;/a> which is more lightweight and efficient.&lt;/p>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/service-discovery" target="_blank" rel="noopener">Service discovery&lt;/a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" target="_blank" rel="noopener">REST, GraphQL, gRPC&lt;/a> and how they compare with each other.&lt;/em>&lt;/p>
&lt;h3 id="newsfeed">Newsfeed&lt;/h3>
&lt;p>When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let&amp;rsquo;s divide our problem into two parts:&lt;/p>
&lt;p>&lt;strong>Generation&lt;/strong>&lt;/p>
&lt;p>Let&amp;rsquo;s assume we want to generate the feed for user A, we will perform the following steps:&lt;/p>
&lt;ol>
&lt;li>Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.&lt;/li>
&lt;li>Fetch the relevant tweets for each of the retrieved IDs.&lt;/li>
&lt;li>Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.&lt;/li>
&lt;li>Return the ranked tweets data to the client in a paginated manner.&lt;/li>
&lt;/ol>
&lt;p>Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.&lt;/p>
&lt;p>&lt;strong>Publishing&lt;/strong>&lt;/p>
&lt;p>Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches:&lt;/p>
&lt;ul>
&lt;li>Pull Model (or Fan-out on load)&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png" alt="newsfeed-pull-model" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.&lt;/p>
&lt;p>The downside of this approach is that the users will not be able to view recent feeds unless they &amp;ldquo;pull&amp;rdquo; the data from the server, which will increase the number of read operations on the server.&lt;/p>
&lt;ul>
&lt;li>Push Model (or Fan-out on write)&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png" alt="newsfeed-push-model" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>In this model, once a user creates a tweet, it is &amp;ldquo;pushed&amp;rdquo; to all the follower&amp;rsquo;s feeds immediately. This prevents the system from having to go through a user&amp;rsquo;s entire followers list to check for updates.&lt;/p>
&lt;p>However, the downside of this approach is that it would increase the number of write operations on the database.&lt;/p>
&lt;ul>
&lt;li>Hybrid Model&lt;/li>
&lt;/ul>
&lt;p>A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.&lt;/p>
&lt;p>The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.&lt;/p>
&lt;h3 id="ranking-algorithm">Ranking Algorithm&lt;/h3>
&lt;p>As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.&lt;/p>
&lt;p>For example, Facebook used to utilize an &lt;a href="https://en.wikipedia.org/wiki/EdgeRank" target="_blank" rel="noopener">EdgeRank&lt;/a> algorithm. Here, the rank of each feed item is described by:&lt;/p>
&lt;p>$$
Rank = Affinity \times Weight \times Decay
$$&lt;/p>
&lt;p>Where,&lt;/p>
&lt;p>&lt;code>Affinity&lt;/code>: is the &amp;ldquo;closeness&amp;rdquo; of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.&lt;/p>
&lt;p>&lt;code>Weight&lt;/code>: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.&lt;/p>
&lt;p>&lt;code>Decay&lt;/code>: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.&lt;/p>
&lt;p>Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.&lt;/p>
&lt;h3 id="retweets">Retweets&lt;/h3>
&lt;p>Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the &lt;code>type&lt;/code> enum and &lt;code>content&lt;/code> property of the new tweet to link it with the original tweet.&lt;/p>
&lt;p>For example, the &lt;code>type&lt;/code> enum property can be of type tweet, similar to text, video, etc and &lt;code>content&lt;/code> can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>id&lt;/th>
&lt;th>userID&lt;/th>
&lt;th>type&lt;/th>
&lt;th>content&lt;/th>
&lt;th>createdAt&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ad34-291a-45f6-b36c&lt;/td>
&lt;td>7a2c-62c4-4dc8-b1bb&lt;/td>
&lt;td>text&lt;/td>
&lt;td>Hey, this is my first tweet…&lt;/td>
&lt;td>1658905644054&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>f064-49ad-9aa2-84a6&lt;/td>
&lt;td>6aa2-2bc9-4331-879f&lt;/td>
&lt;td>tweet&lt;/td>
&lt;td>ad34-291a-45f6-b36c&lt;/td>
&lt;td>1658906165427&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>This is a very basic implementation. To improve this we can create a separate table itself to store retweets.&lt;/p>
&lt;h3 id="search">Search&lt;/h3>
&lt;p>Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. &lt;a href="https://www.elastic.co" target="_blank" rel="noopener">Elasticsearch&lt;/a> can help us with this use case.&lt;/p>
&lt;p>&lt;a href="https://www.elastic.co" target="_blank" rel="noopener">Elasticsearch&lt;/a> is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of &lt;a href="https://lucene.apache.org" target="_blank" rel="noopener">Apache Lucene&lt;/a>.&lt;/p>
&lt;p>&lt;strong>How do we identify trending topics?&lt;/strong>&lt;/p>
&lt;p>Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last &lt;code>N&lt;/code> seconds and update them every &lt;code>M&lt;/code> seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.&lt;/p>
&lt;h3 id="notifications-1">Notifications&lt;/h3>
&lt;p>Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> with the notification service to dispatch requests to &lt;a href="https://firebase.google.com/docs/cloud-messaging" target="_blank" rel="noopener">Firebase Cloud Messaging (FCM)&lt;/a> or &lt;a href="https://developer.apple.com/documentation/usernotifications" target="_blank" rel="noopener">Apple Push Notification Service (APNS)&lt;/a> which will handle the delivery of the push notifications to user devices.&lt;/p>
&lt;p>&lt;em>For more details, refer to the &lt;a href="https://karanpratapsingh.com/courses/system-design/whatsapp#notifications" target="_blank" rel="noopener">WhatsApp&lt;/a> system design where we discuss push notifications in detail.&lt;/em>&lt;/p>
&lt;h2 id="detailed-design-3">Detailed design&lt;/h2>
&lt;p>It&amp;rsquo;s time to discuss our design decisions in detail.&lt;/p>
&lt;h3 id="data-partitioning-3">Data Partitioning&lt;/h3>
&lt;p>To scale out our databases we will need to partition our data. Horizontal partitioning (aka &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a>) can be a good first step. We can use partitions schemes such as:&lt;/p>
&lt;ul>
&lt;li>Hash-Based Partitioning&lt;/li>
&lt;li>List-Based Partitioning&lt;/li>
&lt;li>Range Based Partitioning&lt;/li>
&lt;li>Composite Partitioning&lt;/li>
&lt;/ul>
&lt;p>The above approaches can still cause uneven data and load distribution, we can solve this using &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent hashing&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent Hashing&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="mutual-friends">Mutual friends&lt;/h3>
&lt;p>For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as &lt;a href="https://neo4j.com" target="_blank" rel="noopener">Neo4j&lt;/a> and &lt;a href="https://www.arangodb.com" target="_blank" rel="noopener">ArangoDB&lt;/a>.&lt;/p>
&lt;p>This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.&lt;/p>
&lt;h3 id="metrics-and-analytics-1">Metrics and Analytics&lt;/h3>
&lt;p>Recording analytics and metrics is one of our extended requirements. As we will be using &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> to publish all sorts of events, we can process these events and run analytics on the data using &lt;a href="https://spark.apache.org" target="_blank" rel="noopener">Apache Spark&lt;/a> which is an open-source unified analytics engine for large-scale data processing.&lt;/p>
&lt;h3 id="caching-3">Caching&lt;/h3>
&lt;p>In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.&lt;/p>
&lt;p>To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won&amp;rsquo;t have to retrieve old messages unless requested.&lt;/p>
&lt;p>&lt;strong>Which cache eviction policy to use?&lt;/strong>&lt;/p>
&lt;p>We can use solutions like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_%28LRU%29" target="_blank" rel="noopener">Least Recently Used (LRU)&lt;/a> can be a good policy for our system. In this policy, we discard the least recently used key first.&lt;/p>
&lt;p>&lt;strong>How to handle cache miss?&lt;/strong>&lt;/p>
&lt;p>Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">Caching&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="media-access-and-storage-1">Media access and storage&lt;/h3>
&lt;p>As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.&lt;/p>
&lt;p>But where can we store files at scale? Well, &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" target="_blank" rel="noopener">object storage&lt;/a> is what we&amp;rsquo;re looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" target="_blank" rel="noopener">HDFS&lt;/a> or &lt;a href="https://www.gluster.org" target="_blank" rel="noopener">GlusterFS&lt;/a>.&lt;/p>
&lt;h3 id="content-delivery-network-cdn-2">Content Delivery Network (CDN)&lt;/h3>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" target="_blank" rel="noopener">Content Delivery Network (CDN)&lt;/a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like &lt;a href="https://aws.amazon.com/cloudfront" target="_blank" rel="noopener">Amazon CloudFront&lt;/a> or &lt;a href="https://www.cloudflare.com/cdn" target="_blank" rel="noopener">Cloudflare CDN&lt;/a> for this use case.&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks-3">Identify and resolve bottlenecks&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png" alt="twitter-advanced-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let us identify and resolve bottlenecks such as single points of failure in our design:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What if one of our services crashes?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we distribute our traffic between our components?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce the load on our database?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we make our notification system more robust?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce media storage costs&amp;rdquo;?&lt;/li>
&lt;/ul>
&lt;p>To make our system more resilient we can do the following:&lt;/p>
&lt;ul>
&lt;li>Running multiple instances of each of our services.&lt;/li>
&lt;li>Introducing &lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">load balancers&lt;/a> between clients, servers, databases, and cache servers.&lt;/li>
&lt;li>Using multiple read replicas for our databases.&lt;/li>
&lt;li>Multiple instances and replicas for our distributed cache.&lt;/li>
&lt;li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated &lt;a href="https://karanpratapsingh.com/courses/system-design/message-brokers" target="_blank" rel="noopener">message broker&lt;/a> such as &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> or &lt;a href="https://nats.io" target="_blank" rel="noopener">NATS&lt;/a> to make our notification system more robust.&lt;/li>
&lt;li>We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.&lt;/li>
&lt;/ul>
&lt;h1 id="netflix">Netflix&lt;/h1>
&lt;p>Let&amp;rsquo;s design a &lt;a href="https://netflix.com" target="_blank" rel="noopener">Netflix&lt;/a> like video streaming service, similar to services like &lt;a href="https://www.primevideo.com" target="_blank" rel="noopener">Amazon Prime Video&lt;/a>, &lt;a href="https://www.disneyplus.com" target="_blank" rel="noopener">Disney Plus&lt;/a>, &lt;a href="https://www.hulu.com" target="_blank" rel="noopener">Hulu&lt;/a>, &lt;a href="https://youtube.com" target="_blank" rel="noopener">Youtube&lt;/a>, &lt;a href="https://vimeo.com" target="_blank" rel="noopener">Vimeo&lt;/a>, etc.&lt;/p>
&lt;h2 id="what-is-netflix">What is Netflix?&lt;/h2>
&lt;p>Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.&lt;/p>
&lt;h2 id="requirements-3">Requirements&lt;/h2>
&lt;p>Our system should meet the following requirements:&lt;/p>
&lt;h3 id="functional-requirements-4">Functional requirements&lt;/h3>
&lt;ul>
&lt;li>Users should be able to stream and share videos.&lt;/li>
&lt;li>The content team (or users in YouTube&amp;rsquo;s case) should be able to upload new videos (movies, tv shows episodes, and other content).&lt;/li>
&lt;li>Users should be able to search for videos using titles or tags.&lt;/li>
&lt;li>Users should be able to comment on a video similar to YouTube.&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements-4">Non-Functional requirements&lt;/h3>
&lt;ul>
&lt;li>High availability with minimal latency.&lt;/li>
&lt;li>High reliability, no uploads should be lost.&lt;/li>
&lt;li>The system should be scalable and efficient.&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements-4">Extended requirements&lt;/h3>
&lt;ul>
&lt;li>Certain content should be &lt;a href="https://en.wikipedia.org/wiki/Geo-blocking" target="_blank" rel="noopener">geo-blocked&lt;/a>.&lt;/li>
&lt;li>Resume video playback from the point user left off.&lt;/li>
&lt;li>Record metrics and analytics of videos.&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints-4">Estimation and Constraints&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the estimation and constraints.&lt;/p>
&lt;p>&lt;em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.&lt;/em>&lt;/p>
&lt;h3 id="traffic-3">Traffic&lt;/h3>
&lt;p>This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.&lt;/p>
&lt;p>$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$&lt;/p>
&lt;p>Assuming a &lt;code>200:1&lt;/code> read/write ratio, about 50 million videos will be uploaded every day.&lt;/p>
&lt;p>$$
\frac{1}{200} \times 1 \space billion = 50 \space million/day
$$&lt;/p>
&lt;p>&lt;strong>What would be Requests Per Second (RPS) for our system?&lt;/strong>&lt;/p>
&lt;p>1 billion requests per day translate into 12K requests per second.&lt;/p>
&lt;p>$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$&lt;/p>
&lt;h3 id="storage-5">Storage&lt;/h3>
&lt;p>If we assume each video is 100 MB on average, we will require about 5 PB of storage every day.&lt;/p>
&lt;p>$$
50 \space million \times 100 \space MB = 5 \space PB/day
$$&lt;/p>
&lt;p>And for 10 years, we will require an astounding 18,250 PB of storage.&lt;/p>
&lt;p>$$
5 \space PB \times 365 \space days \times 10 \space years = \sim 18,250 \space PB
$$&lt;/p>
&lt;h3 id="bandwidth-3">Bandwidth&lt;/h3>
&lt;p>As our system is handling 5 PB of ingress every day, we will require a minimum bandwidth of around 58 GB per second.&lt;/p>
&lt;p>$$
\frac{5 \space PB}{(24 \space hrs \times 3600 \space seconds)} = \sim 58 \space GB/second
$$&lt;/p>
&lt;h3 id="high-level-estimate-3">High-level estimate&lt;/h3>
&lt;p>Here is our high-level estimate:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Estimate&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Daily active users (DAU)&lt;/td>
&lt;td>200 million&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Requests per second (RPS)&lt;/td>
&lt;td>12K/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (per day)&lt;/td>
&lt;td>~5 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (10 years)&lt;/td>
&lt;td>~18,250 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth&lt;/td>
&lt;td>~58 GB/s&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="data-model-design-4">Data model design&lt;/h2>
&lt;p>This is the general data model which reflects our requirements.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png" alt="netflix-datamodel" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>We have the following tables:&lt;/p>
&lt;p>&lt;strong>users&lt;/strong>&lt;/p>
&lt;p>This table will contain a user&amp;rsquo;s information such as &lt;code>name&lt;/code>, &lt;code>email&lt;/code>, &lt;code>dob&lt;/code>, and other details.&lt;/p>
&lt;p>&lt;strong>videos&lt;/strong>&lt;/p>
&lt;p>As the name suggests, this table will store videos and their properties such as &lt;code>title&lt;/code>, &lt;code>streamURL&lt;/code>, &lt;code>tags&lt;/code>, etc. We will also store the corresponding &lt;code>userID&lt;/code>.&lt;/p>
&lt;p>&lt;strong>tags&lt;/strong>&lt;/p>
&lt;p>This table will simply store tags associated with a video.&lt;/p>
&lt;p>&lt;strong>views&lt;/strong>&lt;/p>
&lt;p>This table helps us to store all the views received on a video.&lt;/p>
&lt;p>&lt;strong>comments&lt;/strong>&lt;/p>
&lt;p>This table stores all the comments received on a video (like YouTube).&lt;/p>
&lt;h3 id="what-kind-of-database-should-we-use-3">What kind of database should we use?&lt;/h3>
&lt;p>While our data model seems quite relational, we don&amp;rsquo;t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.&lt;/p>
&lt;p>We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a> or a distributed NoSQL database such as &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Apache Cassandra&lt;/a> for our use case.&lt;/p>
&lt;h2 id="api-design-4">API design&lt;/h2>
&lt;p>Let us do a basic API design for our services:&lt;/p>
&lt;h3 id="upload-a-video">Upload a video&lt;/h3>
&lt;p>Given a byte stream, this API enables video to be uploaded to our service.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">uploadVideo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">title&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">description&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">data&lt;/span>: &lt;span class="kt">Stream&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">byte&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">tags?&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">[])&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Title (&lt;code>string&lt;/code>): Title of the new video.&lt;/p>
&lt;p>Description (&lt;code>string&lt;/code>): Description of the new video.&lt;/p>
&lt;p>Data (&lt;code>Byte[]&lt;/code>): Byte stream of the video data.&lt;/p>
&lt;p>Tags (&lt;code>string[]&lt;/code>): Tags for the video &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="streaming-a-video">Streaming a video&lt;/h3>
&lt;p>This API allows our users to stream a video with the preferred codec and resolution.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">streamVideo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">videoID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">codec&lt;/span>: &lt;span class="kt">Enum&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">string&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">resolution&lt;/span>: &lt;span class="kt">Tuple&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">int&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">offset?&lt;/span>: &lt;span class="kt">int&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">VideoStream&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Video ID (&lt;code>UUID&lt;/code>): ID of the video that needs to be streamed.&lt;/p>
&lt;p>Codec (&lt;code>Enum&amp;lt;string&amp;gt;&lt;/code>): Required &lt;a href="https://en.wikipedia.org/wiki/Video_codec" target="_blank" rel="noopener">codec&lt;/a> of the requested video, such as &lt;code>h.265&lt;/code>, &lt;code>h.264&lt;/code>, &lt;code>VP9&lt;/code>, etc.&lt;/p>
&lt;p>Resolution (&lt;code>Tuple&amp;lt;int&amp;gt;&lt;/code>): &lt;a href="https://en.wikipedia.org/wiki/Display_resolution" target="_blank" rel="noopener">Resolution&lt;/a> of the requested video.&lt;/p>
&lt;p>Offset (&lt;code>int&lt;/code>): Offset of the video stream in seconds to stream data from any point in the video &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Stream (&lt;code>VideoStream&lt;/code>): Data stream of the requested video.&lt;/p>
&lt;h3 id="search-for-a-video">Search for a video&lt;/h3>
&lt;p>This API will enable our users to search for a video based on its title or tags.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">searchVideo&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">query&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">nextPage?&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">Video&lt;/span>&lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Query (&lt;code>string&lt;/code>): Search query from the user.&lt;/p>
&lt;p>Next Page (&lt;code>string&lt;/code>): Token for the next page, this can be used for pagination &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Videos (&lt;code>Video[]&lt;/code>): All the videos available for a particular search query.&lt;/p>
&lt;h3 id="add-a-comment">Add a comment&lt;/h3>
&lt;p>This API will allow our users to post a comment on a video (like YouTube).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">comment&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">videoID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">comment&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>VideoID (&lt;code>UUID&lt;/code>): ID of the video user wants to comment on.&lt;/p>
&lt;p>Comment (&lt;code>string&lt;/code>): The text content of the comment.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h2 id="high-level-design-3">High-level design&lt;/h2>
&lt;p>Now let us do a high-level design of our system.&lt;/p>
&lt;h3 id="architecture-2">Architecture&lt;/h3>
&lt;p>We will be using &lt;a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" target="_blank" rel="noopener">microservices architecture&lt;/a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let&amp;rsquo;s try to divide our system into some core services.&lt;/p>
&lt;p>&lt;strong>User Service&lt;/strong>&lt;/p>
&lt;p>This service handles user-related concerns such as authentication and user information.&lt;/p>
&lt;p>&lt;strong>Stream Service&lt;/strong>&lt;/p>
&lt;p>The tweet service will handle video streaming-related functionality.&lt;/p>
&lt;p>&lt;strong>Search Service&lt;/strong>&lt;/p>
&lt;p>The service is responsible for handling search-related functionality. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Media service&lt;/strong>&lt;/p>
&lt;p>This service will handle the video uploads and processing. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Analytics Service&lt;/strong>&lt;/p>
&lt;p>This service will be used for metrics and analytics use cases.&lt;/p>
&lt;p>&lt;strong>What about inter-service communication and service discovery?&lt;/strong>&lt;/p>
&lt;p>Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" target="_blank" rel="noopener">gRPC&lt;/a> which is more lightweight and efficient.&lt;/p>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/service-discovery" target="_blank" rel="noopener">Service discovery&lt;/a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" target="_blank" rel="noopener">REST, GraphQL, gRPC&lt;/a> and how they compare with each other.&lt;/em>&lt;/p>
&lt;h3 id="video-processing">Video processing&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png" alt="video-processing-pipeline" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.&lt;/p>
&lt;p>Here&amp;rsquo;s how we can process videos once they&amp;rsquo;re uploaded by the content team (or users in YouTube&amp;rsquo;s case) and are queued for processing in our &lt;a href="https://karanpratapsingh.com/courses/system-design/message-queues" target="_blank" rel="noopener">message queue&lt;/a>.&lt;/p>
&lt;p>Let&amp;rsquo;s discuss how this works:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>File Chunker&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png" alt="file-chunking" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.&lt;/p>
&lt;p>Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Content Filter&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to &lt;a href="https://en.wikipedia.org/wiki/Motion_picture_content_rating_system" target="_blank" rel="noopener">content rating&lt;/a> of the media or can be strictly enforced like by YouTube.&lt;/p>
&lt;p>This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a &lt;a href="https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues" target="_blank" rel="noopener">dead-letter queue (DLQ)&lt;/a> and someone from the moderation team can do further inspection.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Transcoder&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Transcoding" target="_blank" rel="noopener">Transcoding&lt;/a> is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different &lt;a href="https://en.wikipedia.org/wiki/Video_codec" target="_blank" rel="noopener">codecs&lt;/a> to perform bitrate adjustment, image downsampling, or re-encoding the media.&lt;/p>
&lt;p>This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as &lt;a href="https://ffmpeg.org" target="_blank" rel="noopener">FFmpeg&lt;/a> or cloud-based solutions like &lt;a href="https://aws.amazon.com/mediaconvert" target="_blank" rel="noopener">AWS Elemental MediaConvert&lt;/a> can be used to implement this step of the pipeline.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Quality Conversion&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.&lt;/p>
&lt;p>It allows us to fetch the desired quality of the video as per the user&amp;rsquo;s request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" target="_blank" rel="noopener">HDFS&lt;/a>, &lt;a href="https://www.gluster.org" target="_blank" rel="noopener">GlusterFS&lt;/a>, or an &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" target="_blank" rel="noopener">object storage&lt;/a> such as &lt;a href="https://aws.amazon.com/s3" target="_blank" rel="noopener">Amazon S3&lt;/a> for later retrieval during streaming.&lt;/p>
&lt;p>&lt;em>Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline.&lt;/em>&lt;/p>
&lt;p>&lt;strong>Why are we using a message queue?&lt;/strong>&lt;/p>
&lt;p>Processing videos as a long-running task and using a &lt;a href="https://karanpratapsingh.com/courses/system-design/message-queues" target="_blank" rel="noopener">message queue&lt;/a> makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like &lt;a href="https://aws.amazon.com/sqs" target="_blank" rel="noopener">Amazon SQS&lt;/a> or &lt;a href="https://www.rabbitmq.com" target="_blank" rel="noopener">RabbitMQ&lt;/a> to support this.&lt;/p>
&lt;h3 id="video-streaming">Video streaming&lt;/h3>
&lt;p>Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don&amp;rsquo;t re-fetch the same content, we can use a &lt;a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" target="_blank" rel="noopener">Content Delivery Network (CDN)&lt;/a>.&lt;/p>
&lt;p>Netflix takes this a step further with its &lt;a href="https://openconnect.netflix.com" target="_blank" rel="noopener">Open Connect&lt;/a> program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.&lt;/p>
&lt;p>&lt;strong>What is the difference between Netflix&amp;rsquo;s Open Connect and a traditional Content Delivery Network (CDN)?&lt;/strong>&lt;/p>
&lt;p>Netflix Open Connect is a purpose-built &lt;a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" target="_blank" rel="noopener">Content Delivery Network (CDN)&lt;/a> responsible for serving Netflix&amp;rsquo;s video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.&lt;/p>
&lt;p>Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.&lt;/p>
&lt;p>Additionally, we can use &lt;a href="https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming" target="_blank" rel="noopener">Adaptive bitrate streaming&lt;/a> protocols such as &lt;a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming" target="_blank" rel="noopener">HTTP Live Streaming (HLS)&lt;/a> which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.&lt;/p>
&lt;p>Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the &lt;code>offset&lt;/code> property we stored in the &lt;code>views&lt;/code> table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.&lt;/p>
&lt;h3 id="searching">Searching&lt;/h3>
&lt;p>Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. &lt;a href="https://www.elastic.co" target="_blank" rel="noopener">Elasticsearch&lt;/a> can help us with this use case.&lt;/p>
&lt;p>&lt;a href="https://www.elastic.co" target="_blank" rel="noopener">Elasticsearch&lt;/a> is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of &lt;a href="https://lucene.apache.org" target="_blank" rel="noopener">Apache Lucene&lt;/a>.&lt;/p>
&lt;p>&lt;strong>How do we identify trending content?&lt;/strong>&lt;/p>
&lt;p>Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last &lt;code>N&lt;/code> seconds and update them every &lt;code>M&lt;/code> seconds using some sort of batch job mechanism.&lt;/p>
&lt;h3 id="sharing">Sharing&lt;/h3>
&lt;p>Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.&lt;/p>
&lt;p>&lt;em>For more details, refer to the &lt;a href="https://karanpratapsingh.com/courses/system-design/url-shortener" target="_blank" rel="noopener">URL Shortener&lt;/a> system design.&lt;/em>&lt;/p>
&lt;h2 id="detailed-design-4">Detailed design&lt;/h2>
&lt;p>It&amp;rsquo;s time to discuss our design decisions in detail.&lt;/p>
&lt;h3 id="data-partitioning-4">Data Partitioning&lt;/h3>
&lt;p>To scale out our databases we will need to partition our data. Horizontal partitioning (aka &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a>) can be a good first step. We can use partitions schemes such as:&lt;/p>
&lt;ul>
&lt;li>Hash-Based Partitioning&lt;/li>
&lt;li>List-Based Partitioning&lt;/li>
&lt;li>Range Based Partitioning&lt;/li>
&lt;li>Composite Partitioning&lt;/li>
&lt;/ul>
&lt;p>The above approaches can still cause uneven data and load distribution, we can solve this using &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent hashing&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent Hashing&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="geo-blocking">Geo-blocking&lt;/h3>
&lt;p>Platforms like Netflix and YouTube use &lt;a href="https://en.wikipedia.org/wiki/Geo-blocking" target="_blank" rel="noopener">Geo-blocking&lt;/a> to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.&lt;/p>
&lt;p>We can determine the user&amp;rsquo;s location either using their &lt;a href="https://karanpratapsingh.com/courses/system-design/ip" target="_blank" rel="noopener">IP&lt;/a> or region settings in their profile then use services like &lt;a href="https://aws.amazon.com/cloudfront" target="_blank" rel="noopener">Amazon CloudFront&lt;/a> which supports a geographic restrictions feature or a &lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html" target="_blank" rel="noopener">geolocation routing policy&lt;/a> with &lt;a href="https://aws.amazon.com/route53" target="_blank" rel="noopener">Amazon Route53&lt;/a> to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.&lt;/p>
&lt;h3 id="recommendations">Recommendations&lt;/h3>
&lt;p>Netflix uses a machine learning model which uses the user&amp;rsquo;s viewing history to predict what the user might like to watch next, an algorithm like &lt;a href="https://en.wikipedia.org/wiki/Collaborative_filtering" target="_blank" rel="noopener">Collaborative Filtering&lt;/a> can be used.&lt;/p>
&lt;p>However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as:&lt;/p>
&lt;ul>
&lt;li>User profile information like age, gender, and location.&lt;/li>
&lt;li>Browsing and scrolling behavior of the user.&lt;/li>
&lt;li>Time and date a user watched a title.&lt;/li>
&lt;li>The device which was used to stream the content.&lt;/li>
&lt;li>The number of searches and what terms were searched.&lt;/li>
&lt;/ul>
&lt;p>&lt;em>For more detail, refer to &lt;a href="https://research.netflix.com/research-area/recommendations" target="_blank" rel="noopener">Netflix recommendation research&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="metrics-and-analytics-2">Metrics and Analytics&lt;/h3>
&lt;p>Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using &lt;a href="https://spark.apache.org" target="_blank" rel="noopener">Apache Spark&lt;/a> which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.&lt;/p>
&lt;h3 id="caching-4">Caching&lt;/h3>
&lt;p>In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> but what kind of cache eviction policy would best fit our needs?&lt;/p>
&lt;p>&lt;strong>Which cache eviction policy to use?&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_%28LRU%29" target="_blank" rel="noopener">Least Recently Used (LRU)&lt;/a> can be a good policy for our system. In this policy, we discard the least recently used key first.&lt;/p>
&lt;p>&lt;strong>How to handle cache miss?&lt;/strong>&lt;/p>
&lt;p>Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">Caching&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="media-streaming-and-storage">Media streaming and storage&lt;/h3>
&lt;p>As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.&lt;/p>
&lt;p>We will use distributed file storage such as &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#hdfs" target="_blank" rel="noopener">HDFS&lt;/a>, &lt;a href="https://www.gluster.org" target="_blank" rel="noopener">GlusterFS&lt;/a>, or an &lt;a href="https://karanpratapsingh.com/courses/system-design/storage#object-storage" target="_blank" rel="noopener">object storage&lt;/a> such as &lt;a href="https://aws.amazon.com/s3" target="_blank" rel="noopener">Amazon S3&lt;/a> for storage and streaming of the content.&lt;/p>
&lt;h3 id="content-delivery-network-cdn-3">Content Delivery Network (CDN)&lt;/h3>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/content-delivery-network" target="_blank" rel="noopener">Content Delivery Network (CDN)&lt;/a> increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like &lt;a href="https://aws.amazon.com/cloudfront" target="_blank" rel="noopener">Amazon CloudFront&lt;/a> or &lt;a href="https://www.cloudflare.com/cdn" target="_blank" rel="noopener">Cloudflare CDN&lt;/a> for this use case.&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks-4">Identify and resolve bottlenecks&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png" alt="netflix-advanced-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let us identify and resolve bottlenecks such as single points of failure in our design:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What if one of our services crashes?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we distribute our traffic between our components?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce the load on our database?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>To make our system more resilient we can do the following:&lt;/p>
&lt;ul>
&lt;li>Running multiple instances of each of our services.&lt;/li>
&lt;li>Introducing &lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">load balancers&lt;/a> between clients, servers, databases, and cache servers.&lt;/li>
&lt;li>Using multiple read replicas for our databases.&lt;/li>
&lt;li>Multiple instances and replicas for our distributed cache.&lt;/li>
&lt;/ul>
&lt;h1 id="uber">Uber&lt;/h1>
&lt;p>Let&amp;rsquo;s design an &lt;a href="https://uber.com" target="_blank" rel="noopener">Uber&lt;/a> like ride-hailing service, similar to services like &lt;a href="https://www.lyft.com" target="_blank" rel="noopener">Lyft&lt;/a>, &lt;a href="https://www.olacabs.com" target="_blank" rel="noopener">OLA Cabs&lt;/a>, etc.&lt;/p>
&lt;h2 id="what-is-uber">What is Uber?&lt;/h2>
&lt;p>Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.&lt;/p>
&lt;h2 id="requirements-4">Requirements&lt;/h2>
&lt;p>Our system should meet the following requirements:&lt;/p>
&lt;h3 id="functional-requirements-5">Functional requirements&lt;/h3>
&lt;p>We will design our system for two types of users: Customers and Drivers.&lt;/p>
&lt;p>&lt;strong>Customers&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.&lt;/li>
&lt;li>Customers should be able to book a cab to a destination.&lt;/li>
&lt;li>Customers should be able to see the location of the driver.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Drivers&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Drivers should be able to accept or deny the customer-requested ride.&lt;/li>
&lt;li>Once a driver accepts the ride, they should see the pickup location of the customer.&lt;/li>
&lt;li>Drivers should be able to mark the trip as complete on reaching the destination.&lt;/li>
&lt;/ul>
&lt;h3 id="non-functional-requirements-5">Non-Functional requirements&lt;/h3>
&lt;ul>
&lt;li>High reliability.&lt;/li>
&lt;li>High availability with minimal latency.&lt;/li>
&lt;li>The system should be scalable and efficient.&lt;/li>
&lt;/ul>
&lt;h3 id="extended-requirements-5">Extended requirements&lt;/h3>
&lt;ul>
&lt;li>Customers can rate the trip after it&amp;rsquo;s completed.&lt;/li>
&lt;li>Payment processing.&lt;/li>
&lt;li>Metrics and analytics.&lt;/li>
&lt;/ul>
&lt;h2 id="estimation-and-constraints-5">Estimation and Constraints&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the estimation and constraints.&lt;/p>
&lt;p>&lt;em>Note: Make sure to check any scale or traffic-related assumptions with your interviewer.&lt;/em>&lt;/p>
&lt;h3 id="traffic-4">Traffic&lt;/h3>
&lt;p>Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.&lt;/p>
&lt;p>If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.&lt;/p>
&lt;p>$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$&lt;/p>
&lt;p>&lt;strong>What would be Requests Per Second (RPS) for our system?&lt;/strong>&lt;/p>
&lt;p>1 billion requests per day translate into 12K requests per second.&lt;/p>
&lt;p>$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$&lt;/p>
&lt;h3 id="storage-6">Storage&lt;/h3>
&lt;p>If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.&lt;/p>
&lt;p>$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$&lt;/p>
&lt;p>And for 10 years, we will require about 1.4 PB of storage.&lt;/p>
&lt;p>$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$&lt;/p>
&lt;h3 id="bandwidth-4">Bandwidth&lt;/h3>
&lt;p>As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.&lt;/p>
&lt;p>$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$&lt;/p>
&lt;h3 id="high-level-estimate-4">High-level estimate&lt;/h3>
&lt;p>Here is our high-level estimate:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Estimate&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Daily active users (DAU)&lt;/td>
&lt;td>100 million&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Requests per second (RPS)&lt;/td>
&lt;td>12K/s&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (per day)&lt;/td>
&lt;td>~400 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Storage (10 years)&lt;/td>
&lt;td>~1.4 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bandwidth&lt;/td>
&lt;td>~5 MB/s&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="data-model-design-5">Data model design&lt;/h2>
&lt;p>This is the general data model which reflects our requirements.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png" alt="uber-datamodel" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>We have the following tables:&lt;/p>
&lt;p>&lt;strong>customers&lt;/strong>&lt;/p>
&lt;p>This table will contain a customer&amp;rsquo;s information such as &lt;code>name&lt;/code>, &lt;code>email&lt;/code>, and other details.&lt;/p>
&lt;p>&lt;strong>drivers&lt;/strong>&lt;/p>
&lt;p>This table will contain a driver&amp;rsquo;s information such as &lt;code>name&lt;/code>, &lt;code>email&lt;/code>, &lt;code>dob&lt;/code> and other details.&lt;/p>
&lt;p>&lt;strong>trips&lt;/strong>&lt;/p>
&lt;p>This table represents the trip taken by the customer and stores data such as &lt;code>source&lt;/code>, &lt;code>destination&lt;/code>, and &lt;code>status&lt;/code> of the trip.&lt;/p>
&lt;p>&lt;strong>cabs&lt;/strong>&lt;/p>
&lt;p>This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.&lt;/p>
&lt;p>&lt;strong>ratings&lt;/strong>&lt;/p>
&lt;p>As the name suggests, this table stores the &lt;code>rating&lt;/code> and &lt;code>feedback&lt;/code> for the trip.&lt;/p>
&lt;p>&lt;strong>payments&lt;/strong>&lt;/p>
&lt;p>The payments table contains the payment-related data with the corresponding &lt;code>tripID&lt;/code>.&lt;/p>
&lt;h3 id="what-kind-of-database-should-we-use-4">What kind of database should we use?&lt;/h3>
&lt;p>While our data model seems quite relational, we don&amp;rsquo;t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.&lt;/p>
&lt;p>We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a> or a distributed NoSQL database such as &lt;a href="https://cassandra.apache.org/_/index.html" target="_blank" rel="noopener">Apache Cassandra&lt;/a> for our use case.&lt;/p>
&lt;h2 id="api-design-5">API design&lt;/h2>
&lt;p>Let us do a basic API design for our services:&lt;/p>
&lt;h3 id="request-a-ride">Request a Ride&lt;/h3>
&lt;p>Through this API, customers will be able to request a ride.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">requestRide&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">customerID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">source&lt;/span>: &lt;span class="kt">Tuple&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">float&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">destination&lt;/span>: &lt;span class="kt">Tuple&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">float&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">cabType&lt;/span>: &lt;span class="kt">Enum&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">string&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="nx">paymentMethod&lt;/span>: &lt;span class="kt">Enum&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">string&lt;/span>&lt;span class="p">&amp;gt;)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">Ride&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Customer ID (&lt;code>UUID&lt;/code>): ID of the customer.&lt;/p>
&lt;p>Source (&lt;code>Tuple&amp;lt;float&amp;gt;&lt;/code>): Tuple containing the latitude and longitude of the trip&amp;rsquo;s starting location.&lt;/p>
&lt;p>Destination (&lt;code>Tuple&amp;lt;float&amp;gt;&lt;/code>): Tuple containing the latitude and longitude of the trip&amp;rsquo;s destination.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>Ride&lt;/code>): Associated ride information of the trip.&lt;/p>
&lt;h3 id="cancel-the-ride">Cancel the Ride&lt;/h3>
&lt;p>This API will allow customers to cancel the ride.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">cancelRide&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">customerID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">reason?&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Customer ID (&lt;code>UUID&lt;/code>): ID of the customer.&lt;/p>
&lt;p>Reason (&lt;code>UUID&lt;/code>): Reason for canceling the ride &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="accept-or-deny-the-ride">Accept or Deny the Ride&lt;/h3>
&lt;p>This API will allow the driver to accept or deny the trip.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">acceptRide&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">driverID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">rideID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">denyRide&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">driverID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">rideID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Driver ID (&lt;code>UUID&lt;/code>): ID of the driver.&lt;/p>
&lt;p>Ride ID (&lt;code>UUID&lt;/code>): ID of the customer requested ride.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="start-or-end-the-trip">Start or End the Trip&lt;/h3>
&lt;p>Using this API, a driver will be able to start and end the trip.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">startTrip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">driverID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">tripID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">endTrip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">driverID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">tripID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Driver ID (&lt;code>UUID&lt;/code>): ID of the driver.&lt;/p>
&lt;p>Trip ID (&lt;code>UUID&lt;/code>): ID of the requested trip.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h3 id="rate-the-trip">Rate the Trip&lt;/h3>
&lt;p>This API will enable customers to rate the trip.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-tsx" data-lang="tsx">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">rateTrip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">customerID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">tripID&lt;/span>: &lt;span class="kt">UUID&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">rating&lt;/span>: &lt;span class="kt">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">feedback?&lt;/span>: &lt;span class="kt">string&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kr">boolean&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Parameters&lt;/strong>&lt;/p>
&lt;p>Customer ID (&lt;code>UUID&lt;/code>): ID of the customer.&lt;/p>
&lt;p>Trip ID (&lt;code>UUID&lt;/code>): ID of the completed trip.&lt;/p>
&lt;p>Rating (&lt;code>int&lt;/code>): Rating of the trip.&lt;/p>
&lt;p>Feedback (&lt;code>string&lt;/code>): Feedback about the trip by the customer &lt;em>(optional)&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Returns&lt;/strong>&lt;/p>
&lt;p>Result (&lt;code>boolean&lt;/code>): Represents whether the operation was successful or not.&lt;/p>
&lt;h2 id="high-level-design-4">High-level design&lt;/h2>
&lt;p>Now let us do a high-level design of our system.&lt;/p>
&lt;h3 id="architecture-3">Architecture&lt;/h3>
&lt;p>We will be using &lt;a href="https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices" target="_blank" rel="noopener">microservices architecture&lt;/a> since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let&amp;rsquo;s try to divide our system into some core services.&lt;/p>
&lt;p>&lt;strong>Customer Service&lt;/strong>&lt;/p>
&lt;p>This service handles customer-related concerns such as authentication and customer information.&lt;/p>
&lt;p>&lt;strong>Driver Service&lt;/strong>&lt;/p>
&lt;p>This service handles driver-related concerns such as authentication and driver information.&lt;/p>
&lt;p>&lt;strong>Ride Service&lt;/strong>&lt;/p>
&lt;p>This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Trip Service&lt;/strong>&lt;/p>
&lt;p>This service handles trip-related functionality in our system.&lt;/p>
&lt;p>&lt;strong>Payment Service&lt;/strong>&lt;/p>
&lt;p>This service will be responsible for handling payments in our system.&lt;/p>
&lt;p>&lt;strong>Notification Service&lt;/strong>&lt;/p>
&lt;p>This service will simply send push notifications to the users. It will be discussed in detail separately.&lt;/p>
&lt;p>&lt;strong>Analytics Service&lt;/strong>&lt;/p>
&lt;p>This service will be used for metrics and analytics use cases.&lt;/p>
&lt;p>&lt;strong>What about inter-service communication and service discovery?&lt;/strong>&lt;/p>
&lt;p>Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc" target="_blank" rel="noopener">gRPC&lt;/a> which is more lightweight and efficient.&lt;/p>
&lt;p>&lt;a href="https://karanpratapsingh.com/courses/system-design/service-discovery" target="_blank" rel="noopener">Service discovery&lt;/a> is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc" target="_blank" rel="noopener">REST, GraphQL, gRPC&lt;/a> and how they compare with each other.&lt;/em>&lt;/p>
&lt;h3 id="how-is-the-service-expected-to-work">How is the service expected to work?&lt;/h3>
&lt;p>Here&amp;rsquo;s how our service is expected to work:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png" alt="uber-working" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol>
&lt;li>Customer requests a ride by specifying the source, destination, cab type, payment method, etc.&lt;/li>
&lt;li>Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).&lt;/li>
&lt;li>The request is then broadcasted to the nearby drivers for them to accept or deny.&lt;/li>
&lt;li>If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.&lt;/li>
&lt;li>The customer is picked up and the driver can start the trip.&lt;/li>
&lt;li>Once the destination is reached, the driver will mark the ride as complete and collect payment.&lt;/li>
&lt;li>After the payment is complete, the customer can leave a rating and feedback for the trip if they like.&lt;/li>
&lt;/ol>
&lt;h3 id="location-tracking">Location Tracking&lt;/h3>
&lt;p>How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:&lt;/p>
&lt;p>&lt;strong>Pull model&lt;/strong>&lt;/p>
&lt;p>The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling" target="_blank" rel="noopener">Long polling&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Push model&lt;/strong>&lt;/p>
&lt;p>The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" target="_blank" rel="noopener">WebSockets&lt;/a> or &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" target="_blank" rel="noopener">Server-Sent Events (SSE)&lt;/a> for this.&lt;/p>
&lt;p>The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets" target="_blank" rel="noopener">WebSockets&lt;/a> is a better choice because then we can push data to the client once it&amp;rsquo;s available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse" target="_blank" rel="noopener">Server-Sent Events (SSE)&lt;/a> which are only unidirectional.&lt;/p>
&lt;p>Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.&lt;/p>
&lt;p>&lt;em>Note: Learn more about &lt;a href="https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events" target="_blank" rel="noopener">Long polling, WebSockets, Server-Sent Events (SSE)&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="ride-matching">Ride Matching&lt;/h3>
&lt;p>We need a way to efficiently store and query nearby drivers. Let&amp;rsquo;s explore different solutions we can incorporate into our design.&lt;/p>
&lt;p>&lt;strong>SQL&lt;/strong>&lt;/p>
&lt;p>We already have access to the latitude and longitude of our customers, and with databases like &lt;a href="https://www.postgresql.org" target="_blank" rel="noopener">PostgreSQL&lt;/a> and &lt;a href="https://www.mysql.com" target="_blank" rel="noopener">MySQL&lt;/a> we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">SELECT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">locations&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WHERE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">lat&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">BETWEEN&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">X&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">R&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">X&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">R&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">long&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">BETWEEN&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Y&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">R&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Y&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">R&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, this is not scalable, and performing this query on large datasets will be quite slow.&lt;/p>
&lt;p>&lt;strong>Geohashing&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://ng-tech.icu/courses/sytem-design/geohashing-and-quadtrees#geohashing">Geohashing&lt;/a> is a &lt;a href="https://en.wikipedia.org/wiki/Address_geocoding" target="_blank" rel="noopener">geocoding&lt;/a> method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by &lt;a href="https://twitter.com/gniemeyer" target="_blank" rel="noopener">Gustavo Niemeyer&lt;/a> in 2008.&lt;/p>
&lt;p>Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png" alt="geohashing" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>For example, San Francisco with coordinates &lt;code>37.7564, -122.4016&lt;/code> can be represented in geohash as &lt;code>9q8yy9mf&lt;/code>.&lt;/p>
&lt;p>Now, using the customer&amp;rsquo;s geohash we can determine the nearest available driver by simply comparing it with the driver&amp;rsquo;s geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.&lt;/p>
&lt;p>&lt;strong>Quadtrees&lt;/strong>&lt;/p>
&lt;p>A &lt;a href="https://ng-tech.icu/courses/sytem-design/geohashing-and-quadtrees#quadtrees">Quadtree&lt;/a> is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of &lt;a href="https://en.wikipedia.org/wiki/Octree" target="_blank" rel="noopener">Octrees&lt;/a> which are used to partition three-dimensional space.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png" alt="quadtree" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.&lt;/p>
&lt;p>We can save further computation by only subdividing a node after a certain threshold.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png" alt="quadtree-subdivision" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>&lt;a href="https://ng-tech.icu/courses/sytem-design/geohashing-and-quadtrees#quadtrees">Quadtree&lt;/a> seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> to cache the latest updates. And with the application of mapping algorithms such as the &lt;a href="https://en.wikipedia.org/wiki/Hilbert_curve" target="_blank" rel="noopener">Hilbert curve&lt;/a>, we can perform efficient range queries to find nearby drivers for the customer.&lt;/p>
&lt;p>&lt;strong>What about race conditions?&lt;/strong>&lt;/p>
&lt;p>Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a &lt;a href="https://en.wikipedia.org/wiki/Lock_%28computer_science%29" target="_blank" rel="noopener">Mutex&lt;/a> to avoid any race conditions. Furthermore, every action should be transactional in nature.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/transactions" target="_blank" rel="noopener">Transactions&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/distributed-transactions" target="_blank" rel="noopener">Distributed Transactions&lt;/a>.&lt;/em>&lt;/p>
&lt;p>&lt;strong>How to find the best drivers nearby?&lt;/strong>&lt;/p>
&lt;p>Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.&lt;/p>
&lt;p>&lt;strong>Dealing with high demand&lt;/strong>&lt;/p>
&lt;p>In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.&lt;/p>
&lt;p>&lt;em>For more details, learn how &lt;a href="https://www.uber.com/us/en/drive/driver-app/how-surge-works" target="_blank" rel="noopener">surge pricing works&lt;/a> with Uber.&lt;/em>&lt;/p>
&lt;h3 id="payments">Payments&lt;/h3>
&lt;p>Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like &lt;a href="https://stripe.com" target="_blank" rel="noopener">Stripe&lt;/a> or &lt;a href="https://www.paypal.com" target="_blank" rel="noopener">PayPal&lt;/a>. Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a &lt;a href="https://en.wikipedia.org/wiki/Webhook" target="_blank" rel="noopener">webhook&lt;/a> to capture all the payment-related data.&lt;/p>
&lt;h3 id="notifications-2">Notifications&lt;/h3>
&lt;p>Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> with the notification service to dispatch requests to &lt;a href="https://firebase.google.com/docs/cloud-messaging" target="_blank" rel="noopener">Firebase Cloud Messaging (FCM)&lt;/a> or &lt;a href="https://developer.apple.com/documentation/usernotifications" target="_blank" rel="noopener">Apple Push Notification Service (APNS)&lt;/a> which will handle the delivery of the push notifications to user devices.&lt;/p>
&lt;p>&lt;em>For more details, refer to the &lt;a href="https://karanpratapsingh.com/courses/system-design/whatsapp#notifications" target="_blank" rel="noopener">WhatsApp&lt;/a> system design where we discuss push notifications in detail.&lt;/em>&lt;/p>
&lt;h2 id="detailed-design-5">Detailed design&lt;/h2>
&lt;p>It&amp;rsquo;s time to discuss our design decisions in detail.&lt;/p>
&lt;h3 id="data-partitioning-5">Data Partitioning&lt;/h3>
&lt;p>To scale out our databases we will need to partition our data. Horizontal partitioning (aka &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a>) can be a good first step. We can shard our database either based on existing &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria" target="_blank" rel="noopener">partition schemes&lt;/a> or regions. If we divide the locations into regions using let&amp;rsquo;s say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent hashing&lt;/a>.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/sharding" target="_blank" rel="noopener">Sharding&lt;/a> and &lt;a href="https://karanpratapsingh.com/courses/system-design/consistent-hashing" target="_blank" rel="noopener">Consistent Hashing&lt;/a>.&lt;/em>&lt;/p>
&lt;h3 id="metrics-and-analytics-3">Metrics and Analytics&lt;/h3>
&lt;p>Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using &lt;a href="https://spark.apache.org" target="_blank" rel="noopener">Apache Spark&lt;/a> which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.&lt;/p>
&lt;h3 id="caching-5">Caching&lt;/h3>
&lt;p>In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like &lt;a href="https://redis.io" target="_blank" rel="noopener">Redis&lt;/a> or &lt;a href="https://memcached.org" target="_blank" rel="noopener">Memcached&lt;/a> but what kind of cache eviction policy would best fit our needs?&lt;/p>
&lt;p>&lt;strong>Which cache eviction policy to use?&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_%28LRU%29" target="_blank" rel="noopener">Least Recently Used (LRU)&lt;/a> can be a good policy for our system. In this policy, we discard the least recently used key first.&lt;/p>
&lt;p>&lt;strong>How to handle cache miss?&lt;/strong>&lt;/p>
&lt;p>Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.&lt;/p>
&lt;p>&lt;em>For more details, refer to &lt;a href="https://karanpratapsingh.com/courses/system-design/caching" target="_blank" rel="noopener">Caching&lt;/a>.&lt;/em>&lt;/p>
&lt;h2 id="identify-and-resolve-bottlenecks-5">Identify and resolve bottlenecks&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png" alt="uber-advanced-design" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Let us identify and resolve bottlenecks such as single points of failure in our design:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;What if one of our services crashes?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How will we distribute our traffic between our components?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we reduce the load on our database?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How to improve the availability of our cache?&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;How can we make our notification system more robust?&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>To make our system more resilient we can do the following:&lt;/p>
&lt;ul>
&lt;li>Running multiple instances of each of our services.&lt;/li>
&lt;li>Introducing &lt;a href="https://karanpratapsingh.com/courses/system-design/load-balancing" target="_blank" rel="noopener">load balancers&lt;/a> between clients, servers, databases, and cache servers.&lt;/li>
&lt;li>Using multiple read replicas for our databases.&lt;/li>
&lt;li>Multiple instances and replicas for our distributed cache.&lt;/li>
&lt;li>Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated &lt;a href="https://karanpratapsingh.com/courses/system-design/message-brokers" target="_blank" rel="noopener">message broker&lt;/a> such as &lt;a href="https://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka&lt;/a> or &lt;a href="https://nats.io" target="_blank" rel="noopener">NATS&lt;/a> to make our notification system more robust.&lt;/li>
&lt;/ul>
&lt;h1 id="next-steps">Next Steps&lt;/h1>
&lt;p>Congratulations, you&amp;rsquo;ve finished the course!&lt;/p>
&lt;p>Now that you know the fundamentals of System Design, here are some additional resources:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=UEAMfLPZZhE&amp;amp;list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB" target="_blank" rel="noopener">Distributed Systems&lt;/a> (by Dr. Martin Kleppmann)&lt;/li>
&lt;li>&lt;a href="https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF" target="_blank" rel="noopener">System Design Interview: An Insider&amp;rsquo;s Guide&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://microservices.io" target="_blank" rel="noopener">Microservices&lt;/a> (by Chris Richardson)&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Serverless_computing" target="_blank" rel="noopener">Serverless computing&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io" target="_blank" rel="noopener">Kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://engineering.microsoft.com" target="_blank" rel="noopener">Microsoft Engineering&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://googleresearch.blogspot.com" target="_blank" rel="noopener">Google Research Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://techblog.netflix.com" target="_blank" rel="noopener">Netflix Tech Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/blogs/aws" target="_blank" rel="noopener">AWS Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.facebook.com/Engineering" target="_blank" rel="noopener">Facebook Engineering&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://eng.uber.com" target="_blank" rel="noopener">Uber Engineering Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://nerds.airbnb.com" target="_blank" rel="noopener">Airbnb Engineering&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.blog/category/engineering" target="_blank" rel="noopener">GitHub Engineering Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://software.intel.com/en-us/blogs" target="_blank" rel="noopener">Intel Software Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://engineering.linkedin.com/blog" target="_blank" rel="noopener">LinkedIn Engineering&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/paypal-engineering" target="_blank" rel="noopener">Paypal Developer Blog&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.twitter.com/engineering" target="_blank" rel="noopener">Twitter Engineering&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.&lt;/p>
&lt;p>I hope this course was a great learning experience. I would love to hear feedback from you.&lt;/p>
&lt;p>Wishing you all the best for further learning!&lt;/p>
&lt;h1 id="references">References&lt;/h1>
&lt;p>Here are the resources that were referenced while creating this course.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.cloudflare.com/learning" target="_blank" rel="noopener">Cloudflare learning center&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.ibm.com/blogs" target="_blank" rel="noopener">IBM Blogs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.fastly.com/blog" target="_blank" rel="noopener">Fastly Blogs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ns1.com/blog" target="_blank" rel="noopener">NS1 Blogs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.educative.io/courses/grokking-the-system-design-interview" target="_blank" rel="noopener">Grokking the System Design Interview&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/donnemartin/system-design-primer" target="_blank" rel="noopener">System Design Primer&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/blogs" target="_blank" rel="noopener">AWS Blogs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://martinfowler.com" target="_blank" rel="noopener">Martin Fowler&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.pagerduty.com/resources" target="_blank" rel="noopener">PagerDuty resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blogs.vmware.com/learning" target="_blank" rel="noopener">VMWare Blogs&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;em>All the diagrams were made using &lt;a href="https://excalidraw.com" target="_blank" rel="noopener">Excalidraw&lt;/a> and are available &lt;a href="https://github.com/karanpratapsingh/system-design/tree/main/diagrams" target="_blank" rel="noopener">here&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Live-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/live-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/live-cheatsheet/</guid><description>&lt;blockquote>
&lt;p>本文节选自 &lt;a href="https://github.com/wx-chevalier/Awesome-CheatSheets/blob/master/IndustrialApplication/IM/Live-CheatSheet.md" target="_blank" rel="noopener">Live CheatSheet | 直播技术理论基础与实践概论&lt;/a>，&lt;strong>很多内容非作者原创&lt;/strong>，而是对 &lt;a href="https://github.com/wx-chevalier/Awesome-Lists/blob/master/IndustrialApplication/IM/Live-List.md" target="_blank" rel="noopener">Live Links&lt;/a> 中列举出的多篇文章的盘点总结，更多直播相关内容可以前往 &lt;a href="https://ng-tech.icu/books/home/#/search?query=%E7%9B%B4%E6%92%AD" target="_blank" rel="noopener">xCompass&lt;/a> 交互式检索或 &lt;a href="https://github.com/wx-chevalier/MushiChat" target="_blank" rel="noopener">MushiChat&lt;/a> 查看代码。&lt;/p>
&lt;/blockquote>
&lt;h1 id="live-cheatsheet--直播技术理论基础与实践概论">Live CheatSheet | 直播技术理论基础与实践概论&lt;/h1>
&lt;p>音视频直播的基本流程都是&lt;code>采集 → 编码推流 → 网络分发 → 解码 → 播放&lt;/code>这五大环节，其中又会涉及平台硬件、编解码、网络传输、服务并发、数字信号处理、在线学习等多方面技术。从交互模式上，又可以泛分为单对单模式与会议模式两大类；从实时性要求上，直播又可以分为伪实时、准实时与真实时三个等级:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>伪实时：视频消费延迟超过 3 秒，单向观看实时，通用架构是 CDN + RTMP + HLS，譬如很多的直播平台&lt;/p>
&lt;/li>
&lt;li>
&lt;p>准实时：视频消费延迟 1 ~ 3 秒，能进行双方互动但互动有障碍；可以通过 TCP/UDP + FLV 已经实现了这类技术，譬如 YY 直播等&lt;/p>
&lt;/li>
&lt;li>
&lt;p>真实时：视频消费延迟 &amp;lt; 1 秒，平均 500 毫秒，譬如 QQ、微信、Skype 和 WebRTC 等&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="编解码">编解码&lt;/h1>
&lt;p>视频封装格式就是我们通常所说的 .mp4,.flv,.ogv,.webm 等，它其实就是一个盒子，用来将实际的视频流以一定的顺序放入，确保播放的有序和完整性。视频压缩格式(视频编码)就是指能够对数字视频进行压缩或者解压缩(视频解码)的程序或者设备。通常这种压缩属于有损数据压缩。&lt;/p>
&lt;p>视频压缩格式和视频格式具体的区别就是，它是将原始的视频码流变为可用的数字编码。首先，由原始数码设备提供相关的数字信号流，然后经由视频压缩算法，大幅度的减少流的大小，然后交给视频盒子，打上相应的 dts，pts 字段，最终生成可用的视频文件。视频编码也可以指通过过特定的压缩技术，将某个视频格式转换成另一种视频格式。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47571461-2cbb4a80-d96b-11e8-855f-19dc0c8f8305.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="视频封装格式">视频封装格式&lt;/h2>
&lt;p>常见的视频封装格式(简称：视频格式)包括了 AVI，MPEG，VOB 等，即相当于一种储存视频信息的容器，由相应的公司开发出来的。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47571490-3e9ced80-d96b-11e8-97ec-f1fd8af219e2.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h3 id="avi">AVI&lt;/h3>
&lt;p>AVI 格式(后缀为.AVI)：它的英文全称为 Audio Video Interleaved，即音频视频交错格式。它于 1992 年被 Microsoft 公司推出。&lt;/p>
&lt;p>这种视频格式的优点是图像质量好。由于无损 AVI 可以保存 alpha 通道，经常被我们使用。缺点太多，体积过于庞大，而且更加糟糕的是压缩标准不统一，最普遍的现象就是高版本 Windows 媒体播放器播放不了采用早期编码编辑的 AVI 格式视频，而低版本 Windows 媒体播放器又播放不了采用最新编码编辑的 AVI 格式视频，所以我们在进行一些 AVI 格式的视频播放时常会出现由于视频编码问题而造成的视频不能播放或即使能够播放，但存在不能调节播放进度和播放时只有声音没有图像等一些莫名其妙的问题。&lt;/p>
&lt;h3 id="dv-avi">DV-AVI&lt;/h3>
&lt;p>DV-AVI 格式(后缀为.AVI)：DV 的英文全称是 Digital Video Format，是由索尼、松下、JVC 等多家厂商联合提出的一种家用数字视频格式。&lt;/p>
&lt;p>数字摄像机就是使用这种格式记录视频数据的。它可以通过电脑的 IEEE 1394 端口传输视频数据到电脑，也可以将电脑中编辑好的的视频数据回录到数码摄像机中。这种视频格式的文件扩展名也是 avi。电视台采用录像带记录模拟信号，通过 EDIUS 由 IEEE 1394 端口采集卡从录像带中采集出来的视频就是这种格式。&lt;/p>
&lt;h3 id="mov">MOV&lt;/h3>
&lt;p>QuickTime File Format 格式(后缀为.MOV)：美国 Apple 公司开发的一种视频格式，默认的播放器是苹果的 QuickTime。&lt;/p>
&lt;p>具有较高的压缩比率和较完美的视频清晰度等特点，并可以保存 alpha 通道。大家可能注意到了，每次安装 EDIUS，我们都要安装苹果公司推出的 QuickTime。安装其目的就是为了支持 JPG 格式图像和 MOV 视频格式导入。&lt;/p>
&lt;h3 id="mpeg">MPEG&lt;/h3>
&lt;p>MPEG 格式(文件后缀可以是 .MPG .MPEG .MPE .DAT .VOB .ASF .3GP .MP4 等)：它的英文全称为 Moving Picture Experts Group，即运动图像专家组格式，该专家组建于 1988 年，专门负责为 CD 建立视频和音频标准，而成员都是为视频、音频及系统领域的技术专家。&lt;/p>
&lt;p>MPEG 文件格式是运动图像压缩算法的国际标准。MPEG 格式目前有三个压缩标准，分别是 MPEG－1、MPEG－2、和 MPEG－4。MPEG－1、MPEG－2 目前已经使用较少，着重介绍 MPEG－4，其制定于 1998 年，MPEG－4 是为了播放流式媒体的高质量视频而专门设计的，以求使用最少的数据获得最佳的图像质量。目前 MPEG-4 最有吸引力的地方在于它能够保存接近于 DVD 画质的小体积视频文件。你可能一定注意到了，怎么没有 MPEG－3 编码，因为这个项目原本目标是为高分辨率电视(HDTV)设计，随后发现 MPEG-2 已足够 HDTV 应用，故 MPEG-3 的研发便中止。&lt;/p>
&lt;h3 id="wmv">WMV&lt;/h3>
&lt;p>WMV 格式(后缀为.WMV .ASF)：它的英文全称为 Windows Media Video，也是微软推出的一种采用独立编码方式并且可以直接在网上实时观看视频节目的文件压缩格式。&lt;/p>
&lt;p>WMV 格式的主要优点包括：本地或网络回放,丰富的流间关系以及扩展性等。WMV 格式需要在网站上播放，需要安装 Windows Media Player(简称 WMP)，很不方便，现在已经几乎没有网站采用了。&lt;/p>
&lt;h3 id="real-video">Real Video&lt;/h3>
&lt;p>Real Video 格式(后缀为.RM .RMVB)：Real Networks 公司所制定的音频视频压缩规范称为 Real Media。&lt;/p>
&lt;p>用户可以使用 RealPlayer 根据不同的网络传输速率制定出不同的压缩比率，从而实现在低速率的网络上进行影像数据实时传送和播放。RMVB 格式：这是一种由 RM 视频格式升级延伸出的新视频格式，当然性能上有很大的提升。RMVB 视频也是有着较明显的优势，一部大小为 700MB 左右的 DVD 影片，如果将其转录成同样品质的 RMVB 格式，其个头最多也就 400MB 左右。大家可能注意到了，以前在网络上下载电影和视频的时候，经常接触到 RMVB 格式，但是随着时代的发展这种格式被越来越多的更优秀的格式替代，著名的人人影视字幕组在 2013 年已经宣布不再压制 RMVB 格式视频。&lt;/p>
&lt;h3 id="flv">FLV&lt;/h3>
&lt;p>Flash Video 格式(后缀为.FLV)：由 Adobe Flash 延伸出来的的一种流行网络视频封装格式。随着视频网站的丰富，这个格式已经非常普及。&lt;/p>
&lt;h3 id="mkv">MKV&lt;/h3>
&lt;p>Matroska 格式(后缀为.MKV)：是一种新的多媒体封装格式，这个封装格式可把多种不同编码的视频及 16 条或以上不同格式的音频和语言不同的字幕封装到一个 Matroska Media 档内。它也是其中一种开放源代码的多媒体封装格式。Matroska 同时还可以提供非常好的交互功能，而且比 MPEG 的方便、强大。&lt;/p>
&lt;h2 id="视频编解码">视频编解码&lt;/h2>
&lt;p>视频实际上就是一帧一帧的图片，拼接起来进行播放；标准的图像格式使用 RGB 三字节描述像素颜色值，会占用较大的存储空间与带宽。视频编解码器会根据前后图像的变化做运动检测，通过各种压缩把变化的结果发送到对方。&lt;/p>
&lt;p>实时视频编码器需要考虑两个因素：编码计算量和码率带宽，实时视频会运行在移动端上，需要保证实时性就需要编码足够快，码率尽量小。基于这个原因现阶段一般认为 H.264 是最佳的实时视频编码器，而且各个移动平台也支持它的硬编码技术；譬如 1080P 进行过 H.264 编码后带宽也就在 200KB/S ~ 300KB/S 左右。&lt;/p>
&lt;h3 id="编码基础">编码基础&lt;/h3>
&lt;p>总的来说，常用的编码方式分为三种：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>变换编码：消除图像的帧内冗余。涉及到图像学里面的两个概念：空域和频域。空域就是我们物理的图片，频域就是将物理图片根据其颜色值等映射为数字大小。而变换编码的目的是利用频域实现去相关和能量集中。常用的正交变换有离散傅里叶变换，离散余弦变换等等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>运动估计和运动补偿：消除帧间冗余。视频压缩还存在时间上的关联性。例如，针对一些视频变化，背景图不变而只是图片中部分物体的移动，针对这种方式，可以只对相邻视频帧中变化的部分进行编码。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>熵编码：提高压缩效率，熵编码主要是针对码节长度优化实现的。原理是针对信源中出现概率大的符号赋予短码，对于概率小的符号赋予长码，然后总的来说实现平均码长的最小值。编码方式（可变字长编码）有：霍夫曼编码、算术编码、游程编码等。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>I,B,P 实际上是从运动补偿中引出来的，这里为了后面的方便先介绍一下。&lt;/p>
&lt;ul>
&lt;li>I 帧(I-frame): 学名叫做: &lt;code>Intra-coded picture&lt;/code>。也可以叫做独立帧。该帧是编码器随机挑选的参考图像，换句话说，一个 I 帧本身就是一个静态图像。它是作为 B,P 帧的参考点。对于它的压缩，只能使用&lt;code>熵&lt;/code> 和 &lt;code>变化编码&lt;/code> 这两种方式进行帧内压缩。所以，它的运动学补偿基本没有。&lt;/li>
&lt;li>P 帧(P‑frame): 又叫做 &lt;code>Predicted picture&lt;/code>&amp;ndash;前向预测帧。即，他会根据前面一张图像，来进行图片间的动态压缩，它的压缩率和 I 帧比起来要高一些。&lt;/li>
&lt;li>B 帧(B‑frame): 又叫做 &lt;code>Bi-predictive picture&lt;/code>&amp;ndash; 双向预测。它比 P 帧来说，还多了后一张图像的预测，所以它的压缩率更高。&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47571758-ea463d80-d96b-11e8-93d3-dacdd68cbeec.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>考虑到不同帧传输的无序性，我们还需要引入 PTS 与 DTS 来进行控制，使用 DTS 来解码，PTS 来进行播放。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>PTS(presentation time stamps): 显示时间戳，显示器从接受到解码到显示的时间。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DTS(decoder timestamps): 解码时间戳。也表示该 sample 在整个流中的顺序&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="h26x">H.26X&lt;/h3>
&lt;p>H.26X 系列由 ITU 国际电传视讯联盟主导包括，H.261、H.262、H.263、H.264、H.265 等：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>H.261：主要在老的视频会议和视频电话产品中使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>H.263：主要用在视频会议、视频电话和网络视频上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>H.264：H.264/MPEG-4 第十部分，或称 AVC(Advanced Video Coding，高级视频编码)，是一种视频压缩标准，一种被广泛使用的高精度视频的录制、压缩和发布格式。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>H.265：高效率视频编码(High Efficiency Video Coding，简称 HEVC)是一种视频压缩标准，H.264/MPEG-4 AVC 的继任者。HEVC 被认为不仅提升图像质量，同时也能达到 H.264/MPEG-4 AVC 两倍之压缩率(等同于同样画面质量下比特率减少了 50%)，可支持 4K 分辨率甚至到超高画质电视，最高分辨率可达到 8192×4320(8K 分辨率)，这是目前发展的趋势。直至 2013 年，Potplayer 添加了对于 H.265 视频的解码，尚未有大众化编码软件出现。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>H.264 是由 ITU 和 MPEG 两个组织共同提出的标准，整个编码器包括帧内预测编码、帧间预测编码、运动估计、熵编码等过程，支持分层编码技术(SVC)。单帧 720P 分辨率一般 PC 上的平均编码延迟 10 毫秒左右，码率范围 1200 ~ 2400kpbs，同等视频质量压缩率是 MPEG4 的 2 倍，H.264 也提供 VBR、ABR、CBR、CQ 等多种编码模式，各个移动平台兼容性好。&lt;/p>
&lt;p>H.264 为了防止丢包和减小带宽还引入一种双向预测编码的 B 帧，B 帧以前面的 I 或 P 帧和后面的 P 帧为参考帧。H.264 为了防止中间 P 帧丢失视频图像会一直错误它引入分组序列（GOP）编码，也就是隔一段时间发一个全量 I 帧，上一个 I 帧与下一个 I 帧之间为一个分组 GOP。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47572890-a30d7c00-d96e-11e8-91d9-45a6bce68ad1.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>在实时视频当中最好不要加入 B 帧，因为 B 帧是双向预测，需要根据后面的视频帧来编码，这会增大编解码延迟。&lt;/p>
&lt;h3 id="mpga-系列">MPGA 系列&lt;/h3>
&lt;p>MPEG 系列由 ISO 国际标准组织机构下属的 MPEG 运动图象专家组开发视频编码方面主要有：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>MPEG-1 第二部分(MPEG-1 第二部分主要使用在 VCD 上，有些在线视频也使用这种格式。该编解码器的质量大致上和原有的 VHS 录像带相当。)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MPEG-2 第二部分(MPEG-2 第二部分等同于 H.262，使用在 DVD、SVCD 和大多数数字视频广播系统和有线分布系统(cable distribution systems)中。)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MPEG-4 第二部分(MPEG-4 第二部分标准可以使用在网络传输、广播和媒体存储上。比起 MPEG-2 和第一版的 H.263，它的压缩性能有所提高。)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MPEG-4 第十部分(MPEG-4 第十部分技术上和 ITU-T H.264 是相同的标准，有时候也被叫做“AVC”)最后这两个编码组织合作，诞生了 H.264/AVC 标准。ITU-T 给这个标准命名为 H.264，而 ISO/IEC 称它为 MPEG-4 高级视频编码(Advanced Video Coding，AVC)。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="音频编码器">音频编码器&lt;/h2>
&lt;p>实时音视频除了视频编码器以外还需要音频编码器，音频编码器只需要考虑编码延迟和丢包容忍度，所以一般的 MP3、AAC、OGG 都不太适合作为实时音频编码器。从现在市场上来使用来看，Skype 研发的 Opus 已经成为实时音频主流的编码器。Opus 优点众多，编码计算量小、编码延迟 20ms、窄带编码-silk、宽带编码器 CELT、自带网络自适应编码等。&lt;/p>
&lt;p>同视频编码类似，将原始的音频流按照一定的标准进行编码，上传，解码，同时在播放器里播放，当然音频也有许多编码标准，例如 PCM 编码，WMA 编码，AAC 编码等等。&lt;/p>
&lt;h1 id="直播协议">直播协议&lt;/h1>
&lt;p>常用的直播协议包括了 HLS, RTMP 与 HTTP-FLV 这三种，其对比如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>协议&lt;/th>
&lt;th>优势&lt;/th>
&lt;th>缺陷&lt;/th>
&lt;th>延迟性&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>HLS&lt;/td>
&lt;td>支持性广&lt;/td>
&lt;td>延时巨高&lt;/td>
&lt;td>10s 以上&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RTMP&lt;/td>
&lt;td>延时性好，灵活&lt;/td>
&lt;td>量大的话，负载较高&lt;/td>
&lt;td>1s 以上&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>HTTP-FLV&lt;/td>
&lt;td>延时性好，游戏直播常用&lt;/td>
&lt;td>只能在手机 APP 播放&lt;/td>
&lt;td>2s 以上&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="hls">HLS&lt;/h2>
&lt;p>HLS, HTTP Live Streaming 是 Apple 提出的直播流协议，其将整个流分成一个个小的块，并基于 HTTP 的文件来下载；HLS 由两部分构成，一个是 .m3u8 文件，一个是 .ts 视频文件；每一个 .m3u8 文件，分别对应若干个 ts 文件，这些 ts 文件才是真正存放视频的数据，m3u8 文件只是存放了一些 ts 文件的配置信息和相关路径，当视频播放时，.m3u8 是动态改变的，video 标签会解析这个文件，并找到对应的 ts 文件来播放，所以一般为了加快速度，.m3u8 放在 web 服务器上，ts 文件放在 CDN 上。HLS 协议视频支持 H.264 格式的编码，支持的音频编码方式是 AAC 编码。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47569752-fbd91680-d966-11e8-8e5d-491fa49ec18e.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>.m3u8 文件，其实就是以 UTF-8 编码的 m3u 文件，这个文件本身不能播放，只是存放了播放信息的文本文件：&lt;/p>
&lt;pre tabindex="0">&lt;code>#EXTM3U m3u文件头
#EXT-X-MEDIA-SEQUENCE 第一个TS分片的序列号
#EXT-X-TARGETDURATION 每个分片TS的最大的时长
#EXT-X-ALLOW-CACHE 是否允许cache
#EXT-X-ENDLIST m3u8文件结束符
#EXTINF 指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效
mystream-12.ts
&lt;/code>&lt;/pre>&lt;p>HLS 协议的使用也非常便捷，将 m3u8 直接写入到 src 中然后交与浏览器解析，也可以使用 fetch 来手动解析并且获取相关文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nx">video&lt;/span> &lt;span class="nx">controls&lt;/span> &lt;span class="nx">autoplay&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nx">source&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">src&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;http://devimages.apple.com/iphone/samples/bipbop/masterplaylist.m3u8&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">type&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;application/vnd.apple.mpegurl&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nx">p&lt;/span> &lt;span class="kr">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;warning&amp;#34;&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="nx">Your&lt;/span> &lt;span class="nx">browser&lt;/span> &lt;span class="nx">does&lt;/span> &lt;span class="nx">not&lt;/span> &lt;span class="nx">support&lt;/span> &lt;span class="nx">HTML5&lt;/span> &lt;span class="nx">video&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="err">/p&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="err">/video&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>HLS 详细版的内容比上面的简版多了一个 playlist，也可以叫做 master。在 master 中，会根据网络段实现设置好不同的 m3u8 文件，比如，3G/4G/wifi 网速等。比如，一个 master 文件中为：&lt;/p>
&lt;pre tabindex="0">&lt;code>#EXTM3U
#EXT-X-VERSION:6
#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=2855600,CODECS=&amp;#34;avc1.4d001f,mp4a.40.2&amp;#34;,RESOLUTION=960x540
live/medium.m3u8
#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=5605600,CODECS=&amp;#34;avc1.640028,mp4a.40.2&amp;#34;,RESOLUTION=1280x720
live/high.m3u8
#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=1755600,CODECS=&amp;#34;avc1.42001f,mp4a.40.2&amp;#34;,RESOLUTION=640x360
live/low.m3u8
#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=545600,CODECS=&amp;#34;avc1.42001e,mp4a.40.2&amp;#34;,RESOLUTION=416x234
live/cellular.m3u8
&lt;/code>&lt;/pre>&lt;p>以 high.m3u8 文件为例，其内容会包含：&lt;/p>
&lt;pre tabindex="0">&lt;code>#EXTM3U
#EXT-X-VERSION:6
#EXT-X-TARGETDURATION:10
#EXT-X-MEDIA-SEQUENCE:26
#EXTINF:9.901,
http://media.example.com/wifi/segment26.ts
#EXTINF:9.901,
http://media.example.com/wifi/segment27.ts
#EXTINF:9.501,
http://media.example.com/wifi/segment28.ts
&lt;/code>&lt;/pre>&lt;p>该二级 m3u8 文件也可以称为 media 文件，其有三种类型：&lt;/p>
&lt;ul>
&lt;li>live playlist: 动态列表。顾名思义，该列表是动态变化的，里面的 ts 文件会实时更新，并且过期的 ts 索引会被删除。默认，情况下都是使用动态列表。&lt;/li>
&lt;li>event playlist: 静态列表。它和动态列表主要区别就是，原来的 ts 文件索引不会被删除，该列表是不断更新，而且文件大小会逐渐增大。它会在文件中，直接添加 #EXT-X-PLAYLIST-TYPE:EVENT 作为标识。&lt;/li>
&lt;li>VOD playlist: 全量列表。它就是将所有的 ts 文件都列在 list 当中。如果，使用该列表，就和播放一整个视频没有啥区别了。它是使用 #EXT-X-ENDLIST 表示文件结尾。&lt;/li>
&lt;/ul>
&lt;p>显而易见，HLS 的延时包含了 TCP 握手、m3u8 文件下载与解析、ts 文件下载与解析等多个步骤，可以缩短列表的长度和单个 ts 文件的大小来降低延迟，极致来说可以缩减列表长度为 1，并且 ts 的时长为 1s，但是这样会造成请求次数增加，增大服务器压力，当网速慢时回造成更多的缓冲，所以苹果官方推荐的 ts 时长时 10s，所以这样就会大改有 30s 的延迟。&lt;/p>
&lt;h2 id="rtmp">RTMP&lt;/h2>
&lt;p>RTMP，Real-Time Messaging Protocol 是由 Adobe 推出的音视频流传递协议；它通过一种自定义的协议，来完成对指定直播流的播放和相关的操作。在 Web 上可以通过 MSE（MediaSource Extensions）来接入 RTMP，基本思路是根据 WebSocket 直接建立长连接进行数据的交流和监听。RTMP 协议根据不同的套层，也可以分为：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>纯 RTMP: 直接通过 TCP 连接，端口为 1935&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RTMPS: RTMP + TLS/SSL，用于安全性的交流。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RTMPE: RTMP + encryption。在 RTMP 原始协议上使用，Adobe 自身的加密方法&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RTMPT: RTMP + HTTP。使用 HTTP 的方式来包裹 RTMP 流，这样能直接通过防火墙。不过，延迟性比较大。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RTMFP: RMPT + UDP。该协议常常用于 P2P 的场景中，针对延时有变态的要求。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>RTMP 内部是借由 TCP 长连接协议传输相关数据，所以，它的延时性非常低。并且，该协议灵活性非常好（所以，也很复杂），它可以根据 message stream ID 传输数据，也可以根据 chunk stream ID 传递数据。两者都可以起到流的划分作用。流的内容也主要分为：视频，音频，相关协议包等。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47570269-56bf3d80-d968-11e8-8e9c-4fc8a5e1a873.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="http-flv">HTTP-FLV&lt;/h2>
&lt;p>RTMP 是直接将流的传输架在 RTMP 协议之上，而 HTTP-FLV 是在 RTMP 和客户端之间套了一层转码的过程，即：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47570314-735b7580-d968-11e8-9b7e-7c42d830afc9.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>每个 FLV 文件是通过 HTTP 的方式获取的，所以，它通过抓包得出的协议头需要使用 chunked 编码：&lt;/p>
&lt;pre tabindex="0">&lt;code>Content-Type:video/x-flv
Expires:Fri, 10 Feb 2017 05:24:03 GMT
Pragma:no-cache
Transfer-Encoding:chunked
&lt;/code>&lt;/pre>&lt;h1 id="网络传输">网络传输&lt;/h1>
&lt;p>单对单模式主要是怎么通过路由路径优化手段达到两点之间最优，这方面 SKYPE 首先提出基于 P2P 的 Real-time Network 模型。而 单对多模式是一个分发树模型，各个客户端节点需要就近接入离自己最近的服务器，然后在服务器与服务器构建一个实时通信网络。&lt;/p>
&lt;h2 id="基础">基础&lt;/h2>
&lt;h3 id="推流">推流&lt;/h3>
&lt;p>所谓推流，就是将我们已经编码好的音视频数据发往视频流服务器中。实时音视频系统都是一个客户端到其他一个或者多个客户端的通信行为，这就意味着需要将客户端编码后的音视频数据传输到其他实时音视频系统都是一个客户端到其他一个或者多个客户端的通信行为，这就意味着需要将客户端编码后的音视频数据传输到其他客户端上，一般做法是先将数据实时上传到服务器上，服务器再进行转发到其他客户端，客户端这个上传音视频数据行为称为推流。&lt;/p>
&lt;p>我们可以通过 Nginx 的 RTMP 扩展方便地搭建推流服务器：&lt;/p>
&lt;pre tabindex="0">&lt;code>rtmp {
server {
listen 1935; #监听的端口
chunk_size 4000;
application hls { #rtmp推流请求路径
live on;
hls on;
hls_path /usr/local/var/www/hls;
hls_fragment 5s;
}
}
}
&lt;/code>&lt;/pre>&lt;p>推流会受到客户端网络的影响，例如：wifi 信号衰减、4G 弱网、拥挤的宽带网络等。为了应对这个问题，实时音视频系统会设计一个基于拥塞控制和 QOS 策略的推流模块。&lt;/p>
&lt;h3 id="webrtc">WebRTC&lt;/h3>
&lt;p>WebRTC 是一个开源项目，旨在使得浏览器能为实时通信（RTC）提供简单的 JavaScript 接口。说的简单明了一点就是让浏览器提供 JS 的即时通信接口。这个接口所创立的信道并不是像 WebSocket 一样，打通一个浏览器与 WebSocket 服务器之间的通信，而是通过一系列的信令，建立一个浏览器与浏览器之间（peer-to-peer）的信道，这个信道可以发送任何数据，而不需要经过服务器。并且 WebRTC 通过实现 MediaStream，通过浏览器调用设备的摄像头、话筒，使得浏览器之间可以传递音频和视频。WebRTC 有三个重要的部分：MediaStream、RTCPeerConnection、RTCDataChannel:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>MediaStream：通过设备的摄像头及话筒获得视频、音频的同步流&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PeerConnection: 用于构建点对点之间稳定、高效的流传输的组件&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DataChannel：能够使得浏览器之间(点对点)简历一个高吞吐量、低延时的信道，用于传输任何数据&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="实时网络传输优化">实时网络传输优化&lt;/h2>
&lt;h3 id="tcp-与-udp">TCP 与 UDP&lt;/h3>
&lt;p>在大规模实时多媒体传输网络中，TCP 和 RTMP 都不占优势。TCP 是个拥塞公平传输的协议，它的拥塞控制都是为了保证网络的公平性而不是快速到达，我们知道，TCP 层只有顺序到对应的报文才会提示应用层读数据，如果中间有报文乱序或者丢包都会在 TCP 做等待，所以 TCP 的发送窗口缓冲和重发机制在网络不稳定的情况下会造成延迟不可控，而且传输链路层级越多延迟会越大。&lt;/p>
&lt;p>在实时传输中使用 UDP 更加合理，UDP 避免了 TCP 繁重的三次握手、四次挥手和各种繁杂的传输特性，只需要在 UDP 上做一层简单的链路 QoS 监测和报文重发机制，实时性会比 TCP 好，这一点从 RTP 和 DDCP 协议可以证明这一点，我们正式参考了这两个协议来设计自己的通信协议。&lt;/p>
&lt;p>UDP 不可避免地存在抖动、乱序、丢包问题，视频必须按照严格是时间戳来播放，否则的就会出现视频动作加快或者放慢的现象，如果我们按照接收到视频数据就立即播放，那么这种加快和放慢的现象会非常频繁和明显。也就是说网络抖动会严重影响视频播放的质量，一般为了解决这个问题会设计一个视频播放缓冲区，通过缓冲接收到的视频帧，再按视频帧内部的时间戳来播放既可。&lt;/p>
&lt;p>UDP 除了小范围的抖动以外，还是出现大范围的乱序现象，就是后发的报文先于先发的报文到达接收方。乱序会造成视频帧顺序错乱，一般解决的这个问题会在视频播放缓冲区里做一个先后排序功能让先发送的报文先进行播放。&lt;/p>
&lt;p>UDP 在传输过程还会出现丢包，丢失的原因有多种，例如：网络出口不足、中间网络路由拥堵、socket 收发缓冲区太小、硬件问题、传输损耗问题等等。在基于 UDP 视频传输过程中，丢包是非常频繁发生的事情，丢包会造成视频解码器丢帧，从而引起视频播放卡顿。这也是大部分视频直播用 TCP 和 RTMP 的原因，因为 TCP 底层有自己的重传机制，可以保证在网络正常的情况下视频在传输过程不丢。基于 UDP 丢包补偿方式一般有以下几种：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>报文冗余，报文冗余很好理解，就是一个报文在发送的时候发送 2 次或者多次。这个做的好处是简单而且延迟小，坏处就是需要额外 N 倍（N 取决于发送的次数）的带宽。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>FEC, Forward Error Correction，即向前纠错算法，常用的算法有纠删码技术（EC），在分布式存储系统中比较常见。最简单的就是 A B 两个报文进行 XOR（与或操作）得到 C，同时把这三个报文发往接收端，如果接收端只收到 AC,通过 A 和 C 的 XOR 操作就可以得到 B 操作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>丢包重传，丢包重传有两种方式，一种是 push 方式，一种是 pull 方式。Push 方式是发送方没有收到接收方的收包确认进行周期性重传，TCP 用的是 push 方式。pull 方式是接收方发现报文丢失后发送一个重传请求给发送方，让发送方重传丢失的报文。丢包重传是按需重传，比较适合视频传输的应用场景，不会增加太对额外的带宽，但一旦丢包会引来至少一个 RTT 的延迟。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="拥塞控制">拥塞控制&lt;/h3>
&lt;p>要评估一个网络通信质量的好坏和延迟一个重要的因素就是 Round-Trip Time（网络往返延迟）,也就是 RTT。评估两端之间的 RTT 方法很简单，大致如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>发送端方一个带本地时间戳 T1 的 ping 报文到接收端；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>接收端收到 ping 报文，以 ping 中的时间戳 T1 构建一个携带 T1 的 pong 报文发往发送端；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>发送端接收到接收端发了的 pong 时，获取本地的时间戳 T2，用 T2 – T1 就是本次评测的 RTT。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>因为客户端有可能在弱网环境下进行推流，音视频数据如果某一时刻发多了，就会引起网络拥塞或者延迟，如果发少了，可能视频的清晰不好。在实时音视频传输过程会设计一个自动适应本地网络变化的拥塞控制算法，像 QUIC 中的 BBR、webRTC 中 GCC 和通用的 RUDP。思路是通过 UDP 协议反馈的丢包和网络延迟(RTT)来计算当前网络的变化和最大瞬时吞吐量，根据这几个值调整上层的视频编码器的码率、视频分辨率等，从而达到适应当前网络状态的目的。&lt;/p>
&lt;h3 id="qos-策略">QoS 策略&lt;/h3>
&lt;p>客户端推流除了需要考虑网络上传能力以外，还需要考虑客户端的计算能力。如果在 5 年前的安卓机上去编码一个分辨率为 640P 的高清视频流，那这个过程必然会产生延迟甚至无法工作。为此需要针对各个终端的计算能力设计一个 QoS 策略，不同计算能力的终端采用不同的视频编码器、分辨率、音频处理算法等，这个 QoS 策略会配合拥塞控制做一个状态不可逆的查找过程，直到找到最合适的 QoS 策略位置&lt;/p>
&lt;h2 id="媒体处理技术">媒体处理技术&lt;/h2>
&lt;h3 id="回声消除">回声消除&lt;/h3>
&lt;p>在实时音视频系统中，回声消除是一个难点，尽管 webRTC 提供了开源的回声消除模块，但在移动端和一些特殊的场景表现不佳。专业的实时音视频系统会进行回声消除的优化。回声消除的原理描述很简单，就是将扬声器播放的声音波形和麦克风录制的波形进行抵消，达到消除回声的作用。因为回声的回录时间不确定，所以很难确定什么时间点进行对应声音数据的抵消。在专业的回声消除模块里面通常会设计一个逼近函数，通过不断对输出和输入声音波形进行在线学习逼近，确定回声消除的时间差值点。&lt;/p>
&lt;h1 id="简单-web-实验">简单 Web 实验&lt;/h1>
&lt;p>本部分的代码实验参考 &lt;a href="https://github.com/wx-chevalier/MushiChat" target="_blank" rel="noopener">MushiChat&lt;/a>。&lt;/p>
&lt;h2 id="media-source-extension">Media Source Extension&lt;/h2>
&lt;p>MSE 全称就是 Media Source Extensions。它是一套处理视频流技术的简称，里面包括了一系列 API：Media Source，Source Buffer 等。在没有 MSE 出现之前，前端对 video 的操作，仅仅局限在对视频文件的操作，而并不能对视频流做任何相关的操作。现在 MSE 提供了一系列的接口，使开发者可以直接提供 media stream。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">vidElement&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">document&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">querySelector&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;video&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nb">window&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">MediaSource&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">mediaSource&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">MediaSource&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">vidElement&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">src&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">URL&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">createObjectURL&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mediaSource&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">mediaSource&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">addEventListener&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;sourceopen&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">sourceOpen&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;The Media Source Extensions API is not supported.&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">function&lt;/span> &lt;span class="nx">sourceOpen&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">e&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">URL&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">revokeObjectURL&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">vidElement&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">src&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">mime&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;video/webm; codecs=&amp;#34;opus, vp9&amp;#34;&amp;#39;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">mediaSource&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">e&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">target&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">sourceBuffer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">mediaSource&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">addSourceBuffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">mime&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">videoUrl&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;droid.webm&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">fetch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">videoUrl&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="nx">then&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kd">function&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">response&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">response&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">arrayBuffer&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="nx">then&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kd">function&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">arrayBuffer&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sourceBuffer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">addEventListener&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;updateend&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">e&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="nx">sourceBuffer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">updating&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nx">mediaSource&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">readyState&lt;/span> &lt;span class="o">===&lt;/span> &lt;span class="s2">&amp;#34;open&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">mediaSource&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">endOfStream&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sourceBuffer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">appendBuffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">arrayBuffer&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中 MediaSource 只是一系列视频流的管理工具，它可以将音视频流完整的暴露给 Web 开发者来进行相关的操作和处理。所以，它本身不会造成过度的复杂性。&lt;/p></description></item><item><title>Redis-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/redis-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/redis-cheatsheet/</guid><description>&lt;h1 id="redis-cheatsheet">Redis CheatSheet&lt;/h1>
&lt;p>REmote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 key-value 存储系统。Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。&lt;/p>
&lt;h2 id="一数据类型">一、数据类型&lt;/h2>
&lt;p>Redis 5 支持以下多种数据类型：&lt;/p>
&lt;ul>
&lt;li>二进制安全的字符串。&lt;/li>
&lt;li>&lt;strong>Lists (列表)&lt;/strong>：根据插入顺序排序的字符串元素的集合。&lt;/li>
&lt;li>&lt;strong>Sets (集)&lt;/strong>：未排序的不重复的字符串元素的集合。&lt;/li>
&lt;li>&lt;strong>Sorted Sets (排序集)&lt;/strong>：类似于集，但每个字符串元素与被称为分数的值相关，元素总是按其分数排序。&lt;/li>
&lt;li>&lt;strong>Hashes (散列)&lt;/strong> ：由字段 (Field) 和值都是字符串组成的映射的集合。&lt;/li>
&lt;li>&lt;strong>Bit Arrays (也称 bitmaps 位图)&lt;/strong> ：Bitmaps 本身不是一种数据结构， 实际上它就是字符串，但是它可以对字符串的位进行操作，所以在 Redis 官方的分类当中将其单独归为一类。&lt;/li>
&lt;li>&lt;strong>HyperLogLogs&lt;/strong>：实际类型为字符串类型 ，它是一种基数算法， 通过 HyperLogLog 可以利用极小的内存空间完成独立总数的统计。&lt;/li>
&lt;li>&lt;strong>Streams (流)&lt;/strong> ：Stream 是 Redis 5.0 引入的一种新数据类型，用于在生产者和消费者之间建立数据通道。&lt;/li>
&lt;/ul>
&lt;h2 id="二常用命令">二、常用命令&lt;/h2>
&lt;h3 id="21-字符串">2.1 字符串&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>命令格式&lt;/th>
&lt;th>参数或示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>设置值&lt;/td>
&lt;td>set key value [ex seconds][px milliseconds][nx|xx] setnx setex&lt;/td>
&lt;td>ex seconds：为键设置秒级过期时间； &lt;br/>px milliseconds：为键设置毫秒级过期时间；&lt;br/>nx： 键不存在时才可以添加成功；&lt;br/>xx： 键存在时才可以修改成功。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取值&lt;/td>
&lt;td>get key&lt;/td>
&lt;td>如果获取的键不存在 ，则返回 nil&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>批量设置&lt;/td>
&lt;td>mset key value [key value &amp;hellip;]&lt;/td>
&lt;td>mset a 1 b 2 c 3 d 4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>批量获取值&lt;/td>
&lt;td>mget key [key &amp;hellip;]&lt;/td>
&lt;td>mget a b c d&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计数&lt;/td>
&lt;td>incr key &lt;br/>decr key&lt;br/>incrby key increment（指定数值自增）&lt;br/>decrby key decrement（指定数值自减）&lt;br/>incrbyfloat key increment （浮点数自增）&lt;/td>
&lt;td>值是整数时返回自增或自减后的结果；&lt;br/>值不是整数时返回错误；&lt;br/>键不存在时自动创建，并按照初始值为 0 进行自增或自减。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>追加值&lt;/td>
&lt;td>append key value&lt;/td>
&lt;td>向字符串尾部追加值。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>字符串长度&lt;/td>
&lt;td>strlen key&lt;/td>
&lt;td>获取字符串长度，中文占用三个字节&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>设置并返回原值&lt;/td>
&lt;td>getset key value&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>设置指定位置的字符串&lt;/td>
&lt;td>setrange key offeset value&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取部分字符串&lt;/td>
&lt;td>getrange key start end&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="23-哈希">2.3 哈希&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;th>参数或示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>设置值&lt;/td>
&lt;td>hset key field value&lt;/td>
&lt;td>hset user:1 name tom&lt;br/>hset user:1 age 12&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取值&lt;/td>
&lt;td>hget key field&lt;/td>
&lt;td>hget user:1 name&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除 field&lt;/td>
&lt;td>hdel key field [field &amp;hellip;]&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计算 field 个数&lt;/td>
&lt;td>hlen key&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>批量设置或获取&lt;/td>
&lt;td>hmget key field [field]&lt;br/>hmset key field value [field value&amp;hellip;]&lt;/td>
&lt;td>hmset user:1 name mike age 12 city tianjin&lt;br/>hmget user:1 name city&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>判断 field 是否存在&lt;/td>
&lt;td>hexists key field&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取所有 field&lt;/td>
&lt;td>hkeys key&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取所有 value&lt;/td>
&lt;td>hvals key&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取所有的 filed-value&lt;/td>
&lt;td>hgetall key&lt;/td>
&lt;td>如果哈希元素个数比较多可能会阻塞 Redis，此时可以使用 hscan 渐进式遍历&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计数&lt;/td>
&lt;td>hincrby key field&lt;br/>hincrbyfloat key field&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="24-列表">2.4 列表&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;th>参数或示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>增&lt;/td>
&lt;td>左侧插入：lpush key value [value &amp;hellip;] &lt;br/>右侧插入：rpush key value [value &amp;hellip;] &lt;br/>某个指定元素前后插入：linsert key before|after pivot value&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>查&lt;/td>
&lt;td>获取指定范围内的元素列表：lrange key start end &lt;br/>获取列表指定索引下标的元素：lindex key index &lt;br/>获取列表指定长度：llen key&lt;/td>
&lt;td>lrange listkey 0 -1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删&lt;/td>
&lt;td>从列表左侧弹出元素：lpop key &lt;br/>从列表右侧弹出元素：rpop key &lt;br/>删除指定元素：lrem key count value &lt;br/>截取列表：ltrim key start end&lt;/td>
&lt;td>count&amp;gt;0：从左到右， 删除最多 count 个元素。&lt;br/>count&amp;lt;0：从右到左， 删除最多 -count 个元素。&lt;br/>count=0： 删除所有&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>改&lt;/td>
&lt;td>修改指定下标的元素：lset key index newValue&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>阻塞操作&lt;/td>
&lt;td>blpop key [key &amp;hellip;] timeout &lt;br/>brpop key [key &amp;hellip;] timeout&lt;/td>
&lt;td>key[key&amp;hellip;]： 多个列表的键。 timeout： 阻塞时间|等待时间（单位秒）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="25-集合">2.5 集合&lt;/h3>
&lt;p>集合（set） 类型也是用来保存多个的字符串元素， 但和列表类型不一样的是， 集合中的元素是无序的， 不允许有重复元素，不能通过下标获取元素。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;th>参数或示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>添加元素&lt;/td>
&lt;td>sadd key element [element &amp;hellip;]&lt;/td>
&lt;td>返回结果为添加成功的元素个数&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除元素&lt;/td>
&lt;td>srem key element [element &amp;hellip;]&lt;/td>
&lt;td>返回结果为成功删除的元素个数&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计算元素个数&lt;/td>
&lt;td>scard key&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>判断元素是否在集合中&lt;/td>
&lt;td>sismember key element&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>随机返回&lt;/td>
&lt;td>srandmember key [count]&lt;/td>
&lt;td>随机从集合返回指定个数元素，count 默认为 1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>从集合随机弹出元素&lt;/td>
&lt;td>spop key&lt;/td>
&lt;td>srandmember 不会从集合中删除元素，spop 会&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>获取集合中所有元素&lt;/td>
&lt;td>smembers key&lt;/td>
&lt;td>可用 sscan 代替&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>集合间操作&lt;/strong>：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>求多个集合的交集&lt;/td>
&lt;td>sinter key [key &amp;hellip;]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>求多个集合的并集&lt;/td>
&lt;td>suinon key [key &amp;hellip;]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>求多个集合的差集&lt;/td>
&lt;td>sdiff key [key &amp;hellip;]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>将交集、并集、差集的结果保存&lt;/td>
&lt;td>sinterstore destination key [key &amp;hellip;] &lt;br/>suionstore destination key [key &amp;hellip;]&lt;br/>sdiffstore destination key [key &amp;hellip;]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="26-有序集合">2.6 有序集合&lt;/h3>
&lt;p>有序集合中的元素可以排序。它给每个元素设置一个分数（score） 作为排序的依据。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;th>参数或示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>添加成员&lt;/td>
&lt;td>zadd key score member [score member &amp;hellip;]&lt;/td>
&lt;td>nx： member 不存在时才可设置成功， 用于添加；&lt;br>xx： member 存在时可以设置成功， 用于更新；&lt;br/>ch： 返回此次操作后， 有序集合内元素和分数发生变化的个数；&lt;br/>incr：对 score 做增加， 相当于下面的 zincrby。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计算成员个数&lt;/td>
&lt;td>zcard key&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计算某个成员的分数&lt;/td>
&lt;td>zscore key member&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>计算某个成员的排名&lt;/td>
&lt;td>zrank key member zrevrank key member&lt;/td>
&lt;td>zrank 是从分数从低到高返回排名， zrevrank 反之。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除成员&lt;/td>
&lt;td>zrem key member [member &amp;hellip;]&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>增加成员分数&lt;/td>
&lt;td>zincrby key increment member&lt;/td>
&lt;td>zincrby user:ranking 9 tom&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>返回指定排名范围的成员&lt;/td>
&lt;td>zrange key start end [withscores] &lt;br/>zrevrange key start end [withscores]&lt;/td>
&lt;td>zrange 是从低到高返回， zrevrange 反之。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>返回指定分数范围内的成员&lt;/td>
&lt;td>zrangebyscore key min max [withscores][limit offset count] &lt;br/>zrevrangebyscore key max min [withscores][limit offset count]&lt;/td>
&lt;td>其中 zrangebyscore 按照分数从低到高返回， zrevrangebyscore 反之；&lt;br/> [limit offset count] 选项用于限制输出的起始位置和个数； &lt;br/>min 和 max 代表最小和最大值，支持开闭区间， 也可以使用 -inf 和+inf 代表无限小和无限大。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除指定排名内的升序元素&lt;/td>
&lt;td>zremrangerank key start end&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删除指定分数范围的成员&lt;/td>
&lt;td>zremrangebyscore key min max&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>集合间操作&lt;/strong>：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>作用&lt;/th>
&lt;th>格式&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>交集&lt;/td>
&lt;td>zinterstore destination numkeys key [key &amp;hellip;] [weights weight [weight &amp;hellip;]] [aggregate sum|min|max]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>并集&lt;/td>
&lt;td>zunionstore destination numkeys key [key &amp;hellip;] [weights weight [weight &amp;hellip;]] [aggregate sum|min|max]&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>&lt;strong>destination&lt;/strong>： 交集计算的结果保存到这个键。&lt;/li>
&lt;li>&lt;strong>numkeys&lt;/strong>： 需要做交集计算键的个数。&lt;/li>
&lt;li>&lt;strong>key[key&amp;hellip;]&lt;/strong>： 需要做交集计算的键。&lt;/li>
&lt;li>&lt;strong>weights weight[weight&amp;hellip;]&lt;/strong>： 每个键的权重， 在做交集计算时， 每个键中的每个 member 会将自己分数乘以这个权重， 每个键的权重默认是 1。&lt;/li>
&lt;li>&lt;strong>aggregate sum|min|max&lt;/strong>： 计算成员交集后， 分值可以按照 sum（和）、min（最小值）、max（最大值）做汇总， 默认值是 sum 。&lt;/li>
&lt;/ul>
&lt;h3 id="27-全局命令">2.7 全局命令&lt;/h3>
&lt;ol>
&lt;li>查看所有键： &lt;code>keys *&lt;/code>&lt;/li>
&lt;li>查看键总数：dbsize&lt;/li>
&lt;li>检查键是否存在：exists key&lt;/li>
&lt;li>删除键：del key [key &amp;hellip;]&lt;/li>
&lt;li>键过期：expire key seconds ，使用 ttl 命令可以查看键剩余的过期时间， 它有以下三种返回值：
&lt;ul>
&lt;li>大于等于 0 的整数： 键剩余的过期时间。&lt;/li>
&lt;li>-1： 键未设置过期时间。&lt;/li>
&lt;li>-2： 键不存在&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>查看键的数据类型：type key&lt;/li>
&lt;/ol>
&lt;h3 id="28-键过期">2.8 键过期&lt;/h3>
&lt;p>可以使用以下命令完成设置键的过期时间：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>expire key seconds&lt;/strong>： 键在 seconds 秒后过期；&lt;/li>
&lt;li>&lt;strong>expireat key timestamp&lt;/strong>： 键在秒级时间戳 timestamp 后过期；&lt;/li>
&lt;li>&lt;strong>pexpire key milliseconds&lt;/strong>： 键在 milliseconds 毫秒后过期；&lt;/li>
&lt;li>&lt;strong>pexpireat key milliseconds-timestamp&lt;/strong>：键在毫秒级时间戳 timestamp 后过期。&lt;/li>
&lt;/ul>
&lt;p>注意事项：&lt;/p>
&lt;ul>
&lt;li>如果 expire key 的键不存在， 返回结果为 0；&lt;/li>
&lt;li>如果设置过期时间为负值， 键会立即被删除， 此时等价于 del 命令；&lt;/li>
&lt;li>persist key 命令可以将键的过期时间清除，使键变成永久的；&lt;/li>
&lt;li>需要特别注意对于字符串类型键， 执行 set 命令会清除掉已有的过期时间；&lt;/li>
&lt;li>Redis 不支持对二级数据结构的内部元素设置过期时间， 例如不能对列表内的某个元素设置过期时间；&lt;/li>
&lt;li>setex 命令是 set+expire 的组合， 它是一个原子操作。&lt;/li>
&lt;/ul>
&lt;h3 id="29-渐进式键遍历">2.9 渐进式键遍历&lt;/h3>
&lt;p>使用 keys 命令遍历键可能会带来阻塞的风险，因为 Redis 提供了渐进式键遍历命令 scan ，使用格式如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">scan cursor &lt;span class="o">[&lt;/span>match pattern&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>count number&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;strong>cursor&lt;/strong>：游标，第一次遍历从 0 开始， 每次遍历完都会返回当前游标的值， 直到游标值为 0， 表示遍历结束。&lt;/li>
&lt;li>&lt;strong>match pattern&lt;/strong>：可选参数， 它的作用的是匹配特定模式的键；&lt;/li>
&lt;li>&lt;strong>count number&lt;/strong>：可选参数， 它的作用是表明每次要遍历的键个数， 默认值是 10。&lt;/li>
&lt;/ul>
&lt;h3 id="210-数据库管理">2.10 数据库管理&lt;/h3>
&lt;p>1.切换数据库：select dbIndex&lt;/p>
&lt;p>2.清除数据库：flushdb/flushall，flushdb 只清除当前数据库， flushall 会清除所有数据库。&lt;/p>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="http://www.runoob.com/redis/sets-scard.html" target="_blank" rel="noopener">http://www.runoob.com/redis/sets-scard.html&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://mp.weixin.qq.com/s/TSYDcEA78Mcj7BRXlAHxHw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TSYDcEA78Mcj7BRXlAHxHw&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>SoftwareTest-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/softwaretest-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/softwaretest-cheatsheet/</guid><description>&lt;h1 id="software-test-cheatsheet">Software Test CheatSheet&lt;/h1>
&lt;p>单元测试&lt;/p>
&lt;p>单元测试是针对代码单元的测试，通常只测试一个函数和方法调用，验证其运行结果是否符合预期，是对代码质量最快速的反馈。高覆盖率、高质量的单元测试是保障代码质量的第一道保护伞。在掌握 TDD（Test-Driven Design，测试驱动开发）的前提下，单元测试更是对代码重构起到了非常关键的作用。&lt;/p>
&lt;p>集成测试&lt;/p>
&lt;p>虽然单独测试模块非常重要，但是测试各个模块之间交互是否正常，同样也占据了重要的地位。在微服务架构下，集成测试的目的是把一些子模块组合在一起，测试其作为子系统是否存在缺陷，检查模块之间的通信和交互是否通畅且准确，是否以预期的方式协作。&lt;/p>
&lt;p>组件测试&lt;/p>
&lt;p>在微服务架构中，组件实际上就代表着微服务本身，所以组件测试就是检查服务内部功能实现是否完整，内部逻辑是否正确，异常处理是否正常等。&lt;/p>
&lt;p>契约测试&lt;/p>
&lt;p>契约测试称之为消费者驱动的契约（Consumer-Driven Contracts，简称 CDC）测试。契约测试是为了测试服务之间连接的正确性，测试服务能否符合契约预期，即是否能真正满足服务消费者的需求。&lt;/p>
&lt;p>端到端测试&lt;/p>
&lt;p>端到端测试是从 UI 层开始执行，目的是检查整个软件系统是否符合用户的预期需求。一个常规页面功能展示的背后往往涉及多个服务，所以运行端到端测试需要部署多个服务。这样的测试能够达到更广的覆盖面，但是也面临测试不稳定，定位问题难等问题。&lt;/p>
&lt;h1 id="压力测试">压力测试&lt;/h1>
&lt;h2 id="请求测试">请求测试&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 其中－n表示请求数，－c表示并发数&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ ab -n &lt;span class="m">100&lt;/span> -c &lt;span class="m">10&lt;/span> http://test.com/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="数据库测试">数据库测试&lt;/h2>
&lt;h1 id="单元测试">单元测试&lt;/h1>
&lt;p>在企业应用中，一个问题的完整解决方案通常包括很多的流程，这其中每个环节都需要反复迭代 优化调试，如何能够将复杂任务进行模块划分，并且保证整体流程的正确性呢?最实用的方法就是单元测试。
单元测试并不只是简单的一种测试技能，它首先是一种设计能力。并不是每份代码都可以做单元&lt;/p>
&lt;h1 id="接口测试">接口测试&lt;/h1>
&lt;p>接口测试是测试系统组件间接口（API）的一种测试，主要用于检测内部与外部系统、内部子系统之间的交互质量，其测试重点是检查数据交换、传递的准确性，控制和交互管理过程，以及系统间相互逻辑依赖关系等。&lt;/p>
&lt;p>现在的互联网应用（App）已经普遍基于前后端分离架构思路构建，即后端提供数据接口，前端调用接口返回 JSon 数据渲染到 UI。而随着微服务的流行，后端服务模块越来越多，技术团队迫切需要一个效率更高更稳定的获取系统质量信息的方法，以便进行缺陷检测和质量监督。&lt;/p>
&lt;p>之前基于 UI 自动化测试技术的思路和手段由于低效繁杂且容易出错已经无法满足实际需要，而面向服务的接口自动化测试体系则应运而生，成为业界最主流的质量管理手段。尤其是对高复杂性的互联网企业平台，系统越复杂庞大，接口测试自动化和持续集成的效果就越明显。业界已经有成熟的低成本、高效率的解决方案、开源工具和案例经验。当下，熟悉和掌握接口自动化测试技术也成为了一线互联网企业对中高级测试开发工程师的基本要求。&lt;/p>
&lt;p>质量维度
功能正常：保持新老版本的兼容
性能正常：单次请求的响应时间跟总体的 qps 相关
变更检测：字段的缺失，字段的类型变更
异常和健壮性测试&lt;/p>
&lt;p>质量体系
构建接口层的快速稳定的质量保证体系
构建接口监控体系&lt;/p>
&lt;p>接口测试流程&lt;/p>
&lt;p>在企业内部实施接口测试的实际流程如下：&lt;/p>
&lt;p>接口的范围：需要覆盖多少业务和接口
接口分析：接口的协议、上下游依赖
接口测试用例设计：业务用例如何模拟和覆盖
接口测试框架选择：选择合适的框架
测试用例编写与维护：用例编写与维护更新
持续集成：不断集成测试&lt;/p>
&lt;p>待测接口范围&lt;/p>
&lt;p>常见的待测接口范围如下：&lt;/p>
&lt;p>业务需求调研：研发和产品反馈常出问题的业务
接口文档：人工文档、Swagger 自动生成的文档
代码分析：分析 Spring 等框架的代码
线上 Log 和数据：线上的生产监控和接口 Log
客户端抓包：基于用户角度的接口行为分析&lt;/p>
&lt;p>常见抓包分析&lt;/p>
&lt;p>监听分析：TCPDUMP + WireShark + HAR 提取工具
代理分析：Charles + BurpSuite
转发分析：修改 Host 域名 + 反向代理转发&lt;/p>
&lt;p>测试用例设计&lt;/p>
&lt;p>接口调用的流程分析
代理抓包
线上 Log 提取
人工用例补充：用流程图和思维导图进行业务建模
正常场景用例 Right Path
异常场景用例
安全和稳定性用例&lt;/p>
&lt;p>接口测试框架选择&lt;/p>
&lt;p>关于如何选择接口测试框架，列举几个常见的框架特性供参考：&lt;/p>
&lt;p>早期阶段：基于各种语言的 HTTPClient 封装
JMeter：性能测试工具，不具备完备的接口测试框架功能
RobotFramework：强大的 ATDD 工具，不过约束性太大
RestAssured + Swagger
SoapUI [商业化]&lt;/p>
&lt;p>这里推荐开源的 Rest-Assured，它有如下优点：&lt;/p>
&lt;p>简约的接口测试 DSL
支持 XML JSon 的结构化解析
支持 XPath JSonPath GPath 等多种解析方式
对 Spring 的支持比较全面质量维度
功能正常：保持新老版本的兼容
性能正常：单次请求的响应时间跟总体的 qps 相关
变更检测：字段的缺失，字段的类型变更
异常和健壮性测试&lt;/p>
&lt;p>质量体系
构建接口层的快速稳定的质量保证体系
构建接口监控体系&lt;/p>
&lt;p>接口测试流程&lt;/p>
&lt;p>在企业内部实施接口测试的实际流程如下：&lt;/p>
&lt;p>接口的范围：需要覆盖多少业务和接口
接口分析：接口的协议、上下游依赖
接口测试用例设计：业务用例如何模拟和覆盖
接口测试框架选择：选择合适的框架
测试用例编写与维护：用例编写与维护更新
持续集成：不断集成测试&lt;/p>
&lt;p>待测接口范围&lt;/p>
&lt;p>常见的待测接口范围如下：&lt;/p>
&lt;p>业务需求调研：研发和产品反馈常出问题的业务
接口文档：人工文档、Swagger 自动生成的文档
代码分析：分析 Spring 等框架的代码
线上 Log 和数据：线上的生产监控和接口 Log
客户端抓包：基于用户角度的接口行为分析&lt;/p>
&lt;p>常见抓包分析&lt;/p>
&lt;p>监听分析：TCPDUMP + WireShark + HAR 提取工具
代理分析：Charles + BurpSuite
转发分析：修改 Host 域名 + 反向代理转发&lt;/p>
&lt;p>测试用例设计&lt;/p>
&lt;p>接口调用的流程分析
代理抓包
线上 Log 提取
人工用例补充：用流程图和思维导图进行业务建模
正常场景用例 Right Path
异常场景用例
安全和稳定性用例&lt;/p>
&lt;p>接口测试框架选择&lt;/p>
&lt;p>关于如何选择接口测试框架，列举几个常见的框架特性供参考：&lt;/p>
&lt;p>早期阶段：基于各种语言的 HTTPClient 封装
JMeter：性能测试工具，不具备完备的接口测试框架功能
RobotFramework：强大的 ATDD 工具，不过约束性太大
RestAssured + Swagger
SoapUI [商业化]&lt;/p>
&lt;p>这里推荐开源的 Rest-Assured，它有如下优点：&lt;/p>
&lt;p>简约的接口测试 DSL
支持 XML JSon 的结构化解析
支持 XPath JSonPath GPath 等多种解析方式
对 Spring 的支持比较全面&lt;/p>
&lt;h1 id="驱动模式driven-pattern">驱动模式(Driven Pattern)&lt;/h1>
&lt;h2 id="tdd">TDD&lt;/h2>
&lt;p>测试驱动开发的基本思想就是在开发功能代码之前，先编写测试代码。也就是说在明确要开发某个功能后，首先思考如何对这个功能进行测试，并完成测试代码的编写，然后编写相关的代码满足这些测试用例。然后循环进行添加其他功能，直到完全部功能的开发。我们这里把这个技术的应用领域从代码编写扩展到整个开发过程。应该对整个开发过程的各个阶段进行测试驱动，首先思考如何对这个阶段进行测试、验证、考核，并编写相关的测试文档，然后开始下一步工作，最后再验证相关的工作。下图是一个比较流行的测试模型：V 测试模型。&lt;/p></description></item><item><title>Spring-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/spring-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/spring-cheatsheet/</guid><description>&lt;h1 id="spring-cheatsheet--spring-概念使用与实践">Spring CheatSheet | Spring 概念、使用与实践&lt;/h1>
&lt;p>Spring 的设计目标是为我们提供一个一站式的轻量级应用开发平台，抽象了应用开发中遇到的共性问题。作为平台，它考虑到了企业应用资源的使用，比如数据的持久化、数据集成、事务处理、消息中间件、分布式式计算等高效可靠处理企业数据方法的技术抽象。开发过程中的共性问题，Spring 封装成了各种组件，而且 Spring 通过社区，形成了一个开放的生态系统，比如 Spring Security 就是来源于一个社区贡献。&lt;/p>
&lt;p>使用 Spring 进行开发，对开发人员比较轻量，可以使用 POJO 和 JavaBean 的开发方式，使应用面向接口开发，充分支持了面向对象的设计方法。通过 IOC 容器减少了直接耦合，通过 AOP 以动态和非侵入的方式增加了服务的功能，为灵活选取不同的服务实现提供了基础，这也是 Spring 的核心。轻量级是相对于传统 J2EE 而言的，传统的 J2EE 开发，需要依赖按照 J2EE 规范实现的 J2EE 应用服务器，设计和实现时，需要遵循一系列的接口标准，这种开发方式耦合性高，使应用在可测试性和部署上都有影响，对技术的理解和要求相对较高。&lt;/p>
&lt;h1 id="架构与生态圈">架构与生态圈&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/42418773-d9693618-82d9-11e8-9981-328db1065def.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="java-web-关键技术">Java Web 关键技术&lt;/h2>
&lt;p>Java Servlet（Java 服务器小程序）是一个基于 Java 技术的 Web 组件，运行在服务器端，它由 Servlet 容器所管理，用于生成动态的内容。Servlet 是平台独立的 Java 类，编写一个 Servlet，实际上就是按照 Servlet 规范编写一个 Java 类。Servlet 被编译为平台独立 的字节码，可以被动态地加载到支持 Java 技术的 Web 服务器中运行。&lt;/p>
&lt;p>Servlet 容器也叫做 Servlet 引擎，是 Web 服务器或应用程序服务器的一部分，用于在发送的请求和响应之上提供网络服务，解码基于 MIME 的请求，格式化基于 MIME 的响应。Servlet 没有 main 方法，不能独立运行，它必须被部署到 Servlet 容器中，由容器来实例化和调用 Servlet 的方法（如 doGet()和 doPost()），Servlet 容器在 Servlet 的生命周期内包容和管理 Servlet。在 JSP 技术 推出后，管理和运行 Servlet/JSP 的容器也称为 Web 容器。&lt;/p>
&lt;p>有了 Servlet 之后，用户通过单击某个链接或者直接在浏览器的地址栏中输入 URL 来访问 Servlet，Web 服务器接收到该请求后，并不是将 请求直接交给 Servlet，而是交给 Servlet 容器。Servlet 容器实例化 Servlet，调用 Servlet 的一个特定方法对请求进行处理，并产生一个响应。这个响应由 Servlet 容器返回给 Web 服务器，Web 服务器包装这个响应，以 HTTP 响应的形式发送给 Web 浏览器。&lt;/p>
&lt;h3 id="servlet-容器">Servlet 容器&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>通信支持：利用容器提供的方法，你能轻松的让 servlet 与 web 服务器对话，而不用自己建立 serversocket、监听某个端口、创建流等 等。容器知道自己与 web 服务器之间的协议，所以你的 servlet 不用担心 web 服务器（如 Apache）和你自己的 web 代码之间的 API，只需要考 虑如何在 servlet 中实现业务逻辑（如处理一个订单）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>生命周期管理：servlet 容器控制着 servlet 的生与死，它负责加载类、实例化和初始化 servlet，调用 servlet 方法，以及使 servlet 实例被垃圾回收，有了 servlet 容器，你不需要太多的考虑资源管理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>多线程支持：容器会自动为它所接收的每个 servlet 请求创建一个新的 java 线程。针对用户的请求，如果 servlet 已经运行完相应的 http 服务方法，这个线程就会结束。这并不是说你不需要考虑线程安全性，其实你还会遇到同步问题，不过这样能使你少做很多工作。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>声明方式实现安全：利用 servlet 容器，你可以使用 xml 部署描述文件来配置和修改安全性，而不必将其硬编码写到 servlet 类代码中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>JSP 支持：servlet 容器负责将 jsp 代码翻译为真正的 java 代码。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>根据 Servlet 容器工作模式的不同，可以将 Servlet 容器分为以下三类：&lt;/p>
&lt;p>1）独立的 Servlet 容器&lt;/p>
&lt;p>当我们使用基于 Java 技术的 Web 服务器时，Servlet 容器作为构成 Web 服务器的一部分而存在。然而大多数的 Web 服务器并非基于 Java，因此，就有了下面两种 Servlet 容器的工作模式。&lt;/p>
&lt;p>2）进程内的 Servlet 容器&lt;/p>
&lt;p>Servlet 容器由 Web 服务器插件和 Java 容器两部分的实现组成。Web 服务器插件在某个 Web 服务器内部地址空间中打开一个 JVM（Java 虚拟机），使得 Java 容器可以在此 JVM 中加载并运行 Servlet。如有客户端调用 Servlet 的请求到来，插件取得对此请求的控 制并将它传递（使用 JNI 技术）给 Java 容器，然后由 Java 容器将此请求交由 Servlet 进行处理。进程内的 Servlet 容器对于单进程、多线程 的服务器非常适合，提供了较高的运行速度，但伸缩性有所不足。&lt;/p>
&lt;p>3）进程外的 Servlet 容器&lt;/p>
&lt;p>Servlet 容器运行于 Web 服务器之外的地址空间，它也是由 Web 服务器插件和 Java 容器两部分的实现组成的。Web 服务器插件和 Java 容 器（在外部 JVM 中运行）使用 IPC 机制（通常是 TCP/IP）进行通信。当一个调用 Servlet 的请求到达时，插件取得对此请求的控制并将其传递（使 用 IPC 机制）给 Java 容器。进程外 Servlet 容器对客户请求的响应速度不如进程内的 Servlet 容器，但进程外容器具有更好的伸缩性和稳定性。&lt;/p>
&lt;h2 id="内建模块">内建模块&lt;/h2>
&lt;p>核心容器由 spring-core、spring-beans、spring-context、spring-context-support 和 spring-expression 模块组成：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>spring-core 和 spring-beans 提供框架的基础部分，包括 IOC 功能，BeanFactory 是一个复杂的工厂模式的实现，将配置和特定的依赖从实际程序逻辑中解耦。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>context 模块建立在 core 和 beans 模块的基础上，增加了对国际化的支持、事件广播、资源加载和创建上下文，ApplicationContext 是 context 模块的重点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-context-support 提供对常见第三个库的支持，集成到 spring 上下文中，比如缓存(ehcache,guava)、通信(javamail)、调度(commonj,quartz)、模板引擎等(freemarker,velocity)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-expression 模块提供了一个强大的表达式语言用来在运行时查询和操作对象图，这种语言支持对属性值、属性参数、方法调用、数组内容存储、集合和索引、逻辑和算数操作及命名变量，并且通过名称从 spring 的控制反转容器中取回对象。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>AOP 和服务器工具&lt;/p>
&lt;ul>
&lt;li>
&lt;p>spring-aop 模块提供面向切面编程实现，单独的 spring-aspects 模块提供了 aspectj 的集成和适用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-instrument 提供一些类级的工具支持和 ClassLoader 级的实现，用于服务器。spring-instrument-tomcat 针对 tomcat 的 instrument 实现。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>消息组件&lt;/p>
&lt;ul>
&lt;li>Spring 4 包含了 spring-messaging 模块，从 spring 集成项目中抽象出来，比如 Messge、MessageChannel、MessageHandler 及其他用来提供基于消息的基础服务。&lt;/li>
&lt;/ul>
&lt;p>数据访问和集成层由 JDBC、ORM、OXM、JMS 和事务模块组成。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>spring-jdbc 模块提供了不需要编写冗长的 JDBC 代码和解析数据库厂商特有的错误代码的 JDBC 抽象出。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-tx 模块提供可编程和声明式事务管理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-orm 模块提供了领先的对象关系映射 API 集成层，如 JPA、Hibernate 等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-oxm 模块提供抽象层用于支持 Object/XML maping 的实现，如 JAXB、XStream 等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-jms 模块包含生产和消费消息的功能，从 Spring4.1 开始提供集成 spring-messaging 模块。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Web 层包含 spring-web、spirng-webmvc、spring-websocket 和 spring-webmvc-portlet 等模块。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>spring-web 模块提供了基本的面向 web 开发的集成功能，例如多文件上传、使用 servert listeners 和 web 开发应用程序上下文初始化 IOC 容器。也包含 HTTP 客户端以及 spring 远程访问的支持的 web 相关部分。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-webmvc 包含 spring 的 model-view-controller 和 REST web services 实现的 Web 应用程序。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spring-webmvc-portlet 模块提供了 MVC 模式的 portlet 实现，protlet 与 Servlet 的最大区别是请求的处理分为 action 和 render 阶段，在一个请求中，action 阶段只执行一次，但 render 阶段可能由于用户的浏览器操作而被执行多次。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>传统的 Spring MVC 基于 Servlet API 构建，使用单请求单线程处理的同步阻塞型模型；而 Spring WebFlux 则是 Reactive Stack，能够充分利用现代多核处理器的特性，从底层机制上保证了对于海量并发请求处理的能力。WebFlux 使用 Netty, Servlet 3.1+ Containers 替代传统的 Servlet Containers，使用 Reactive Stream Adapters 替代 Servlet API，使用 Spring Security Reactive 替代 Spring Security，使用 Spring Data Reactive Repositories 替代 Spring Data Repositories。&lt;/p>
&lt;p>spring-test 模块支持通过组合 Junit 或 TestNG 来进行单元测试和集成测试，提供了连续的加载 ApplicationContext 并且缓存这些上下文。&lt;/p>
&lt;h2 id="生态圈">生态圈&lt;/h2>
&lt;p>Spring Boot 简化新 Spring 应用的初始搭建以及开发过程，使用特定的方式进行配置，使开发人员不再需要定义样板化的配置，实现快速开发。数据访问模块，提供了对 JDBC 及 ORM 很好的支持，随着 NOSQL 和 BigData 的兴起，出现了越来越多的新技术，比如非关系型数据库、MapReduce 框架，为了让 spring 开发者能更方便地使用这些新技术，通过 Spring Data，开发者可以用 Spring 提供的相对一致的方式访问位于不同类型的数据存储中的数据。Spring Cloud Data Flow 是基于原生云对 Spring XD 的重新设计，项目目标是简化大数据应用的开发。Spring XD 的流处理和批处理模块的重构分别基于 spring boot 的 stream 和 task/batch 的微服务程序。这些程序原生的支持像 Apache YARN、Apache Mesos 和 Kubernetes 等现代运行环境，都是自动部署单元。&lt;/p>
&lt;p>Spring Cloud 为分布式系统开发提供工具集，基于 Spring Boot，为基于 JVM 的云应用开发中的配置管理、服务发现、断路器、智能路由、控制总线、全局锁、决策竞选、分布式会话、集群状态管理等操作提供了一种简单的开发方式，其下有很多子项目。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>分布式/版本化配置：Spring Cloud Config&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务注册和发现：Netflix Eureka 或者 Spring Cloud Eureka（对前者的二次封装）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>路由：Spring Cloud Zuul，基于 Netflix Zuul&lt;/p>
&lt;/li>
&lt;li>
&lt;p>service - to - service 调用：Spring Cloud Feign&lt;/p>
&lt;/li>
&lt;li>
&lt;p>负载均衡：Spring Cloud Ribbon 基于 Netflix Ribbon 实现&lt;/p>
&lt;/li>
&lt;li>
&lt;p>断路器：Spring Cloud Hystrix&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分布式消息传递：Spring Cloud Bus&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Spring Batch 简化及优化大量数据的批处理操作，支持事务、并发、流程、监控、纵向和横向扩展，提供统一的接口管理和任务管理。例如它提供了很多方法来读取大型的文件（比如 1GB 的 CSV、XML 文件），在数据库中加载或更新几万甚至几十万条记录，如果直接 select 出所有记录，以至于拖垮整个系统，而使用了 Spring Batch，框架会帮助他每次捞取一部分记录进行分页，在更新时分批进行提交。&lt;/p>
&lt;p>Spring Security 是一款 Spring 的认证和安全工具。其前身是 Acegi，目标是为 Spring 应用提供一个安全服务，比如用户认证、授权等。它使用 Servlet 规范中的 Filter 保护 Web 请求并限制 URL 级别的访问，还能够使用 Spring AOP 保护方法调用——借助于对象代理和使用通知，能够确保只有具备适当权限的用户才能访问安全保护的方法。它非常灵活，能够基于各种数据存储来认证用户。它内置了多种常见的用户存储场景，如内存、关系型数据库以及 LDAP，还可以编写并插入自定义的用户存储实现。&lt;/p></description></item><item><title>SpringBoot-CheatSheet</title><link>https://ng-tech.icu/books/awesome-cheatsheets/03.system/springboot-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-cheatsheets/03.system/springboot-cheatsheet/</guid><description>&lt;h1 id="spring-boot-cheatsheet">Spring Boot CheatSheet&lt;/h1>
&lt;p>Spring Boot 应用本质上就是一个基于 Spring 框架的应用，它是 Spring 对“约定优先于配置”理念的最佳实践产物，它能够帮助开发者更快速高效地构建基于 Spring 生态圈的应用；最重要的 4 大核心特性包括了自动配置、起步依赖、Actuator、命令行界面(CLI)。&lt;/p>
&lt;p>可以在 &lt;a href="https://start.spring.io/" target="_blank" rel="noopener">Spring Initializr&lt;/a> 动态地选择需要的组件，对于 Spring 框架/生态的讨论，以及 IOC/DI 等机制原理的分析参考 &lt;a href="https://github.com/wx-chevalier/Awesome-CheatSheets/blob/master/Backend/WebFramework/Java/Spring-CheatSheet.md" target="_blank" rel="noopener">Spring CheatSheet&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// @SpringBootApplication 整合了 @Configuration + @ComponentScan + @EnableAutoConfiguration，其会自动进行组件扫描与配置
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@SpringBootApplication&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">FooApplication&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// Bootstrap the application
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="n">SpringApplication&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">run&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">FooApplication&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>@Configuration: Marks a class as a config class using Spring&amp;rsquo;s Java based configuration&lt;/li>
&lt;li>@ComponentScan: Enables component-scanning so that web controller classes can be automatically registered as beans in the Spring application context&lt;/li>
&lt;li>@EnableAutoConfiguration: Configures the application based on the dependencies&lt;/li>
&lt;/ul>
&lt;h1 id="依赖声明与注入">依赖声明与注入&lt;/h1>
&lt;h2 id="依赖声明">依赖声明&lt;/h2>
&lt;h3 id="注解声明">注解声明&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Component&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyComponent&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在 Spring2.0 之前的版本中，@Repository 注解可以标记在任何的类上，用来表明该类是用来执行与数据库相关的操作（即 dao 对象），并支持自动处理数据库操作产生的异常&lt;/p>
&lt;p>在 Spring2.5 版本中，引入了更多的 Spring 类注解：@Component,@Service,@Controller。@Component 是一个通用的 Spring 容器管理的单例 bean 组件。而@Repository, @Service, @Controller 就是针对不同的使用场景所采取的特定功能化的注解组件。&lt;/p>
&lt;p>因此，当你的一个类被@Component 所注解，那么就意味着同样可以用@Repository, @Service, @Controller 来替代它，同时这些注解会具备有更多的功能，而且功能各异。&lt;/p>
&lt;p>最后，如果你不知道要在项目的业务层采用@Service 还是@Component 注解。那么，@Service 是一个更好的选择。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Configuration&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TestConfig&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Bean&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;helloClient&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="n">HessianProxyFactoryBean&lt;/span> &lt;span class="nf">helloClient&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">HessianProxyFactoryBean&lt;/span> &lt;span class="n">factory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HessianProxyFactoryBean&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">factory&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="conditional-configuration--条件化配置">Conditional Configuration | 条件化配置&lt;/h3>
&lt;p>Class conditions allow us to specify that a configuration bean will be included if a specified class is present.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Configuration&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConditionalOnClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DataSource&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MySQLAutoconfiguration&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">//...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>也可以根据某个 Bean 是否存在来决定是否需要创建 Bean:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Bean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConditionalOnBean&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;dataSource&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConditionalOnMissingBean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">LocalContainerEntityManagerFactoryBean&lt;/span> &lt;span class="nf">entityManagerFactory&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">LocalContainerEntityManagerFactoryBean&lt;/span> &lt;span class="n">em&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">LocalContainerEntityManagerFactoryBean&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">em&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>还可以根据是否存在某个属性配置来决定是否需要创建某个 Bean:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Bean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConditionalOnProperty&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;usemysql&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">havingValue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;local&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConditionalOnMissingBean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">DataSource&lt;/span> &lt;span class="nf">dataSource&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">DriverManagerDataSource&lt;/span> &lt;span class="n">dataSource&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">DriverManagerDataSource&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dataSource&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Defining Condition that checks if the JdbcTemplate is available on the classpath
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">//
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Conditions are used by the auto-configuration mechanism of Spring Boot
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// There are several configuration classes in the spring-boot-autoconfigure.jar
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// which contribute to the configuration if specific conditions are met
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">JdbcTemplateCondition&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">Condition&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Override&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">matches&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ConditionContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">AnnotatedTypeMetadata&lt;/span> &lt;span class="n">metadata&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">context&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getClassLoader&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">loadClass&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;org.springframework.jdbc.core.JdbcTemplate&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Exception&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Use a custom condition class to decide whether a Bean should be created or not
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@Conditional&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">JdbcTemplateCondition&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">MyService&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th>条件化注解&lt;/th>
&lt;th>配置生效条件&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>@ConditionalOnBean&lt;/td>
&lt;td>配置了某个特定 bean&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnMissingBean&lt;/td>
&lt;td>没有配置特定的 bean&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnClass&lt;/td>
&lt;td>Classpath 里有指定的类&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnMissingClass&lt;/td>
&lt;td>Classpath 里没有指定的类&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnExpression&lt;/td>
&lt;td>给定的 Spring Expression Language 表达式计算结果为 true&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnJava&lt;/td>
&lt;td>Java 的版本匹配特定指或者一个范围值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnProperty&lt;/td>
&lt;td>指定的配置属性要有一个明确的值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnResource&lt;/td>
&lt;td>Classpath 里有指定的资源&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnWebApplication&lt;/td>
&lt;td>这是一个 Web 应用程序&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>@ConditionalOnNotWebApplication&lt;/td>
&lt;td>这不是一个 Web 应用程序&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="作用域与生命周期">作用域与生命周期&lt;/h2>
&lt;p>Spring 中为 Bean 定义了 5 种作用域，分别为 Singleton(单例), Prototype(原型), Request,Session 和 Global Session:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Singleton, 单例模式，Spring IoC 容器中只会存在一个共享的 Bean 实例，无论有多少个 Bean 引用它，始终指向同一对象。Singleton 作用域是 Spring 中的缺省作用域，也可以显式的将 Bean 定义为 Singleton 模式&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prototype, 原型模式，每次通过 Spring 容器获取 prototype 定义的 bean 时，容器都将创建一个新的 Bean 实例，每个 Bean 实例都有自己的属性和状态，而 Singleton 全局只有一个对象。根据经验，对有状态的 bean 使用 prototype 作用域，而对无状态的 bean 使用 Singleton 作用域。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Request, 在一次 Http 请求中，容器会返回该 Bean 的同一实例。而对不同的 Http 请求则会产生新的 Bean，而且该 bean 仅在当前 Http Request 内有效。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Session, 在一次 Http Session 中，容器会返回该 Bean 的同一实例。而对不同的 Session 请求则会创建新的实例，该 bean 实例仅在当前 Session 内有效。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Global Session, 在一个全局的 Http Session 中，容器会返回该 Bean 的同一个实例，仅在使用 portlet context 时有效。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>可以通过 @Scope 注解来指定作用域。Spring 容器可以管理 Singleton 作用域下 Bean 的生命周期，在此作用域下，Spring 能够精确地知道 Bean 何时被创建，何时初始化完成，以及何时被销毁。而对于 prototype 作用域的 Bean，Spring 只负责创建，当容器创建了 Bean 的实例后，Bean 的实例就交给了客户端的代码管理，Spring 容器将不再跟踪其生命周期，并且不会管理那些被配置成 prototype 作用域的 Bean 的生命周期。Spring 中 Bean 的生命周期的执行是一个很复杂的过程，读者可以利用 Spring 提供的方法来定制 Bean 的创建过程。Spring 容器在保证一个 Bean 实例能够使用之前会做很多工作：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/5803001/47768779-677b0500-dd14-11e8-9f33-f06dbbebd08b.png" alt="image" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>我们常用的生命周期的 Hook 方法就是在其创建后与销毁之前：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@PostConstruct&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">initAfterStartup&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@PreDestroy&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">cleanupBeforeExit&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于使用 Bean 注解的对象，可以添加 destroyMethod 等参数来介入其生命周期：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Bean&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">destroyMethod&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;close&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">MyBean&lt;/span> &lt;span class="nf">myBean&lt;/span>&lt;span class="o">(){...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="application-lifecycle--应用生命周期">Application LifeCycle | 应用生命周期&lt;/h3>
&lt;p>Spring Boot 为我们提供了两个接口，CommandLineRunner 与 ApplicationRunner，它们能够在应用启动之后执行部分业务逻辑。CommandLineRunner 能够允许我们访问到应用的启动参数：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Component&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">CommandLineAppStartupRunner&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">CommandLineRunner&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Logger&lt;/span> &lt;span class="n">logger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">LoggerFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLogger&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">CommandLineAppStartupRunner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Override&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">run&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">...&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">info&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;Application started with command-line arguments: {} . \n To kill this application, press Ctrl + C.&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ApplicationRunner 则是对启动参数进行了二次封装：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Component&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">AppStartupRunner&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">ApplicationRunner&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">final&lt;/span> &lt;span class="n">Logger&lt;/span> &lt;span class="n">logger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">LoggerFactory&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLogger&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">AppStartupRunner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Override&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">run&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ApplicationArguments&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">logger&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">info&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;Your application started with option names : {}&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">args&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getOptionNames&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="配置管理">配置管理&lt;/h2>
&lt;p>Spring Boot 的一大特性即是外置所有的配置，并且提供了多种配置访问方式；首先我们可以通过动态地指定配置文件的方式来完成不同环境下的配置文件加载：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 在本地跑时，默认是 local，在其它环境跑时，要通过 -Dspring.profiles.active= 来指定&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">spring.profiles.active&lt;span class="o">=&lt;/span>&lt;span class="nb">local&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>当某些属性的值需要配置的时候，我们一般会在 application.properties 文件中新建配置项，然后在 bean 中使用 @Value 注解来获取配置的值：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// jdbc.mysql.url=jdbc:mysql://localhost:3306/sampledb
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 配置数据源
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@Configuration&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">HikariDataSourceConfiguration&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Value&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;jdbc.mysql.url&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">url&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Bean&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="n">HikariDataSource&lt;/span> &lt;span class="nf">dataSource&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">HikariConfig&lt;/span> &lt;span class="n">hikariConfig&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HikariConfig&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hikariConfig&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">setJdbcUrl&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">url&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">HikariDataSource&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hikariConfig&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于更为复杂的配置，Spring Boot 提供了更优雅的实现方式，那就是 @ConfigurationProperties 注解：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Configuration&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@PropertySource&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;classpath:configprops.properties&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ConfigurationProperties&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;mail&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ConfigProperties&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Credentials&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">authMethod&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">username&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">password&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// standard getters and setters
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">host&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">port&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">from&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">Credentials&lt;/span> &lt;span class="n">credentials&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">List&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">defaultRecipients&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">additionalHeaders&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// standard getters and setters
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 使用的时候直接注入
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@AutoWired&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">ConfigProperties&lt;/span> &lt;span class="n">config&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#Simple properties&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.host&lt;span class="o">=&lt;/span>mailer@mail.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.port&lt;span class="o">=&lt;/span>&lt;span class="m">9000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.from&lt;span class="o">=&lt;/span>mailer@mail.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#List properties&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.defaultRecipients&lt;span class="o">[&lt;/span>0&lt;span class="o">]=&lt;/span>admin@mail.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.defaultRecipients&lt;span class="o">[&lt;/span>1&lt;span class="o">]=&lt;/span>owner@mail.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#Map Properties&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.additionalHeaders.redelivery&lt;span class="o">=&lt;/span>&lt;span class="nb">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.additionalHeaders.secure&lt;span class="o">=&lt;/span>&lt;span class="nb">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#Object properties&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.credentials.username&lt;span class="o">=&lt;/span>john
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.credentials.password&lt;span class="o">=&lt;/span>password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mail.credentials.authMethod&lt;span class="o">=&lt;/span>SHA1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>也可以为配置类添加校验：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Length&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">max&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">min&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">authMethod&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="端口设置">端口设置&lt;/h2>
&lt;h1 id="controller--请求处理">Controller | 请求处理&lt;/h1>
&lt;p>传统的 Spring MVC 基于 Servlet API 构建，使用单请求单线程处理的同步阻塞型模型；而 Spring WebFlux 则是 Reactive Stack，能够充分利用现代多核处理器的特性，从底层机制上保证了对于海量并发请求处理的能力。WebFlux 使用 Netty, Servlet 3.1+ Containers 替代传统的 Servlet Containers，使用 Reactive Stream Adapters 替代 Servlet API，使用 Spring Security Reactive 替代 Spring Security，使用 Spring Data Reactive Repositories 替代 Spring Data Repositories。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://docs.spring.io/spring/docs/current/spring-framework-reference/images/spring-mvc-and-webflux-venn.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="路由与参数">路由与参数&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@RestController&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@RequestMapping&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;/persons&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">class&lt;/span> &lt;span class="nc">PersonController&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@GetMapping&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;/{id}&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="n">Person&lt;/span> &lt;span class="nf">getPerson&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@PathVariable&lt;/span> &lt;span class="n">Long&lt;/span> &lt;span class="n">id&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@PostMapping&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@ResponseStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HttpStatus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">CREATED&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">add&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@RequestBody&lt;/span> &lt;span class="n">Person&lt;/span> &lt;span class="n">person&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="请求校验">请求校验&lt;/h2>
&lt;p>Spring 为我们提供了开箱即用的简单校验，当定义某个 REST 端点之后，可以针对 PathVariable 与 RequestParameter 设置某个值是否为必须：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@GetMapping&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;/hello/{name}&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="nf">hello&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@PathVariable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">required&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">){&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">//...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@GetMapping&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;/name&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">ResponseEntity&lt;/span>&lt;span class="o">&amp;lt;?&amp;gt;&lt;/span> &lt;span class="n">queryPerson&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@RequestParam&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;query&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">required&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>对于复杂请求体的验证，可以使用 Spring 内置的 &lt;a href="http://beanvalidation.org/1.0/spec/" target="_blank" rel="noopener">JSR 303 Bean Validation&lt;/a> 提供的 NotNull, Max, Min 等等注解：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">Message&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@NotNull&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">title&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@NotNull&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">message&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// getters/setters/etc
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后在 Controller 中注解响应体：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@PostMapping&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">ResponseEntity&lt;/span>&lt;span class="o">&amp;lt;?&amp;gt;&lt;/span> &lt;span class="n">createMessage&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="nd">@Valid&lt;/span> &lt;span class="nd">@RequestBody&lt;/span> &lt;span class="n">Message&lt;/span> &lt;span class="n">message&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// ...
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果我们需要去自定义校验器，则可以选择去扩展 ConstraintValidator 接口：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">InRangeValidator&lt;/span> &lt;span class="kd">implements&lt;/span> &lt;span class="n">ConstraintValidator&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">InRange&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">min&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">max&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Override&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">initialize&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">InRange&lt;/span> &lt;span class="n">constraintAnnotation&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">min&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">constraintAnnotation&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">min&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">this&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">max&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">constraintAnnotation&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">max&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Override&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">boolean&lt;/span> &lt;span class="nf">isValid&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Integer&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ConstraintValidatorContext&lt;/span> &lt;span class="n">context&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">value&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">null&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">value&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">min&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">value&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">max&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 扩展 InRange 接口，添加自定义属性
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@Target&lt;/span>&lt;span class="o">({&lt;/span> &lt;span class="n">ElementType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">METHOD&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ElementType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">FIELD&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ElementType&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">PARAMETER&lt;/span> &lt;span class="o">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Retention&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">RetentionPolicy&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">RUNTIME&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Documented&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Constraint&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">validatedBy&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="n">InRangeValidator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span> &lt;span class="o">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="nd">@interface&lt;/span> &lt;span class="n">InRange&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">String&lt;/span> &lt;span class="nf">message&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="s">&amp;#34;Value is out of range&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Class&lt;/span>&lt;span class="o">&amp;lt;?&amp;gt;[]&lt;/span> &lt;span class="n">groups&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Class&lt;/span>&lt;span class="o">&amp;lt;?&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">Payload&lt;/span>&lt;span class="o">&amp;gt;[]&lt;/span> &lt;span class="nf">payload&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="o">{&lt;/span> &lt;span class="o">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="nf">min&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MIN_VALUE&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="nf">max&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="k">default&lt;/span> &lt;span class="n">Integer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">MAX_VALUE&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在使用的时候，直接注解即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@NotNull&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">groups&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>&lt;span class="n">Existing&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">New&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@InRange&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">min&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">18&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">message&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;User must be at least 18 years old&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">groups&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">{&lt;/span>&lt;span class="n">Existing&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">New&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">Integer&lt;/span> &lt;span class="n">age&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>最后，我们还可以自定义返回的错误格式，譬如以 JSON 的方式返回：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ExceptionHandler&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ResponseStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">HttpStatus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">BAD_REQUEST&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">ErrorResponse&lt;/span> &lt;span class="nf">handleException&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">MethodArgumentNotValidException&lt;/span> &lt;span class="n">exception&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">String&lt;/span> &lt;span class="n">errorMsg&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">exception&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getBindingResult&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">getFieldErrors&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">stream&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="na">map&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">DefaultMessageSourceResolvable&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="n">getDefaultMessage&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="na">findFirst&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="na">orElse&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">exception&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getMessage&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">ErrorResponse&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">message&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">errorMsg&lt;/span>&lt;span class="o">).&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="响应">响应&lt;/h2>
&lt;h1 id="service--服务">Service | 服务&lt;/h1>
&lt;h2 id="logging--日志">Logging | 日志&lt;/h2>
&lt;h2 id="日志配置">日志配置&lt;/h2>
&lt;p>对外接口统一拦截捕获，避免异常向外系统传播，自身系统无法感知问题。&lt;/p>
&lt;p>严格规范日志输出等级，尤其 Error 级别。影响业务进行或意料外异常输出 Error 级别，Error 级别日志统一输出到独立文件，并接入 xflush 系统错误监控告警。做到 Error 日志输出即为需要人为介入处理。为了避免干扰，对现有 Error 做降噪检查。&lt;/p>
&lt;p>服务层日志统一输出，包括耗时、接口成功标识、业务成功标识，为监控做准备。&lt;/p>
&lt;p>所有日志 traceId 的统一输出。通过扩展 ch.qos.logback.classic.pattern.ClassicConverter，现实 traceId 自动输出。这极大的提升了系统运维效率。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;appender&lt;/span> &lt;span class="na">name=&lt;/span>&lt;span class="s">&amp;#34;ERROR-APPENDER&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="na">class=&lt;/span>&lt;span class="s">&amp;#34;ch.qos.logback.core.rolling.RollingFileAppender&amp;#34;&lt;/span>&lt;span class="nt">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;file&amp;gt;&lt;/span>${LOG_PATH}/common-error.log&lt;span class="nt">&amp;lt;/file&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c">&amp;lt;!-- Error 级别过滤 --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;filter&lt;/span> &lt;span class="na">class=&lt;/span>&lt;span class="s">&amp;#34;ch.qos.logback.classic.filter.LevelFilter&amp;#34;&lt;/span>&lt;span class="nt">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;level&amp;gt;&lt;/span>ERROR&lt;span class="nt">&amp;lt;/level&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;onMatch&amp;gt;&lt;/span>ACCEPT&lt;span class="nt">&amp;lt;/onMatch&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;onMismatch&amp;gt;&lt;/span>DENY&lt;span class="nt">&amp;lt;/onMismatch&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;/filter&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;encoder&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;pattern&amp;gt;&lt;/span>%d{yyyy-MM-dd HH:mm:ss.SSS} ${LOG_LEVEL_PATTERN:-%5p} - [%thread] : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;/pattern&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;/encoder&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;rollingPolicy&lt;/span> &lt;span class="na">class=&lt;/span>&lt;span class="s">&amp;#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&amp;#34;&lt;/span>&lt;span class="nt">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c">&amp;lt;!-- 按天滚动，可根据实际量调整单位 --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;fileNamePattern&amp;gt;&lt;/span>${LOG_PATH}/common-error.log.%d{yyyy-MM-dd}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;/fileNamePattern&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;maxHistory&amp;gt;&lt;/span>15&lt;span class="nt">&amp;lt;/maxHistory&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;/rollingPolicy&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;/appender&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-xml" data-lang="xml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;root&lt;/span> &lt;span class="na">level=&lt;/span>&lt;span class="s">&amp;#34;INFO&amp;#34;&lt;/span>&lt;span class="nt">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c">&amp;lt;!-- root中增加Error输出配置 --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;appender-ref&lt;/span> &lt;span class="na">ref=&lt;/span>&lt;span class="s">&amp;#34;ERROR-APPENDER&amp;#34;&lt;/span> &lt;span class="nt">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;/root&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;logger&lt;/span> &lt;span class="na">name=&lt;/span>&lt;span class="s">&amp;#34;testLog&amp;#34;&lt;/span> &lt;span class="na">level=&lt;/span>&lt;span class="s">&amp;#34;INFO&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="na">additivity=&lt;/span>&lt;span class="s">&amp;#34;false&amp;#34;&lt;/span>&lt;span class="nt">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;appender-ref&lt;/span> &lt;span class="na">ref=&lt;/span>&lt;span class="s">&amp;#34;WORK_SHIFT_CORE_MONITOR_LOG&amp;#34;&lt;/span> &lt;span class="nt">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c">&amp;lt;!-- 每个logger增加ERROR输出 --&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;appender-ref&lt;/span> &lt;span class="na">ref=&lt;/span>&lt;span class="s">&amp;#34;ERROR-APPENDER&amp;#34;&lt;/span> &lt;span class="nt">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;/logger&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="缓存">缓存&lt;/h2>
&lt;p>Spring Cache 为我们提供了非常便捷的方法调用缓存功能，在依赖中引入 spring-boot-starter-cache:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-groovy" data-lang="groovy">&lt;span class="line">&lt;span class="cl">&lt;span class="n">dependencies&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">compile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s2">&amp;#34;org.springframework.boot:spring-boot-starter-cache&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后在 Application 类中添加 &lt;code>@EnableCaching&lt;/code> 注解，这样我们在进行方法调用时可以缓存调用结果：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Cacheable&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;books&amp;#34;&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="n">Book&lt;/span> &lt;span class="nf">getByIsbn&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">isbn&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="storage--数据访问">Storage | 数据访问&lt;/h1>
&lt;h2 id="spring-jdbc-template">Spring JDBC Template&lt;/h2>
&lt;h2 id="mybatis">MyBatis&lt;/h2>
&lt;h2 id="redis">Redis&lt;/h2>
&lt;h1 id="test--测试">Test | 测试&lt;/h1>
&lt;h2 id="请求">请求&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Testing classes in Spring Boot
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@RunWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">SpringJUnit4ClassRunner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Load context via Spring Boot
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@SpringApplicationConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">classes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ReadinglistApplication&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@WebAppConfiguration&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">ReadinglistApplicationTests&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// Test that the context successfully loads (the method can be empty -&amp;gt; the test will fail if the context cannot be loaded)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nd">@Test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">contextLoads&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="服务">服务&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Integration test by loading Springs application context
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// To to integration testing with Spring, all components of the application have to be configured and wired up.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Instead of doing this by hand we can use Spring&amp;#39;s SpringJUnit4ClassRunner.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// It helps load a Spring application context in JUnit-based application tests.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// This method with the @ContextConfiguration annotation doesn&amp;#39;t apply extenal properites (application.properties) and logging
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// @ContextConfiguration specifies how to load the application context: A configuraiton class is passed to it as a parameter
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nd">@RunWith&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">SpringJUnit4ClassRunner&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@ContextConfiguration&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">classes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">PlaylistConfiguration&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">class&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">PlaylistServiceTests&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Autowired&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">PlaylistService&lt;/span> &lt;span class="n">playlistService&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testService&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Playlist&lt;/span> &lt;span class="n">playlist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">playlistService&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">findByName&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;X-Mas Songs&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">assertEquals&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;X-Mas Songs&amp;#34;&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">playlist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">assertEquals&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="mi">12&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">playlist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">countSongs&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="数据存储">数据存储&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@SpringBootTest&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nd">@Transactional&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">class&lt;/span> &lt;span class="nc">MySpec&lt;/span> &lt;span class="kd">extends&lt;/span> &lt;span class="n">Specification&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nd">@Autowired&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MyRepository&lt;/span> &lt;span class="n">myRepo&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">def&lt;/span> &lt;span class="s">&amp;#34;Persist an entity&amp;#34;&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">given&lt;/span>&lt;span class="o">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MyEntity&lt;/span> &lt;span class="n">entity&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">MyEntity&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl"> when:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">myRepo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">saveAndFlush&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">entity&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl"> then:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">myRepo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">def&lt;/span> &lt;span class="s">&amp;#34;Persist another entity&amp;#34;&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">given&lt;/span>&lt;span class="o">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MyEntity&lt;/span> &lt;span class="n">entity&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">MyEntity&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl"> when:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">myRepo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">saveAndFlush&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">entity&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nl"> then:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">myRepo&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">count&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-ann-modelattrib-methods" target="_blank" rel="noopener">https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-ann-modelattrib-methods&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.baeldung.com/spring-jdbc-jdbctemplate" target="_blank" rel="noopener">https://www.baeldung.com/spring-jdbc-jdbctemplate&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>
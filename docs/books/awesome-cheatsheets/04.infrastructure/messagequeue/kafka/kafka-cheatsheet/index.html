<!doctype html><html lang=zh><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=google-site-verification content="google69a5cccb61297807"><meta name=baidu-site-verification content="cqmZHEleVh"><meta name=description content="Kafka CheatSheet Kafka 简介 一、简介 ApacheKafka 是一个分布式的流处理平台。它具有以下特点： 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列； 支持数据实时处理； 能保证消息的可靠性投递； 支持消息的持久化存储，并"><link rel=alternate hreflang=zh href=https://ng-tech.icu/books/awesome-cheatsheets/04.infrastructure/messagequeue/kafka/kafka-cheatsheet/><meta name=theme-color content="#0a55a7"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin=anonymous><link rel=stylesheet href=/css/wowchemy.63df6ae9fc2b4cc71b83f1774d780209.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-40NYXJ8823")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://ng-tech.icu/books/awesome-cheatsheets/04.infrastructure/messagequeue/kafka/kafka-cheatsheet/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wx-chevalier"><meta property="twitter:creator" content="@wx-chevalier"><meta property="og:site_name" content="Next-gen Tech Edu"><meta property="og:url" content="https://ng-tech.icu/books/awesome-cheatsheets/04.infrastructure/messagequeue/kafka/kafka-cheatsheet/"><meta property="og:title" content="Kafka-CheatSheet | Next-gen Tech Edu"><meta property="og:description" content="Kafka CheatSheet Kafka 简介 一、简介 ApacheKafka 是一个分布式的流处理平台。它具有以下特点： 支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列； 支持数据实时处理； 能保证消息的可靠性投递； 支持消息的持久化存储，并"><meta property="og:image" content="https://ng-tech.icu/media/sharing.png"><meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png"><meta property="og:locale" content="zh"><title>Kafka-CheatSheet | Next-gen Tech Edu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=07458bdd1701a52dec4e369da03d1471><button onclick=topFunction() id=backTopBtn title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden=true></i></button>
<script src=/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class="col-6 search-title"><p>搜索</p></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=关闭><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div><div id=search-common-queries></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/books-gallery><span>笔记（万篇）</span></a></li><li class=nav-item><a class=nav-link href=/#knowledge-map><span>知识图谱</span></a></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>实验室</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/galaxy-home/gh-craft><span>Craft 方块世界</span></a>
<a class=dropdown-item href=/galaxy-home/glossary-cards><span>3D 知识卡牌</span></a></div></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>其他阅读渠道</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png></img><span>知乎</span></a>
<a class=dropdown-item href=https://segmentfault.com/blog/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png></img><span>SegmentFault</span></a>
<a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png></img><span>掘金</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/wx-chevalier aria-label=GitHub><i class="fa-brands fa-github" aria-hidden=true></i></a></li><div></div><style>@media only screen and (max-width:600px){.jimmysong-template{display:none!important}}</style><li class=jimmysong-template style=color:#fff;font-size:12px><a href=https://jimmysong.io style=color:#fff>By Jimmy Song's Template</a></li></ul></div></nav></header></div><div class=page-body><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><div class="container-xl docs"><div class="row flex-xl-nowrap"><div class=docs-sidebar><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">Kafka</span>
<span><i class="fas fa-chevron-down"></i></span></div></button>
<button class="form-control sidebar-search js-search d-none d-md-flex">
<i class="fas fa-search pr-2"></i>
<span class=sidebar-search-text>搜索...</span>
<span class=sidebar-search-shortcut>/</span></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li style=display:inline-flex><a style=cursor:pointer onclick=window.history.back()><i class="fas fa-arrow-left pr-1"></i>
Back</a>
<span>|</span>
<a href=/books/><i class="fa-solid fa-house" style=margin-right:4px></i>
Books</a></li></ul><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idf910ea24e55aa5d41f8e514f503ae01d")' href=#idf910ea24e55aa5d41f8e514f503ae01d aria-expanded=false aria-controls=idf910ea24e55aa5d41f8e514f503ae01d aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/>MessageQueue</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idf910ea24e55aa5d41f8e514f503ae01d aria-expanded=false aria-controls=idf910ea24e55aa5d41f8e514f503ae01d><i class="fa-solid fa-angle-down" id=caret-idf910ea24e55aa5d41f8e514f503ae01d></i></a></div><ul class="nav docs-sidenav collapse show" id=idf910ea24e55aa5d41f8e514f503ae01d><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-ida13c7bf5533977d458e4532d1466ded5")' href=#ida13c7bf5533977d458e4532d1466ded5 aria-expanded=false aria-controls=ida13c7bf5533977d458e4532d1466ded5 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/kafka/>Kafka</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#ida13c7bf5533977d458e4532d1466ded5 aria-expanded=false aria-controls=ida13c7bf5533977d458e4532d1466ded5><i class="fa-solid fa-angle-down" id=caret-ida13c7bf5533977d458e4532d1466ded5></i></a></div><ul class="nav docs-sidenav collapse show" id=ida13c7bf5533977d458e4532d1466ded5><li class="child level active"><a href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/kafka/kafka-cheatsheet/>Kafka-CheatSheet</a></li></ul></div><li class="child level"><a href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/pulsar-cheatsheet/>Pulsar-CheatSheet</a></li><li class="child level"><a href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/rabbitmq-cheatsheet/>RabbitMQ-CheatSheet</a></li><li class="child level"><a href=/books/awesome-cheatsheets/04.infrastructure/messagequeue/rocketmq-cheatsheet/>RocketMQ-CheatSheet</a></li></ul></div></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>目录</a></li></ul><nav id=TableOfContents><ul><li><a href=#一简介>一、简介</a></li><li><a href=#二基本概念>二、基本概念</a><ul><li><a href=#21-messages-and-batches>2.1 Messages And Batches</a></li><li><a href=#22-topics-and-partitions>2.2 Topics And Partitions</a></li><li><a href=#23-producers-and-consumers>2.3 Producers And Consumers</a></li><li><a href=#24-brokers-and-clusters>2.4 Brokers And Clusters</a></li></ul></li></ul><ul><li><a href=#一生产者发送消息的过程>一、生产者发送消息的过程</a></li><li><a href=#二创建生产者>二、创建生产者</a><ul><li><a href=#21-项目依赖>2.1 项目依赖</a></li><li><a href=#22-创建生产者>2.2 创建生产者</a></li><li><a href=#23-测试>2.3 测试</a></li><li><a href=#24-可能出现的问题>2.4 可能出现的问题</a></li></ul></li><li><a href=#二发送消息>二、发送消息</a><ul><li><a href=#21-同步发送>2.1 同步发送</a></li><li><a href=#22-异步发送>2.2 异步发送</a></li></ul></li><li><a href=#三自定义分区器>三、自定义分区器</a><ul><li><a href=#31-自定义分区器>3.1 自定义分区器</a></li><li><a href=#32-测试>3.2 测试</a></li></ul></li><li><a href=#四生产者其他属性>四、生产者其他属性</a><ul><li><a href=#1-acks>1. acks</a></li><li><a href=#2-buffermemory>2. buffer.memory</a></li><li><a href=#3-compressiontype>3. compression.type</a></li><li><a href=#4-retries>4. retries</a></li><li><a href=#5-batchsize>5. batch.size</a></li><li><a href=#6-lingerms>6. linger.ms</a></li><li><a href=#7-clentid>7. clent.id</a></li><li><a href=#8-maxinflightrequestsperconnection>8. max.in.flight.requests.per.connection</a></li><li><a href=#9-timeoutms-requesttimeoutms--metadatafetchtimeoutms>9. timeout.ms, request.timeout.ms & metadata.fetch.timeout.ms</a></li><li><a href=#10-maxblockms>10. max.block.ms</a></li><li><a href=#11-maxrequestsize>11. max.request.size</a></li><li><a href=#12-receivebufferbytes--sendbufferbyte>12. receive.buffer.bytes & send.buffer.byte</a></li></ul></li></ul><ul><li><a href=#一消费者和消费者群组>一、消费者和消费者群组</a></li><li><a href=#二分区再均衡>二、分区再均衡</a></li><li><a href=#三创建-kafka-消费者>三、创建 Kafka 消费者</a></li><li><a href=#三-自动提交偏移量>三、 自动提交偏移量</a><ul><li><a href=#31-偏移量的重要性>3.1 偏移量的重要性</a></li><li><a href=#32-自动提交偏移量>3.2 自动提交偏移量</a></li></ul></li><li><a href=#四手动提交偏移量>四、手动提交偏移量</a><ul><li><a href=#41-同步提交>4.1 同步提交</a></li><li><a href=#42-异步提交>4.2 异步提交</a></li><li><a href=#43-同步加异步提交>4.3 同步加异步提交</a></li><li><a href=#44-提交特定偏移量>4.4 提交特定偏移量</a></li></ul></li><li><a href=#五监听分区再均衡>五、监听分区再均衡</a></li><li><a href=#六-退出轮询>六 、退出轮询</a></li><li><a href=#七独立的消费者>七、独立的消费者</a></li><li><a href=#附录--kafka-消费者可选属性>附录 : Kafka 消费者可选属性</a><ul><li><a href=#1-fetchminbyte>1. fetch.min.byte</a></li><li><a href=#2-fetchmaxwaitms>2. fetch.max.wait.ms</a></li><li><a href=#3-maxpartitionfetchbytes>3. max.partition.fetch.bytes</a></li><li><a href=#4-sessiontimeoutms>4. session.timeout.ms</a></li><li><a href=#5-autooffsetreset>5. auto.offset.reset</a></li><li><a href=#6-enableautocommit>6. enable.auto.commit</a></li><li><a href=#7-clientid>7. client.id</a></li><li><a href=#8-maxpollrecords>8. max.poll.records</a></li><li><a href=#9-receivebufferbytes--sendbufferbyte>9. receive.buffer.bytes & send.buffer.byte</a></li></ul></li></ul><ul><li><a href=#一kafka-集群>一、Kafka 集群</a></li><li><a href=#二副本机制>二、副本机制</a><ul><li><a href=#21-分区和副本>2.1 分区和副本</a></li><li><a href=#22-isr-机制>2.2 ISR 机制</a></li><li><a href=#23-不完全的首领选举>2.3 不完全的首领选举</a></li><li><a href=#24-最少同步副本>2.4 最少同步副本</a></li><li><a href=#25-发送确认>2.5 发送确认</a></li></ul></li><li><a href=#三数据请求>三、数据请求</a><ul><li><a href=#31-元数据请求机制>3.1 元数据请求机制</a></li><li><a href=#32-数据可见性>3.2 数据可见性</a></li><li><a href=#33-零拷贝>3.3 零拷贝</a></li></ul></li><li><a href=#四物理存储>四、物理存储</a><ul><li><a href=#41-分区分配>4.1 分区分配</a></li><li><a href=#42-分区数据保留规则>4.2 分区数据保留规则</a></li><li><a href=#43-文件格式>4.3 文件格式</a></li></ul></li></ul></nav><div class="subscribe-module col-24 mt-1"><img src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png alt=image title=王下邀月熊的微信公众号></div></div><main class="py-md-3 pl-md-3 docs-content col-xl-8" role=main><article class=article><h1>Kafka-CheatSheet</h1><div class=article-style><h1 id=kafka-cheatsheet>Kafka CheatSheet</h1><h1 id=kafka-简介>Kafka 简介</h1><h2 id=一简介>一、简介</h2><p>ApacheKafka 是一个分布式的流处理平台。它具有以下特点：</p><ul><li>支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</li><li>支持数据实时处理；</li><li>能保证消息的可靠性投递；</li><li>支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；</li><li>高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</li></ul><h2 id=二基本概念>二、基本概念</h2><h3 id=21-messages-and-batches>2.1 Messages And Batches</h3><p>Kafka 的基本数据单元被称为 message(消息)，为减少网络开销，提高效率，多个消息会被放入同一批次 (Batch) 中后再写入。</p><h3 id=22-topics-and-partitions>2.2 Topics And Partitions</h3><p>Kafka 的消息通过 Topics(主题) 进行分类，一个主题可以被分为若干个 Partitions(分区)，一个分区就是一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能。</p><p>由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-topic.png></div><h3 id=23-producers-and-consumers>2.3 Producers And Consumers</h3><h4 id=1-生产者>1. 生产者</h4><p>生产者负责创建消息。一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过自定义分区器来实现。</p><h4 id=2-消费者>2. 消费者</h4><p>消费者是消费者群组的一部分，消费者负责消费消息。消费者可以订阅一个或者多个主题，并按照消息生成的顺序来读取它们。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-producer-consumer.png></div><p>一个分区只能被同一个消费者群组里面的一个消费者读取，但可以被不同消费者群组中所组成的多个消费者共同读取。多个消费者群组中消费者共同读取同一个主题时，彼此之间互不影响。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka消费者.png></div><h3 id=24-brokers-and-clusters>2.4 Brokers And Clusters</h3><p>一个独立的 Kafka 服务器被称为 Broker。Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。</p><p>Broker 是集群 (Cluster) 的组成部分。每一个集群都会选举出一个 Broker 作为集群控制器 (Controller)，集群控制器负责管理工作，包括将分区分配给 Broker 和监控 Broker。</p><p>在集群中，一个分区 (Partition) 从属一个 Broker，该 Broker 被称为分区的首领 (Leader)。一个分区可以分配给多个 Brokers，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个 Broker 失效，其他 Broker 可以接管领导权。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-cluster.png></div><h1 id=kafka-生产者详解>Kafka 生产者详解</h1><h2 id=一生产者发送消息的过程>一、生产者发送消息的过程</h2><p>首先介绍一下 Kafka 生产者发送消息的过程：</p><ul><li>Kafka 会将发送消息包装为 ProducerRecord 对象， ProducerRecord 对象包含了目标主题和要发送的内容，同时还可以指定键和分区。在发送 ProducerRecord 对象前，生产者会先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。</li><li>接下来，数据被传给分区器。如果之前已经在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情。如果没有指定分区 ，那么分区器会根据 ProducerRecord 对象的键来选择一个分区，紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。有一个独立的线程负责把这些记录批次发送到相应的 broker 上。</li><li>服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka，就返回一个 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，如果达到指定的重试次数后还没有成功，则直接抛出异常，不再重试。</li></ul><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-send-messgaes.png></div><h2 id=二创建生产者>二、创建生产者</h2><h3 id=21-项目依赖>2.1 项目依赖</h3><p>本项目采用 Maven 构建，想要调用 Kafka 生产者 API，需要导入 <code>kafka-clients</code> 依赖，如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;groupId&gt;</span>org.apache.kafka<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;artifactId&gt;</span>kafka-clients<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;version&gt;</span>2.2.0<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/dependency&gt;</span>
</span></span></code></pre></div><h3 id=22-创建生产者>2.2 创建生产者</h3><p>创建 Kafka 生产者时，以下三个属性是必须指定的：</p><ul><li><strong>bootstrap.servers</strong> ：指定 broker 的地址清单，清单里不需要包含所有的 broker 地址，生产者会从给定的 broker 里查找 broker 的信息。不过建议至少要提供两个 broker 的信息作为容错；</li><li><strong>key.serializer</strong> ：指定键的序列化器；</li><li><strong>value.serializer</strong> ：指定值的序列化器。</li></ul><p>创建的示例代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=n>public</span> <span class=k>class</span> <span class=nc>SimpleProducer</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>public</span> <span class=n>static</span> <span class=n>void</span> <span class=n>main</span><span class=o>(</span><span class=nc>String</span><span class=o>[]</span> <span class=n>args</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nc>String</span> <span class=n>topicName</span> <span class=k>=</span> <span class=s>&#34;Hello-Kafka&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nc>Properties</span> <span class=n>props</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>Properties</span><span class=o>();</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;bootstrap.servers&#34;</span><span class=o>,</span> <span class=s>&#34;hadoop001:9092&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;key.serializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;value.serializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*创建生产者*/</span>
</span></span><span class=line><span class=cl>        <span class=nc>Producer</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>producer</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>KafkaProducer</span><span class=o>&lt;&gt;(</span><span class=n>props</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=n>int</span> <span class=n>i</span> <span class=k>=</span> <span class=mi>0</span><span class=o>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=o>;</span> <span class=n>i</span><span class=o>++)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=nc>ProducerRecord</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>ProducerRecord</span><span class=o>&lt;&gt;(</span><span class=n>topicName</span><span class=o>,</span> <span class=s>&#34;hello&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                                                                         <span class=s>&#34;world&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=cm>/* 发送消息*/</span>
</span></span><span class=line><span class=cl>            <span class=n>producer</span><span class=o>.</span><span class=n>send</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*关闭生产者*/</span>
</span></span><span class=line><span class=cl>        <span class=n>producer</span><span class=o>.</span><span class=n>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><blockquote><p>本篇文章的所有示例代码可以从 Github 上进行下载：<a href=https://github.com/heibaiying/BigData-Notes/tree/master/code/Kafka/kafka-basis target=_blank rel=noopener>kafka-basis</a></p></blockquote><h3 id=23-测试>2.3 测试</h3><h4 id=1-启动-kakfa>1. 启动 Kakfa</h4><p>Kafka 的运行依赖于 zookeeper，需要预先启动，可以启动 Kafka 内置的 zookeeper，也可以启动自己安装的：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># zookeeper启动命令</span>
</span></span><span class=line><span class=cl>bin/zkServer.sh start
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 内置zookeeper启动命令</span>
</span></span><span class=line><span class=cl>bin/zookeeper-server-start.sh config/zookeeper.properties
</span></span></code></pre></div><p>启动单节点 kafka 用于测试：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># bin/kafka-server-start.sh config/server.properties</span>
</span></span></code></pre></div><h4 id=2-创建-topic>2. 创建 topic</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 创建用于测试主题</span>
</span></span><span class=line><span class=cl>bin/kafka-topics.sh --create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                    --bootstrap-server hadoop001:9092 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                     --replication-factor <span class=m>1</span> --partitions <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                     --topic Hello-Kafka
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看所有主题</span>
</span></span><span class=line><span class=cl> bin/kafka-topics.sh --list --bootstrap-server hadoop001:9092
</span></span></code></pre></div><h4 id=3-启动消费者>3. 启动消费者</h4><p>启动一个控制台消费者用于观察写入情况，启动命令如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># bin/kafka-console-consumer.sh --bootstrap-server hadoop001:9092 --topic Hello-Kafka --from-beginning</span>
</span></span></code></pre></div><h4 id=4-运行项目>4. 运行项目</h4><p>此时可以看到消费者控制台，输出如下，这里 <code>kafka-console-consumer</code> 只会打印出值信息，不会打印出键信息。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-simple-producer.png></div><h3 id=24-可能出现的问题>2.4 可能出现的问题</h3><p>在这里可能出现的一个问题是：生产者程序在启动后，一直处于等待状态。这通常出现在你使用默认配置启动 Kafka 的情况下，此时需要对 <code>server.properties</code> 文件中的 <code>listeners</code> 配置进行更改：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># hadoop001 为我启动kafka服务的主机名，你可以换成自己的主机名或者ip地址</span>
</span></span><span class=line><span class=cl><span class=nv>listeners</span><span class=o>=</span>PLAINTEXT://hadoop001:9092
</span></span></code></pre></div><h2 id=二发送消息>二、发送消息</h2><p>上面的示例程序调用了 <code>send</code> 方法发送消息后没有做任何操作，在这种情况下，我们没有办法知道消息发送的结果。想要知道消息发送的结果，可以使用同步发送或者异步发送来实现。</p><h3 id=21-同步发送>2.1 同步发送</h3><p>在调用 <code>send</code> 方法后可以接着调用 <code>get()</code> 方法，<code>send</code> 方法的返回值是一个 Future&lt;RecordMetadata>对象，RecordMetadata 里面包含了发送消息的主题、分区、偏移量等信息。改写后的代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>for</span> <span class=o>(</span><span class=n>int</span> <span class=n>i</span> <span class=k>=</span> <span class=mi>0</span><span class=o>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=o>;</span> <span class=n>i</span><span class=o>++)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=nc>ProducerRecord</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>ProducerRecord</span><span class=o>&lt;&gt;(</span><span class=n>topicName</span><span class=o>,</span> <span class=s>&#34;k&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>,</span> <span class=s>&#34;world&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*同步发送消息*/</span>
</span></span><span class=line><span class=cl>        <span class=nc>RecordMetadata</span> <span class=n>metadata</span> <span class=k>=</span> <span class=n>producer</span><span class=o>.</span><span class=n>send</span><span class=o>(</span><span class=n>record</span><span class=o>).</span><span class=n>get</span><span class=o>();</span>
</span></span><span class=line><span class=cl>        <span class=nc>System</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>printf</span><span class=o>(</span><span class=s>&#34;topic=%s, partition=%d, offset=%s \n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                <span class=n>metadata</span><span class=o>.</span><span class=n>topic</span><span class=o>(),</span> <span class=n>metadata</span><span class=o>.</span><span class=n>partition</span><span class=o>(),</span> <span class=n>metadata</span><span class=o>.</span><span class=n>offset</span><span class=o>());</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=nc>InterruptedException</span> <span class=o>|</span> <span class=nc>ExecutionException</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>e</span><span class=o>.</span><span class=n>printStackTrace</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>此时得到的输出如下：偏移量和调用次数有关，所有记录都分配到了 0 分区，这是因为在创建 <code>Hello-Kafka</code> 主题时候，使用 <code>--partitions</code> 指定其分区数为 1，即只有一个分区。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>40</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>41</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>42</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>43</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>44</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>45</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>46</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>47</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>48</span>
</span></span><span class=line><span class=cl><span class=nv>topic</span><span class=o>=</span>Hello-Kafka, <span class=nv>partition</span><span class=o>=</span>0, <span class=nv>offset</span><span class=o>=</span><span class=m>49</span>
</span></span></code></pre></div><h3 id=22-异步发送>2.2 异步发送</h3><p>通常我们并不关心发送成功的情况，更多关注的是失败的情况，因此 Kafka 提供了异步发送和回调函数。 代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>for</span> <span class=o>(</span><span class=n>int</span> <span class=n>i</span> <span class=k>=</span> <span class=mi>0</span><span class=o>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=o>;</span> <span class=n>i</span><span class=o>++)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=nc>ProducerRecord</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>ProducerRecord</span><span class=o>&lt;&gt;(</span><span class=n>topicName</span><span class=o>,</span> <span class=s>&#34;k&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>,</span> <span class=s>&#34;world&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=cm>/*异步发送消息，并监听回调*/</span>
</span></span><span class=line><span class=cl>    <span class=n>producer</span><span class=o>.</span><span class=n>send</span><span class=o>(</span><span class=n>record</span><span class=o>,</span> <span class=k>new</span> <span class=nc>Callback</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>        <span class=n>public</span> <span class=n>void</span> <span class=n>onCompletion</span><span class=o>(</span><span class=nc>RecordMetadata</span> <span class=n>metadata</span><span class=o>,</span> <span class=nc>Exception</span> <span class=n>exception</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=o>(</span><span class=n>exception</span> <span class=o>!=</span> <span class=kc>null</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=nc>System</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>println</span><span class=o>(</span><span class=s>&#34;进行异常处理&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span> <span class=k>else</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=nc>System</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>printf</span><span class=o>(</span><span class=s>&#34;topic=%s, partition=%d, offset=%s \n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>metadata</span><span class=o>.</span><span class=n>topic</span><span class=o>(),</span> <span class=n>metadata</span><span class=o>.</span><span class=n>partition</span><span class=o>(),</span> <span class=n>metadata</span><span class=o>.</span><span class=n>offset</span><span class=o>());</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>});</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h2 id=三自定义分区器>三、自定义分区器</h2><p>Kafka 有着默认的分区机制：</p><ul><li>如果键值为 null， 则使用轮询 (Round Robin) 算法将消息均衡地分布到各个分区上；</li><li>如果键值不为 null，那么 Kafka 会使用内置的散列算法对键进行散列，然后分布到各个分区上。</li></ul><p>某些情况下，你可能有着自己的分区需求，这时候可以采用自定义分区器实现。这里给出一个自定义分区器的示例：</p><h3 id=31-自定义分区器>3.1 自定义分区器</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm> * 自定义分区器
</span></span></span><span class=line><span class=cl><span class=cm> */</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>CustomPartitioner</span> <span class=kd>implements</span> <span class=n>Partitioner</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>private</span> <span class=kt>int</span> <span class=n>passLine</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>configure</span><span class=o>(</span><span class=n>Map</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=o>?&gt;</span> <span class=n>configs</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*从生产者配置中获取分数线*/</span>
</span></span><span class=line><span class=cl>        <span class=n>passLine</span> <span class=o>=</span> <span class=o>(</span><span class=n>Integer</span><span class=o>)</span> <span class=n>configs</span><span class=o>.</span><span class=na>get</span><span class=o>(</span><span class=s>&#34;pass.line&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>int</span> <span class=nf>partition</span><span class=o>(</span><span class=n>String</span> <span class=n>topic</span><span class=o>,</span> <span class=n>Object</span> <span class=n>key</span><span class=o>,</span> <span class=kt>byte</span><span class=o>[]</span> <span class=n>keyBytes</span><span class=o>,</span> <span class=n>Object</span> <span class=n>value</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                         <span class=kt>byte</span><span class=o>[]</span> <span class=n>valueBytes</span><span class=o>,</span> <span class=n>Cluster</span> <span class=n>cluster</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*key 值为分数，当分数大于分数线时候，分配到 1 分区，否则分配到 0 分区*/</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>(</span><span class=n>Integer</span><span class=o>)</span> <span class=n>key</span> <span class=o>&gt;=</span> <span class=n>passLine</span> <span class=o>?</span> <span class=mi>1</span> <span class=o>:</span> <span class=mi>0</span><span class=o>;</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>close</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=s>&#34;分区器关闭&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>需要在创建生产者时指定分区器，和分区器所需要的配置参数：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>ProducerWithPartitioner</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=o>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>String</span> <span class=n>topicName</span> <span class=o>=</span> <span class=s>&#34;Kafka-Partitioner-Test&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>Properties</span> <span class=n>props</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Properties</span><span class=o>();</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&#34;bootstrap.servers&#34;</span><span class=o>,</span> <span class=s>&#34;hadoop001:9092&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&#34;key.serializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.IntegerSerializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&#34;value.serializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=cm>/*传递自定义分区器*/</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&#34;partitioner.class&#34;</span><span class=o>,</span> <span class=s>&#34;com.heibaiying.producers.partitioners.CustomPartitioner&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*传递分区器所需的参数*/</span>
</span></span><span class=line><span class=cl>        <span class=n>props</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=s>&#34;pass.line&#34;</span><span class=o>,</span> <span class=mi>6</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>Producer</span><span class=o>&lt;</span><span class=n>Integer</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>producer</span> <span class=o>=</span> <span class=k>new</span> <span class=n>KafkaProducer</span><span class=o>&lt;&gt;(</span><span class=n>props</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=o>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=mi>10</span><span class=o>;</span> <span class=n>i</span><span class=o>++)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>String</span> <span class=n>score</span> <span class=o>=</span> <span class=s>&#34;score:&#34;</span> <span class=o>+</span> <span class=n>i</span><span class=o>;</span>
</span></span><span class=line><span class=cl>            <span class=n>ProducerRecord</span><span class=o>&lt;</span><span class=n>Integer</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>=</span> <span class=k>new</span> <span class=n>ProducerRecord</span><span class=o>&lt;&gt;(</span><span class=n>topicName</span><span class=o>,</span> <span class=n>i</span><span class=o>,</span> <span class=n>score</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=cm>/*异步发送消息*/</span>
</span></span><span class=line><span class=cl>            <span class=n>producer</span><span class=o>.</span><span class=na>send</span><span class=o>(</span><span class=n>record</span><span class=o>,</span> <span class=o>(</span><span class=n>metadata</span><span class=o>,</span> <span class=n>exception</span><span class=o>)</span> <span class=o>-&gt;</span>
</span></span><span class=line><span class=cl>                    <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&#34;%s, partition=%d, \n&#34;</span><span class=o>,</span> <span class=n>score</span><span class=o>,</span> <span class=n>metadata</span><span class=o>.</span><span class=na>partition</span><span class=o>()));</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>producer</span><span class=o>.</span><span class=na>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h3 id=32-测试>3.2 测试</h3><p>需要创建一个至少有两个分区的主题：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl> bin/kafka-topics.sh --create <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                    --bootstrap-server hadoop001:9092 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                     --replication-factor <span class=m>1</span> --partitions <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>                     --topic Kafka-Partitioner-Test
</span></span></code></pre></div><p>此时输入如下，可以看到分数大于等于 6 分的都被分到 1 分区，而小于 6 分的都被分到了 0 分区。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>score:6, <span class=nv>partition</span><span class=o>=</span>1,
</span></span><span class=line><span class=cl>score:7, <span class=nv>partition</span><span class=o>=</span>1,
</span></span><span class=line><span class=cl>score:8, <span class=nv>partition</span><span class=o>=</span>1,
</span></span><span class=line><span class=cl>score:9, <span class=nv>partition</span><span class=o>=</span>1,
</span></span><span class=line><span class=cl>score:10, <span class=nv>partition</span><span class=o>=</span>1,
</span></span><span class=line><span class=cl>score:0, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>score:1, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>score:2, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>score:3, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>score:4, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>score:5, <span class=nv>partition</span><span class=o>=</span>0,
</span></span><span class=line><span class=cl>分区器关闭
</span></span></code></pre></div><h2 id=四生产者其他属性>四、生产者其他属性</h2><p>上面生产者的创建都仅指定了服务地址，键序列化器、值序列化器，实际上 Kafka 的生产者还有很多可配置属性，如下：</p><h3 id=1-acks>1. acks</h3><p>acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的：</p><ul><li><strong>acks=0</strong> ： 消息发送出去就认为已经成功了，不会等待任何来自服务器的响应；</li><li><strong>acks=1</strong> ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应；</li><li><strong>acks=all</strong> ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。</li></ul><h3 id=2-buffermemory>2. buffer.memory</h3><p>设置生产者内存缓冲区的大小。</p><h3 id=3-compressiontype>3. compression.type</h3><p>默认情况下，发送的消息不会被压缩。如果想要进行压缩，可以配置此参数，可选值有 snappy，gzip，lz4。</p><h3 id=4-retries>4. retries</h3><p>发生错误后，消息重发的次数。如果达到设定值，生产者就会放弃重试并返回错误。</p><h3 id=5-batchsize>5. batch.size</h3><p>当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。</p><h3 id=6-lingerms>6. linger.ms</h3><p>该参数制定了生产者在发送批次之前等待更多消息加入批次的时间。</p><h3 id=7-clentid>7. clent.id</h3><p>客户端 id,服务器用来识别消息的来源。</p><h3 id=8-maxinflightrequestsperconnection>8. max.in.flight.requests.per.connection</h3><p>指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量，把它设置为 1 可以保证消息是按照发送的顺序写入服务器，即使发生了重试。</p><h3 id=9-timeoutms-requesttimeoutms--metadatafetchtimeoutms>9. timeout.ms, request.timeout.ms & metadata.fetch.timeout.ms</h3><ul><li>timeout.ms 指定了 borker 等待同步副本返回消息的确认时间；</li><li>request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间；</li><li>metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如分区首领是谁）时等待服务器返回响应的时间。</li></ul><h3 id=10-maxblockms>10. max.block.ms</h3><p>指定了在调用 <code>send()</code> 方法或使用 <code>partitionsFor()</code> 方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。</p><h3 id=11-maxrequestsize>11. max.request.size</h3><p>该参数用于控制生产者发送的请求大小。它可以指发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。例如，假设这个值为 1000K ，那么可以发送的单个最大消息为 1000K ，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1K。</p><h3 id=12-receivebufferbytes--sendbufferbyte>12. receive.buffer.bytes & send.buffer.byte</h3><p>这两个参数分别指定 TCP socket 接收和发送数据包缓冲区的大小，-1 代表使用操作系统的默认值。</p><h1 id=kafka-消费者详解>Kafka 消费者详解</h1><h2 id=一消费者和消费者群组>一、消费者和消费者群组</h2><p>在 Kafka 中，消费者通常是消费者群组的一部分，多个消费者群组共同读取同一个主题时，彼此之间互不影响。Kafka 之所以要引入消费者群组这个概念是因为 Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS ，或者进行耗时的计算，在这些情况下，单个消费者无法跟上数据生成的速度。此时可以增加更多的消费者，让它们分担负载，分别处理部分分区的消息，这就是 Kafka 实现横向伸缩的主要手段。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-consumer01.png></div><p>需要注意的是：同一个分区只能被同一个消费者群组里面的一个消费者读取，不可能存在同一个分区被同一个消费者群里多个消费者共同读取的情况，如图：</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-consumer02.png></div><p>可以看到即便消费者 Consumer5 空闲了，但是也不会去读取任何一个分区的数据，这同时也提醒我们在使用时应该合理设置消费者的数量，以免造成闲置和额外开销。</p><h2 id=二分区再均衡>二、分区再均衡</h2><p>因为群组里的消费者共同读取主题的分区，所以当一个消费者被关闭或发生崩溃时，它就离开了群组，原本由它读取的分区将由群组里的其他消费者来读取。同时在主题发生变化时 ， 比如添加了新的分区，也会发生分区与消费者的重新分配，分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。正是因为再均衡，所以消费费者群组才能保证高可用性和伸缩性。</p><p>消费者通过向群组协调器所在的 broker 发送心跳来维持它们和群组的从属关系以及它们对分区的所有权。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发再均衡。</p><h2 id=三创建-kafka-消费者>三、创建 Kafka 消费者</h2><p>在创建消费者的时候以下以下三个选项是必选的：</p><ul><li><strong>bootstrap.servers</strong> ：指定 broker 的地址清单，清单里不需要包含所有的 broker 地址，生产者会从给定的 broker 里查找 broker 的信息。不过建议至少要提供两个 broker 的信息作为容错；</li><li><strong>key.deserializer</strong> ：指定键的反序列化器；</li><li><strong>value.deserializer</strong> ：指定值的反序列化器。</li></ul><p>除此之外你还需要指明你需要想订阅的主题，可以使用如下两个 API :</p><ul><li><strong>consumer.subscribe(Collection&lt;String> topics)</strong> ：指明需要订阅的主题的集合；</li><li><strong>consumer.subscribe(Pattern pattern)</strong> ：使用正则来匹配需要订阅的集合。</li></ul><p>最后只需要通过轮询 API(<code>poll</code>) 向服务器定时请求数据。一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，这使得开发者只需要关注从分区返回的数据，然后进行业务处理。 示例如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=nc>String</span> <span class=n>topic</span> <span class=k>=</span> <span class=s>&#34;Hello-Kafka&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl><span class=nc>String</span> <span class=n>group</span> <span class=k>=</span> <span class=s>&#34;group1&#34;</span><span class=o>;</span>
</span></span><span class=line><span class=cl><span class=nc>Properties</span> <span class=n>props</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>Properties</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;bootstrap.servers&#34;</span><span class=o>,</span> <span class=s>&#34;hadoop001:9092&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=cm>/*指定分组 ID*/</span>
</span></span><span class=line><span class=cl><span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;group.id&#34;</span><span class=o>,</span> <span class=n>group</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;key.deserializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=n>props</span><span class=o>.</span><span class=n>put</span><span class=o>(</span><span class=s>&#34;value.deserializer&#34;</span><span class=o>,</span> <span class=s>&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=nc>KafkaConsumer</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>consumer</span> <span class=k>=</span> <span class=k>new</span> <span class=nc>KafkaConsumer</span><span class=o>&lt;&gt;(</span><span class=n>props</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/*订阅主题 (s)*/</span>
</span></span><span class=line><span class=cl><span class=n>consumer</span><span class=o>.</span><span class=n>subscribe</span><span class=o>(</span><span class=nc>Collections</span><span class=o>.</span><span class=n>singletonList</span><span class=o>(</span><span class=n>topic</span><span class=o>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*轮询获取数据*/</span>
</span></span><span class=line><span class=cl>        <span class=nc>ConsumerRecords</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=k>=</span> <span class=n>consumer</span><span class=o>.</span><span class=n>poll</span><span class=o>(</span><span class=nc>Duration</span><span class=o>.</span><span class=n>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=nc>ChronoUnit</span><span class=o>.</span><span class=nc>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=nc>ConsumerRecord</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=k>:</span> <span class=kt>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=nc>System</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>printf</span><span class=o>(</span><span class=s>&#34;topic = %s,partition = %d, key = %s, value = %s, offset = %d,\n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>           <span class=n>record</span><span class=o>.</span><span class=n>topic</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=n>partition</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=n>key</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=n>value</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=n>offset</span><span class=o>());</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=n>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><blockquote><p>本篇文章的所有示例代码可以从 Github 上进行下载：<a href=https://github.com/heibaiying/BigData-Notes/tree/master/code/Kafka/kafka-basis target=_blank rel=noopener>kafka-basis</a></p></blockquote><h2 id=三-自动提交偏移量>三、 自动提交偏移量</h2><h3 id=31-偏移量的重要性>3.1 偏移量的重要性</h3><p>Kafka 的每一条消息都有一个偏移量属性，记录了其在分区中的位置，偏移量是一个单调递增的整数。消费者通过往一个叫作 <code>＿consumer_offset</code> 的特殊主题发送消息，消息里包含每个分区的偏移量。 如果消费者一直处于运行状态，那么偏移量就没有
什么用处。不过，如果有消费者退出或者新分区加入，此时就会触发再均衡。完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。 因为这个原因，所以如果不能正确提交偏移量，就可能会导致数据丢失或者重复出现消费，比如下面情况：</p><ul><li>如果提交的偏移量小于客户端处理的最后一个消息的偏移量 ，那么处于两个偏移量之间的消息就会被重复消费；</li><li>如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。</li></ul><h3 id=32-自动提交偏移量>3.2 自动提交偏移量</h3><p>Kafka 支持自动提交和手动提交偏移量两种方式。这里先介绍比较简单的自动提交：</p><p>只需要将消费者的 <code>enable.auto.commit</code> 属性配置为 <code>true</code> 即可完成自动提交的配置。 此时每隔固定的时间，消费者就会把 <code>poll()</code> 方法接收到的最大偏移量进行提交，提交间隔由 <code>auto.commit.interval.ms</code> 属性进行配置，默认值是 5s。</p><p>使用自动提交是存在隐患的，假设我们使用默认的 5s 提交时间间隔，在最近一次提交之后的 3s 发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了 3s ，所以在这 3s 内到达的消息会被重复处理。可以通过修改提交时间间隔来更频繁地提交偏移量，减小可能出现重复消息的时间窗，不过这种情况是无法完全避免的。基于这个原因，Kafka 也提供了手动提交偏移量的 API，使得用户可以更为灵活的提交偏移量。</p><h2 id=四手动提交偏移量>四、手动提交偏移量</h2><p>用户可以通过将 <code>enable.auto.commit</code> 设为 <code>false</code>，然后手动提交偏移量。基于用户需求手动提交偏移量可以分为两大类：</p><ul><li>手动提交当前偏移量：即手动提交当前轮询的最大偏移量；</li><li>手动提交固定偏移量：即按照业务需求，提交某一个固定的偏移量。</li></ul><p>而按照 Kafka API，手动提交偏移量又可以分为同步提交和异步提交。</p><h3 id=41-同步提交>4.1 同步提交</h3><p>通过调用 <code>consumer.commitSync()</code> 来进行同步提交，不传递任何参数时提交的是当前轮询的最大偏移量。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=cm>/*同步提交*/</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>commitSync</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>如果某个提交失败，同步提交还会进行重试，这可以保证数据能够最大限度提交成功，但是同时也会降低程序的吞吐量。基于这个原因，Kafka 还提供了异步提交的 API。</p><h3 id=42-异步提交>4.2 异步提交</h3><p>异步提交可以提高程序的吞吐量，因为此时你可以尽管请求数据，而不用等待 Broker 的响应。代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=cm>/*异步提交并定义回调*/</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>commitAsync</span><span class=o>(</span><span class=k>new</span> <span class=n>OffsetCommitCallback</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>        <span class=kd>public</span> <span class=kt>void</span> <span class=nf>onComplete</span><span class=o>(</span><span class=n>Map</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>,</span> <span class=n>OffsetAndMetadata</span><span class=o>&gt;</span> <span class=n>offsets</span><span class=o>,</span> <span class=n>Exception</span> <span class=n>exception</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>          <span class=k>if</span> <span class=o>(</span><span class=n>exception</span> <span class=o>!=</span> <span class=kc>null</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>             <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=s>&#34;错误处理&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>             <span class=n>offsets</span><span class=o>.</span><span class=na>forEach</span><span class=o>((</span><span class=n>x</span><span class=o>,</span> <span class=n>y</span><span class=o>)</span> <span class=o>-&gt;</span> <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&#34;topic = %s,partition = %d, offset = %s \n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                                                            <span class=n>x</span><span class=o>.</span><span class=na>topic</span><span class=o>(),</span> <span class=n>x</span><span class=o>.</span><span class=na>partition</span><span class=o>(),</span> <span class=n>y</span><span class=o>.</span><span class=na>offset</span><span class=o>()));</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>});</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>异步提交存在的问题是，在提交失败的时候不会进行自动重试，实际上也不能进行自动重试。假设程序同时提交了 200 和 300 的偏移量，此时 200 的偏移量失败的，但是紧随其后的 300 的偏移量成功了，此时如果重试就会存在 200 覆盖 300 偏移量的可能。同步提交就不存在这个问题，因为在同步提交的情况下，300 的提交请求必须等待服务器返回 200 提交请求的成功反馈后才会发出。基于这个原因，某些情况下，需要同时组合同步和异步两种提交方式。</p><blockquote><p>注：虽然程序不能在失败时候进行自动重试，但是我们是可以手动进行重试的，你可以通过一个 Map&lt;TopicPartition, Integer> offsets 来维护你提交的每个分区的偏移量，然后当失败时候，你可以判断失败的偏移量是否小于你维护的同主题同分区的最后提交的偏移量，如果小于则代表你已经提交了更大的偏移量请求，此时不需要重试，否则就可以进行手动重试。</p></blockquote><h3 id=43-同步加异步提交>4.3 同步加异步提交</h3><p>下面这种情况，在正常的轮询中使用异步提交来保证吞吐量，但是因为在最后即将要关闭消费者了，所以此时需要用同步提交来保证最大限度的提交成功。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-scala data-lang=scala><span class=line><span class=cl><span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=nc>ConsumerRecords</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=k>=</span> <span class=n>consumer</span><span class=o>.</span><span class=n>poll</span><span class=o>(</span><span class=nc>Duration</span><span class=o>.</span><span class=n>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=nc>ChronoUnit</span><span class=o>.</span><span class=nc>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=nc>ConsumerRecord</span><span class=o>&lt;</span><span class=nc>String</span><span class=o>,</span> <span class=nc>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=k>:</span> <span class=kt>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=nc>System</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>println</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 异步提交
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>consumer</span><span class=o>.</span><span class=n>commitAsync</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=nc>Exception</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>e</span><span class=o>.</span><span class=n>printStackTrace</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 因为即将要关闭消费者，所以要用同步提交保证提交成功
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>consumer</span><span class=o>.</span><span class=n>commitSync</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>consumer</span><span class=o>.</span><span class=n>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h3 id=44-提交特定偏移量>4.4 提交特定偏移量</h3><p>在上面同步和异步提交的 API 中，实际上我们都没有对 commit 方法传递参数，此时默认提交的是当前轮询的最大偏移量，如果你需要提交特定的偏移量，可以调用它们的重载方法。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=cm>/*同步提交特定偏移量*/</span>
</span></span><span class=line><span class=cl><span class=n>commitSync</span><span class=o>(</span><span class=n>Map</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>,</span> <span class=n>OffsetAndMetadata</span><span class=o>&gt;</span> <span class=n>offsets</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=cm>/*异步提交特定偏移量*/</span>
</span></span><span class=line><span class=cl><span class=n>commitAsync</span><span class=o>(</span><span class=n>Map</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>,</span> <span class=n>OffsetAndMetadata</span><span class=o>&gt;</span> <span class=n>offsets</span><span class=o>,</span> <span class=n>OffsetCommitCallback</span> <span class=n>callback</span><span class=o>)</span>
</span></span></code></pre></div><p>需要注意的是，因为你可以订阅多个主题，所以 <code>offsets</code> 中必须要包含所有主题的每个分区的偏移量，示例代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=cm>/*记录每个主题的每个分区的偏移量*/</span>
</span></span><span class=line><span class=cl>            <span class=n>TopicPartition</span> <span class=n>topicPartition</span> <span class=o>=</span> <span class=k>new</span> <span class=n>TopicPartition</span><span class=o>(</span><span class=n>record</span><span class=o>.</span><span class=na>topic</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>partition</span><span class=o>());</span>
</span></span><span class=line><span class=cl>            <span class=n>OffsetAndMetadata</span> <span class=n>offsetAndMetadata</span> <span class=o>=</span> <span class=k>new</span> <span class=n>OffsetAndMetadata</span><span class=o>(</span><span class=n>record</span><span class=o>.</span><span class=na>offset</span><span class=o>()+</span><span class=mi>1</span><span class=o>,</span> <span class=s>&#34;no metaData&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=cm>/*TopicPartition 重写过 hashCode 和 equals 方法，所以能够保证同一主题和分区的实例不会被重复添加*/</span>
</span></span><span class=line><span class=cl>            <span class=n>offsets</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=n>topicPartition</span><span class=o>,</span> <span class=n>offsetAndMetadata</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=cm>/*提交特定偏移量*/</span>
</span></span><span class=line><span class=cl>        <span class=n>consumer</span><span class=o>.</span><span class=na>commitAsync</span><span class=o>(</span><span class=n>offsets</span><span class=o>,</span> <span class=kc>null</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h2 id=五监听分区再均衡>五、监听分区再均衡</h2><p>因为分区再均衡会导致分区与消费者的重新划分，有时候你可能希望在再均衡前执行一些操作：比如提交已经处理但是尚未提交的偏移量，关闭数据库连接等。此时可以在订阅主题时候，调用 <code>subscribe</code> 的重载方法传入自定义的分区再均衡监听器。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl> <span class=cm>/*订阅指定集合内的所有主题*/</span>
</span></span><span class=line><span class=cl><span class=n>subscribe</span><span class=o>(</span><span class=n>Collection</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span> <span class=n>topics</span><span class=o>,</span> <span class=n>ConsumerRebalanceListener</span> <span class=n>listener</span><span class=o>)</span>
</span></span><span class=line><span class=cl> <span class=cm>/*使用正则匹配需要订阅的主题*/</span>
</span></span><span class=line><span class=cl><span class=n>subscribe</span><span class=o>(</span><span class=n>Pattern</span> <span class=n>pattern</span><span class=o>,</span> <span class=n>ConsumerRebalanceListener</span> <span class=n>listener</span><span class=o>)</span>
</span></span></code></pre></div><p>代码示例如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>Map</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>,</span> <span class=n>OffsetAndMetadata</span><span class=o>&gt;</span> <span class=n>offsets</span> <span class=o>=</span> <span class=k>new</span> <span class=n>HashMap</span><span class=o>&lt;&gt;();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>consumer</span><span class=o>.</span><span class=na>subscribe</span><span class=o>(</span><span class=n>Collections</span><span class=o>.</span><span class=na>singletonList</span><span class=o>(</span><span class=n>topic</span><span class=o>),</span> <span class=k>new</span> <span class=n>ConsumerRebalanceListener</span><span class=o>()</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=cm>/*该方法会在消费者停止读取消息之后，再均衡开始之前就调用*/</span>
</span></span><span class=line><span class=cl>    <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>onPartitionsRevoked</span><span class=o>(</span><span class=n>Collection</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>&gt;</span> <span class=n>partitions</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=s>&#34;再均衡即将触发&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 提交已经处理的偏移量
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>consumer</span><span class=o>.</span><span class=na>commitSync</span><span class=o>(</span><span class=n>offsets</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=cm>/*该方法会在重新分配分区之后，消费者开始读取消息之前被调用*/</span>
</span></span><span class=line><span class=cl>    <span class=nd>@Override</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>onPartitionsAssigned</span><span class=o>(</span><span class=n>Collection</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>&gt;</span> <span class=n>partitions</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=n>record</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=n>TopicPartition</span> <span class=n>topicPartition</span> <span class=o>=</span> <span class=k>new</span> <span class=n>TopicPartition</span><span class=o>(</span><span class=n>record</span><span class=o>.</span><span class=na>topic</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>partition</span><span class=o>());</span>
</span></span><span class=line><span class=cl>            <span class=n>OffsetAndMetadata</span> <span class=n>offsetAndMetadata</span> <span class=o>=</span> <span class=k>new</span> <span class=n>OffsetAndMetadata</span><span class=o>(</span><span class=n>record</span><span class=o>.</span><span class=na>offset</span><span class=o>()</span> <span class=o>+</span> <span class=mi>1</span><span class=o>,</span> <span class=s>&#34;no metaData&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl>            <span class=cm>/*TopicPartition 重写过 hashCode 和 equals 方法，所以能够保证同一主题和分区的实例不会被重复添加*/</span>
</span></span><span class=line><span class=cl>            <span class=n>offsets</span><span class=o>.</span><span class=na>put</span><span class=o>(</span><span class=n>topicPartition</span><span class=o>,</span> <span class=n>offsetAndMetadata</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=n>consumer</span><span class=o>.</span><span class=na>commitAsync</span><span class=o>(</span><span class=n>offsets</span><span class=o>,</span> <span class=kc>null</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h2 id=六-退出轮询>六 、退出轮询</h2><p>Kafka 提供了 <code>consumer.wakeup()</code> 方法用于退出轮询，它通过抛出 <code>WakeupException</code> 异常来跳出循环。需要注意的是，在退出线程时最好显示的调用 <code>consumer.close()</code> , 此时消费者会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己要离开群组，接下来就会触发再均衡 ，而不需要等待会话超时。</p><p>下面的示例代码为监听控制台输出，当输入 <code>exit</code> 时结束轮询，关闭消费者并退出程序：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=cm>/*调用 wakeup 优雅的退出*/</span>
</span></span><span class=line><span class=cl><span class=kd>final</span> <span class=n>Thread</span> <span class=n>mainThread</span> <span class=o>=</span> <span class=n>Thread</span><span class=o>.</span><span class=na>currentThread</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=k>new</span> <span class=n>Thread</span><span class=o>(()</span> <span class=o>-&gt;</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>Scanner</span> <span class=n>sc</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Scanner</span><span class=o>(</span><span class=n>System</span><span class=o>.</span><span class=na>in</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=n>sc</span><span class=o>.</span><span class=na>hasNext</span><span class=o>())</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=o>(</span><span class=s>&#34;exit&#34;</span><span class=o>.</span><span class=na>equals</span><span class=o>(</span><span class=n>sc</span><span class=o>.</span><span class=na>next</span><span class=o>()))</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>consumer</span><span class=o>.</span><span class=na>wakeup</span><span class=o>();</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=cm>/*等待主线程完成提交偏移量、关闭消费者等操作*/</span>
</span></span><span class=line><span class=cl>                <span class=n>mainThread</span><span class=o>.</span><span class=na>join</span><span class=o>();</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span><span class=o>;</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=n>InterruptedException</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>                <span class=n>e</span><span class=o>.</span><span class=na>printStackTrace</span><span class=o>();</span>
</span></span><span class=line><span class=cl>            <span class=o>}</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}).</span><span class=na>start</span><span class=o>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>try</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>rd</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>            <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&#34;topic = %s,partition = %d, key = %s, value = %s, offset = %d,\n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>rd</span><span class=o>.</span><span class=na>topic</span><span class=o>(),</span> <span class=n>rd</span><span class=o>.</span><span class=na>partition</span><span class=o>(),</span> <span class=n>rd</span><span class=o>.</span><span class=na>key</span><span class=o>(),</span> <span class=n>rd</span><span class=o>.</span><span class=na>value</span><span class=o>(),</span> <span class=n>rd</span><span class=o>.</span><span class=na>offset</span><span class=o>());</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span> <span class=k>catch</span> <span class=o>(</span><span class=n>WakeupException</span> <span class=n>e</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>//对于 wakeup() 调用引起的 WakeupException 异常可以不必处理
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=o>}</span> <span class=k>finally</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>close</span><span class=o>();</span>
</span></span><span class=line><span class=cl>    <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>println</span><span class=o>(</span><span class=s>&#34;consumer 关闭&#34;</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h2 id=七独立的消费者>七、独立的消费者</h2><p>因为 Kafka 的设计目标是高吞吐和低延迟，所以在 Kafka 中，消费者通常都是从属于某个群组的，这是因为单个消费者的处理能力是有限的。但是某些时候你的需求可能很简单，比如可能只需要一个消费者从一个主题的所有分区或者某个特定的分区读取数据，这个时候就不需要消费者群组和再均衡了， 只需要把主题或者分区分配给消费者，然后开始读取消息井提交偏移量即可。</p><p>在这种情况下，就不需要订阅主题， 取而代之的是消费者为自己分配分区。 一个消费者可以订阅主题（井加入消费者群组），或者为自己分配分区，但不能同时做这两件事情。 分配分区的示例代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>List</span><span class=o>&lt;</span><span class=n>TopicPartition</span><span class=o>&gt;</span> <span class=n>partitions</span> <span class=o>=</span> <span class=k>new</span> <span class=n>ArrayList</span><span class=o>&lt;&gt;();</span>
</span></span><span class=line><span class=cl><span class=n>List</span><span class=o>&lt;</span><span class=n>PartitionInfo</span><span class=o>&gt;</span> <span class=n>partitionInfos</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>partitionsFor</span><span class=o>(</span><span class=n>topic</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/*可以指定读取哪些分区 如这里假设只读取主题的 0 分区*/</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=o>(</span><span class=n>PartitionInfo</span> <span class=n>partition</span> <span class=o>:</span> <span class=n>partitionInfos</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=o>(</span><span class=n>partition</span><span class=o>.</span><span class=na>partition</span><span class=o>()==</span><span class=mi>0</span><span class=o>){</span>
</span></span><span class=line><span class=cl>        <span class=n>partitions</span><span class=o>.</span><span class=na>add</span><span class=o>(</span><span class=k>new</span> <span class=n>TopicPartition</span><span class=o>(</span><span class=n>partition</span><span class=o>.</span><span class=na>topic</span><span class=o>(),</span> <span class=n>partition</span><span class=o>.</span><span class=na>partition</span><span class=o>()));</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 为消费者指定分区
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>consumer</span><span class=o>.</span><span class=na>assign</span><span class=o>(</span><span class=n>partitions</span><span class=o>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=o>(</span><span class=kc>true</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=n>ConsumerRecords</span><span class=o>&lt;</span><span class=n>Integer</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>records</span> <span class=o>=</span> <span class=n>consumer</span><span class=o>.</span><span class=na>poll</span><span class=o>(</span><span class=n>Duration</span><span class=o>.</span><span class=na>of</span><span class=o>(</span><span class=mi>100</span><span class=o>,</span> <span class=n>ChronoUnit</span><span class=o>.</span><span class=na>MILLIS</span><span class=o>));</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=o>(</span><span class=n>ConsumerRecord</span><span class=o>&lt;</span><span class=n>Integer</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>record</span> <span class=o>:</span> <span class=n>records</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>System</span><span class=o>.</span><span class=na>out</span><span class=o>.</span><span class=na>printf</span><span class=o>(</span><span class=s>&#34;partition = %s, key = %d, value = %s\n&#34;</span><span class=o>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>record</span><span class=o>.</span><span class=na>partition</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>key</span><span class=o>(),</span> <span class=n>record</span><span class=o>.</span><span class=na>value</span><span class=o>());</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>    <span class=n>consumer</span><span class=o>.</span><span class=na>commitSync</span><span class=o>();</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><h2 id=附录--kafka-消费者可选属性>附录 : Kafka 消费者可选属性</h2><h3 id=1-fetchminbyte>1. fetch.min.byte</h3><p>消费者从服务器获取记录的最小字节数。如果可用的数据量小于设置值，broker 会等待有足够的可用数据时才会把它返回给消费者。</p><h3 id=2-fetchmaxwaitms>2. fetch.max.wait.ms</h3><p>broker 返回给消费者数据的等待时间，默认是 500ms。</p><h3 id=3-maxpartitionfetchbytes>3. max.partition.fetch.bytes</h3><p>该属性指定了服务器从每个分区返回给消费者的最大字节数，默认为 1MB。</p><h3 id=4-sessiontimeoutms>4. session.timeout.ms</h3><p>消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。</p><h3 id=5-autooffsetreset>5. auto.offset.reset</h3><p>该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：</p><ul><li>latest (默认值) ：在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的最新记录）;</li><li>earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录。</li></ul><h3 id=6-enableautocommit>6. enable.auto.commit</h3><p>是否自动提交偏移量，默认值是 true。为了避免出现重复消费和数据丢失，可以把它设置为 false。</p><h3 id=7-clientid>7. client.id</h3><p>客户端 id，服务器用来识别消息的来源。</p><h3 id=8-maxpollrecords>8. max.poll.records</h3><p>单次调用 <code>poll()</code> 方法能够返回的记录数量。</p><h3 id=9-receivebufferbytes--sendbufferbyte>9. receive.buffer.bytes & send.buffer.byte</h3><p>这两个参数分别指定 TCP socket 接收和发送数据包缓冲区的大小，-1 代表使用操作系统的默认值。</p><h1 id=深入理解-kafka-副本机制>深入理解 Kafka 副本机制</h1><h2 id=一kafka-集群>一、Kafka 集群</h2><p>Kafka 使用 Zookeeper 来维护集群成员 (brokers) 的信息。每个 broker 都有一个唯一标识 <code>broker.id</code>，用于标识自己在集群中的身份，可以在配置文件 <code>server.properties</code> 中进行配置，或者由程序自动生成。下面是 Kafka brokers 集群自动创建的过程：</p><ul><li>每一个 broker 启动的时候，它会在 Zookeeper 的 <code>/brokers/ids</code> 路径下创建一个 <code>临时节点</code>，并将自己的 <code>broker.id</code> 写入，从而将自身注册到集群；</li><li>当有多个 broker 时，所有 broker 会竞争性地在 Zookeeper 上创建 <code>/controller</code> 节点，由于 Zookeeper 上的节点不会重复，所以必然只会有一个 broker 创建成功，此时该 broker 称为 controller broker。它除了具备其他 broker 的功能外，<strong>还负责管理主题分区及其副本的状态</strong>。</li><li>当 broker 出现宕机或者主动退出从而导致其持有的 Zookeeper 会话超时时，会触发注册在 Zookeeper 上的 watcher 事件，此时 Kafka 会进行相应的容错处理；如果宕机的是 controller broker 时，还会触发新的 controller 选举。</li></ul><h2 id=二副本机制>二、副本机制</h2><p>为了保证高可用，kafka 的分区是多副本的，如果一个副本丢失了，那么还可以从其他副本中获取分区数据。但是这要求对应副本的数据必须是完整的，这是 Kafka 数据一致性的基础，所以才需要使用 <code>controller broker</code> 来进行专门的管理。下面将详解介绍 Kafka 的副本机制。</p><h3 id=21-分区和副本>2.1 分区和副本</h3><p>Kafka 的主题被分为多个分区 ，分区是 Kafka 最基本的存储单位。每个分区可以有多个副本 (可以在创建主题时使用 <code>replication-factor</code> 参数进行指定)。其中一个副本是首领副本 (Leader replica)，所有的事件都直接发送给首领副本；其他副本是跟随者副本 (Follower replica)，需要通过复制来保持与首领副本数据一致，当首领副本不可用时，其中一个跟随者副本将成为新首领。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-cluster.png></div><h3 id=22-isr-机制>2.2 ISR 机制</h3><p>每个分区都有一个 ISR(in-sync Replica) 列表，用于维护所有同步的、可用的副本。首领副本必然是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步副本：</p><ul><li>与 Zookeeper 之间有一个活跃的会话，即必须定时向 Zookeeper 发送心跳；</li><li>在规定的时间内从首领副本那里低延迟地获取过消息。</li></ul><p>如果副本不满足上面条件的话，就会被从 ISR 列表中移除，直到满足条件才会被再次加入。</p><p>这里给出一个主题创建的示例：使用 <code>--replication-factor</code> 指定副本系数为 3，创建成功后使用 <code>--describe</code> 命令可以看到分区 0 的有 0,1,2 三个副本，且三个副本都在 ISR 列表中，其中 1 为首领副本。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-分区副本.png></div><h3 id=23-不完全的首领选举>2.3 不完全的首领选举</h3><p>对于副本机制，在 broker 级别有一个可选的配置参数 <code>unclean.leader.election.enable</code>，默认值为 fasle，代表禁止不完全的首领选举。这是针对当首领副本挂掉且 ISR 中没有其他可用副本时，是否允许某个不完全同步的副本成为首领副本，这可能会导致数据丢失或者数据不一致，在某些对数据一致性要求较高的场景 (如金融领域)，这可能无法容忍的，所以其默认值为 false，如果你能够允许部分数据不一致的话，可以配置为 true。</p><h3 id=24-最少同步副本>2.4 最少同步副本</h3><p>ISR 机制的另外一个相关参数是 <code>min.insync.replicas</code> , 可以在 broker 或者主题级别进行配置，代表 ISR 列表中至少要有几个可用副本。这里假设设置为 2，那么当可用副本数量小于该值时，就认为整个分区处于不可用状态。此时客户端再向分区写入数据时候就会抛出异常 <code>org.apache.kafka.common.errors.NotEnoughReplicasExceptoin: Messages are rejected since there are fewer in-sync replicas than required。</code></p><h3 id=25-发送确认>2.5 发送确认</h3><p>Kafka 在生产者上有一个可选的参数 ack，该参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入成功：</p><ul><li><strong>acks=0</strong> ：消息发送出去就认为已经成功了，不会等待任何来自服务器的响应；</li><li><strong>acks=1</strong> ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应；</li><li><strong>acks=all</strong> ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。</li></ul><h2 id=三数据请求>三、数据请求</h2><h3 id=31-元数据请求机制>3.1 元数据请求机制</h3><p>在所有副本中，只有领导副本才能进行消息的读写处理。由于不同分区的领导副本可能在不同的 broker 上，如果某个 broker 收到了一个分区请求，但是该分区的领导副本并不在该 broker 上，那么它就会向客户端返回一个 <code>Not a Leader for Partition</code> 的错误响应。 为了解决这个问题，Kafka 提供了元数据请求机制。</p><p>首先集群中的每个 broker 都会缓存所有主题的分区副本信息，客户端会定期发送发送元数据请求，然后将获取的元数据进行缓存。定时刷新元数据的时间间隔可以通过为客户端配置 <code>metadata.max.age.ms</code> 来进行指定。有了元数据信息后，客户端就知道了领导副本所在的 broker，之后直接将读写请求发送给对应的 broker 即可。</p><p>如果在定时请求的时间间隔内发生的分区副本的选举，则意味着原来缓存的信息可能已经过时了，此时还有可能会收到 <code>Not a Leader for Partition</code> 的错误响应，这种情况下客户端会再次求发出元数据请求，然后刷新本地缓存，之后再去正确的 broker 上执行对应的操作，过程如下图：</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-元数据请求.png></div><h3 id=32-数据可见性>3.2 数据可见性</h3><p>需要注意的是，并不是所有保存在分区首领上的数据都可以被客户端读取到，为了保证数据一致性，只有被所有同步副本 (ISR 中所有副本) 都保存了的数据才能被客户端读取到。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-数据可见性.png></div><h3 id=33-零拷贝>3.3 零拷贝</h3><p>Kafka 所有数据的写入和读取都是通过零拷贝来实现的。传统拷贝与零拷贝的区别如下：</p><h4 id=传统模式下的四次拷贝与四次上下文切换>传统模式下的四次拷贝与四次上下文切换</h4><p>以将磁盘文件通过网络发送为例。传统模式下，一般使用如下伪代码所示的方法先将文件数据读入内存，然后通过 Socket 将内存中的数据发送出去。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>buffer</span> <span class=o>=</span> <span class=n>File</span><span class=o>.</span><span class=na>read</span>
</span></span><span class=line><span class=cl><span class=n>Socket</span><span class=o>.</span><span class=na>send</span><span class=o>(</span><span class=n>buffer</span><span class=o>)</span>
</span></span></code></pre></div><p>这一过程实际上发生了四次数据拷贝。首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝），然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝），接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝），最后通过 DMA 拷贝将数据拷贝到 NIC Buffer。同时，还伴随着四次上下文切换，如下图所示：</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-BIO.png></div><h4 id=sendfile-和-transferto-实现零拷贝>sendfile 和 transferTo 实现零拷贝</h4><p>Linux 2.4+ 内核通过 <code>sendfile</code> 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件到网络发送由一个 <code>sendfile</code> 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。零拷贝过程如下图所示：</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-零拷贝.png></div><p>从具体实现来看，Kafka 的数据传输通过 TransportLayer 来完成，其子类 <code>PlaintextTransportLayer</code> 的 <code>transferFrom</code> 方法通过调用 Java NIO 中 FileChannel 的 <code>transferTo</code> 方法实现零拷贝，如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Override</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kt>long</span> <span class=nf>transferFrom</span><span class=o>(</span><span class=n>FileChannel</span> <span class=n>fileChannel</span><span class=o>,</span> <span class=kt>long</span> <span class=n>position</span><span class=o>,</span> <span class=kt>long</span> <span class=n>count</span><span class=o>)</span> <span class=kd>throws</span> <span class=n>IOException</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>fileChannel</span><span class=o>.</span><span class=na>transferTo</span><span class=o>(</span><span class=n>position</span><span class=o>,</span> <span class=n>count</span><span class=o>,</span> <span class=n>socketChannel</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p><strong>注：</strong> <code>transferTo</code> 和 <code>transferFrom</code> 并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供 <code>sendfile</code> 这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。</p><h2 id=四物理存储>四、物理存储</h2><h3 id=41-分区分配>4.1 分区分配</h3><p>在创建主题时，Kafka 会首先决定如何在 broker 间分配分区副本，它遵循以下原则：</p><ul><li>在所有 broker 上均匀地分配分区副本；</li><li>确保分区的每个副本分布在不同的 broker 上；</li><li>如果使用了 <code>broker.rack</code> 参数为 broker 指定了机架信息，那么会尽可能的把每个分区的副本分配到不同机架的 broker 上，以避免一个机架不可用而导致整个分区不可用。</li></ul><p>基于以上原因，如果你在一个单节点上创建一个 3 副本的主题，通常会抛出下面的异常：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-properties data-lang=properties><span class=line><span class=cl><span class=na>Error</span> <span class=s>while executing topic command : org.apache.kafka.common.errors.InvalidReplicationFactor</span>
</span></span><span class=line><span class=cl><span class=na>Exception</span><span class=o>:</span> <span class=s>Replication factor: 3 larger than available brokers: 1.</span>
</span></span></code></pre></div><h3 id=42-分区数据保留规则>4.2 分区数据保留规则</h3><p>保留数据是 Kafka 的一个基本特性， 但是 Kafka 不会一直保留数据，也不会等到所有消费者都读取了消息之后才删除消息。相反， Kafka 为每个主题配置了数据保留期限，规定数据被删除之前可以保留多长时间，或者清理数据之前可以保留的数据量大小。分别对应以下四个参数：</p><ul><li><code>log.retention.bytes</code> ：删除数据前允许的最大数据量；默认值-1，代表没有限制；</li><li><code>log.retention.ms</code>：保存数据文件的毫秒数，如果未设置，则使用 <code>log.retention.minutes</code> 中的值，默认为 null；</li><li><code>log.retention.minutes</code>：保留数据文件的分钟数，如果未设置，则使用 <code>log.retention.hours</code> 中的值，默认为 null；</li><li><code>log.retention.hours</code>：保留数据文件的小时数，默认值为 168，也就是一周。</li></ul><p>因为在一个大文件里查找和删除消息是很费时的，也很容易出错，所以 Kafka 把分区分成若干个片段，当前正在写入数据的片段叫作活跃片段。活动片段永远不会被删除。如果按照默认值保留数据一周，而且每天使用一个新片段，那么你就会看到，在每天使用一个新片段的同时会删除一个最老的片段，所以大部分时间该分区会有 7 个片段存在。</p><h3 id=43-文件格式>4.3 文件格式</h3><p>通常保存在磁盘上的数据格式与生产者发送过来消息格式是一样的。 如果生产者发送的是压缩过的消息，那么同一个批次的消息会被压缩在一起，被当作“包装消息”进行发送 (格式如下所示) ，然后保存到磁盘上。之后消费者读取后再自己解压这个包装消息，获取每条消息的具体信息。</p><div align=center><img src=https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka-compress-message.png></div></div><div class=article-widget><div class="container-xl row post-nav"></div></div><div class=body-footer><p>最近更新于 0001-01-01</p><section id=comments class="mb-3 pt-0"><div id=disqus_thread></div><script>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="https://ngte.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><footer class=site-footer><div class="copyright py-4 bg-footer"><div class="row justify-content-center"><div class="text-center footer-color"><p class=mb-0>© 2017-2022 NGTE all rights reserved</p></div></div></div><script type=text/javascript id=clstr_globe async src="//clustrmaps.com/globe.js?d=kgpJG5sWZQpKujBmD-uW1B54-WBPol-DuDtrB2KFjKs"></script></footer></main></div></div><script src=//unpkg.com/heti/umd/heti-addon.min.js></script>
<script>const heti=new Heti(".article");heti.autoSpacing()</script><script type=text/javascript>window.$crisp=[],window.CRISP_WEBSITE_ID="12adcc35-9621-4313-8262-62dc654b29d8",function(){setTimeout(function(){d=document,s=d.createElement("script"),s.src="https://client.crisp.chat/l.js",s.async=1,d.getElementsByTagName("head")[0].appendChild(s)},2500)}()</script></div><div class=page-footer></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script id=search-hit-algolia-template type=text/html><div class=search-hit><div class=search-hit-content><div class=search-hit-name><a href={{relpermalink}}>{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a></div><div class="article-metadata search-hit-type">{{type}}</div><p class=search-hit-description>{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p></div></div></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js crossorigin=anonymous></script>
<script id=dsq-count-scr src=https://ngte.disqus.com/count.js async></script>
<script src=/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js type=module></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js></script>
<script>var mybutton=document.getElementById("backTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.style.display="block":mybutton.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script src=https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin=anonymous></script>
<script>anchors.add()</script><script>(function(){"use strict";if(!document.queryCommandSupported("copy"))return;function e(e,t){e.className="highlight-copy-btn",e.textContent=t,setTimeout(function(){e.textContent="",e.className="highlight-copy-btn fa fa-copy"},1e3)}function t(e){var t=window.getSelection(),n=document.createRange();return n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n),t}function n(n){var o,s=document.createElement("button");s.className="highlight-copy-btn fa fa-copy",s.textContent="",o=n.firstElementChild,s.addEventListener("click",function(){try{var n=t(o);document.execCommand("copy"),n.removeAllRanges(),e(s,"已复制")}catch(t){console&&console.log(t),e(s,"Failed :'(")}}),n.appendChild(s)}var s=document.getElementsByClassName("highlight");Array.prototype.forEach.call(s,n)})()</script></body></html>
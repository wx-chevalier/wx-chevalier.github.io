<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2.分库分表 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link><atom:link href="https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/index.xml" rel="self" type="application/rss+xml"/><description>2.分库分表</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>2.分库分表</title><link>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link></image><item><title>分库分表</title><link>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</guid><description>&lt;h1 id="分库分表">分库分表&lt;/h1>
&lt;h1 id="垂直拆分">垂直拆分&lt;/h1>
&lt;p>对于一个刚上线的互联网项目来说，由于前期活跃用户数量并不多，并发量也相对较小，所以此时企业一般都会选择将所有数据存放在一个数据库 中进行访问操作。举例来说，对于一个电商系统，其用户模块和产品模块的表刚开始都是位于一个库中。&lt;/p>
&lt;p>user、useraccount 表属于用户模块，productcategory、product 表属于产品模块。随着公司业务的发展，技术团队人员也得到了扩张，划分为不同的技术小组，不同的小组负责不同的业务模块。例如 A 小组负责用户模块，B 小组负责产品模块。此时数据库也迎来了第一次拆分：垂直拆分。&lt;/p>
&lt;p>这里的垂直拆分，指的是将一个包含了很多表的数据库，根据表的功能的不同，拆分为多个小的数据库，每个库包含部分表。通常来说，垂直拆分，都是根据业务来对一个库中的表进行拆分的。关于垂直拆分，还有另一种说法，将一个包含了很多字段的大表拆分为多个小表，每个表包含部分字段，这种情况在实际开发中基本很少遇到。&lt;/p>
&lt;p>垂直拆分的另一个典型应用场景是服务化(SOA)改造。在服务化的背景下，除了业务上需要进行拆分，底层的存储也需要进行隔离。垂直拆分会使得单个用户请求的响应时间变长，原因在于，在单体应用的场景下，所有的业务都可以在一个节点内部完成，而垂直拆分之后，通常会需要进行 RPC 调用。然后虽然单个请求的响应时间增加了，但是整个服务的吞吐量确会大大的增加。&lt;/p>
&lt;h1 id="sharding--水平分区">Sharding | 水平分区&lt;/h1>
&lt;p>经过水平分区设置后的业务表，必然能够将原本一张表维护的海量数据分配给 N 个子表进行存储和维护。水平分表从具体实现上又可以分为 3 种：只分表、只分库、分库分表。如果说读写分离实现了数据库读能力的水平扩展，那么分库分表就是实现了写能力的水平扩展。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>只分表：将 db 库中的 user 表拆分为 2 个分表，user_0 和 user_1，这两个表还位于同一个库中。适用场景：如果库中的多个表中只有某张表或者少数表数据量过大，那么只需要针对这些表进行拆分，其他表保持不变。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>只分库：将 db 库拆分为 db_0 和 db_1 两个库，同时在 db_0 和 db_1 库中各自新建一个 user 表，db_0.user 表和 db_1.user 表中各自只存原来的 db.user 表中的部分数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分库分表：将 db 库拆分为 db_0 和 db_1 两个库，db_0 中包含 user_0、user_1 两个分表，db_1 中包含 user_2、user_3 两个分表。下图演示了在分库分表的情况下，数据是如何拆分的：假设 db 库的 user 表中原来有 4000W 条数据，现在将 db 库拆分为 2 个分库 db_0 和 db_1，user 表拆分为 user_0、user_1、user_2、user_3 四个分表，每个分表存储 1000W 条数据。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="水平分区的优势">水平分区的优势&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>存储能力的水平扩展：在读写分离的情况下，每个集群中的 master 和 slave 基本上数据是完全一致的，从存储能力来说，在存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，我们可以搭建多个 mysql 主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个 master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。而在分库分表的情况下，每个分片所属的集群都有一个 master 节点，都可以执行写入操作，实现写能力的水平扩展。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="sql-解析与执行">SQL 解析与执行&lt;/h1>
&lt;p>分库分表的挑战主要体现在 4 个方面：基本的数据库增删改功能，分布式 id，分布式事务，动态扩容。&lt;/p>
&lt;p>对于开发人员而言，虽然分库分表的，但是其还是希望能和单库单表那样的去操作数据库。例如我们要批量插入四条用户记录，并且希望根据用户的 id 字段，确定这条记录插入哪个库的哪张表。例如 1 号记录插入 user1 表，2 号记录插入 user2 表，3 号记录插入 user3 表，4 号记录插入 user0 表，以此类推。sql 如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">insert&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">into&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">user&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">values&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="n">tianshouzhi&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="p">),(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="n">huhuamin&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="n">wanghanao&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="p">),(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="n">luyang&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://tva1.sinaimg.cn/large/007rAy9hgy1g2i9xt8aozj30u00dijst.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>这种 sql 语法只能操作 mysql 的单个库和单个表。所以必须将 sql 改成 4 条如下所示，然后分别到每个库上去执行。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">insert&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">into&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user0&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">values&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="n">luyang&lt;/span>&lt;span class="err">”&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>该操作包含以下流程：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>sql 解析：首先对 sql 进行解析，得到需要插入的四条记录的 id 字段的值分别为 1,2,3,4&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sql 路由：sql 路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sql 改写：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对 sql 进行改写，每个库只插入一条记录。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sql 执行：一条 sql 经过改写后变成了多条 sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行&lt;/p>
&lt;/li>
&lt;li>
&lt;p>结果集合并：每个 sql 执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="sql-解析">SQL 解析&lt;/h2>
&lt;p>用户执行只是一条 sql，并传入相关参数。数据库中间件内部需要通过 sql 解析器，对 sql 进行解析。可以将 sql 解析，类比为 xml 解析，xml 解析的最终结果是得到一个 document 对象，而 sql 解析最终得到一个抽象语法树(AST)。通过这个语法树，我们可以很简单的获取到 sql 的一些执行，例如当前执行的 sql 类型，查询了那些字段，数据库表名，where 条件，sql 的参数等一系列信息。&lt;/p>
&lt;p>通常来说，对于 sql 解析，内部需要经过词法(lex)解析和语法(Syntax)解析两个阶段，最终得到一个语法树。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://tva1.sinaimg.cn/large/007rAy9hgy1g2i9xt8aozj30u00dijst.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>例如 mycat、zebra 采用的都是 druid 解析器，shard-jdbc 一开始也用的是 druid 解析器，后面自研了解析器。目前较为流行的 sql 解析器包括：FoundationDB SQL Parser，Jsqlparser，Druid SQL Parser 等。其中，其中 Fdbparser 和 jsqlparser 都是基于 javacc 实现的。mycat 团队曾经做过一个性能测试，druid 解析器的解析性能通常能达到基于 javacc 生成的 sql 解析器 10~20 倍。&lt;/p>
&lt;h2 id="sql-路由">SQL 路由&lt;/h2>
&lt;p>路由规则是分库分表的基础，其规定了数据应该按照怎样的规则路由到不同的分库分表中。对于一个数据库中间件来说，通常是支持用户自定义任何路由规则的。路由规则本质上是一个脚本表达式，数据库中间件通过内置的脚本引擎对表达式进行计算，确定最终要操作哪些分库、分表。&lt;/p>
&lt;p>常见的路由规则包括哈希取模，按照日期等。常见的路由规则包括哈希取模，按照日期等。常见的用户表分表时，使用 id 来作为计算分表、分表，因此把 id 字段就称之为路由字段，或者分区字段。&lt;/p>
&lt;p>不管执行的是 INSERT、UPDATE、DELETE、SELECT 语句，SQL 中都应该包含这个路由字段。否则，对于插入语句来说，就不知道插入到哪个分库或者分表；对于 UPDATE、DELETE、SELECT 语句而言，则更为严重，因为不知道操作哪个分库分表，意味着必须要对所有分表都进行操作。SELECT 聚合所有分表的内容，极容易内存溢出，UPDATE、DELETE 更新、删除所有的记录，非常容易误更新、删除数据。因此，一些数据库中间件，对于 SQL 可能有一些限制，例如 UPDATE、DELETE 必须要带上分区字段，或者指定过滤条件。&lt;/p>
&lt;h2 id="sql-改写">SQL 改写&lt;/h2>
&lt;p>通常对于 INSERT、UPDATE、DELETE 等，改写相对简单。比较复杂的是 SELECT 语句的改写，对于一些复杂的 SELECT 语句，改写过程中会进行一些优化，例如将子查询改成 JOIN，过滤条件下推等。因为 SQL 改写很复杂，所以很多数据库中间件并不支持复杂的 SQL(通常有一个支持的 SQL)，只能支持一些简单的 OLTP 场景。&lt;/p>
&lt;p>当然也有一些数据库中间件，不满足于只支持 OLTP，在迈向 OLAP 的方向上进行了更多的努力。例如阿里的 TDDL、蚂蚁的 Zdal、大众点评的 zebra，都引入了 apache calcite，尝试对复杂的查询 SQL(例如嵌套子查询，join 等)进行支持，通过过滤条件下推，流式读取，并结合 RBO(基于规则的优化)、CBO(基于代价的优化)来对一些简单的 OLAP 场景进行支持。&lt;/p>
&lt;h2 id="sql-执行">SQL 执行&lt;/h2>
&lt;p>当经过 SQL 改写阶段后，会产生多个 SQL，需要到不同的分片上去执行，通常我们会使用一个线程池，将每个 SQL 包装成一个任务，提交到线程池里面并发的去执行，以提升效率。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/fWvdqN5S/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>这些执行的 SQL 中，如果有一个失败，则整体失败，返回异常给业务代码。&lt;/p>
&lt;h2 id="结果集合并">结果集合并&lt;/h2>
&lt;p>结果集合并，是数据库中间件的一大难点，需要针对性分析，主要是考虑实现的复杂度，以及执行的效率问题，对于一些复杂的 SQL，可能并不支持。例如：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对于查询条件：大部分中间件都支持 =、IN 作为查询条件，且可以作为分区字段。但是对于 NIT IN、BETWEEN…AND、LIKE,NOT LIKE 等，只能作为普通的查询条件，因为根据这些条件，无法记录到底是在哪个分库或者分表，只能全表扫描。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>聚合函数：大部分中间件都支持 MAX、MIN、COUNT、SUM，但是对于 AVG 可能只是部分支持。另外，如果是函数嵌套、分组(GROUP BY)聚合，可能也有一些数据库中间件不支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>子查询：分为 FROM 部分的子查询和 WHERE 部分的子查询。大部分中对于子查询的支持都是非常有限，例如语法上兼容，但是无法识别子查询中的分区字段，或者要求子查询的表名必须与外部查询表名相同，又或者只能支持一级嵌套子查询。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>JOIN：对于 JOIN 的支持通常很复杂，如果做不到过滤条件下推和流式读取，在中间件层面，基本无法对 JOIN 进行支持，因为不可能把两个表的所有分表，全部拿到内存中来进行 JOIN，内存早就崩了。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>分页排序：通常中间件都是支持 ORDER BY 和 LIMIT 的。但是在分库分表的情况下，分页的效率较低。例如对于 &lt;code>limit 100，10 ORDER BY id&lt;/code>。表示按照 id 排序，从第 100 个位置开始取 10 条记录。那么，大部分数据库中间件实际上是要从每个分表都查询 110(100+10)条记录，拿到内存中进行重新排序，然后取出 10 条。假设有 10 个分表，那么实际上要查询 1100 条记录，而最终只过滤出了 10 记录。因此，在分页的情况下，通常建议使用 &lt;code>where id &amp;gt; ? limit 10&lt;/code> 的方式来进行查询，应用记住每次查询的最大的记录 id。之后查询时，每个分表只需要从这个 id 之后，取 10 条记录即可，而不是取 offset + rows 条记录。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="binding-table">Binding Table&lt;/h3>
&lt;h3 id="小表广播">小表广播&lt;/h3>
&lt;h1 id="分布式系统">分布式系统&lt;/h1>
&lt;p>在分库分表后，我们不能再使用 mysql 的自增主键。因为在插入记录的时候，不同的库生成的记录的自增 id 可能会出现冲突。因此需要有一个全局的 id 生成器。目前分布式 id 有很多中方案，其中一个比较轻量级的方案是 twitter 的 snowflake 算法。&lt;/p>
&lt;p>分布式事务是分库分表绕不过去的一个坎，因为涉及到了同时更新多个分片数据。例如上面的批量插入记录到四个不同的库，如何保证要么同时成功，要么同时失败。关于分布式事务，mysql 支持 XA 事务，但是效率较低。柔性事务是目前比较主流的方案，柔性事务包括：最大努力通知型、可靠消息最终一致性方案以及 TCC 两阶段提交。但是无论 XA 事务还是柔性事务，实现起来都是非常复杂的。&lt;/p>
&lt;h1 id="动态扩容">动态扩容&lt;/h1>
&lt;p>动态扩容指的是增加分库分表的数量。例如原来的 user 表拆分到 2 个库的四张表上。现在我们希望将分库的数量变为 4 个，分表的数量变为 8 个。这种情况下一般要伴随着数据迁移。例如在 4 张表的情况下，id 为 7 的记录，7%4=3，因此这条记录位于 user3 这张表上。但是现在分表的数量变为了 8 个，而 7%8=0，而 user0 这张表上根本就没有 id=7 的这条记录，因此如果不进行数据迁移的话，就会出现记录找不到的情况。&lt;/p></description></item><item><title>分库分表.old</title><link>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.old/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.old/</guid><description>&lt;h1 id="links">Links&lt;/h1>
&lt;h1 id="mysql-分库与分表">MySQL 分库与分表&lt;/h1>
&lt;h1 id="垂直划分">垂直划分&lt;/h1>
&lt;p>按照功能划分，把数据分别放到不同的数据库和服务器。当一个网站开始刚刚创建时，可能只是考虑一天只有几十或者几百个人访问，数据库可能就个 db，所有表都放一起，一台普通的服务器可能就够了，而且开发人员也非常高兴，而且信心十足，因为所有的表都在一个库中，这样查询语句就可以随便关联了，多美的一件事情。但是随着访问压力的增加，读写操作不断增加，数据库的压力绝对越来越大，可能接近极限，这时可能人们想到增加从服务器，做什么集群之类的，可是问题又来了，数据量也快速增长。这时可以考虑对读写操作进行分离，按照业务把不同的数据放到不同的库中。其实在一个大型而且臃肿的数据库中表和表之间的数据很多是没有关系的，或者更加不需要(join)操作，理论上就应该把他们分别放到不同的服务器。例如用户的收藏夹的数据和博客的数据库就可以放到两个独立的服务器。这个就叫垂直划分(其实叫什么不重要)。&lt;/p>
&lt;h2 id="水平划分">水平划分&lt;/h2>
&lt;p>垂直数据划分包括把数据库表分割成在不同服务器上保存的不同数据库实例。每台服务器一般分配完成一个特殊的任务。这样就可以对那些表中的 IO 进行分割。这种类型的分割取决于将系统逻辑地划分成许多部分，以便这些部分能够独立操作。如果实例间需要最少量的交互进行事务处理，这种处理就很有必要。&lt;/p>
&lt;p>例如，如果你的数据库系统维护销售、营销和广告数据，最好是把这些表分割成单个的数据库实例，阻止它们共享同一台服务器上的 IO。可能你还需要处理这两个共享一些相同数据(例如客户数据)的系统。能够分割这些商业功能，你就可以在必要时向外扩展数据库环境，提高系统效率。&lt;/p>
&lt;p>你可以采取一些措施，如在每一台服务器上使用相互连接的表和视图，以便实例可以从其它实例中查看数据。这样做可以减少应用程序层决定在哪找到它需要的数据时所需的额外计算量。你需要保证应用程序层具有必要的逻辑性，以决定将数据保存在哪台服务器上。&lt;/p>
&lt;h1 id="links-1">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA5Nzc4OTA1Mw==&amp;amp;mid=2659598135&amp;amp;idx=1&amp;amp;sn=2f1daf51d92b9c5ed06d9422fdd19d49&amp;amp;scene=0#wechat_redirect" target="_blank" rel="noopener">http://mp.weixin.qq.com/s?__biz=MzA5Nzc4OTA1Mw==&amp;mid=2659598135&amp;idx=1&amp;sn=2f1daf51d92b9c5ed06d9422fdd19d49&amp;scene=0#wechat_redirect&lt;/a>&lt;/li>
&lt;/ul>
&lt;ul>
&lt;li>&lt;a href="https://parg.co/E2k" target="_blank" rel="noopener">https://parg.co/E2k&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>数据迁移</title><link>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mysql-series/5.%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8B%86%E5%88%86/2.%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</guid><description>&lt;h1 id="数据迁移">数据迁移&lt;/h1>
&lt;p>为了最大限度地减少服务拆分与分库分表给业务带来的影响（不影响业务开发也是架构转型的前提），我们采用了一种温和的渐进式拆分方案：&lt;/p>
&lt;ul>
&lt;li>对于每块需要拆分的领域，首先拆分出子服务，并将所有该领域的数据库操作封装为 RPC 接口；&lt;/li>
&lt;li>将其它所有服务中对该领域数据表的操作替换为 RPC 调用；&lt;/li>
&lt;li>拆分该领域的数据表，使用数据同步保证旧库中的表与新表数据一致；&lt;/li>
&lt;li>将该子服务中的数据库操作逐步迁移到新表，分批上线；&lt;/li>
&lt;li>全部迁移完成后，切断同步，该服务拆分结束。&lt;/li>
&lt;/ul>
&lt;p>这种方案能够做到平滑迁移，但其中却有几个棘手的问题：&lt;/p>
&lt;ul>
&lt;li>旧表新表的数据一致性如何保证？&lt;/li>
&lt;li>如何支持异构迁移？（由于旧表的设计往往非常范式化，因此拆分后的新表会增加很多来自其它表的冗余列）&lt;/li>
&lt;li>如何保证数据同步的实时性？（往往会先迁移读操作到新表，这时就要求旧表的写操作必须准实时地同步到新表）&lt;/li>
&lt;/ul>
&lt;p>典型的解决方案有两种：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>双写(dual write): 即所有写入操作同时写入旧表和新表，这种方式可以完全控制应用代码如何写数据库，听上去简单明了。但它会引入复杂的分布式一致性问题：要保证新旧库中两张表数据一致，双写操作就必须在一个分布式事务中完成，而分布式事务的代价太高了。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据变更抓取(change data capture, CDC): 通过数据源的事务日志抓取数据源变更，这能解决一致性问题(只要下游能保证变更应用到新库上)。它的问题在于各种数据源的变更抓取没有统一的协议，如 MySQL 用 Binlog，PostgreSQL 用 Logical decoding 机制，MongoDB 里则是 oplog。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>最终我们选择使用数据变更抓取实现数据同步与迁移，一是因为数据一致性的优先级更高，二是因为开源社区的多种组件能够帮助我们解决没有统一协议带来的 CDC 模块开发困难的问题。只有一个 CDC 模块当然是不够的，因为下游的消费者不可能随时就位等待 CDC 模块的推送。因此我们还需要引入一个变更分发平台，它的作用是：&lt;/p>
&lt;ul>
&lt;li>提供变更数据的堆积能力；&lt;/li>
&lt;li>支持多个下游消费者按不同速度消费；&lt;/li>
&lt;li>解耦 CDC 模块与消费者；&lt;/li>
&lt;/ul>
&lt;p>这也就是一套实时数据管道，设计目标是通过 CDC 模块抓取业务数据源变更，并以统一的格式发布到变更分发平台，所有消费者通过客户端库接入变更分发平台获取实时数据变更。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>一致性：数据变更分发给下游应用后，下游应用可以不断重试保证变更成功应用到目标数据源——这个过程要真正实现一致性还要满足两个前提，一是从数据变更抓取模块投递到下游应用并消费这个过程不能丢数据，也就是要保证至少一次交付；二是下游应用的消费必须是幂等的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>异构迁移：异构包含多种含义：表的 Schema 不同、表的物理结构不同(单表到分片表)、数据库不同(如 MySQL -&amp;gt; EleasticSearch)，后两者只要下游消费端实现对应的写入接口就能解决；而 Schema 不同，尤其是当新库的表聚合了多张旧库的表信息时，就要用反查源数据库或 Stream Join 等手段实现。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>实时性：只要保证各模块的数据传输与写入的效率，该模型便能保证实时性。&lt;/p>
&lt;/li>
&lt;/ul></description></item></channel></rss>
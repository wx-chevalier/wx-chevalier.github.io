<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>索引 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/</link><atom:link href="https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/index.xml" rel="self" type="application/rss+xml"/><description>索引</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>索引</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/</link></image><item><title>01.无索引</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/01.%E6%97%A0%E7%B4%A2%E5%BC%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/01.%E6%97%A0%E7%B4%A2%E5%BC%95/</guid><description>&lt;h1 id="简单的-bash-数据库">简单的 Bash 数据库&lt;/h1>
&lt;h2 id="数据存取">数据存取&lt;/h2>
&lt;p>世界上最简单的数据库可以用两个 Bash 函数实现：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="err">#&lt;/span>&lt;span class="o">!/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bash&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">db_set&lt;/span> &lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">echo&lt;/span> &lt;span class="s">&amp;#34;$1,$2&amp;#34;&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">database&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">db_get&lt;/span> &lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">grep&lt;/span> &lt;span class="s">&amp;#34;^$1,&amp;#34;&lt;/span> &lt;span class="n">database&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">sed&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">e&lt;/span> &lt;span class="s">&amp;#34;s/^$1,//&amp;#34;&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">tail&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这两个函数实现了键值存储的功能。执行 db_set key value，会将 键（key）和值（value）存储在数据库中。键和值（几乎）可以是你喜欢的任何东西，例如，值可以是 JSON 文档。然后调用 db_get key，查找与该键关联的最新值并将其返回。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ db_set &lt;span class="m">123456&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;London&amp;#34;,&amp;#34;attractions&amp;#34;:[&amp;#34;Big Ben&amp;#34;,&amp;#34;London Eye&amp;#34;]}&amp;#39;&lt;/span> $
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ db_set &lt;span class="m">42&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;San Francisco&amp;#34;,&amp;#34;attractions&amp;#34;:[&amp;#34;Golden Gate Bridge&amp;#34;]}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ db_get &lt;span class="m">42&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;San Francisco&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;attractions&amp;#34;&lt;/span>:&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;Golden Gate Bridge&amp;#34;&lt;/span>&lt;span class="o">]}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>底层的存储格式非常简单：一个文本文件，每行包含一条逗号分隔的键值对（忽略转义问题的话，大致与 CSV 文件类似）。每次对 db_set 的调用都会向文件末尾追加记录，所以更新键的时候旧版本的值不会被覆盖。我们使用了 tail -n 1，因而查找最新值的时候，需要找到文件中键最后一次出现的位置。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ db_set &lt;span class="m">42&lt;/span> &lt;span class="s1">&amp;#39;{&amp;#34;name&amp;#34;:&amp;#34;San Francisco&amp;#34;,&amp;#34;attractions&amp;#34;:[&amp;#34;Exploratorium&amp;#34;]}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ db_get &lt;span class="m">42&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;San Francisco&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;attractions&amp;#34;&lt;/span>:&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;Exploratorium&amp;#34;&lt;/span>&lt;span class="o">]}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ cat database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">123456,&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;London&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;attractions&amp;#34;&lt;/span>:&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;Big Ben&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;London Eye&amp;#34;&lt;/span>&lt;span class="o">]}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">42,&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;San Francisco&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;attractions&amp;#34;&lt;/span>:&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;Golden Gate Bridge&amp;#34;&lt;/span>&lt;span class="o">]}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">42,&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;San Francisco&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;attractions&amp;#34;&lt;/span>:&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;Exploratorium&amp;#34;&lt;/span>&lt;span class="o">]}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>db_set 函数对于极其简单的场景其实有非常好的性能，因为在文件尾部追加写入通常是非常高效的。与 db_set 做的事情类似，许多数据库在内部使用了日志（log），也就是一个 仅追加（append-only）的数据文件。真正的数据库有更多的问题需要处理（如并发控制，回收磁盘空间以避免日志无限增长，处理错误与部分写入的记录），但基本原理是一样的。&lt;/p>
&lt;h2 id="索引">索引&lt;/h2>
&lt;p>如果这个数据库中有着大量记录，则这个 db_get 函数的性能会非常糟糕。每次你想查找一个键时，db_get 必须从头到尾扫描整个数据库文件来查找键的出现。用算法的语言来说，查找的开销是 O(n)：如果数据库记录数量 n 翻了一倍，查找时间也要翻一倍。这就不好了。&lt;/p>
&lt;p>为了高效查找数据库中特定键的值，我们需要一个数据结构：索引（index）。索引背后的大致思想是，保存一些额外的元数据作为路标，帮助你找到想要的数据。如果您想在同一份数据中以几种不同的方式进行搜索，那么你也许需要不同的索引，建在数据的不同部分上。&lt;/p>
&lt;p>索引是从主数据衍生的附加（additional）结构。许多数据库允许添加与删除索引，这不会影响数据的内容，它只影响查询的性能。维护额外的结构会产生开销，特别是在写入时。写入性能很难超过简单地追加写入文件，因为追加写入是最简单的写入操作。任何类型的索引通常都会减慢写入速度，因为每次写入数据时都需要更新索引。&lt;/p>
&lt;p>这是存储系统中一个重要的权衡：精心选择的索引加快了读查询的速度，但是每个索引都会拖慢写入速度。因为这个原因，数据库默认并不会索引所有的内容，而需要你（程序员或 DBA）通过对应用查询模式的了解来手动选择索引。你可以选择能为应用带来最大收益，同时又不会引入超出必要开销的索引。&lt;/p></description></item><item><title>02.数组</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/02.%E6%95%B0%E7%BB%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/02.%E6%95%B0%E7%BB%84/</guid><description>&lt;h1 id="数组">数组&lt;/h1>
&lt;p>数组要求插入的时候保证有序，这样查找的时候可以利用二分查找法达到 &lt;code>O(log(N))&lt;/code> 的时间复杂度，对范围查询支持也很好，但是插入的时候如果不是在数组尾部，就需要摞动后面所有的数据，时间复杂度为 &lt;code>O(N)&lt;/code>。所以有序数组只适合存储静态数据，例如几乎很少变动的配置数据，或者是历史数据。这里应该会有人有疑问：我用另外一种线性数据结构链表来替代数组不就可以解决数组插入因为要移动数据导致太慢的问题了么，要回答这个问题我们需要了解操作系统读取文件的流程，磁盘 IO 是一个相对很慢的操作，为了提高读取速度，我们应该尽量减少磁盘 IO 操作，而操作系统一般以 4KB 为一个数据页读取数据，而 MySQL 一般为 16kb 作为一个数据块，已经读取的数据块会在内存进行缓存，如果多次数据读取在同一个数据块，则只需要一次磁盘 IO，而如果顺序一致的记录在文件中也是顺序存储的，就可以一次读取多个数据块，这样范围查询的速度也可以大大提升，显然链表没有这方面的优势。&lt;/p></description></item><item><title>03.二叉树</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/03.%E4%BA%8C%E5%8F%89%E6%A0%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/03.%E4%BA%8C%E5%8F%89%E6%A0%91/</guid><description>&lt;h1 id="二叉树">二叉树&lt;/h1>
&lt;p>典型的索引譬如在内存中维护一个二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在 &lt;code>O(log2n)&lt;/code> 的复杂度内获取到相应数据。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://ww1.sinaimg.cn/large/007rAy9hgy1g10cogz8p1j30gc089dge.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>左侧为数据记录的物理地址，右侧为查找树，需要注意的是，逻辑上相邻的记录在磁盘上也并不是一定物理相邻的。&lt;/p>
&lt;p>二叉树在极端情况下会变成线性结构，也就是每个节点都只有左子节点或者只有右子节点，这样就无法利用二分查找只能从第一个节点开始向后遍历了，所以为了维持　 O(log(N))　的时间复杂度，我们需要在插入节点的时候对节点进行调整以保证树的平衡，所以平衡二叉树插入的时间复杂度也是　 O(log(N))　，二叉树只有两个子节点，如果数据量很大则树就很高，树的每一层一般不在同一个数据块中存储，为了尽量的减少磁盘读写次数，我们用Ｎ叉树来代替二叉树，在 MySQL 中这个Ｎ一般为　 1200，这样树高是　４　的话也可以存储亿级别的数据，而且树的前面两层一般都在内存中，MySQL 中用到的　Ｂ＋　树，一般用非叶子节点构建索引，而叶子节点用来存储具体的值。&lt;/p></description></item><item><title>04.哈希索引</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/04.%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/04.%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95/</guid><description>&lt;h1 id="哈希索引">哈希索引&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230417214047.png" alt="image.png" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>哈希索引即是基于哈希技术，如上图所示，我们将一系列的最终的键值通过哈希函数转化为存储实际数据桶的地址数值。值本身存储的地址就是基于哈希函数的计算结果，而搜索的过程就是利用哈希函数从元数据中推导出桶的地址。&lt;/p>
&lt;ul>
&lt;li>添加新值的流程，首先会根据哈希函数计算出存储数据的地址，如果该地址已经被占用，则添加新桶并重新计算哈希函数。&lt;/li>
&lt;li>更新值的流程则是先搜索到目标值的地址，然后对该内存地址应用所需的操作。&lt;/li>
&lt;/ul>
&lt;p>哈希索引的实现思路是，对一个字符串字段，为其每个值都计算一个哈希值，并且建立一个新字段用于存储这些哈希值，然后为这个新字段建立索引，并且为字符串字段建立插入和更新的触发器，用于更新哈希字段的值。在进行查询时，使用同一哈希算法计算查询的字符串的哈希值，使用该哈希值在哈希字段上进行查询，由于建立了索引，因而查询非常快，对于查询到的结果将查询的字符串与查询结果的字符串字段进行比较，从而得到最后的结果。这里由于新建立的哈希字段是整型的，因而其索引片非常小，并且由于字符串字段的选择性非常高，因而哈希字段的选择性相对非常高，因而总体而言，查询效率是非常高的。&lt;/p>
&lt;p>哈希索引会在进行相等性测试（等或者不等）时候具有非常高的性能，但是在进行比较查询、Order By 等更为复杂的场景下就无能为力。&lt;/p>
&lt;ul>
&lt;li>哈希索引仅仅能满足=，&amp;lt;=&amp;gt;，IN，IS NULL 或者 IS NOT NULL 查询，不能使用范围查询。由于哈希索引比较的是进行哈希运算之后的哈希值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的哈希算法处理之后的哈希值的大小关系，并不能保证和哈希运算前完全一样。&lt;/li>
&lt;li>哈希索引无法被用来避免数据的排序操作。由于哈希索引中存放的是经过哈希计算之后的哈希值，而且哈希值的大小关系并不一定和哈希运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；&lt;/li>
&lt;li>哈希索引不能利用部分索引键查询。对于组合索引，哈希索引在计算哈希值的时候是组合索引键合并后再一起计算哈希值，而不是单独计算哈希值，所以通过组合索引的前面一个或几个索引键进行查询的时候，哈希索引也无法被利用。&lt;/li>
&lt;li>哈希索引在任何时候都不能避免表扫描。前面已经知道，哈希索引是将索引键通过哈希运算之后，将哈希运算结果的哈希值和所对应的行指针信息存放于一个哈希表中，由于不同索引键存在相同哈希值，所以即使取满足某个哈希键值的数据的记录条数，也无法从 哈希索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。&lt;/li>
&lt;li>哈希索引遇到大量哈希值相等的情况后性能并不一定就会比 B-Tree 索引高。对于选择性比较低的索引键，如果创建哈希索引，那么将会存在大量记录指针信息存于同一个哈希值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下&lt;/li>
&lt;/ul>
&lt;h1 id="哈希索引-1">哈希索引&lt;/h1>
&lt;p>键值数据的结构相对简单，其索引也较为直观。键值存储与在大多数编程语言中可以找到的字典（dictionary）类型非常相似，通常字典都是用哈希映射（hash map）（或哈希表（hash table））实现的。既然我们已经有内存中数据结构-哈希映射，为什么不使用它来索引在磁盘上的数据呢？&lt;/p>
&lt;h1 id="内存索引">内存索引&lt;/h1>
&lt;p>假设我们的数据存储只是一个追加写入的文件，就像前面的例子一样。那么最简单的索引策略就是：保留一个内存中的哈希映射，其中每个键都映射到一个数据文件中的字节偏移量，指明了可以找到对应值的位置，如下图所示。当你将新的键值对追加写入文件中时，还要更新哈希映射，以反映刚刚写入的数据的偏移量（这同时适用于插入新键与更新现有键）。当你想查找一个值时，使用哈希映射来查找数据文件中的偏移量，寻找（seek）该位置并读取该值。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/05/1yCVAA.md.png" alt="以类CSV格式存储键值对的日志，并使用内存哈希映射进行索引" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>现实中，Bitcask 实际上就是这么做的（Riak 中默认的存储引擎）Bitcask 提供高性能的读取和写入操作，但所有键必须能放入可用内存中，因为哈希映射完全保留在内存中。这些值可以使用比可用内存更多的空间，因为可以从磁盘上通过一次 seek 加载所需部分，如果数据文件的那部分已经在文件系统缓存中，则读取根本不需要任何磁盘 I/O。&lt;/p>
&lt;p>像 Bitcask 这样的存储引擎非常适合每个键的值经常更新的情况。例如，键可能是视频的 URL，值可能是它播放的次数（每次有人点击播放按钮时递增）。在这种类型的工作负载中，有很多写操作，但是没有太多不同的键——每个键有很多的写操作，但是将所有键保存在内存中是可行的。&lt;/p>
&lt;h1 id="日志分段与压缩">日志分段与压缩&lt;/h1>
&lt;p>直到现在，我们只是追加写入一个文件，所以如何避免最终用完磁盘空间？一种好的解决方案是，将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，并开始写入一个新的段文件。然后，我们就可以对这些段进行压缩（compaction），如下图所示。压缩意味着在日志中丢弃重复的键，只保留每个键的最近更新。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/05/1yC1BQ.png" alt="压缩键值更新日志（统计猫视频的播放次数），只保留每个键的最近值" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>而且，由于压缩经常会使得段变得很小（假设在一个段内键被平均重写了好几次），我们也可以在执行压缩的同时将多个段合并在一起，如下图所示。段被写入后永远不会被修改，所以合并的段被写入一个新的文件。冻结段的合并和压缩可以在后台线程中完成，在进行时，我们仍然可以继续使用旧的段文件来正常提供读写请求。合并过程完成后，我们将读取请求转换为使用新的合并段而不是旧段，然后可以简单地删除旧的段文件。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/05/1yCN90.md.png" alt="同时执行压缩和分段合并" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>每个段现在都有自己的内存哈希表，将键映射到文件偏移量。为了找到一个键的值，我们首先检查最近段的哈希映射;如果键不存在，我们检查第二个最近的段，依此类推。合并过程保持细分的数量，所以查找不需要检查许多哈希映射大量的细节进入实践这个简单的想法工作。&lt;/p>
&lt;h1 id="其他挑战">其他挑战&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>文件格式：CSV 不是日志的最佳格式。使用二进制格式更快，更简单，首先以字节为单位对字符串的长度进行编码，然后使用原始字符串（不需要转义）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>删除记录：如果要删除一个键及其关联的值，则必须在数据文件（有时称为逻辑删除）中附加一个特殊的删除记录。当日志段被合并时，逻辑删除告诉合并过程放弃删除键的任何以前的值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>崩溃恢复：如果数据库重新启动，则内存哈希映射将丢失。原则上，您可以通过从头到尾读取整个段文件并在每次按键时注意每个键的最近值的偏移量来恢复每个段的哈希映射。但是，如果段文件很大，这可能需要很长时间，这将使服务器重新启动痛苦 Bitcask 通过存储加速恢复磁盘上每个段的哈希映射的快照，可以更快地加载到内存中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>部分写入记录：数据库可能随时崩溃，包括将记录附加到日志中途 Bitcask 文件包含校验和，允许检测和忽略日志的这些损坏部分。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="并发控制">并发控制&lt;/h2>
&lt;p>由于写操作是以严格顺序的顺序附加到日志中的，所以常见的实现选择是只有一个写入器线程。数据文件段是附加的，或者是不可变的，所以它们可以被多个线程同时读取。&lt;/p>
&lt;p>为什么不更新文件，用新值覆盖旧值？但是只能追加设计的原因有几个：&lt;/p>
&lt;ul>
&lt;li>追加和分段合并是顺序写入操作，通常比随机写入快得多，尤其是在磁盘旋转硬盘上。在某种程度上，顺序写入在基于闪存的 &lt;strong>固态硬盘（SSD）&lt;/strong> 上也是优选的。&lt;/li>
&lt;li>如果段文件是附加的或不可变的，并发和崩溃恢复就简单多了。例如，您不必担心在覆盖值时发生崩溃的情况，而将包含旧值和新值的一部分的文件保留在一起。&lt;/li>
&lt;li>合并旧段可以避免数据文件随着时间的推移而分散的问题。&lt;/li>
&lt;/ul>
&lt;p>但是，哈希表索引也有局限性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>哈希表必须能放进内存：如果你有非常多的键，那真是倒霉。原则上可以在磁盘上保留一个哈希映射，不幸的是磁盘哈希映射很难表现优秀。它需要大量的随机访问 I/O，当它变满时增长是很昂贵的，并且哈希冲突需要很多的逻辑。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>范围查询效率不高。例如，您无法轻松扫描 kitty00000 和 kitty99999 之间的所有键——您必须在哈希映射中单独查找每个键。&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>05.B-Tree</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/05.b-tree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/05.b-tree/</guid><description>&lt;h1 id="b-tree">B-Tree&lt;/h1>
&lt;p>在《&lt;a href="https://github.com/wx-chevalier/AlgoDS-Series?q=" target="_blank" rel="noopener">AlgoDS-Series&lt;/a>》一节中我们介绍了 B-Tree 的基本概念与实现，这里我们继续来分析下为何 B-Tree 相较于红黑树等二叉查找树会更适合于作为数据库索引的实现。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 IO 消耗，相对于内存存取，IO 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 IO 操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘 IO 的存取次数。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://tva1.sinaimg.cn/large/007rAy9hgy1g3fw872x3gj30ou08aab4.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>根据 B-Tree 的定义，可知检索一次最多需要访问 h 个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次 IO 就可以完全载入。每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个节点只需一次 IO。而检索的时候，一次检索最多需要 h-1 次 IO（根节点常驻内存），其渐进复杂度为 $O(h)=O(log_dN)O(h)=O(log_dN)$，实际应用中，出度 d 是非常大的数字，通常超过 100，因此 h 非常小（通常不超过 3）。而红黑树这种结构，h 明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的 IO 渐进复杂度也为 O(h)，效率明显比 B-Tree 差很多。&lt;/p>
&lt;h1 id="btree">B+Tree&lt;/h1>
&lt;p>B+Tree 是 B-Tree 的变种，有着比 B-Tree 更高的查询性能，其相较于 B-Tree 有了如下的变化：&lt;/p>
&lt;ul>
&lt;li>有 m 个子树的节点包含有 m 个元素（B-Tree 中是 m-1）。&lt;/li>
&lt;li>根节点和分支节点中不保存数据，只用于索引，所有数据都保存在叶子节点中。&lt;/li>
&lt;li>所有分支节点和根节点都同时存在于子节点中，在子节点元素中是最大或者最小的元素。&lt;/li>
&lt;li>叶子节点会包含所有的关键字，以及指向数据记录的指针，并且叶子节点本身是根据关键字的大小从小到大顺序链接。&lt;/li>
&lt;/ul>
&lt;p>一般在数据库系统或文件系统中使用的 B+Tree 结构都在经典 B+Tree 的基础上进行了优化，增加了顺序访问指针：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230417214210.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>如上图所示，在 B+Tree 的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的 B+Tree。做这个优化的目的是为了提高区间访问的性能，例如下图中如果要查询 key 为从 3 到 8 的所有数据记录，当找到 3 后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230417214230.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="b-树">B+ 树&lt;/h1>
&lt;p>刚才讨论的日志结构索引正处在逐渐被接受的阶段，但它们并不是最常见的索引类型。使用最广泛的索引结构在 1970 年被引入，不到 10 年后变得“无处不在”，B 树经受了时间的考验。在几乎所有的关系数据库中，它们仍然是标准的索引实现，许多非关系数据库也使用它们。&lt;/p>
&lt;p>像 SSTables 一样，B 树保持按键排序的键值对，这允许高效的键值查找和范围查询。但这就是相似之处的结尾：B 树有着非常不同的设计理念。我们前面看到的日志结构索引将数据库分解为可变大小的段，通常是几兆字节或更大的大小，并且总是按顺序编写段。相比之下，B 树将数据库分解成固定大小的块或页面，传统上大小为 4KB（有时会更大），并且一次只能读取或写入一个页面。这种设计更接近于底层硬件，因为磁盘也被安排在固定大小的块中。&lt;/p>
&lt;p>每个页面都可以使用地址或位置来标识，这允许一个页面引用另一个页面：类似于指针，但在磁盘而不是在内存中。我们可以使用这些页面引用来构建一个页面树：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/06/1y1Y1U.md.png" alt="使用B树索引查找一个键" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>一个页面会被指定为 B 树的根；在索引中查找一个键时，就从这里开始。该页面包含几个键和对子页面的引用。每个子页面负责一段连续范围的键，引用之间的键，指明了引用子页面的键范围。譬如在上例中，我们正在寻找关键字 251，所以我们知道我们需要遵循边界 200 和 300 之间的页面引用。这将我们带到一个类似的页面，进一步打破了 200 - 300 到子范围。最后，我们可以看到包含单个键（叶页）的页面，该页面包含每个键的内联值，或者包含对可以找到值的页面的引用。&lt;/p>
&lt;p>在 B 树的一个页面中对子页面的引用的数量称为分支因子。例如上例中分支因子是 6。在实践中，分支因子取决于存储页面参考和范围边界所需的空间量，但通常是几百个。如果要更新 B 树中现有键的值，则搜索包含该键的叶页，更改该页中的值，并将该页写回到磁盘（对该页的任何引用保持有效）。如果你想添加一个新的键，你需要找到其范围包含新键的页面，并将其添加到该页面。如果页面中没有足够的可用空间容纳新键，则将其分成两个半满页面，并更新父页面以解释键范围的新分区，如下图所示：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2020/02/06/1y1738.png" alt="通过分割页面来生长B树" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>该算法确保树保持平衡：具有 n 个键的 B 树总是具有 $O(log n)$ 的深度。大多数数据库可以放入一个三到四层的 B 树，所以你不需要遵追踪多页面引用来找到你正在查找的页面，这里分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB。&lt;/p>
&lt;h1 id="日志">日志&lt;/h1>
&lt;p>B 树的基本底层写操作是用新数据覆盖磁盘上的页面。假定覆盖不改变页面的位置;即，当页面被覆盖时，对该页面的所有引用保持完整。这与日志结构索引（如 LSM 树）形成鲜明对比，后者只附加到文件（并最终删除过时的文件），但从不修改文件。&lt;/p>
&lt;p>您可以考虑将硬盘上的页面覆盖为实际的硬件操作。在磁性硬盘驱动器上，这意味着将磁头移动到正确的位置，等待旋转盘上的正确位置出现，然后用新的数据覆盖适当的扇区。在固态硬盘上，由于 SSD 必须一次擦除和重写相当大的存储芯片块，所以会发生更复杂的事情。&lt;/p>
&lt;p>而且，一些操作需要覆盖几个不同的页面。例如，如果因为插入导致页面过度而拆分页面，则需要编写已拆分的两个页面，并覆盖其父页面以更新对两个子页面的引用。这是一个危险的操作，因为如果数据库在仅有一些页面被写入后崩溃，那么最终将导致一个损坏的索引（例如，可能有一个孤儿页面不是任何父项的子项）。&lt;/p>
&lt;p>为了使数据库对崩溃具有韧性，B 树实现通常会带有一个额外的磁盘数据结构：预写式日志（WAL, write-ahead-log）（也称为重做日志（Redo Log））。这是一个仅追加的文件，每个 B 树修改都可以应用到树本身的页面上。当数据库在崩溃后恢复时，这个日志被用来使 B 树恢复到一致的状态。&lt;/p>
&lt;p>更新页面的一个额外的复杂情况是，如果多个线程要同时访问 B 树，则需要仔细的并发控制：否则线程可能会看到树处于不一致的状态。这通常通过使用锁存器（latches）（轻量级锁）保护树的数据结构来完成。日志结构化的方法在这方面更简单，因为它们在后台进行所有的合并，而不会干扰传入的查询，并且不时地将旧的分段原子交换为新的分段。&lt;/p>
&lt;h1 id="b-树优化">B 树优化&lt;/h1>
&lt;p>由于 B 树已经存在了这么久，许多优化已经发展了多年，这并不奇怪。仅举几例：&lt;/p>
&lt;ul>
&lt;li>一些数据库（如 LMDB）使用写时复制方案，而不是覆盖页面并维护 WAL 进行崩溃恢复。修改的页面被写入到不同的位置，并且树中的父页面的新版本被创建，指向新的位置。这种方法对于并发控制也很有用。&lt;/li>
&lt;li>我们可以通过不存储整个键来节省页面空间，但可以缩小它的大小。特别是在树内部的页面上，键只需要提供足够的信息来充当键范围之间的边界。在页面中包含更多的键允许树具有更高的分支因子，因此更少的层次&lt;/li>
&lt;li>通常，页面可以放置在磁盘上的任何位置；没有什么要求附近的键范围页面附近的磁盘上。如果查询需要按照排序顺序扫描大部分关键字范围，那么每个页面的布局可能会非常不方便，因为每个读取的页面都可能需要磁盘查找。因此，许多 B 树实现尝试布局树，使得叶子页面按顺序出现在磁盘上。但是，随着树的增长，维持这个顺序是很困难的。相比之下，由于 LSM 树在合并过程中一次又一次地重写存储的大部分，所以它们更容易使顺序键在磁盘上彼此靠近。&lt;/li>
&lt;li>额外的指针已添加到树中。例如，每个叶子页面可以在左边和右边具有对其兄弟页面的引用，这允许不跳回父页面就能顺序扫描。&lt;/li>
&lt;li>B 树的变体如分形树借用一些日志结构的思想来减少磁盘寻道（而且它们与分形无关）。&lt;/li>
&lt;/ul>
&lt;h1 id="b-树与-lsm-树的比较">B+ 树与 LSM 树的比较&lt;/h1>
&lt;p>尽管 B 树实现通常比 LSM 树实现更成熟，但 LSM 树由于其性能特点也非常有趣。根据经验，通常 LSM 树的写入速度更快，而 B 树的读取速度更快 LSM 树上的读取通常比较慢，因为它们必须在压缩的不同阶段检查几个不同的数据结构和 SSTables。&lt;/p>
&lt;h2 id="lsm-树的优点">LSM 树的优点&lt;/h2>
&lt;p>B 树索引必须至少两次写入每一段数据：一次写入预先写入日志，一次写入树页面本身（也许再次分页）。即使在该页面中只有几个字节发生了变化，也需要一次编写整个页面的开销。有些存储引擎甚至会覆盖同一个页面两次，以免在电源故障的情况下导致页面部分更新。&lt;/p>
&lt;p>由于反复压缩和合并 SSTables，日志结构索引也会重写数据。这种影响：在数据库的生命周期中写入数据库导致对磁盘的多次写入：被称为写放大（write amplification）。需要特别注意的是固态硬盘，固态硬盘的闪存寿命在覆写有限次数后就会耗尽。在写入繁重的应用程序中，性能瓶颈可能是数据库可以写入磁盘的速度。在这种情况下，写放大会导致直接的性能代价：存储引擎写入磁盘的次数越多，可用磁盘带宽内的每秒写入次数越少。&lt;/p>
&lt;p>而且，LSM 树通常能够比 B 树支持更高的写入吞吐量，部分原因是它们有时具有较低的写放大（尽管这取决于存储引擎配置和工作负载），部分是因为它们顺序地写入紧凑的 SSTable 文件而不是必须覆盖树中的几个页面。这种差异在磁性硬盘驱动器上尤其重要，顺序写入比随机写入快得多。&lt;/p>
&lt;p>LSM 树可以被压缩得更好，因此经常比 B 树在磁盘上产生更小的文件 B 树存储引擎会由于分割而留下一些未使用的磁盘空间：当页面被拆分或某行不能放入现有页面时，页面中的某些空间仍未被使用。由于 LSM 树不是面向页面的，并且定期重写 SSTables 以去除碎片，所以它们具有较低的存储开销，特别是当使用平坦压缩时。&lt;/p>
&lt;p>在许多固态硬盘上，固件内部使用日志结构化算法，将随机写入转变为顺序写入底层存储芯片，因此存储引擎写入模式的影响不太明显。但是，较低的写入放大率和减少的碎片对 SSD 仍然有利：更紧凑地表示数据可在可用的 I/O 带宽内提供更多的读取和写入请求。&lt;/p>
&lt;h2 id="lsm-树的缺点">LSM 树的缺点&lt;/h2>
&lt;p>日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。尽管存储引擎尝试逐步执行压缩而不影响并发访问，但是磁盘资源有限，所以很容易发生请求需要等待而磁盘完成昂贵的压缩操作。对吞吐量和平均响应时间的影响通常很小，但是在更高百分比的情况下，对日志结构化存储引擎的查询响应时间有时会相当长，而 B 树的行为则相对更具可预测性。&lt;/p>
&lt;p>压缩的另一个问题出现在高写入吞吐量：磁盘的有限写入带宽需要在初始写入（记录和刷新内存表到磁盘）和在后台运行的压缩线程之间共享。写入空数据库时，可以使用全磁盘带宽进行初始写入，但数据库越大，压缩所需的磁盘带宽就越多。&lt;/p>
&lt;p>如果写入吞吐量很高，并且压缩没有仔细配置，压缩跟不上写入速率。在这种情况下，磁盘上未合并段的数量不断增加，直到磁盘空间用完，读取速度也会减慢，因为它们需要检查更多段文件。通常情况下，即使压缩无法跟上，基于 SSTable 的存储引擎也不会限制传入写入的速率，所以您需要进行明确的监控来检测这种情况。&lt;/p>
&lt;p>B 树的一个优点是每个键只存在于索引中的一个位置，而日志结构化的存储引擎可能在不同的段中有相同键的多个副本。这个方面使得 B 树在想要提供强大的事务语义的数据库中很有吸引力：在许多关系数据库中，事务隔离是通过在键范围上使用锁来实现的，在 B 树索引中，这些锁可以直接连接到树。在第 7 章中，我们将更详细地讨论这一点。&lt;/p>
&lt;p>B 树在数据库体系结构中是非常根深蒂固的，为许多工作负载提供始终如一的良好性能，所以它们不可能很快就会消失。在新的数据存储中，日志结构化索引变得越来越流行。没有快速和容易的规则来确定哪种类型的存储引擎对你的场景更好，所以值得进行一些经验上的测试&lt;/p></description></item><item><title>07.其他索引</title><link>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/07.%E5%85%B6%E4%BB%96%E7%B4%A2%E5%BC%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/database-notes/01.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/%E7%B4%A2%E5%BC%95/07.%E5%85%B6%E4%BB%96%E7%B4%A2%E5%BC%95/</guid><description>&lt;h1 id="其他索引">其他索引&lt;/h1>
&lt;p>到目前为止，我们只讨论了关键值索引，它们就像关系模型中的主键（primary key）索引。主键唯一标识关系表中的一行，或文档数据库中的一个文档或图形数据库中的一个顶点。数据库中的其他记录可以通过其主键（或 ID）引用该行/文档/顶点，并且索引用于解析这样的引用。&lt;/p>
&lt;p>有二级索引也很常见。在关系数据库中，您可以使用 CREATE INDEX 命令在同一个表上创建多个二级索引，而且这些索引通常对于有效地执行联接而言至关重要。例如，user 表中很可能在 user_id 列上有一个二级索引，以便您可以在每个表中找到属于同一用户的所有行。&lt;/p>
&lt;p>一个二级索引可以很容易地从一个键值索引构建。主要的不同是键不是唯一的。即可能有许多行（文档，顶点）具有相同的键。这可以通过两种方式来解决：或者通过使索引中的每个值，成为匹配行标识符的列表（如全文索引中的发布列表），或者通过向每个索引添加行标识符来使每个关键字唯一。无论哪种方式，B 树和日志结构索引都可以用作辅助索引。&lt;/p>
&lt;h1 id="将值存储在索引中">将值存储在索引中&lt;/h1>
&lt;p>索引中的关键字是查询搜索的内容，但是该值可以是以下两种情况之一：它可以是所讨论的实际行（文档，顶点），也可以是对存储在别处的行的引用。在后一种情况下，行被存储的地方被称为堆文件（heap file），并且存储的数据没有特定的顺序（它可以是仅附加的，或者可以跟踪被删除的行以便用新数据覆盖它们后来）。堆文件方法很常见，因为它避免了在存在多个二级索引时复制数据：每个索引只引用堆文件中的一个位置，实际的数据保存在一个地方在不更改键的情况下更新值时，堆文件方法可以非常高效：只要新值不大于旧值，就可以覆盖该记录。如果新值更大，情况会更复杂，因为它可能需要移到堆中有足够空间的新位置。在这种情况下，要么所有的索引都需要更新，以指向记录的新堆位置，或者在旧堆位置留下一个转发指针。&lt;/p>
&lt;p>在某些情况下，从索引到堆文件的额外跳跃对读取来说性能损失太大，因此可能希望将索引行直接存储在索引中。这被称为聚集索引。例如，在 MySQL 的 InnoDB 存储引擎中，表的主键总是一个聚簇索引，二级索引用主键（而不是堆文件中的位置）。在 SQL Server 中，可以为每个表指定一个聚簇索引。&lt;/p>
&lt;p>在 聚集索引（clustered index）（在索引中存储所有行数据）和 非聚集索引（nonclustered index）（仅在索引中存储对数据的引用）之间的折衷被称为 包含列的索引（index with included columns）或覆盖索引（covering index），其存储表的一部分在索引内。这允许通过单独使用索引来回答一些查询（这种情况叫做：索引 覆盖（cover）了查询）。&lt;/p>
&lt;p>与任何类型的数据重复一样，聚簇和覆盖索引可以加快读取速度，但是它们需要额外的存储空间，并且会增加写入开销。数据库还需要额外的努力来执行事务保证，因为应用程序不应该因为重复而导致不一致。&lt;/p>
&lt;h1 id="多列索引">多列索引&lt;/h1>
&lt;p>至今讨论的索引只是将一个键映射到一个值。如果我们需要同时查询一个表中的多个列（或文档中的多个字段），这显然是不够的。最常见的多列索引被称为 连接索引（concatenated index），它通过将一列的值追加到另一列后面，简单地将多个字段组合成一个键（索引定义中指定了字段的连接顺序）。这就像一个老式的纸质电话簿，它提供了一个从（姓，名）到电话号码的索引。由于排序顺序，索引可以用来查找所有具有特定姓氏的人，或所有具有特定姓-名组合的人。然而，如果你想找到所有具有特定名字的人，这个索引是没有用的。&lt;/p>
&lt;p>多维索引（multi-dimensional index）是一种查询多个列的更一般的方法，这对于地理空间数据尤为重要。例如，餐厅搜索网站可能有一个数据库，其中包含每个餐厅的经度和纬度。当用户在地图上查看餐馆时，网站需要搜索用户正在查看的矩形地图区域内的所有餐馆。这需要一个二维范围查询，如下所示：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">SELECT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">restaurants&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WHERE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">latitude&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">51&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mi">4946&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">latitude&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">51&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mi">5079&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">longitude&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mi">1162&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AND&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">longitude&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mi">1004&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>一个标准的 B 树或者 LSM 树索引不能够高效地响应这种查询：它可以返回一个纬度范围内的所有餐馆（但经度可能是任意值），或者返回在同一个经度范围内的所有餐馆（但纬度可能是北极和南极之间的任意地方），但不能同时满足。&lt;/p>
&lt;p>一种选择是使用空间填充曲线将二维位置转换为单个数字，然后使用常规 B 树索引。更普遍的是，使用特殊化的空间索引，例如 R 树。例如，PostGIS 使用 PostgreSQL 的通用 Gist 工具将地理空间索引实现为 R 树。&lt;/p>
&lt;p>一个有趣的主意是，多维索引不仅可以用于地理位置。例如，在电子商务网站上可以使用维度（红色，绿色，蓝色）上的三维索引来搜索特定颜色范围内的产品，也可以在天气观测数据库中搜索二维（日期，温度）的指数，以便有效地搜索 2013 年的温度在 25 至 30°C 之间的所有观测资料。使用一维索引，你将不得不扫描 2013 年的所有记录（不管温度如何），然后通过温度进行过滤，反之亦然二维索引可以同时通过时间戳和温度来收窄数据集。这个技术被 HyperDex 使用。&lt;/p>
&lt;h1 id="全文搜索和模糊索引">全文搜索和模糊索引&lt;/h1>
&lt;p>到目前为止所讨论的所有索引都假定您有确切的数据，并允许您查询键的确切值或具有排序顺序的键的值范围。他们不允许你做的是搜索类似的键，如拼写错误的单词。这种模糊的查询需要不同的技术。&lt;/p>
&lt;p>例如，全文搜索引擎通常允许搜索一个单词以扩展为包括该单词的同义词，忽略单词的语法变体，并且搜索在相同文档中彼此靠近的单词的出现，并且支持各种其他功能取决于文本的语言分析。为了处理文档或查询中的拼写错误，Lucene 能够在一定的编辑距离内搜索文本（编辑距离 1 意味着添加，删除或替换了一个字母）。&lt;/p>
&lt;p>Lucene 为其词典使用了一个类似于 SSTable 的结构。这个结构需要一个小的内存索引，告诉查询在排序文件中哪个偏移量需要查找关键字。在 LevelDB 中，这个内存中的索引是一些键的稀疏集合，但在 Lucene 中，内存中的索引是键中字符的有限状态自动机，类似于 trie。这个自动机可以转换成 Levenshtein 自动机，它支持在给定的编辑距离内有效地搜索单词。&lt;/p>
&lt;h1 id="在内存中存储一切">在内存中存储一切&lt;/h1>
&lt;p>与主内存相比，磁盘处理起来很尴尬。对于磁盘和 SSD，如果要在读取和写入时获得良好性能，则需要仔细地布置磁盘上的数据。但是，我们容忍这种尴尬，因为磁盘有两个显著的优点：它们是耐用的（它们的内容在电源关闭时不会丢失），并且每 GB 的成本比 RAM 低。&lt;/p>
&lt;p>随着 RAM 变得更便宜，每 GB 的成本价格被侵蚀了。许多数据集不是那么大，所以将它们全部保存在内存中是非常可行的，可能分布在多个机器上。这导致了内存数据库的发展。某些内存中的键值存储（如 Memcached）仅用于缓存，在重新启动计算机时丢失的数据是可以接受的。但其他内存数据库的目标是持久性，可以通过特殊的硬件（例如电池供电的 RAM），将更改日志写入磁盘，将定时快照写入磁盘或通过复制内存来实现，记忆状态到其他机器。&lt;/p>
&lt;p>内存数据库重新启动时，需要从磁盘或通过网络从副本重新加载其状态（除非使用特殊的硬件）。尽管写入磁盘，它仍然是一个内存数据库，因为磁盘仅用作耐久性附加日志，读取完全由内存提供。写入磁盘也具有操作优势：磁盘上的文件可以很容易地由外部实用程序进行备份，检查和分析。&lt;/p>
&lt;p>诸如 VoltDB，MemSQL 和 Oracle TimesTen 等产品是具有关系模型的内存数据库，供应商声称，通过消除与管理磁盘上的数据结构相关的所有开销，他们可以提供巨大的性能改进 RAM Cloud 是一个开源的内存键值存储器，具有持久性（对存储器中的数据以及磁盘上的数据使用日志结构化方法）Redis 和 Couchbase 通过异步写入磁盘提供了较弱的持久性。&lt;/p>
&lt;p>反直觉的是，内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。即使是基于磁盘的存储引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使用了磁盘块。相反，它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。。&lt;/p>
&lt;p>除了性能，内存数据库的另一个有趣的领域是提供难以用基于磁盘的索引实现的数据模型。例如，Redis 为各种数据结构（如优先级队列和集合）提供了类似数据库的接口。因为它将所有数据保存在内存中，所以它的实现相对简单。&lt;/p>
&lt;p>最近的研究表明，内存数据库体系结构可以扩展到支持比可用内存更大的数据集，而不必重新采用以磁盘为中心的体系结构。所谓的 反缓存（anti-caching）方法通过在内存不足的情况下将最近最少使用的数据从内存转移到磁盘，并在将来再次访问时将其重新加载到内存中。这与操作系统对虚拟内存和交换文件的操作类似，但数据库可以比操作系统更有效地管理内存，因为它可以按单个记录的粒度工作，而不是整个内存页面。尽管如此，这种方法仍然需要索引能完全放入内存中（就像本章开头的 Bitcask 例子）。&lt;/p>
&lt;p>如果 非易失性存储器（NVM）技术得到更广泛的应用，可能还需要进一步改变存储引擎设计。目前这是一个新的研究领域，值得关注。&lt;/p></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>HDFS | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/</link><atom:link href="https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/index.xml" rel="self" type="application/rss+xml"/><description>HDFS</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>HDFS</title><link>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/</link></image><item><title>HDFS 编程</title><link>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E7%BC%96%E7%A8%8B/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">public&lt;/span> &lt;span class="kd">class&lt;/span> &lt;span class="nc">TestHDFSFile&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">localPath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;C:/D/JavaWorkSpace/bigdata/temp/&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">private&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hdfs://192.168.2.6:9000/user/hadoop/temp/&amp;#34;&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">public&lt;/span> &lt;span class="kd">static&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">args&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// new TestHDFSFile().testUpload();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">// new TestHDFSFile().testCreate();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">//new TestHDFSFile().testRename();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">//new TestHDFSFile().testDel();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">//new TestHDFSFile().testgetModifyTime();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">//new TestHDFSFile().testExists();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">//new TestHDFSFile().testFileBlockLocation();
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">TestHDFSFile&lt;/span>&lt;span class="o">().&lt;/span>&lt;span class="na">testGetHostName&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 上传本地文件到HDFS
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testUpload&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// conf.addResource(new Path(localPath + &amp;#34;core-site.xml&amp;#34;));
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">src&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">localPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;file01.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">copyFromLocalFile&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">src&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;Upload to &amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">conf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="s">&amp;#34;fs.default.name&amp;#34;&lt;/span>&lt;span class="o">));&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">file&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 创建HDFS文件
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testCreate&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">byte&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">buff&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;hello world!&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getBytes&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;hello.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FSDataOutputStream&lt;/span> &lt;span class="n">outputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputStream&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">create&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputStream&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">write&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">buff&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">buff&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">length&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">catch&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">Exception&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">e&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">printStackTrace&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">finally&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">outputStream&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="kc">null&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">outputStream&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">close&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">file&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 重命名HDFS文件
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testRename&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">frpath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;hello.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">topath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;hello2.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">rename&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">frpath&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">topath&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">file&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 刪除HDFS文件
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testDel&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">topath&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;hello2.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">ok&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">delete&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">topath&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ok&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="s">&amp;#34;删除成功&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;删除失败&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">file&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 查看HDFS文件的最后修改时间
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testgetModifyTime&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">listStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">FileStatus&lt;/span> &lt;span class="n">file&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">files&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;\t&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getModificationTime&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getPath&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;\t&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Date&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getModificationTime&lt;/span>&lt;span class="o">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 查看HDFS文件是否存在
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testExists&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;file01.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">boolean&lt;/span> &lt;span class="n">ok&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">exists&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">ok&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="s">&amp;#34;文件存在&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s">&amp;#34;文件不存在&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 查看某个文件在HDFS集群的位置
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testFileBlockLocation&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Path&lt;/span> &lt;span class="n">dst&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">hdfsPath&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;file01.txt&amp;#34;&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">FileStatus&lt;/span> &lt;span class="n">fileStatus&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getFileStatus&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">BlockLocation&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">blockLocations&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getFileBlockLocations&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">fileStatus&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">0&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">fileStatus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getLen&lt;/span>&lt;span class="o">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">BlockLocation&lt;/span> &lt;span class="n">block&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">blockLocations&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">block&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getHosts&lt;/span>&lt;span class="o">())&lt;/span> &lt;span class="o">+&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s">&amp;#34;\t&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Arrays&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">toString&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">block&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getNames&lt;/span>&lt;span class="o">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 获取HDFS集群上所有节点名称
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kd">public&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">testGetHostName&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">Exception&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Configuration&lt;/span> &lt;span class="n">conf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="n">Configuration&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">DistributedFileSystem&lt;/span> &lt;span class="n">hdfs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">DistributedFileSystem&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="n">FileSystem&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">get&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">conf&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">DatanodeInfo&lt;/span>&lt;span class="o">[]&lt;/span> &lt;span class="n">dataNodeStats&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hdfs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getDataNodeStats&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">DatanodeInfo&lt;/span> &lt;span class="n">dataNode&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="n">dataNodeStats&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">System&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">println&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">dataNode&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getHostName&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s">&amp;#34;\t&amp;#34;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dataNode&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">getName&lt;/span>&lt;span class="o">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>HDFS 读取原理</title><link>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E8%AF%BB%E5%8F%96%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E8%AF%BB%E5%8F%96%E5%8E%9F%E7%90%86/</guid><description>&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>HDFS 开创性地设计出一套文件存储方式，即对文件分割后分别存放；HDFS 将要存储的大文件进行分割，分割后存放在既定的存储块(Block )中，并通过预先设定的优化处理，模式对存储的数据进行预处理，从而解决了大文件储存与计算的需求；一个 HDFS 集群包括两大部分，即 NameNode 与 DataNode。一般来说，一个集群中会有一个 NameNode 和多个 DataNode 共同工作；NameNode 是集群的主服务器，主要是用于对 HDFS 中所有的文件及内容数据进行维护，并不断读取记录集群中 DataNode 主机情况与工作状态，并通过读取与写入镜像日志文件的方式进行存储；DataNode 在 HDFS 集群中担任任务具体执行角色，是集群的工作节点。文件被分成若干个相同大小的数据块，分别存储在若干个 DataNode 上，DataNode 会定期向集群内 NameNode 发送自己的运行状态与存储内容，并根据 NameNode 发送的指令进行工作；NameNode 负责接受客户端发送过来的信息，然后将文件存储位置信息发送给提交请求的客户端，由客户端直接与 DataNode 进行联系，从而进行部分文件的运算与操作。Block 是 HDFS 的基本存储单元，默认大小是 64M；HDFS 还可以对已经存储的 Block 进行多副本备份，将每个 Block 至少复制到 3 个相互独立的硬件上，这样可以快速恢复损坏的数据；用户可以使用既定的 API 接口对 HDFS 中的文件进行操作；当客户端的读取操作发生错误的时候，客户端会向 NameNode 报告错误，并请求 NameNode 排除错误的 DataNode 后后重新根据距离排序，从而获得一个新的 DataNode 的读取路径。如果所有的 DataNode 都报告读取失败，那么整个任务就读取失败；对于写出操作过程中出现的问题，FSDataOutputStream 并不会立即关闭。客户端向 NameNode 报告错误信息，并直接向提供备份的 DataNode 中写入数据。备份 DataNode 被升级为首选 DataNode，并在其余 2 个 DataNode 中备份复制数据。NameNode 对错误的 DataNode 进行标记以便后续对其进行处理&lt;/p>
&lt;h1 id="quick-start">Quick Start&lt;/h1>
&lt;p>HDFS 基本命令&lt;/p>
&lt;p>hadoop fs -cmd&lt;/p>
&lt;p>cmd: 具体的操作，基本上与 UNIX 的命令行相同&lt;/p>
&lt;p>args: 参数&lt;/p>
&lt;p>HDFS 资源 URI 格式：&lt;/p>
&lt;p>scheme://authority/path&lt;/p>
&lt;p>scheme：协议名，file 或 hdfs&lt;/p>
&lt;p>authority：namenode 主机名&lt;/p>
&lt;p>path：路径&lt;/p>
&lt;p>示例：hdfs://localhost:9000/user/chunk/test.txt&lt;/p>
&lt;p>假设已经在 core-site.xml 里配置了 fs.default.name=hdfs://localhost:9000，则仅使用 /user/chunk/test.txt 即可。&lt;/p>
&lt;p>hdfs 默认工作目录为 /user/$USER，$USER 是当前的登录用户名。&lt;/p>
&lt;p>HDFS 命令示例：&lt;/p>
&lt;p>hadoop fs -mkdir /user/trunk&lt;/p>
&lt;p>hadoop fs -ls /user&lt;/p>
&lt;p>hadoop fs -lsr /user ( 递归的 )&lt;/p>
&lt;p>hadoop fs -put test.txt /user/trunk&lt;/p>
&lt;p>hadoop fs -put test.txt . ( 复制到 hdfs 当前目录下，首先要创建当前目录 )&lt;/p>
&lt;p>hadoop fs -get /user/trunk/test.txt . ( 复制到本地当前目录下 )&lt;/p>
&lt;p>hadoop fs -cat /user/trunk/test.txt&lt;/p>
&lt;p>hadoop fs -tail /user/trunk/test.txt ( 查看最后 1000 字节 )&lt;/p>
&lt;p>hadoop fs -rm /user/trunk/test.txt&lt;/p>
&lt;p>hadoop fs -help ls ( 查看 ls 命令的帮助文档 )&lt;/p>
&lt;p>图中的 2：文件备份数量，因为采用了两台机器的全分布模式，所以此处为 2. 对于目录，使用 -。&lt;/p>
&lt;p>在 put 的时候遇到问题：&lt;/p>
&lt;h2 id="configuration">Configuration&lt;/h2>
&lt;h2 id="read-file">Read File&lt;/h2>
&lt;h1 id="存储结构">存储结构&lt;/h1>
&lt;h2 id="行存储">行存储&lt;/h2>
&lt;p>HDFS 块内行存储的例子:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://dl.iteye.com/upload/attachment/0083/5102/c5adc6f6-4a57-3994-b44c-2a943152bc58.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>基于 Hadoop 系统行存储结构的优点在于快速数据加载和动态负载的高适应能力，这是因为行存储保证了相同记录的所有域都在同一个集群节点，即同一个 HDFS 块。不过，行存储的缺点也是显而易见的，例如它不能支持快速查询处理，因为当查询仅仅针对多列表中的少数几列时，它不能跳过不必要的列读取；此 外，由于混合着不同数据值的列，行存储不易获得一个极高的压缩比，即空间利用率不易大幅提高。&lt;/p>
&lt;h2 id="列存储">列存储&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://dl.iteye.com/upload/attachment/0083/5104/a432e6af-9a73-355c-ac77-b7c185da959c.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure> 在 HDFS 上按照列组存储表格的例子。在这个例子中，列 A 和列 B 存储在同一列组，而列 C 和列 D 分别存储在单独的列组。查询时列存储能够避免读不必要的列，并且压缩一个列中的相似数据能够达到较高的压缩比。然而，由于元组重构的较高开销，它并不能提供基于 Hadoop 系统的快速查询处理。列存储不能保证同一 记录的所有域都存储在同一集群节点，行存储的例子中，记录的 4 个域存储在位于不同节点的 3 个 HDFS 块中。因此，记录的重构将导致通过集群节点网络的大 量数据传输。尽管预先分组后，多个列在一起能够减少开销，但是对于高度动态的负载模式，它并不具备很好的适应性。&lt;/p>
&lt;h1 id="数据读取">数据读取&lt;/h1>
&lt;p>hdfs 读取数据流程图:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://img.blog.csdn.net/20160525114335782" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure> 1、首先调用 FileSystem 对象的 open 方法，其实获取的是一个 DistributedFileSystem 的实例。2、DistributedFileSystem 通过 RPC( 远程过程调用 ) 获得文件的第一批 block 的 locations，同一 block 按照重复数会返回多个 locations，这些 locations 按照 hadoop 拓扑结构排序，距离客户端近的排在前面。3、前两步会返回一个 FSDataInputStream 对象，该对象会被封装成 DFSInputStream 对象，DFSInputStream 可以方便的管理 datanode 和 namenode 数据流。客户端调用 read 方 法，DFSInputStream 就会找出离客户端最近的 datanode 并连接 datanode。4、数据从 datanode 源源不断的流向客户端。5、如果第一个 block 块的数据读完了，就会关闭指向第一个 block 块的 datanode 连接，接着读取下一个 block 块。这些操作对客户端来说是透明的，从客户端的角度来看只是读一个持续不断的流。6、如果第一批 block 都读完了，DFSInputStream 就会去 namenode 拿下一批 blocks 的 location，然后继续读，如果所有的 block 块都读完，这时就会关闭掉所有的流。&lt;/p>
&lt;h1 id="数据写入">数据写入&lt;/h1>
&lt;p>hdfs 写数据流程:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://img.blog.csdn.net/20160525131839917" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure> 1. 客户端通过调用 DistributedFileSystem 的 create 方法，创建一个新的文件。2.DistributedFileSystem 通过 RPC(远程过程调用)调用 NameNode，去创建一个没有 blocks 关联的新文件。创建前，NameNode 会做各种校验，比如文件是否存在，客户端有无权限去创建等。如果校验通过，NameNode 就会记录下新文件，否则就会抛出 IO 异常。3. 前两步结束后会返回 FSDataOutputStream 的对象，和读文件的时候相似，FSDataOutputStream 被封装成 DFSOutputStream，DFSOutputStream 可以协调 NameNode 和 DataNode。客户端开始写数据到 DFSOutputStream,DFSOutputStream 会把数据切成一个个小 packet，然后排成队列 data queue。4.DataStreamer 会去处理接受 data queue，它先问询 NameNode 这个新的 block 最适合存储的在哪几个 DataNode 里，比如重复数是 3，那么就找到 3 个最适合的 DataNode，把它们排成一个 pipeline。DataStreamer 把 packet 按队列输出到管道的第一个 DataNode 中，第一个 DataNode 又把 packet 输出到第二个 DataNode 中，以此类推。5.DFSOutputStream 还有一个队列叫 ack queue，也是由 packet 组成，等待 DataNode 的收到响应，当 pipeline 中的所有 DataNode 都表示已经收到的时候，这时 akc queue 才会把对应的 packet 包移除掉。6. 客户端完成写数据后，调用 close 方法关闭写入流。7.DataStreamer 把剩余的包都刷到 pipeline 里，然后等待 ack 信息，收到最后一个 ack 后，通知 DataNode 把文件标示为已完成。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://img.blog.csdn.net/20160525133509937" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="namenode-ha">NameNode HA&lt;/h1>
&lt;p>NameNode HA 架构如下:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://img.blog.csdn.net/20160525134854724" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ul>
&lt;li>Active NameNode 和 Standby NameNode：&lt;/li>
&lt;/ul>
&lt;p>两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>主备切换控制器 ZKFailoverController：&lt;/p>
&lt;p>ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Zookeeper 集群：&lt;/p>
&lt;p>为主备切换控制器提供主备选举支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>共享存储系统：&lt;/p>
&lt;p>共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备用 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>HDFS 源代码分析</title><link>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/distributedstorage-notes/20.%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/hdfs/hdfs-%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>&lt;ol>
&lt;li>基础包(包括工具包和安全包)&lt;/li>
&lt;/ol>
&lt;p>包括工具和安全包。其中，hdfs.util 包含了一些 HDFS 实现需要的辅助数据结构；hdfs.security.token.block 和 hdfs.security.token.delegation 结合 Hadoop 的安全框架，提供了安全访问 HDFS 的机制。&lt;/p>
&lt;p>hdfs.util (一些 HDFS 实现需要的辅助数据结构)&lt;/p>
&lt;p>AtomicFileOutputStream.java&amp;mdash;- 继承实现类：原子文件输出流类；DataTransferThrottler.java&amp;mdash;- 独立内存类：数据传送时的调节参数配置表；这个类是线程安全的，能够被多个线程所共享；LightWeightGSet.java&amp;mdash;- 继承实现类：一个低内存占用的实现类；&lt;/p>
&lt;p>hdfs.security.token.block (安全访问 HDFS 机制)&lt;/p>
&lt;p>BlockKey.java&amp;mdash;- 继承实现类：Key 用于生成和校验块的令牌；BlockTokenIdentifier.java&amp;mdash;- 继承实现类：块令牌的标识符；BlockTokenSecretManager.java&amp;mdash;- 继承实现类：块令牌管理类；BlockTokenSecretManager 能够被实例化为两种模式，主模式和从模式。主节点能够生成新的块 key，并导出块 key 到从节点。从节点只能导入并且使用从主节点接收的块 key。主机和从机都可以生成和验证块令牌。BlockTokenSelector.java&amp;mdash;- 继承实现类：为 HDFS 的块令牌选择；ExportedBlockKeys.java&amp;mdash;- 继承实现类：传递块 key 对象；InvalidBlockTokenException.java&amp;mdash;- 继承实现类：访问令牌验证失败；&lt;/p>
&lt;p>hdfs.security.token.delegation (安全访问 HDFS 机制)&lt;/p>
&lt;p>DelegationTokenIdentifier.java&amp;mdash;- 继承实现类：特定针对 HDFS 的代表令牌的标识符；DelegationTokenRenewer.java&amp;mdash;- 继承实现类：这是一个守护进程，实现等待下一个文件系统的接续；DelegationTokenSecretManager.java&amp;mdash;- 继承实现类：这个类实现了 HDFS 特定授权的令牌的管理；这个管理类实现了生成并接受每一个令牌的密码；DelegationTokenSelector.java&amp;mdash;- 继承实现类：专门针对 HDFS 的令牌；&lt;/p>
&lt;p>2.HDFS 实体实现包&lt;/p>
&lt;p>这是代码分析的重点，包含 8 个包：&lt;/p>
&lt;p>hdfs.server.common 包含了一些名字节点和数据节点共享的功能，如系统升级、存储空间信息等。&lt;/p>
&lt;p>hdfs.protocol 和 hdfs.server.protocol 提供了 HDFS 各个实体间通过 IPC 交互的接口的定义和实现。&lt;/p>
&lt;p>hdfs.server.namenode、hdfs.server.datanode 和 hdfs 分别包含了名字节点、数据节点和客户端的实现。上述代码是 HDFS 代码分析的重点。&lt;/p>
&lt;p>hdfs.server.namenode.metrics 和 hdfs.server.datanode.metrics 实现了名字节点和数据节点上度量数据的收集功能。度量数据包括名字节点进程和数据节点进程上事件的计数，例如数据节点上就可以收集到写入字节数、被复制的块的数量等信息。&lt;/p>
&lt;p>hdfs.server.common (一些名字节点和数据节点共享的功能)&lt;/p>
&lt;p>GenerationStamp.java&amp;mdash;- 继承实现类：生成时间戳的功能及读写访问类；HdfsConstants.java&amp;mdash;- 接口类：一些 HDFS 内部的常数；Hdfs 常量字段及取值的定义；InconsistentFSStateException.java&amp;mdash;- 继承实现类：不一致的文件系统状态异常；文件状态检查出错提示信息；IncorrectVersionException.java&amp;mdash;- 继承实现类：不正确的版本异常；版本不正确检查时提示信息；Storage.java&amp;mdash;- 继承实现类：存储信息文件；本地存储信息存储在一个单独的文件版本中；它包含了节点类型、存储布局版本、命名空间 ID 以及文件系统状态创建时间；内存中以扩展表记录方式记录当前 namenode 索引信息及状态信息(文件是否在打开)；StorageInfo.java&amp;mdash;- 独立内存类：存储信息的通用类；内存中文件索引信息基本表；基本作用是保存地储上的文件系统元信息；Upgradeable.java&amp;mdash;- 接口类：分布式升级对象的通用接口；对象升级接口方法集定义；UpgradeManager.java&amp;mdash;- 独立内存类、抽象：通用升级管理；UpgradeObject.java&amp;mdash;- 继承实现类：抽象升级对象；包含常用接口方法的实现；可升级对象的接口方法实现；UpgradeObjectCollection.java&amp;mdash;- 独立内存类：可升级对象的集合容器实现；升级对象在使用前应该先进行注册，才能使用；UpgradeStatusReport.java&amp;mdash;- 继承实现类：系统升级基类；升级过程状态信息表定义；Util.java&amp;mdash;- 独立内存类：获取当前系统时间；&lt;/p>
&lt;p>hdfs.protocol ( HDFS 各个实体间通过 IPC 交互的接口)&lt;/p>
&lt;p>AlreadyBeingCreatedException.java&amp;mdash;- 继承实现类：文件已经建立异常；Block.java&amp;mdash;- 继承实现类：数据块在 HDFS 中的抽象；Bolck 内存基本块结构定义与读写访问；这个类是大量和数据块相关的类的基础，在客户端接口上，这样的类有 LocatedBlock、LocateBlocks 和 BlockLocalPathInfo。BlockListAsLongs.java&amp;mdash;- 独立内存类：这个类提供了一个访问块列表的接口；Bolck 块的索引构成数组；该类的作用，就是将块数组 blcokArray 中的数据，“ 原封不动 ” 的转换成一个 long 类型的数组 blockList；BlockLocalPathInfo.java&amp;mdash;- 继承实现类：应用于 ClientDatanodeProtocol 接口中，用于 HDFS 读文件的数据节点本地读优化。当客户端发现它和它要读取的数据块正好位于同一台主机上的时候，它可以不通过数据节点读数据块，而是直接读取本地文件，以获取数据块的内容。这大大降低了对应数据节点的负载。ClientDatanodeProtocol.java&amp;mdash;- 接口类：客户端与数据节点间的接口。用于客户端和数据节点进行交互，这个接口用得比较少，客户端和数据节点间的主要交互是通过流接口进行读 / 写文件数据的操作。错误发生时，客户端需要数据节点配合进行恢复，或当客户端进行本地文件读优化时，需要通过 IPC 接口获取一些信息。ClientProtocol.java&amp;mdash;- 接口类：客户端与 namenode 之间的接口；是 HDFS 客户访问文件系统的入口；客户端通过这个接口访问名字节点，操作文件或目录的元数据信息；读写文件也必须先访问名字节点，接下来再和数据节点进行交互，操作文件数据；另外，从名字节点能获取分布式文件系统的一些整体运行状态信息，也是通过这个接口进行的；用于访问 NameNode。它包含了文件角度上的 HDFS 功能。和 GFS 一样，HDFS 不提供 POSIX 形式的接口，而是使用了一个私有接口。一般来说，程序员通过 org.apache.hadoop.fs.FileSystem 来和 HDFS 打交道，不需要直接使用该接口。DatanodeID.java&amp;mdash;- 继承实现类：用于在 HDFS 集群中确定一个数据节点；DatanodeInfo.java&amp;mdash;- 继承实现类：继承自 DatanodeID，在 DatanodeID 的基础上，提供了数据节点上的一些度量信息；Datanode 状态信息结构定义及访问读写类；DataTransferProtocol.java&amp;mdash;- 接口类：客户端与数据节点之间应用流协议传输数据的实现；DirectoryListing.java&amp;mdash;- 继承实现类：用于一次返回一个目录下的多个文件 / 子目录的属性；DSQuotaExceededException.java&amp;mdash;- 继承实现类：磁盘空间超出配额异常类；FSConstants.java&amp;mdash;- 接口类：一些有用的常量；HdfsFileStatus.java&amp;mdash;- 继承实现类：保存了 HDFS 文件 / 目录的属性；LayoutVersion.java&amp;mdash;- 独立内存类：这个类跟踪了 HDFS 布局版本中的改变信息；LocatedBlock.java&amp;mdash;- 继承实现类：已经确认了存储位置的数据块；可以用于一次定位多个数据块；LocatedBlocks.java&amp;mdash;- 继承实现类：块的位置和文件长度集合；一组数据块及文件长度说明信息表的定义及读写；NSQuotaExceededException.java&amp;mdash;- 继承实现类：命名空间超出配额异常类；QuotaExceededException.java&amp;mdash;- 继承实现类：超出配额异常；UnregisteredDatanodeException.java&amp;mdash;- 继承实现类：未注册的数据节点异常；&lt;/p>
&lt;p>hdfs.server.protocol ( HDFS 各个实体间接口的实现)&lt;/p>
&lt;p>BalancerBandwidthCommand.java&amp;mdash;- 继承实现类：管理员通过调用 &amp;ldquo;dfsadmin -setBalanacerBandwidth newbandwidth&amp;rdquo; 实现动态的调整 balancer 的带宽参数；BlockCommand.java&amp;mdash;- 继承实现类：BlockCommand 类实现的是数据节点控制下的块的指令；数据块命令定义及实现类；BlockMetaDataInfo.java&amp;mdash;- 继承实现类：一个块的元数据信息；数据块的元数据信息定义及实现；BlockRecoveryInfo.java&amp;mdash;- 继承实现类：块恢复操作信息；BlocksWithLocations.java&amp;mdash;- 继承实现类：BlockLocations 序列的实现类；带位置的块信息的读写；DatanodeCommand.java&amp;mdash;- 抽象类：数据节点命令；数据节点基本信息定义及实现；DatanodeProtocol.java&amp;mdash;- 接口类：服务器间接口：数据节点与名字节点间的接口。在 HDFS 的主从体系结构中，数据节点作为从节点，不断的通过这个接口主节点名字节点报告一些信息，同步信息到名字节点；同时，该接口的一些方法，方法的返回值会带回名字节点指令，根据这些指令，数据节点或移动、或删除，或恢复本地磁盘上的数据块，或者执行其他的操作。DatanodeRegistration.java&amp;mdash;- 继承实现类：DatanodeRegistration 类包含名字节点识别和验证数据节点的所有信息；数据节点的注册信息读写方法定义及实现；DisallowedDatanodeException.java&amp;mdash;- 继承实现类：不允许的数据节点异常；InterDatanodeProtocol.java&amp;mdash;- 接口类：服务器间的接口：数据节点与数据节点间的接口。数据节点通过这个接口，和其他数据节点进行通信，恢复数据块，保证数据的一致性。KeyUpdateCommand.java&amp;mdash;- 继承实现类：key 升级命令；NamenodeProtocol.java&amp;mdash;- 接口类：服务期间接口：第二名字节点、HDFS 均衡器与名字节点间的接口。第二名字节点会不停的获取名字节点上某一个时间点的命名空间镜像和镜像的变化日志，然后会合并得到一个新的镜像，并将该结果发送回名字节点，在这个过程中，名字节点会通过这个接口，配合第二名字节点完成元数据的合并。该接口也为 HDFS 均衡器 balancer 的正常工作提供一些信息。NamespaceInfo.java&amp;mdash;- 继承实现类：NamespaceInfo 类实现了返回名字节点针对数据节点的握手；UpgradeCommand.java&amp;mdash;- 继承实现类：这是一个通用的分布式升级命令类；升级数据块命名实现；&lt;/p>
&lt;p>hdfs.server.namenode (名字节点的实现)&lt;/p>
&lt;p>BlockPlacementPolicy.java&amp;mdash;- 抽象类：这个接口用于选择放置块副本的目标磁盘的所需的数目；BlockPlacementPolicyDefault.java&amp;mdash;- 继承实现类：这个类实现了选择放置块副本的目标磁盘的所需的数目；BlockPlacementPolicyWithNodeGroup.java&amp;mdash;- 继承实现类：这个类实现了在 node-group 层上选择放置块副本的目标磁盘的所需的数目；BlockInfo.java&amp;mdash;- 独立内存类：这个类维护了块到它元数据的映射；CancelDelegationTokenServlet.java&amp;mdash;- 继承实现类：取消代表令牌服务；CheckpointSignature.java&amp;mdash;- 继承实现类：检查点签名类；存贮信息的签名信息表定义；ContentSummaryServlet.java&amp;mdash;- 继承实现类：文件校验服务；CorruptReplicasMap.java&amp;mdash;- 独立内存类：存储文件系统中所有损坏的块的信息；DatanodeDescriptor.java&amp;mdash;- 继承实现类：DatanodeDescriptor 类跟踪并统计了给定的数据节点上的信息，比如可用存储空间，上次更新时间等等；数据节点的状态信息定义及实现；DecommissionManager.java&amp;mdash;- 独立内存类：管理节点的解除；DfsServlet.java&amp;mdash;- 抽象类：DFS 服务的基类；Web 方式操作 DFS 的代理接口；EditLogInputStream.java&amp;mdash;- 抽象类：一个通用的抽象类用来支持从持久型存储读取编辑日志数据；读取日志数据的类方法定义及实现；EditLogOutputStream.java&amp;mdash;- 继承实现类：一个通用的抽象类用来支持从持久型存储记录编辑日志数据；写日志数据的类方法定义及实现；FileChecksumServlets.java&amp;mdash;- 独立内存类：文件校验服务；文件较验 web 操作命令的代理实现；FileDataServlet.java&amp;mdash;- 继承实现类：文件数据 web 操作命令的代理实现；FsckServlet.java&amp;mdash;- 继承实现类：名字节点上 fsck 的 web 服务；文件系统检查 web 操作命令的代理实现；FSClusterStats.java&amp;mdash;- 接口类：这个接口用于检索集群相关的统计；FSDirectory.java&amp;mdash;- 继承实现类：类 FSDirectory 实现了存储文件系统的目录状态；文件目录结构的定义及实现；FSEditLog.java&amp;mdash;- 独立内存类：FSEditLog 类实现了维护命名空间改动的日志记录；文件系统日志表的定义；FSImage.java&amp;mdash;- 继承实现类：FSImage 实现对命名空间的编辑进行检查点操作和日志记录操作；文件系统的目录、文件、数据的索引及关系信息定义；FSInodeInfo.java&amp;mdash;- 接口类：文件系统相关信息；FSNamesystem.java&amp;mdash;- 继承实现类：FSNamesystem 类实现了为数据节点进行实际的记账工作；为数据节点命名的信息结构定义；FSPermissionChecker.java&amp;mdash;- 独立内存类：实现用于检测文件系统权限的类；GetDelegationTokenServlet.java&amp;mdash;- 继承实现类：获取委托令牌服务；GetImageServlet.java&amp;mdash;- 继承实现类：这个类用于在命名系统中检索文件；通常用于第二名字节点来检索镜像以及为周期性的检测点进行编辑文件；Host2NodesMap.java&amp;mdash;- 独立内存类：主机到节点的映射；INode.java&amp;mdash;- 继承实现类：这个抽象类包含了文件和目录索引节点的通用字段；节点基础信息结构定义；INodeDirectory.java&amp;mdash;- 继承实现类：表示目录的索引节点的类；INodeDirectoryWithQuota.java&amp;mdash;- 继承实现类：有配额限制的目录索引节点类；INodeFile.java&amp;mdash;- 继承实现类：目录索引节点文件；文件节点信息结构定义；INodeFileUnderConstruction.java&amp;mdash;- 继承实现类：建立目录索引节点文件；在创建之下的文件节点信息结构定义；JspHelper.java&amp;mdash;- 独立内存类：JSP 实现辅助类；LeaseExpiredException.java&amp;mdash;- 继承实现类：创建的文件已过期异常；LeaseManager.java&amp;mdash;- 独立内存类：LeaseManager 实现了写文件的租赁管理；这个类还提供了租赁恢复的有用的静态方法；契约信息结构定义及实现；ListPathsServlet.java&amp;mdash;- 继承实现类：获取一个文件系统的元信息；MetaRecoveryContext.java&amp;mdash;- 独立内存类：正在进行的名字节点恢复进程的上下文数据；NameCache.java&amp;mdash;- 独立内存类：缓存经常使用的名称以便再用；NameNode.java&amp;mdash;- 继承实现类：名字节点功能管理和实现类；名称节点的核心服务器类；NamenodeFsck.java&amp;mdash;- 独立内存类：这个类提供了 DFS 卷基本的检测；名称节点的系统检测类；NameNodeMXBean.java&amp;mdash;- 接口类：这个类是名字节点信息的 JMX 管理接口；NotReplicatedYetException.java&amp;mdash;- 继承实现类：文件还未赋值异常类；PendingReplicationBlocks.java&amp;mdash;- 独立内存类：这个类 PendingReplicationBlocks 实现了所有快复制的记录；正在复制数据块的信息表定义；PermissionChecker.java&amp;mdash;- 独立内存类：这个类实现了执行权限检查操作；权限检查表结构定义及实现；RenewDelegationTokenServlet.java&amp;mdash;- 继承实现类：续订令牌服务；SafeModeException.java&amp;mdash;- 继承实现类：当名字节点处于安全模式的时候抛出这个异常；客户端不能够修改名字空间直到安全模式关闭；SecondaryNameNode.java&amp;mdash;- 继承实现类：第二名字节点功能的管理和实现类；SerialNumberManager.java&amp;mdash;- 独立内存类：为用户和组管理名称到序列号的映射；StreamFile.java&amp;mdash;- 继承实现类：流文件类的实现；TransferFsImage.java&amp;mdash;- 继承实现类：这个类实现了从名字节点获取一个指定的文件的功能；通过 http 方式来获取文件的镜像信息；UnderReplicatedBlocks.java&amp;mdash;- 继承实现类：复制块的类的实现；复制完成后的块信息表定义；UnsupportedActionException.java&amp;mdash;- 继承实现类：操作不支持的异常；UpgradeManagerNamenode.java&amp;mdash;- 继承实现类：名字节点升级的管理；UpgradeObjectNamenode.java&amp;mdash;- 抽象类：名字节点对象更新类；数据节点的更新运行在单独的线程上；升级名称节点的对象信息；&lt;/p>
&lt;p>hdfs.server.datanode (数据节点的实现)&lt;/p>
&lt;p>BlockAlreadyExistsException.java&amp;mdash;- 继承实现类：目标块已经存在异常；BlockMetadataHeader.java&amp;mdash;- 独立内存类：数据块头部结构定义及实现；BlockReceiver.java&amp;mdash;- 继承实现类：这个类实现了接收一个块并写到自己的磁盘的功能，同时也可以复制它到另外一个磁盘；数据块接收容器信息结构及实现写入到盘中；接收一个数据块，并写到本地的磁盘，同时可能会拷贝到其他的节点上；BlockSender.java&amp;mdash;- 继承实现类：从磁盘读取块，并发送它到接收的目的地；从磁盘中读数据块并发送到相应接收者；BlockTransferThrottler.java&amp;mdash;- 独立内存类：调节数据块的传输；块传送时的调节参数配置表；DataBlockScanner.java&amp;mdash;- 继承实现类：数据块的扫描工具实现；DataBlockScanner 拥有它单独的线程，能定时地从目前 DataNode 管理的数据块文件进行校验；其实最重要的方法就是 verifyBlock；DataBlockScanner 其他的辅助方法用于对 DataBlockScanner 管理的数据块文件信息进行增加 / 删除，排序操作；DataNode.java&amp;mdash;- 继承实现类：数据节点的功能的管理和实现；数据块的核心管理器；DatanodeBlockInfo.java&amp;mdash;- 独立内存类：这个类用于数据节点保持从数据块到它的元数据的映射的功能；建立块文件和其属于哪个 FSVolume 之间的映射关系；DataNodeMXBean.java&amp;mdash;- 接口类：数据节点信息的 JMX 管理接口的实现；DataStorage.java&amp;mdash;- 继承实现类：数据存储信息文件；DataXceiver.java&amp;mdash;- 继承实现类：用于处理输入 / 输出数据流的线程；DataXceiverServer.java&amp;mdash;- 继承实现类：用于接收和发送数据块的服务；FSDataset.java&amp;mdash;- 继承实现类：FSDataset 类实现管理数据块集合的功能；FSDatasetAsyncDiskService.java&amp;mdash;- 独立内存类：这个类实现了每个卷上多个线程池的容器，所以我们能够轻松地调度异步磁盘操作；为每个数据块目录创建一个线程池，并用作为一个线程组，池的最小值为 1，最大值为 4；当前版本，只有 delete 操作会将任务经过线程池调度来进行异步处理，读写操作都是调文件操作同步去执行的；FSDatasetInterface.java&amp;mdash;- 接口类：这是一个接口，这个接口实现了一个数据节点存储块的底层存储；FSDatasetInterface 是 DataNode 对底局存储的抽象；SecureDataNodeStarter.java&amp;mdash;- 继承实现类：这个类实现在一个安全的集群中启动一个数据节点，在启动前需要获得特权资源，并把它们递交给数据节点；UpgradeManagerDatanode.java&amp;mdash;- 继承实现类：这个类实现了数据节点的升级管理；UpgradeObjectDatanode.java&amp;mdash;- 抽象类：这个类是数据节点升级对象的基类；数据节点升级运行在一个单独的线程中；&lt;/p>
&lt;p>hdfs (客户端的实现)&lt;/p>
&lt;p>BlockReader.java&amp;mdash;- 接口类：这个接口供本地和远程块读取共享；BlockReaderLocal.java&amp;mdash;- 继承实现类：本地块读取；ByteRangeInputStream.java&amp;mdash;- 抽象类：为了支持 HTTP 字节流，每次都需要建立一个针对 HTTP 服务的新的连接；ChecksumDistributedFileSystem.java&amp;mdash;- 继承实现类：分布式文件系统检测；DFSClient.java&amp;mdash;- 独立内存类：DFSClient 类能够连接到 Hadoop 文件系统并执行基本的文件操作；DFSConfigKeys.java&amp;mdash;- 继承实现类：这个类包含了 HDFS 中使用的常数；DFSUtil.java&amp;mdash;- 独立内存类：DFS 实用工具；DistributedFileSystem.java&amp;mdash;- 继承实现类：DFS 系统的抽象文件系统实现；分布式文件系统功能的实现；HftpFileSystem.java&amp;mdash;- 继承实现类：通过 HTTP 访问文件系统的协议的执行；采用 HTTP 协议来访问 HDFS 文件；HsftpFileSystem.java&amp;mdash;- 继承实现类：通过 HTTPs 访问文件系统的协议的执行；采用 HTTPs 协议来访问 HDFS 文件；LeaseRenewer.java&amp;mdash;- 独立内存类：更新租赁；&lt;/p>
&lt;p>hdfs.server.namenode.metrics (名字节点上度量数据的收集功能)&lt;/p>
&lt;p>FSNamesystemMBean.java&amp;mdash;- 接口类：这个接口定义了获取一个名字节点的 FSNamesystem 状态的方法；取名称节点的文件状态信息；NameNodeInstrumentation.java&amp;mdash;- 继承实现类：名字节点规范类；&lt;/p>
&lt;p>hdfs.server.datanode.metrics (数据节点上度量数据的收集功能)&lt;/p>
&lt;p>DataNodeInstrumentation.java&amp;mdash;- 继承实现类：数据节点的一些规范；FSDatasetMBean.java&amp;mdash;- 接口类：这个接口中定义了方法来获取一个数据节点的 FSDataset 的状态；数据集的职能定义；&lt;/p>
&lt;ol start="3">
&lt;li>应用包&lt;/li>
&lt;/ol>
&lt;p>包括 hdfs.tools 和 hdfs.server.balancer，这两个包提供查询 HDFS 状态信息工具 dfsadmin、文件系统检查工具 fsck 和 HDFS 均衡器 balancer(通过 start-balancer.sh 启动)的实现。&lt;/p>
&lt;p>hdfs.tools (查询 HDFS 状态信息工具 dfsadmin、文件系统检查工具 fsck 的实现)&lt;/p>
&lt;p>DelegationTokenFetcher.java&amp;mdash;- 独立内存类：这个类实现了从当前的名字节点获取 DelegationToken，并存储它到指定的文件当中；DFSAdmin.java&amp;mdash;- 继承实现类：这个类实现了提供一些 DFS 访问管理；管理员命令的实现；DFSck.java&amp;mdash;- 继承实现类：这个类实现了对 DFS 卷进行基本的检查；文件系统检查命令的实现；HDFSConcat.java&amp;mdash;- 独立内存类：HDFS 串接；&lt;/p>
&lt;p>hdfs.server.balancer ( HDFS 均衡器 balancer 的实现)&lt;/p>
&lt;p>Balancer.java&amp;mdash;- 继承实现类：负载均衡进程，各节点基于他来进行任务量的平衡；balance 是一个工具，用于当一些数据节点全部使用或者有新的节点加入集群的时候，来平衡 HDFS 集群上的磁盘空间使用率；&lt;/p>
&lt;p>4.WebHDFS 相关包&lt;/p>
&lt;p>包括 hdfs.web.resources、hdfs.server.namenode.metrics.web.resources、hdfs.server.datanode.web.resources 和 hdfs.web 共 4 个包。&lt;/p>
&lt;p>WebHDFS 是 HDFS 1.0 中引入的新功能，它提供了一个完整的、通过 HTTP 访问 HDFS 的机制。对比只读的 hftp 文件系统，WebHDFS 提供了 HTTP 上读写 HDFS 的能力，并在此基础上实现了访问 HDFS 的 C 客户端和用户空间文件系统(FUSE )。&lt;/p></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>神经网络 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <atom:link href="https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml" />
    <description>神经网络</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>神经网络</title>
      <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
    </image>
    
    <item>
      <title>丢弃法</title>
      <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E4%B8%A2%E5%BC%83%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E4%B8%A2%E5%BC%83%E6%B3%95/</guid>
      <description>&lt;h1 id=&#34;丢弃法&#34;&gt;丢弃法&lt;/h1&gt;
&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://zh.gluon.ai/chapter_deep-learning-basics/dropout.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://zh.gluon.ai/chapter_deep-learning-basics/dropout.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>多层神经网络</title>
      <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
      <description>&lt;h1 id=&#34;多层神经网络&#34;&gt;多层神经网络&lt;/h1&gt;
&lt;h1 id=&#34;隐藏层&#34;&gt;隐藏层&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>神经网络可视化</title>
      <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96/</guid>
      <description>&lt;h2 id=&#34;tools-to-design-or-visualize-architecture-of-neural-network&#34;&gt;Tools to Design or Visualize Architecture of Neural Network&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gwding/draw_convnet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;draw_convnet&lt;/strong&gt;&lt;/a&gt; : Python script for illustrating Convolutional Neural Network (ConvNet)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/gwding/draw_convnet/master/convnet_fig.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://alexlenail.me/NN-SVG/LeNet.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;NNSVG&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/Q0xOe.png&#34; alt=&#34;AlexNet style&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/K9lmg.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/DlJ8J.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/HarisIqbal88/PlotNeuralNet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PlotNeuralNet&lt;/a&gt;&lt;/strong&gt; : Latex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/17570785/50308846-c2231880-049c-11e9-8763-3daa1024de78.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/17570785/50308873-e2eb6e00-049c-11e9-9587-9da6bdec011b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.tensorflow.org/tensorboard/graphs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tensorboard&lt;/a&gt;&lt;/strong&gt; - TensorBoard’s &lt;strong&gt;Graphs dashboard&lt;/strong&gt; is a powerful tool for examining your TensorFlow model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/zJHpV.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Caffe&lt;/a&gt;&lt;/strong&gt; - In Caffe you can use &lt;a href=&#34;https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;caffe/draw.py&lt;/a&gt; to draw the NetParameter protobuffer:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/5Z1Cb.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://www.mathworks.com/help/nnet/ref/view.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matlab&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/rPpfa.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://transcranial.github.io/keras-js/#/inception-v3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Keras.js&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/vEfTv.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/stared/keras-sequential-ascii/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keras-sequential-ascii&lt;/a&gt;&lt;/strong&gt; - A library for &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Keras&lt;/a&gt; for investigating architectures and parameters of sequential models.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VGG 16 Architecture&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)

              Input   #####      3  224  224
         InputLayer     |   -------------------         0     0.0%
                      #####      3  224  224
      Convolution2D    \|/  -------------------      1792     0.0%
               relu   #####     64  224  224
      Convolution2D    \|/  -------------------     36928     0.0%
               relu   #####     64  224  224
       MaxPooling2D   Y max -------------------         0     0.0%
                      #####     64  112  112
      Convolution2D    \|/  -------------------     73856     0.1%
               relu   #####    128  112  112
      Convolution2D    \|/  -------------------    147584     0.1%
               relu   #####    128  112  112
       MaxPooling2D   Y max -------------------         0     0.0%
                      #####    128   56   56
      Convolution2D    \|/  -------------------    295168     0.2%
               relu   #####    256   56   56
      Convolution2D    \|/  -------------------    590080     0.4%
               relu   #####    256   56   56
      Convolution2D    \|/  -------------------    590080     0.4%
               relu   #####    256   56   56
       MaxPooling2D   Y max -------------------         0     0.0%
                      #####    256   28   28
      Convolution2D    \|/  -------------------   1180160     0.9%
               relu   #####    512   28   28
      Convolution2D    \|/  -------------------   2359808     1.7%
               relu   #####    512   28   28
      Convolution2D    \|/  -------------------   2359808     1.7%
               relu   #####    512   28   28
       MaxPooling2D   Y max -------------------         0     0.0%
                      #####    512   14   14
      Convolution2D    \|/  -------------------   2359808     1.7%
               relu   #####    512   14   14
      Convolution2D    \|/  -------------------   2359808     1.7%
               relu   #####    512   14   14
      Convolution2D    \|/  -------------------   2359808     1.7%
               relu   #####    512   14   14
       MaxPooling2D   Y max -------------------         0     0.0%
                      #####    512    7    7
            Flatten   ||||| -------------------         0     0.0%
                      #####       25088
              Dense   XXXXX ------------------- 102764544    74.3%
               relu   #####        4096
              Dense   XXXXX -------------------  16781312    12.1%
               relu   #####        4096
              Dense   XXXXX -------------------   4097000     3.0%
            softmax   #####        1000
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/lutzroeder/Netron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; Netron &lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/lutzroeder/netron/raw/master/.github/screenshot.png&#34; alt=&#34;screenshot.png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/martisak/dotnets&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DotNet&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/martisak/dotnets/raw/master/test.png&#34; alt=&#34;Simple net&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://www.graphviz.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Graphviz&lt;/strong&gt;&lt;/a&gt; : &lt;strong&gt;&lt;a href=&#34;https://tgmstat.wordpress.com/2013/06/12/draw-neural-network-diagrams-graphviz/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tgmstat.files.wordpress.com/2013/05/multiclass_neural_network_example.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;12&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://keras.io/visualization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Keras Visualization&lt;/a&gt;&lt;/strong&gt; - The &lt;a href=&#34;https://keras.io/visualization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keras.utils.vis_utils module&lt;/a&gt; provides utility functions to plot a Keras model (using graphviz)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/o17GY.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://conx.readthedocs.io/en/latest/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Conx&lt;/a&gt;&lt;/strong&gt; - The Python package &lt;code&gt;conx&lt;/code&gt; can visualize networks with activations with the function &lt;code&gt;net.picture()&lt;/code&gt; to produce SVG, PNG, or PIL Images like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/nhHjO.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://math.mit.edu/ennui/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ENNUI&lt;/a&gt;&lt;/strong&gt; - Working on a drag-and-drop neural network visualizer (and more). Here&amp;rsquo;s an example of a visualization for a LeNet-like architecture.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/pRLeG.png&#34; alt=&#34;A visualization of a LeNet-like architecture&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;&lt;strong&gt;NNet - R Package&lt;/strong&gt; - &lt;strong&gt;&lt;a href=&#34;https://beckmw.wordpress.com/2013/03/04/visualizing-neural-networks-from-the-nnet-package/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;data(infert, package=&amp;#34;datasets&amp;#34;)
plot(neuralnet(case~parity+induced+spontaneous, infert))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;[
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/yyftd.png&#34; alt=&#34;neuralnet&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;](https://&lt;/p&gt;
&lt;ol start=&#34;16&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.graphcore.ai/posts/what-does-machine-learning-look-like&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GraphCore&lt;/a&gt;&lt;/strong&gt; - These approaches are more oriented towards visualizing neural network operation, however, NN architecture is also somewhat visible on the resulting diagrams.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;AlexNet&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.graphcore.ai/hubfs/images/alexnet_label%20logo.jpg&#34; alt=&#34;alexnet_label logo.jpg&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ResNet50&lt;/strong&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.graphcore.ai/hubfs/images/resnet50_label_logo.jpg&#34; alt=&#34;resnet50_label_logo.jpg&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;17&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://wagenaartje.github.io/neataptic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Neataptic&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Neataptic offers flexible neural networks; neurons and synapses can be removed with a single line of code. No fixed architecture is required for neural networks to function at all. This flexibility allows networks to be shaped for your dataset through neuro-evolution, which is done using multiple threads.&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://camo.githubusercontent.com/4326c3f603b828b61fd63d927acca2cfc152773f/68747470733a2f2f692e6779617a6f2e636f6d2f66353636643233363461663433646433613738633839323665643230346135312e706e67&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;18&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://tensorspace.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TensorSpace&lt;/a&gt;&lt;/strong&gt; : TensorSpace is a neural network 3D visualization framework built by TensorFlow.js, Three.js and Tween.js. TensorSpace provides Layer APIs to build deep learning layers, load pre-trained models, and generate a 3D visualization in the browser. By applying TensorSpace API, it is more intuitive to visualize and understand any pre-trained models built by TensorFlow, Keras, TensorFlow.js, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.freecodecamp.org/news/tensorspace-js-a-way-to-3d-visualize-neural-networks-in-browsers-2c0afd7648a8/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/ekF5v.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://dgschwend.github.io/netscope/quickstart.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Netscope CNN Analyzer&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://i.stack.imgur.com/VVDsg.png&#34; alt=&#34;enter image description here&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;20&#34;&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/mlajtos/moniel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monial&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Interactive Notation for Computational Graphs &lt;a href=&#34;https://mlajtos.github.io/moniel/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mlajtos.github.io/moniel/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://miro.medium.com/max/819/1*u6uIQF4xTVe-ylJnAPoIDg.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol start=&#34;21&#34;&gt;
&lt;li&gt;&lt;a href=&#34;http://www.texample.net/tikz/examples/neural-network/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Texample&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://www.texample.net/media/tikz/examples/PNG/neural-network.png&#34; alt=&#34;Neural network&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;\documentclass{article}

\usepackage{tikz}
\begin{document}
\pagestyle{empty}

\def\layersep{2.5cm}

\begin{tikzpicture}[shorten &amp;gt;=1pt,-&amp;gt;,draw=black!50, node distance=\layersep]
    \tikzstyle{every pin edge}=[&amp;lt;-,shorten &amp;lt;=1pt]
    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
    \tikzstyle{input neuron}=[neuron, fill=green!50];
    \tikzstyle{output neuron}=[neuron, fill=red!50];
    \tikzstyle{hidden neuron}=[neuron, fill=blue!50];
    \tikzstyle{annot} = [text width=4em, text centered]

    % Draw the input layer nodes
    \foreach \name / \y in {1,...,4}
    % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
        \node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};

    % Draw the hidden layer nodes
    \foreach \name / \y in {1,...,5}
        \path[yshift=0.5cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {};

    % Draw the output layer node
    \node[output neuron,pin={[pin edge={-&amp;gt;}]right:Output}, right of=H-3] (O) {};

    % Connect every node in the input layer with every node in the
    % hidden layer.
    \foreach \source in {1,...,4}
        \foreach \dest in {1,...,5}
            \path (I-\source) edge (H-\dest);

    % Connect every node in the hidden layer with the output layer
    \foreach \source in {1,...,5}
        \path (H-\source) edge (O);

    % Annotate the layers
    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot,left of=hl] {Input layer};
    \node[annot,right of=hl] {Output layer};
\end{tikzpicture}
% End of code
\end{document}
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;22&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keplr-io/quiver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Quiver&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/5866348/20253975/f3d56f14-a9e4-11e6-9693-9873a18df5d3.gif&#34; alt=&#34;gzqll3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References :&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://datascience.stackexchange.com/questions/2670/visualizing-deep-neural-network-training&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://datascience.stackexchange.com/questions/2670/visualizing-deep-neural-network-training&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>正向传播与反向传播</title>
      <link>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/deeplearning-series/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</guid>
      <description>&lt;h1 id=&#34;正向传播与反向传播&#34;&gt;正向传播与反向传播&lt;/h1&gt;
&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://zh.gluon.ai/chapter_deep-learning-basics/backprop.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://zh.gluon.ai/chapter_deep-learning-basics/backprop.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>01.存储管理 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</link>
      <atom:link href="https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <description>01.存储管理</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>01.存储管理</title>
      <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</link>
    </image>
    
    <item>
      <title>高速缓存</title>
      <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</guid>
      <description>&lt;h1 id=&#34;高速缓存&#34;&gt;高速缓存&lt;/h1&gt;
&lt;h1 id=&#34;程序访问的局部性&#34;&gt;程序访问的局部性&lt;/h1&gt;
&lt;p&gt;最早期的计算机，在执行一段程序时，都是把硬盘中的数据加载到内存，然后 CPU 从内存中取出代码和数据执行，在把计算结果写入内存，最终输出结果。随着程序运行越来越多，就发现一个规律：内存中某个地址被访问后，短时间内还有可能继续访问这块地址。内存中的某个地址被访问后，它相邻的内存单元被访问的概率也很大。&lt;/p&gt;
&lt;p&gt;人们发现的这种规律被称为程序访问的局部性。程序访问的局部性包含 2 种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时间局部性：某个内存单元在较短时间内很可能被再次访问&lt;/li&gt;
&lt;li&gt;空间局部性：某个内存单元被访问后相邻的内存单元较短时间内很可能被访问&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;出现这种情况的原因很简单，因为程序是指令和数据组成的，指令在内存中按顺序存放且地址连续，如果运行一段循环程序或调用一个方法，又或者再程序中遍历一个数组，都有可能符合上面提到的局部性原理。那既然在执行程序时，内存的某些单元很可能会经常的访问或写入，那可否在 CPU 和内存之间，加一个缓存，CPU 在访问数据时，先看一下缓存中是否存在，如果有直接就读取缓存中的数据即可。如果缓存中不存在，再从内存中读取数据。&lt;/p&gt;
&lt;p&gt;事实证明利用这种方式，程序的运行效率会提高 90%以上，这个缓存也叫做高速缓存 Cache。&lt;/p&gt;
&lt;h2 id=&#34;缓存详解&#34;&gt;缓存详解&lt;/h2&gt;
&lt;p&gt;缓存是 CPU 体系结构中最重要的元素之一。要编写高效的代码，开发人员需要了解其系统中的缓存如何工作。高速缓存是较慢的主系统内存的非常快的副本。高速缓存比主存储器要小得多，因为它与寄存器和处理器逻辑一起包含在处理器芯片内。从计算的角度来看，这是主要的房地产，并且其最大大小在经济和物理上都有限制。随着制造商发现越来越多的方法将越来越多的晶体管填充到芯片中，高速缓存的大小已大大增加，但是即使最大的高速缓存也只有几十兆字节，而不是主存储器的千兆字节或硬盘的数兆字节。&lt;/p&gt;
&lt;p&gt;缓存由镜像主内存的小块组成。这些块的大小称为行大小，通常为 32 或 64 字节。在谈论缓存时，谈论行大小或缓存行是很常见的事，它指的是镜像主内存的一块。高速缓存只能以高速缓存行的倍数加载和存储内存。缓存具有自己的层次结构，通常称为 L1，L2 和 L3。L1 高速缓存是最快和最小的；L2 更大，更慢，L3 更大，更慢。&lt;/p&gt;
&lt;p&gt;L1 缓存通常进一步分为指令缓存和数据，在引入中继的基于哈佛 Mark-1 的计算机之后被称为“哈佛架构”。拆分缓存有助于减少流水线瓶颈，因为较早的流水线阶段倾向于引用指令缓存，而较后的阶段则倾向于数据缓存。除了减少对共享资源的争用之外，为指令提供单独的缓存还允许使用指令流性质的替代实现。它们是只读的，因此不需要昂贵的片上功能（例如多端口），也不需要处理子块读取操作，因为指令流通常使用更常规大小的访问。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/01/27/1nssG6.png&#34; alt=&#34;Cache Associativity&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在正常操作期间，处理器会不断要求高速缓存检查高速缓存中是否存储了特定的地址，因此高速缓存需要某种方法来非常快速地查找其是否存在有效行。如果可以将给定地址缓存在缓存中的任何位置，则每次进行引用以确定命中或未命中时都需要搜索每个缓存行。为了保持快速搜索，这是在高速缓存硬件中并行完成的，但是对于合理大小的高速缓存而言，搜索每个条目通常过于昂贵。因此，可以通过限制特定地址必须驻留的位置来简化缓存。这是一个权衡；高速缓存显然比系统内存小得多，因此某些地址必须别名。如果两个彼此互为别名的地址一直在不断更新，则它们将争用缓存行。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;直接映射的缓存（Direct mapped caches）将允许缓存行仅存在于缓存中的单个条目中。这是最简单的在硬件中实现的方法，由于两个阴影地址必须共享同一条缓存行，因此无法避免混淆现象。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;完全关联高速缓存（Fully Associative caches）将允许高速缓存行存在于高速缓存的任何条目中。由于可以使用任何条目，因此可以避免别名问题。但是在硬件中实现非常昂贵，因为必须同时查找每个可能的位置以确定值是否在缓存中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;集合关联缓存（Set Associative caches）是直接关联和完全关联缓存的混合，并且允许特定的缓存值存在于缓存内的某些行子集中。高速缓存被划分为偶数部分，称为方式，并且可以以任何方式定位特定地址。因此，n 路集关联缓存将允许在行大小为 set n 的总块 mod n 中的任何条目中存在一条缓存行。上图中“缓存关联性”显示了一个示例的 8 元素，4 路集关联缓存。在这种情况下，这两个地址具有四个可能的位置，这意味着在查找时仅必须搜索一半的缓存。方式越多，可能的位置就越多，混淆现象就越少，从而导致总体上更好的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一旦缓存已满，处理器就需要清除一行来为新行腾出空间，处理器可以通过多种算法选择逐出哪条线。例如，最近最少使用（LRU）是一种算法，其中丢弃最旧的未使用的行以为新行腾出空间。当仅从高速缓存中读取数据时，无需确保与主内存的一致性。但是，当处理器开始写入高速缓存行时，它需要就如何更新底层主内存做出一些决定。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;直写式高速缓存（Write-through）将在处理器更新高速缓存时将更改直接写入主系统内存。这是较慢的，因为如我们所见，写入主存储器的过程较慢。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回写缓存（Write-back）会将更改延迟写入 RAM，直到绝对必要为止。明显的优点是，写入缓存条目时需要较少的主存储器访问。已写入但未提交给内存的缓存行称为脏行。缺点是，当退出缓存条目时，它可能需要两次内存访问（一次写入脏数据主内存，另一次加载新数据）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果一个条目同时存在于较高级别和较低级别的高速缓存中，则我们说较高级别的高速缓存是 Inclusive；否则，如果具有一行的较高级别的高速缓存消除了具有该行的较低级别的高速缓存的可能性，我们说它是排他的（Exclusive）。&lt;/p&gt;
&lt;h2 id=&#34;缓存寻址&#34;&gt;缓存寻址&lt;/h2&gt;
&lt;p&gt;到目前为止，我们还没有讨论过缓存如何确定给定地址是否驻留在缓存中。显然，高速缓存必须保留当前驻留在高速缓存行中的数据的目录。缓存目录和数据可能位于同一处理器上，但也可能是分开的，例如在具有核心 L3 目录的 POWER5 处理器的情况下，但是实际上访问数据需要遍历 L3 总线才能访问 核心内存。这样的安排可以促进更快的命中/未命中处理，而不会产生将整个缓存保留在内核中的其他成本。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/01/27/1n67Dg.png&#34; alt=&#34;Cache tags&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;需要并行检查标签以降低等待时间。更多的标记位（即，较少的设置关联性）需要更复杂的硬件来实现。另外，更多的集合关联性意味着更少的标签，但是处理器现在需要硬件来多路复用许多集合的输出，这也可能增加延迟。&lt;/p&gt;
&lt;p&gt;为了快速确定地址是否位于缓存中，将其分为三个部分：标签，索引和偏移量。偏移位取决于高速缓存的行大小。例如，一个 32 字节的行大小将使用地址的最后 5 位（即 25）作为行的偏移量。索引是一个条目可能驻留的特定缓存行。例如，让我们考虑一个具有 256 个条目的缓存。如果这是一个直接映射的缓存，我们知道数据可能仅驻留在一条可能的行中，因此偏移量后的下一个 8 位（28）描述了要检查的行-0 到 255 之间。&lt;/p&gt;
&lt;p&gt;现在，考虑相同的 256 元素高速缓存，但是分为两种方式。这意味着有两组 128 行，并且给定地址可以位于这两个组中的任何一个中。因此，仅需要 7 位作为索引即可偏移到 128 个条目的路径中。对于给定的高速缓存大小，随着方法数量的增加，由于每种方法都会变小，因此减少了作为索引所需的位数。高速缓存目录仍然需要检查高速缓存中存储的特定地址是否是它感兴趣的那个地址。因此，该地址的其余位是高速缓存目录对照传入的地址标记位进行检查以确定是否存在标记位。缓存命中与否。“缓存标签”中说明了这种关系。&lt;/p&gt;
&lt;p&gt;当存在多种方式时，此检查必须在每种方式中并行进行，然后将其结果传递到多路复用器，该多路复用器输出最终的命中或未命中结果。如上所述，高速缓存的关联性越高，索引所需的位越少，而标记位则越多-到完全关联的高速缓存的极端（其中没有位用作索引位）。标签位的并行匹配是高速缓存设计的昂贵组件，并且通常是高速缓存可以增长多少行（即，多大）的限制因素。&lt;/p&gt;
&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kaito-kidd.com/2018/08/23/computer-system-cpu-cache/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://kaito-kidd.com/2018/08/23/computer-system-cpu-cache/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>内存寻址</title>
      <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%AF%BB%E5%9D%80/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%AF%BB%E5%9D%80/</guid>
      <description>&lt;h1 id=&#34;内存寻址&#34;&gt;内存寻址&lt;/h1&gt;
&lt;p&gt;一个应用程序(源程序)经编译后，通常会形成若干个目标程序；这些目标程序再经过链接便形成了可装入程序。这些程序的地址都是从“0”开始的，程序中的其它地址都是相对于起始地址计算的。由这些地址所形成的地址范围称为“地址空间”，其中的地址称为“逻辑地址”或“相对地址”。此外，由内存中的一系列单元所限定的地址范围称为“内存空间”，其中的地址称为“物理地址”。在多道程序环境下，每道程序不可能都从“0”地址开始装入(内存)，这就致使地址空间内的逻辑地址和内存空间中的物理地址不相一致。为使程序能正确运行，存储器管理必须提供地址映射功能，以将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。该功能应在硬件的支持下完成。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>物理内存分配与回收</title>
      <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6/</guid>
      <description>&lt;h1 id=&#34;物理内存分配与回收&#34;&gt;物理内存分配与回收&lt;/h1&gt;
&lt;h1 id=&#34;swap-分区&#34;&gt;Swap 分区&lt;/h1&gt;
&lt;p&gt;Linux 内核为了提高读写效率与速度，会将文件在内存中进行缓存，这部分内存就是 Cache Memory(缓存内存)。即使你的程序运行结束后，Cache Memory 也不会自动释放。这就会导致你在 Linux 系统中程序频繁读写文件后，你会发现可用物理内存变少。&lt;/p&gt;
&lt;p&gt;当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到 Swap 空间中，等到那些程序要运行时，再从 Swap 分区中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行 Swap 交换。&lt;/p&gt;
&lt;p&gt;系统的 Swap 分区大小设置多大才是最优，只能有一个统一的参考标准，具体还应该根据系统实际情况和内存的负荷综合考虑，像 ORACLE 的官方文档就推荐如下设置，这个是根据物理内存来做参考的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4G 以内的物理内存，SWAP 设置为内存的 2 倍。&lt;/li&gt;
&lt;li&gt;4 ~ 8G 的物理内存，SWAP 等于内存大小。&lt;/li&gt;
&lt;li&gt;8 ~ 64G 的物理内存，SWAP 设置为 8G。&lt;/li&gt;
&lt;li&gt;64 ~ 256G 物理内存，SWAP 设置为 16G。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以使用 &lt;code&gt;swapon -s&lt;/code&gt; 释放 Swap 分区，使用 swapoff 关闭交换分区，使用 swapon 启用交换分区，此时查看交换分区的使用情况，你会发现 used 为 0 了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>虚拟存储管理</title>
      <link>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/linux-notes/02.%E5%AD%98%E5%82%A8/01.%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;虚拟存储管理&#34;&gt;虚拟存储管理&lt;/h1&gt;
&lt;p&gt;在&lt;a href=&#34;https://parg.co/Z47&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;存储管理&lt;/a&gt;一节中我们介绍了计算机系统中常见的存储类型与管理方式，本章则是对于虚拟存储管理相关的内容进行详细介绍。&lt;/p&gt;
&lt;p&gt;虚拟存储器是基于程序局部性原理上的一种假想的而不是物理存在的存储器，允许用户程序以逻辑地址来寻址，而不必考虑物理上可获得的内存大小。这种将物理空间和逻辑空间分开编址但又统一管理和使用的技术为用户编程提供了极大方便，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。此时，用户作业空间称虚拟地址空间，其中的地址称虚地址。&lt;/p&gt;
&lt;p&gt;虚拟存储器的容量由计算机的地址结构和辅助存储器的容量决定，建立在离散分配的存储管理方式的基础上，它允许将一个作业分多次调入内存。Linux 内存管理的设计充分利用了计算机系统所提供的虚拟存储技术，真正实现了虚拟存储器管理，其关注于程序编译链接后形成的地址空间管理、如何将虚地址转化为物理地址等方面。&lt;/p&gt;
&lt;p&gt;从进程的视角来看，其虚拟地址空间最上面的区域是为操作系统中的代码和数据保留的，这对所有进程来说都是一样的。地址空间的底部区域存放用户进程定义的代码和数据。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://user-images.githubusercontent.com/5803001/52272019-52032000-2980-11e9-953c-89de286e5174.png&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&#34;虚拟内存内核空间和用户空间&#34;&gt;虚拟内存、内核空间和用户空间&lt;/h1&gt;
&lt;p&gt;Linux 简化了分段机制，使得虚地址与线性地址总是一致的；系统将虚拟地址分为两部分：一部分专门给系统内核使用，另一部分给用户进程使用。对于 32 位的系统，虚拟地址范围是 0x00000000 ~ 0xFFFFFFFF，即最大虚拟内存为 2^32 Bytes = 4GB，系统将最高的 1G 字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF）分配内核使用，此区域称作内核空间；另外将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://assets.ng-tech.icu/item/20230430222956.png&#34; alt=&#34;内存地址与核空间&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;因为每个进程可以通过系统调用进入内核，因此, Linux 内核空间由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4GB 的虚拟地址空间（也叫虚拟内存）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内核空间：系统内核使用的内存空间，当一个进程执行调用系统命令(例如 read, write)时，会进入内核代码的执行，进程此时的状态我们称之为内核态。&lt;/li&gt;
&lt;li&gt;用户空间：用户进程使用的内存空间，当一个进程执行用户自己的代码时，该进程此时的状态为用户态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;任意一个时刻,在一个 CPU 上只有一个进程在运行。所以对于此 CPU 来讲,在这时刻,整个系统只存在一个 4GB 的虚拟地址空间,这个虚拟地址空间是面向此进程的。当进程发生切换的时候,虚拟地址空间也随着切换。Linux 为每一个进程都建立其页表,将每个进程的虚拟地址空间根据自己的需要映射到物理地址空间上。既然某一时刻在某一 CPU 上只能有个进程在运行,那么当进程发生切换的时候,将页表也更换为相应进程的页表,这就可以实现每个进程都有自己的虚拟地址空间而互不影响。所以,在任意时刻对于一个 CPU 来说,只需要有当前进程的页表,就可以实现其虚拟地址到物理地址的转化。&lt;/p&gt;
&lt;p&gt;虽然内核空间占据了每个虚拟空间中的最高 1GB,但映射到物理内存却总是从最低的地址(0x0000000)开始的,以方便在内核空间与物理内存之间建立起简单的线性映射关系。其中,3GB(0xC000000)就是物理地址与虚拟地址之间的位移量,在 Linux 代码中就叫做 &lt;code&gt;PAGE_OFFSET&lt;/code&gt;。&lt;/p&gt;
&lt;h1 id=&#34;分页式管理&#34;&gt;分页式管理&lt;/h1&gt;
&lt;p&gt;Linux 采用了分页式虚拟存储系统，当作业被调度投入运行时，并不把作业的程序和数据全部装入主存，而仅仅装入立即使用的那些页面，至少要将作业的第一页信息装入主存，在执行过程中访问到不在主存的页面时，再把它们动态地装入。用得较多的分页式虚拟存储管理是请页式（Demand Paging），当需要执行某条指令或使用某个数据，而发现它们并不在主存时，产生一个缺页中断，系统从辅存中把该指令或数据所在的页面调入内存。&lt;/p&gt;
&lt;p&gt;如前文介绍，每个进程都有 3G 的私有进程空间，所以系统的物理内存无法对这些地址空间进行一一映射，因此内核需要一种机制，把进程地址空间映射到物理内存上。当一个进程请求访问内存时，操作系统通过存储在内核中的进程页表把这个虚拟地址映射到物理地址，如果还没有为这个地址建立页表项，那么操作系统就为这个访问的地址建立页表项。最基本的映射单位是 Page，对应的是页表项 PTE。&lt;/p&gt;
&lt;p&gt;页表是内存管理系统中的数据结构，用于向每个进程提供一致的虚拟地址空间，每个页表项保存的是虚拟地址到物理地址的映射以及一些管理标志。应用进程只能访问虚拟地址，内核必须借助页表和硬件把虚拟地址翻译为对物理地址的访问。页表项和物理地址是多对一的关系，即多个页表项可以对应一个物理页面，因而支持共享内存的实现（几个进程同时共享物理内存）。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3D-Reconstruction | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/02.frontend/10.cg/3d-cv/3d-reconstruction/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/02.frontend/10.cg/3d-cv/3d-reconstruction/index.xml" rel="self" type="application/rss+xml" />
    <description>3D-Reconstruction</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>3D-Reconstruction</title>
      <link>https://ng-tech.icu/books/awesome-lists/02.frontend/10.cg/3d-cv/3d-reconstruction/</link>
    </image>
    
    <item>
      <title>3D-Reconstruction-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/02.frontend/10.cg/3d-cv/3d-reconstruction/3d-reconstruction-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/02.frontend/10.cg/3d-cv/3d-reconstruction/3d-reconstruction-list/</guid>
      <description>&lt;h1 id=&#34;3d-reconstruction-list&#34;&gt;3D Reconstruction List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openMVG/awesome_3DReconstruction_list&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-Awesome 3D reconstruction list üóÉÔ∏è&lt;/a&gt;: A curated list of papers &amp;amp; resources linked to 3D reconstruction from images.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/LiangliangNan/PolyFit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-PolyFit 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/LiangliangNan/PolyFit&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: PolyFit implements the hypothesis and selection based surface reconstruction method described in the following paper.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/danielTobon43/pointcloudToMesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-pointcloudToMesh 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/danielTobon43/pointcloudToMesh&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: C++ application to convert pcd file, ply file, txt file or xyz point cloud to MESH representation (Gp3).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lynetcha/completion3d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-completion3d 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/lynetcha/completion3d&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Source code for baselines of the Stanford 3D Point Cloud Completion Benchmark (completion3d.stanford.edu) and TopNet: Structural Point Cloud Decoder, CVPR 2019&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ranahanocka/Point2Mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2020-Point2Mesh 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/ranahanocka/Point2Mesh&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Point2Mesh is a technique for reconstructing a surface mesh from an input point cloud. This approach &amp;ldquo;learns&amp;rdquo; from a single object, by optimizing the weights of a CNN to deform some initial mesh to shrink-wrap the input point cloud. The argument for going this route is: since the (local) convolutional kernels are optimized globally across the entire shape, this encourages local-scale geometric self-similarity across the reconstructed shape surface.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cvg/pcdmeshing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2021-pcdmeshing 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/cvg/pcdmeshing&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: pcdmeshing is a Python package to reconstruct meshes from point clouds using CGAL.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

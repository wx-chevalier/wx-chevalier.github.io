<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RNN | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/rnn/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/rnn/index.xml" rel="self" type="application/rss+xml" />
    <description>RNN</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>RNN</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/rnn/</link>
    </image>
    
    <item>
      <title>RecurrentNeuralNetwork-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/rnn/recurrentneuralnetwork-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/rnn/recurrentneuralnetwork-list/</guid>
      <description>&lt;h1 id=&#34;recurrent-neural-network-list&#34;&gt;Recurrent Neural Network List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://suriyadeepan.github.io/2017-01-07-unfolding-rnn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-Unfolding RNNs #Series#&lt;/a&gt;: &lt;a href=&#34;http://suriyadeepan.github.io/2017-01-07-unfolding-rnn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RNN : Concepts and Architectures&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/bsS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-RECURRENT NEURAL NETWORKS TUTORIAL&lt;/a&gt;: Recurrent Neural Networks (RNNs) are popular models that have shown great promise in many NLP tasks. But despite their recent popularity I’ve only found a limited number of resources that throughly explain how RNNs work, and how to implement them. That’s what this tutorial is about. It’s a multi-part series in which I’m planning to cover the following.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/bsJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LSTM by Example using TensorFlow&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22930328&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;循环神经网络 RNN 打开手册&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/Dark_Scope/article/details/47056361&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RNN 以及 LSTM 的介绍和公式梳理 &lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kjw0612/awesome-rnn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Recurrent Neural Networks&lt;/a&gt;:Github 上关于 RNN 的资源集锦&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anyone Can Learn To Code an LSTM-RNN in Python&lt;/a&gt;: 简单的以讲解代码为主的 RNN 与 LSTM 入门教程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@camrongodbout/recurrent-neural-networks-for-beginners-7aca4e933b82#.2fl2af7wa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recurrent Neural Networks for Beginners&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/mindorks/understanding-the-recurrent-neural-network-44d593f112a2?source=userActivityShare-fe48c4221a4c-1524115570&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Understanding The Recurrent Neural Network&lt;/a&gt;: What is Recurrent Neural Network (RNN)?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;lstm&#34;&gt;LSTM&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-Understanding LSTM Networks&lt;/a&gt;: 中文版为理解 LSTM 网络。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Notes-Prediction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LSTM NEURAL NETWORK FOR TIME SERIES PREDICTION&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/Uxp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Understanding Long Short-Term Memory Networks (LSTMs)&lt;/a&gt;: This upgraded version of RNNs solved some of the problems that these networks usually have.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

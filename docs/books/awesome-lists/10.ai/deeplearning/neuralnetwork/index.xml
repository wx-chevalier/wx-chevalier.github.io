<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NeuralNetwork | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/neuralnetwork/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/neuralnetwork/index.xml" rel="self" type="application/rss+xml" />
    <description>NeuralNetwork</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>NeuralNetwork</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/neuralnetwork/</link>
    </image>
    
    <item>
      <title>NeuralNetwork-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/neuralnetwork/neuralnetwork-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/deeplearning/neuralnetwork/neuralnetwork-list/</guid>
      <description>&lt;h1 id=&#34;neural-network-list&#34;&gt;Neural Network List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Learning Basics: Neural Networks, Backpropagation and Stochastic Gradient Descent&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.hackcv.com/index.php/archives/104/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[ ç¿»è¯‘ ] ç¥ç»ç½‘ç»œçš„ç›´è§‚è§£é‡Š&lt;/a&gt;: å·ç§¯ç¥ç»ç½‘ç»œçš„è®²è§£éå¸¸é€šä¿—æ˜“æ‡‚ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/bNa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neural networks from scratch for Javascript linguists #Series#&lt;/a&gt;: so letâ€™s go on a journey, Iâ€™ll tell you everything I learned, some misconceptions I had, how to interpret the results, and some basic vocabulary and fun facts along the way.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://m.leiphone.com/news/201703/3qMp45aQtbxTdzmK.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;è°·æ­Œå·¥ç¨‹å¸ˆï¼šèŠä¸€èŠæ·±åº¦å­¦ä¹ çš„ weight initialization&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.3556&amp;amp;rep=rep1&amp;amp;type=pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Beginner&amp;rsquo;s Guide to the Mathematics of Neural Networks&lt;/a&gt;: In this paper I try to describe both the role of mathematics in shaping our understanding of how neural networks operate, and the curious new mathematical concepts generated by our attempts to capture neural networks in equations. My target reader being the non-expert, I will present a biased selection of relatively simple examples of neural network tasks, models and calculations, rather than try to give a full encyclopedic review-like account of the many mathematical developments in this eld.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ConvnetJS demo&lt;/a&gt;: toy 2d classification with 2-layer neural network&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/b2W&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-Build a flexible Neural Network with Backpropagation in Python&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.kdnuggets.com/2016/08/role-activation-function-neural-network.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-What is the Role of the Activation Function in a Neural Network?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://iamtrask.github.io/2015/07/12/basic-python-network/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Neural Network in 11 lines of Python (Part 1)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/maybe2030/p/5597716.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mechine Learning &amp;amp; Algorithm ç¥ç»ç½‘ç»œåŸºç¡€&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://culurciello.github.io/tech/2016/06/04/nets.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neural Network Architectures: ç¥ç»ç½‘ç»œæ¶æ„æ¼”åŒ–æµ…æ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.nafnz3ycy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yes you should understand backprop&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23270674&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;æ·±åº¦å­¦ä¹  &amp;mdash; åå‘ä¼ æ’­çš„å…·ä½“æ¡ˆä¾‹&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=1&amp;amp;sn=3004c425e0d427f4900a182d74bed31d&amp;amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;amp;mpshare=1&amp;amp;scene=23&amp;amp;srcid=1125vMg6l3RZKirGuqd1sVSF#rd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;åŸºç¡€ | ç¥ç»ç½‘ç»œå¿«é€Ÿå…¥é—¨ï¼šä»€ä¹ˆæ˜¯å¤šå±‚æ„ŸçŸ¥å™¨å’Œåå‘ä¼ æ’­ï¼Ÿ&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25110450&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;èŠä¸€èŠæ·±åº¦å­¦ä¹ çš„ activation function&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://iamtrask.github.io/2015/07/12/basic-python-network/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-A Neural Network in 11 lines of Python&lt;/a&gt;: A bare bones neural network implementation to describe the inner workings of backpropagation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://victorzhou.com/blog/intro-to-neural-networks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Machine Learning for Beginners: An Introduction to Neural Networks&lt;/a&gt;: A simple explanation of how they work and how to implement one from scratch in Python.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/karpathy/nn-zero-to-hero&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2022-Neural Networks: Zero to Hero ğŸ¥&lt;/a&gt;: A course on neural networks that starts all the way at the basics. The course is a series of YouTube videos where we code and train neural networks together. The Jupyter notebooks we build in the videos are then captured here inside the lectures directory. Every lecture also has a set of exercises included in the video description. (This may grow into something more respectable).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;back-propagation--åå‘ä¼ æ’­&#34;&gt;Back Propagation | åå‘ä¼ æ’­&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/27239198&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¦‚ä½•ç›´è§‚çš„è§£é‡Š back propagation ç®—æ³•ï¼Ÿå…³æ³¨è€… 1267 è¢«æµè§ˆ 59615&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://karpathy.github.io/neuralnets/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Hacker&amp;rsquo;s guide to Neural Networks&lt;/a&gt;: You might be eager to jump right in and learn about Neural Networks, backpropagation, how they can be applied to datasets in practice, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Coding Neural Networkâ€Šâ€”â€ŠForward Propagation and Backpropagtion&lt;/a&gt;: This post will be the first in a series of posts that cover implementing neural network in numpy including gradient checking, parameter initialization, L2 regularization, dropout.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

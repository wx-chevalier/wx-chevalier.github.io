<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ComputerVision | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/computervision/index.xml" rel="self" type="application/rss+xml" />
    <description>ComputerVision</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>ComputerVision</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/</link>
    </image>
    
    <item>
      <title>ComputerVision-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/computervision-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/computervision-list/</guid>
      <description>&lt;h1 id=&#34;computer-vision-list&#34;&gt;Computer Vision List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kjw0612/awesome-deep-vision&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A curated list of deep learning resources for computer vision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/kLYm3hNFiEXNAlSW3Zaq5g&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-å›¾åƒå¤„ç†ï¼Œè®¡ç®—æœºè§†è§‰å’Œäººå·¥æ™ºèƒ½ä¹‹é—´çš„å·®å¼‚&lt;/a&gt;: å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†å¸®åŠ©ä½ äº†è§£å›¾åƒå¤„ç†ï¼Œè®¡ç®—æœºè§†è§‰å’Œäººå·¥æ™ºèƒ½ä¹‹é—´çš„åŒºåˆ«ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/hPzB0gpbJax3b65nx1Ovdw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-è®¡ç®—æœºè§†è§‰åœ¨åˆ¶é€ ä¸šåº”ç”¨çš„åå¤§æœ€æ–°æ¡ˆä¾‹&lt;/a&gt;: æ˜¨å¤©å‘ç°ä¸€ç¯‡æ–‡ç« ï¼Œåˆ†äº«äº†è®¡ç®—æœºè§†è§‰åœ¨åˆ¶é€ ä¸šåº”ç”¨ä¸­çš„ 10 ä¸ªæ¡ˆä¾‹ï¼Œç‰¹æ­¤è½¬è½½è¿‡æ¥åˆ†äº«ç»™å¤§å®¶ï¼Œå¸Œæœ›å¯¹å¤§å®¶æœ‰å¸®åŠ©ï¼Œæœ‰ç–‘é—®çš„å¯ä»¥åœ¨æ–‡æœ«ç•™è¨€äº’ç›¸äº¤æµï½&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;collection&#34;&gt;Collection&lt;/h2&gt;
&lt;h2 id=&#34;series&#34;&gt;Series&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/computervision-recipes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2020-computervision-recipes #Series#&lt;/a&gt;: Best Practices, code samples, and documentation for Computer Vision.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WZMIAOMIAO/deep-learning-for-image-processing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨æ•™ç¨‹ #Series#&lt;/a&gt;: æœ¬æ•™ç¨‹æ˜¯å¯¹æœ¬äººç ”ç©¶ç”ŸæœŸé—´çš„ç ”ç©¶å†…å®¹è¿›è¡Œæ•´ç†æ€»ç»“ï¼Œæ€»ç»“çš„åŒæ—¶ä¹Ÿå¸Œæœ›èƒ½å¤Ÿå¸®åŠ©æ›´å¤šçš„å°ä¼™ä¼´ã€‚åæœŸå¦‚æœæœ‰å­¦ä¹ åˆ°æ–°çš„çŸ¥è¯†ä¹Ÿä¼šä¸å¤§å®¶ä¸€èµ·åˆ†äº«ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ocr&#34;&gt;OCR&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;2017-Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/DmitryUlyanov/deep-image-prior&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-Deep image prior 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Image restoration with neural networks but without learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/UsP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-How to break a CAPTCHA system in 15 minutes with Machine Learning&lt;/a&gt;: Letâ€™s hack the worldâ€™s most popular Wordpress CAPTCHA Plug-in.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/karandesai-96/digit-classifier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;digit-classifier&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;face-recognition-äººè„¸è¯†åˆ«&#34;&gt;Face Recognition: äººè„¸è¯†åˆ«&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://trackingjs.com/docs.html#introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tracking.js 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Tracking.js å¯ä»¥å±•ç¤ºæ•ˆæœç±»ä¼¼ Kinect æˆ–è€… Wii çš„ä½“æ„Ÿåº”ç”¨ï¼Œä¸”è¯¥ JavaScript åº“ä½“ç§¯å° (~7k)ï¼Œéå¸¸è½»é‡çº§ï¼Œä¸”æ¥å£ç®€æ´ã€‚Tracking.js èƒ½å¤Ÿåœ¨ç§»åŠ¨ Web åº”ç”¨ã€æ¡Œé¢åº”ç”¨ä¸­å·¥ä½œï¼Œç”šè‡³å¯ä»¥å’ŒåŸºäº Node.js çš„æœåŠ¡å™¨è¿›è¡Œé…å¯¹ã€‚å®ƒä¼šç»™æµè§ˆå™¨å¸¦æ¥è®¡ç®—æœºå›¾å½¢å­¦ç®—æ³•å’ŒæŠ€æœ¯ï¼Œå…¶æ‹¥æœ‰åŠŸèƒ½ï¼šè„¸éƒ¨è¯†åˆ« ( æŸä¸ªç‰¹å®šçš„é¢œè‰²æ—¶æˆ–äººç‰© / è„¸åº / èº«ä½“å‡ºç°ç§»åŠ¨çš„æ—¶å€™ )ã€å®æ—¶è‰²å½©è·Ÿè¸ªã€‚å¯¹äº Web å¼€å‘è€Œ è¨€ï¼Œä»¥å‰éœ€è¦é€šè¿‡ C æˆ– C++ çš„æŠ€æœ¯æ‰èƒ½å®ç°ç±»ä¼¼æ•ˆæœã€‚è€Œç°åœ¨ Traking.js æä¾›äº†ä¸€ä¸ª Web ç»„ä»¶ï¼Œå› æ­¤ Web å‰ç«¯å¼€å‘äººå‘˜å¯ä»¥è®¿é—® HTML æ ‡ç­¾ç»„ä»¶ æ¥å®ç°ç±»ä¼¼åŠŸèƒ½ï¼Œè€Œæ— éœ€äº†è§£ JavaScriptï¼Œè¿™æå¤§çš„ç®€åŒ–äº† Web å¼€å‘ã€‚Tracking.js åŒ…æ‹¬ä¸€ä¸ªè‰²å½©è·Ÿè¸ªç®—æ³•å’Œå¯¹è±¡è·Ÿè¸ªç»„ä»¶ï¼Œå®ƒèƒ½ä½¿ Web æµè§ˆå™¨è¯†åˆ«è„¸éƒ¨åŠçœ¼ç›çš„å˜åŒ–ã€‚ä¾‹å¦‚ï¼ŒWeb å‰ç«¯è¿˜å¯ä»¥å¯¹äºç”¨è¿™ä¸ªåŠŸèƒ½ æ¥è®¾ç½®ç”¨æˆ·å¤´åƒï¼Œå¯¹ä¸€äº›ç½‘ç«™è€Œè¨€ï¼Œè¿™ä¹Ÿæ˜¯ä¸ªå¾ˆç‚«çš„åŠŸèƒ½ï¼›åŒæ—¶å¯¹è·Ÿè¸ªçš„è„¸éƒ¨æ•°æ®å’Œåå°æ•°æ®åº“è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œå’Œåé¦ˆç»™ç”¨æˆ·æ›´å¤šæœ‰ç”¨çš„æ•°æ®ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;image-search&#34;&gt;Image Search&lt;/h1&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bryandlee/animegan2-pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;animegan2-pytorch 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: PyTorch implementation of AnimeGANv2.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Object-Detection-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/object-detection-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/object-detection-list/</guid>
      <description>&lt;h1 id=&#34;object-detection-list&#34;&gt;Object Detection List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/move-cursor-with-tensorflow-3727ed5e2795&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Move Your Cursor with Webcam Using TensorFlow Object Detection API&lt;/a&gt;: TensorMouse is a small open source Python application that allows you to move your cursor by moving a random household object (like a cup, apple or banana) in front of webcam and acts as a replacement for computer mouse or trackpad.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.algorithmia.com/deep-dive-into-object-detection-with-open-images-using-tensorflow/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Deep Dive into Object Detection with Open Images, using TensorFlow&lt;/a&gt;: TensorFlowâ€™s Object Detection API and its ability to handle large volumes of data make it a perfect choice, so letâ€™s jump right inâ€¦&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OCR-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/ocr-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/ocr-list/</guid>
      <description>&lt;h1 id=&#34;ocr-list&#34;&gt;OCR List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://leadtools.gcpowertools.com.cn/orders/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LEADTOOLs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/garnele007/SwiftOCR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SwiftOCR&lt;/a&gt;: Fast and simple OCR library written in Swift&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.a9t9.com/2015/02/ocr-online-converter-review.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Best Online OCR Software for Converting Images to Text&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.newocr.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NewOCR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.onlineocr.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OnlineOCR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.gnu.org/software/ocrad/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ocrad&lt;/a&gt;: is an OCR (Optical Character Recognition) program based on a feature extraction method. It reads images in pbm (bitmap), pgm (greyscale) or ppm (color) formats and produces text in byte (8-bit) or UTF-8 formats.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/A9T9/OCR-Benchmark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OCR-Benchmark&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wanghaisheng/awesome-ocr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;awesome-ocr&lt;/a&gt;: A curated list of promising OCR resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;engineering-practices&#34;&gt;Engineering Practices&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.dropbox.com/tech/2018/10/using-machine-learning-to-index-text-from-billions-of-images/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Dropbox-Using machine learning to index text from billions of images&lt;/a&gt;: So now, when a user searches for English text that appears in one of these files, it will show up in the search results. This blog post describes how we built this feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study&lt;/h2&gt;
&lt;h1 id=&#34;resource&#34;&gt;Resource&lt;/h1&gt;
&lt;h2 id=&#34;collection&#34;&gt;Collection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/OXmWLuZR2mzEz7drn4xGDQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-æœ€å…¨ OCR ç›¸å…³èµ„æ–™æ•´ç† ğŸ—ƒï¸&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://my.oschina.net/zhouxiang/blog/161619&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Java ä½¿ç”¨ Tess4J è¿›è¡Œ å›¾ç‰‡æ–‡å­—è¯†åˆ« ç¬”è®°&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OpenCV-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/opencv-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/opencv-list/</guid>
      <description>&lt;h1 id=&#34;opencv-list&#34;&gt;OpenCV List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-LearnOpenCV #Book#&lt;/a&gt;: This repo contains code for Computer Vision, Deep learning, and AI articles shared on our blog LearnOpenCV.com.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>StableDiffusion-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/stablediffusion-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/stablediffusion-list/</guid>
      <description>&lt;h1 id=&#34;stablediffusion-list&#34;&gt;StableDiffusion List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/diffusion-models-class&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugging Face Diffusion Models Course ğŸ¥&lt;/a&gt;: Materials for the Hugging Face Diffusion Models Course.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Diffusion Bee 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/AbdBarho/stable-diffusion-webui-docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stable Diffusion WebUI Docker 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Run Stable Diffusion on your machine with a nice UI without any hassle! This repository provides multiple UIs for you to play around with stable diffusion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.charl-e.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CHARL-E 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: CHARL-E packages Stable Diffusion into a simple app. No complex setup, dependencies, or internet required â€” just download and say what you want to see.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ahrm/UnstableFusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UnstableFusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A Stable Diffusion desktop frontend with inpainting, img2img and more!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lkwq007/stablediffusion-infinity&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stablediffusion-infinity 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Outpainting with Stable Diffusion on an infinite canvas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Diffusion Bee 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/invoke-ai/InvokeAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;InvokeAI 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: This version of Stable Diffusion features a slick WebGUI, an interactive command-line script that combines text2img and img2img functionality in a &amp;ldquo;dream bot&amp;rdquo; style interface, and multiple features and other enhancements. For more info, see the website link below.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GuyTevet/motion-diffusion-model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MDM: Human Motion Diffusion Model 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: The official PyTorch implementation of the paper &amp;ldquo;Human Motion Diffusion Model&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/amotile/stable-diffusion-studio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stable-diffusion-studio 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An animation focused workflow frontend for Stable Diffusion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/JingShing/novelai-colab-ver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;novelai-colab-ver 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: You can use this version to experience how novelai works without a good gpu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/TheLastBen/fast-stable-diffusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fast-stable-diffusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: fast-stable-diffusion colabs, +25-50% speed increase + memory efficient + DreamBooth&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/civitai/civitai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-civitai 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/civitai/civitai&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Our goal with this project is to create a platform where people can share their stable diffusion models (textual inversions, hypernetworks, aesthetic gradients, VAEs, and any other crazy stuff people do to customize their AI generations), collaborate with others to improve them, and learn from each other&amp;rsquo;s work. The platform allows users to create an account, upload their models, and browse models that have been shared by others. Users can also leave comments and feedback on each other&amp;rsquo;s models to facilitate collaboration and knowledge sharing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;showcase&#34;&gt;Showcase&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/KKGo1999/Stable-diffusion-person&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Stable-diffusion-person 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/KKGo1999/Stable-diffusion-person&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: æœ¬æ–‡ä»‹ç»ç”±åŸºäº Stable-diffusion çš„ Chilloutmix æ¨¡å‹ï¼ˆä»¥åŠæœ€æ–°çš„ ControlNetï¼‰ç”Ÿæˆé«˜æ¸…çœŸå®äººåƒçš„æ–¹æ³•åŠ Demoã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/replicate/scribble-diffusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-scribble-diffusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/replicate/scribble-diffusion&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Turn your rough sketch into a refined image using AI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;app&#34;&gt;APP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justjake/Gauss&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2022-Gauss 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/justjake/Gauss&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A Stable Diffusion app for macOS built with SwiftUI and Apple&amp;rsquo;s ml-stable-diffusion CoreML models.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

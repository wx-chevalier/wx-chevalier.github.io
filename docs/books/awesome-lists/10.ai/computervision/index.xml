<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ComputerVision | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/computervision/index.xml" rel="self" type="application/rss+xml" />
    <description>ComputerVision</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>ComputerVision</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/</link>
    </image>
    
    <item>
      <title>ComputerVision-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/computervision-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/computervision-list/</guid>
      <description>&lt;h1 id=&#34;computer-vision-list&#34;&gt;Computer Vision List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kjw0612/awesome-deep-vision&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A curated list of deep learning resources for computer vision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/kLYm3hNFiEXNAlSW3Zaq5g&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-图像处理，计算机视觉和人工智能之间的差异&lt;/a&gt;: 因此，在本文中，我将帮助你了解图像处理，计算机视觉和人工智能之间的区别。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/hPzB0gpbJax3b65nx1Ovdw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-计算机视觉在制造业应用的十大最新案例&lt;/a&gt;: 昨天发现一篇文章，分享了计算机视觉在制造业应用中的 10 个案例，特此转载过来分享给大家，希望对大家有帮助，有疑问的可以在文末留言互相交流～&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;collection&#34;&gt;Collection&lt;/h2&gt;
&lt;h2 id=&#34;series&#34;&gt;Series&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/computervision-recipes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2020-computervision-recipes #Series#&lt;/a&gt;: Best Practices, code samples, and documentation for Computer Vision.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/WZMIAOMIAO/deep-learning-for-image-processing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;深度学习在图像处理中的应用教程 #Series#&lt;/a&gt;: 本教程是对本人研究生期间的研究内容进行整理总结，总结的同时也希望能够帮助更多的小伙伴。后期如果有学习到新的知识也会与大家一起分享。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ocr&#34;&gt;OCR&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;2017-Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/DmitryUlyanov/deep-image-prior&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-Deep image prior 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Image restoration with neural networks but without learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://parg.co/UsP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-How to break a CAPTCHA system in 15 minutes with Machine Learning&lt;/a&gt;: Let’s hack the world’s most popular Wordpress CAPTCHA Plug-in.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/karandesai-96/digit-classifier&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;digit-classifier&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;face-recognition-人脸识别&#34;&gt;Face Recognition: 人脸识别&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://trackingjs.com/docs.html#introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tracking.js 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Tracking.js 可以展示效果类似 Kinect 或者 Wii 的体感应用，且该 JavaScript 库体积小 (~7k)，非常轻量级，且接口简洁。Tracking.js 能够在移动 Web 应用、桌面应用中工作，甚至可以和基于 Node.js 的服务器进行配对。它会给浏览器带来计算机图形学算法和技术，其拥有功能：脸部识别 ( 某个特定的颜色时或人物 / 脸庞 / 身体出现移动的时候 )、实时色彩跟踪。对于 Web 开发而 言，以前需要通过 C 或 C++ 的技术才能实现类似效果。而现在 Traking.js 提供了一个 Web 组件，因此 Web 前端开发人员可以访问 HTML 标签组件 来实现类似功能，而无需了解 JavaScript，这极大的简化了 Web 开发。Tracking.js 包括一个色彩跟踪算法和对象跟踪组件，它能使 Web 浏览器识别脸部及眼睛的变化。例如，Web 前端还可以对于用这个功能 来设置用户头像，对一些网站而言，这也是个很炫的功能；同时对跟踪的脸部数据和后台数据库进行匹配，从而和反馈给用户更多有用的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;image-search&#34;&gt;Image Search&lt;/h1&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bryandlee/animegan2-pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;animegan2-pytorch 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: PyTorch implementation of AnimeGANv2.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Object-Detection-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/object-detection-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/object-detection-list/</guid>
      <description>&lt;h1 id=&#34;object-detection-list&#34;&gt;Object Detection List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/towards-data-science/move-cursor-with-tensorflow-3727ed5e2795&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Move Your Cursor with Webcam Using TensorFlow Object Detection API&lt;/a&gt;: TensorMouse is a small open source Python application that allows you to move your cursor by moving a random household object (like a cup, apple or banana) in front of webcam and acts as a replacement for computer mouse or trackpad.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.algorithmia.com/deep-dive-into-object-detection-with-open-images-using-tensorflow/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Deep Dive into Object Detection with Open Images, using TensorFlow&lt;/a&gt;: TensorFlow’s Object Detection API and its ability to handle large volumes of data make it a perfect choice, so let’s jump right in…&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OCR-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/ocr-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/ocr-list/</guid>
      <description>&lt;h1 id=&#34;ocr-list&#34;&gt;OCR List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://leadtools.gcpowertools.com.cn/orders/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LEADTOOLs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/garnele007/SwiftOCR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SwiftOCR&lt;/a&gt;: Fast and simple OCR library written in Swift&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.a9t9.com/2015/02/ocr-online-converter-review.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Best Online OCR Software for Converting Images to Text&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.newocr.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NewOCR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.onlineocr.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OnlineOCR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.gnu.org/software/ocrad/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ocrad&lt;/a&gt;: is an OCR (Optical Character Recognition) program based on a feature extraction method. It reads images in pbm (bitmap), pgm (greyscale) or ppm (color) formats and produces text in byte (8-bit) or UTF-8 formats.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/A9T9/OCR-Benchmark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OCR-Benchmark&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wanghaisheng/awesome-ocr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;awesome-ocr&lt;/a&gt;: A curated list of promising OCR resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;engineering-practices&#34;&gt;Engineering Practices&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.dropbox.com/tech/2018/10/using-machine-learning-to-index-text-from-billions-of-images/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018-Dropbox-Using machine learning to index text from billions of images&lt;/a&gt;: So now, when a user searches for English text that appears in one of these files, it will show up in the search results. This blog post describes how we built this feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;case-study&#34;&gt;Case Study&lt;/h2&gt;
&lt;h1 id=&#34;resource&#34;&gt;Resource&lt;/h1&gt;
&lt;h2 id=&#34;collection&#34;&gt;Collection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/OXmWLuZR2mzEz7drn4xGDQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2019-最全 OCR 相关资料整理 🗃️&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://my.oschina.net/zhouxiang/blog/161619&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Java 使用 Tess4J 进行 图片文字识别 笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>OpenCV-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/opencv-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/opencv-list/</guid>
      <description>&lt;h1 id=&#34;opencv-list&#34;&gt;OpenCV List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spmallick/learnopencv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2015-LearnOpenCV #Book#&lt;/a&gt;: This repo contains code for Computer Vision, Deep learning, and AI articles shared on our blog LearnOpenCV.com.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>StableDiffusion-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/stablediffusion-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/computervision/stablediffusion-list/</guid>
      <description>&lt;h1 id=&#34;stablediffusion-list&#34;&gt;StableDiffusion List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/diffusion-models-class&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugging Face Diffusion Models Course 🎥&lt;/a&gt;: Materials for the Hugging Face Diffusion Models Course.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Diffusion Bee 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/AbdBarho/stable-diffusion-webui-docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stable Diffusion WebUI Docker 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Run Stable Diffusion on your machine with a nice UI without any hassle! This repository provides multiple UIs for you to play around with stable diffusion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.charl-e.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CHARL-E 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: CHARL-E packages Stable Diffusion into a simple app. No complex setup, dependencies, or internet required — just download and say what you want to see.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ahrm/UnstableFusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UnstableFusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A Stable Diffusion desktop frontend with inpainting, img2img and more!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/lkwq007/stablediffusion-infinity&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stablediffusion-infinity 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Outpainting with Stable Diffusion on an infinite canvas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/divamgupta/diffusionbee-stable-diffusion-ui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Diffusion Bee 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/invoke-ai/InvokeAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;InvokeAI 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: This version of Stable Diffusion features a slick WebGUI, an interactive command-line script that combines text2img and img2img functionality in a &amp;ldquo;dream bot&amp;rdquo; style interface, and multiple features and other enhancements. For more info, see the website link below.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GuyTevet/motion-diffusion-model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MDM: Human Motion Diffusion Model 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: The official PyTorch implementation of the paper &amp;ldquo;Human Motion Diffusion Model&amp;rdquo;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/amotile/stable-diffusion-studio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stable-diffusion-studio 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An animation focused workflow frontend for Stable Diffusion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/JingShing/novelai-colab-ver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;novelai-colab-ver 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: You can use this version to experience how novelai works without a good gpu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/TheLastBen/fast-stable-diffusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fast-stable-diffusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: fast-stable-diffusion colabs, +25-50% speed increase + memory efficient + DreamBooth&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/civitai/civitai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-civitai 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/civitai/civitai&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Our goal with this project is to create a platform where people can share their stable diffusion models (textual inversions, hypernetworks, aesthetic gradients, VAEs, and any other crazy stuff people do to customize their AI generations), collaborate with others to improve them, and learn from each other&amp;rsquo;s work. The platform allows users to create an account, upload their models, and browse models that have been shared by others. Users can also leave comments and feedback on each other&amp;rsquo;s models to facilitate collaboration and knowledge sharing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;showcase&#34;&gt;Showcase&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/KKGo1999/Stable-diffusion-person&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Stable-diffusion-person 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/KKGo1999/Stable-diffusion-person&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: 本文介绍由基于 Stable-diffusion 的 Chilloutmix 模型（以及最新的 ControlNet）生成高清真实人像的方法及 Demo。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/replicate/scribble-diffusion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-scribble-diffusion 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/replicate/scribble-diffusion&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Turn your rough sketch into a refined image using AI.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;app&#34;&gt;APP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justjake/Gauss&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2022-Gauss 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/justjake/Gauss&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A Stable Diffusion app for macOS built with SwiftUI and Apple&amp;rsquo;s ml-stable-diffusion CoreML models.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GradientDescent | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/machinelearning/inference/gradientdescent/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/machinelearning/inference/gradientdescent/index.xml" rel="self" type="application/rss+xml" />
    <description>GradientDescent</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>GradientDescent</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/machinelearning/inference/gradientdescent/</link>
    </image>
    
    <item>
      <title>GradientDescent-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/machinelearning/inference/gradientdescent/gradientdescent-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/machinelearning/inference/gradientdescent/gradientdescent-list/</guid>
      <description>&lt;h1 id=&#34;梯度下降资料索引&#34;&gt;梯度下降资料索引&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://yphuang.github.io/blog/2016/03/17/Gradient-Descent-Algorithm-Implementation-in-Python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gradient-Descent-Algorithm-Implementation-in-Python&lt;/a&gt;: 基于 Python 的梯度下降实现&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/woxincd/article/details/7040944&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;梯度下降法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zm10.sm-tc.cn/?src=http%3A%2F%2Fwww.cnblogs.com%2Feczhou%2Fp%2F3951861.html&amp;amp;uid=66401001ef07d768fb736842d08693a1&amp;amp;hid=2c31dc241f17ed70af5e75a8ea5673f7&amp;amp;pos=5&amp;amp;cid=9&amp;amp;time=1457136762694&amp;amp;from=click&amp;amp;restype=1&amp;amp;pagetype=0000004000000402&amp;amp;bu=structure_web_info&amp;amp;query=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95&amp;amp;mode=&amp;amp;uc_param_str=dnntnwvepffrgibijbprsvpi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;线性回归与梯度下降算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://hbfs.wordpress.com/2012/04/24/introduction-to-gradient-descent/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to Gradient Descent&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/eC8KLrvNK60VYAdtM7N2JQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017-各类的梯度优化&lt;/a&gt;: 本次分享旨在为您提供对不同梯度算法的直观感受，以期会帮助您更好地使用不同的梯度下降算法。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

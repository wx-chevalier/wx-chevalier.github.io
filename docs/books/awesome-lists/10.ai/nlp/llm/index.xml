<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link><atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml"/><description>LLM</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>LLM</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link></image><item><title>GPT-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</guid><description>&lt;h1 id="gpt-list">GPT List&lt;/h1>
&lt;h1 id="resource">Resource&lt;/h1>
&lt;h2 id="course">Course&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/karpathy/ng-video-lecture" target="_blank" rel="noopener">2023-nanogpt-lecture 🎥&lt;/a>: Code created in the Neural Networks: Zero To Hero video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the git log history of it, etc.&lt;/li>
&lt;/ul>
&lt;h1 id="chatgpt">ChatGPT&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/file/d/1UOfN0iB_A0rEGYc2CbYnpIF44FupQn2I/view" target="_blank" rel="noopener">2022-The ChatGPT Cheat Sheet&lt;/a>: This cheat sheet illustrates the diverse abilities of OpenAI’s ChatGPT for developers and content creators to enhance their proficiency in large language model prompting across various domains including media content creation, natural language processing, and programming.&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/jaymody/picoGPT" target="_blank" rel="noopener">2023-picoGPT
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jaymody/picoGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/li>
&lt;/ul></description></item><item><title>LLM-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid><description>&lt;h1 id="llm-list">LLM List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/howl-anderson/unlocking-the-power-of-llms" target="_blank" rel="noopener">2023-使用 Prompts 和 Chains 让 ChatGPT 成为神奇的生产力工具！&lt;/a>: ChatGPT 诞生后，因其非常强大的又难以置信的的能力，得到了非常广泛的关注。用户将 ChatGPT 视作一种有趣且知识渊博的聊天工具。但事实上，使用合适的 Prompts 和 Chains，可以将 ChatGPT 作为一个神奇的生产力工具，能够处理各种各样复杂的任务。本仓库将详细介绍如何使用 ChatGPT 完成各种任务。&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/cfortuner/promptable" target="_blank" rel="noopener">2023-Promptable
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cfortuner/promptable" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/amazon-science/mm-cot" target="_blank" rel="noopener">2023-mm-cot
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/amazon-science/mm-cot" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Prompt-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</guid><description>&lt;h1 id="prompt-list">Prompt List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/prompt-engine" target="_blank" rel="noopener">2022-prompt-engine
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/microsoft/prompt-engine" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Prompt engineering can be as simple as formatting a question and passing it to the model, but it can also get quite complex - requiring substantial code to manipulate and update strings. This library aims to make that easier. It also aims to codify patterns and practices around prompt engineering.&lt;/li>
&lt;/ul></description></item></channel></rss>
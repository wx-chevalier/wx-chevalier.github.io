<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link><atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml"/><description>LLM</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>LLM</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link></image><item><title>GPT-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</guid><description>&lt;h1 id="gpt-list">GPT List&lt;/h1>
&lt;h1 id="resource">Resource&lt;/h1>
&lt;h2 id="course">Course&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/karpathy/ng-video-lecture" target="_blank" rel="noopener">2023-nanogpt-lecture 🎥&lt;/a>: Code created in the Neural Networks: Zero To Hero video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the git log history of it, etc.&lt;/li>
&lt;/ul>
&lt;h1 id="chatgpt">ChatGPT&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/file/d/1UOfN0iB_A0rEGYc2CbYnpIF44FupQn2I/view" target="_blank" rel="noopener">2022-The ChatGPT Cheat Sheet&lt;/a>: This cheat sheet illustrates the diverse abilities of OpenAI’s ChatGPT for developers and content creators to enhance their proficiency in large language model prompting across various domains including media content creation, natural language processing, and programming.&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/jaymody/picoGPT" target="_blank" rel="noopener">2023-picoGPT
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jaymody/picoGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/li>
&lt;/ul></description></item><item><title>LLM-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid><description>&lt;h1 id="llm-list">LLM List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/howl-anderson/unlocking-the-power-of-llms" target="_blank" rel="noopener">2023-使用 Prompts 和 Chains 让 ChatGPT 成为神奇的生产力工具！&lt;/a>: ChatGPT 诞生后，因其非常强大的又难以置信的的能力，得到了非常广泛的关注。用户将 ChatGPT 视作一种有趣且知识渊博的聊天工具。但事实上，使用合适的 Prompts 和 Chains，可以将 ChatGPT 作为一个神奇的生产力工具，能够处理各种各样复杂的任务。本仓库将详细介绍如何使用 ChatGPT 完成各种任务。&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/cfortuner/promptable" target="_blank" rel="noopener">2023-Promptable
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cfortuner/promptable" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/amazon-science/mm-cot" target="_blank" rel="noopener">2023-mm-cot
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/amazon-science/mm-cot" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener">2023-LangChains
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/hwchase17/langchain" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/logspace-ai/langflow" target="_blank" rel="noopener">LangFlow
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/logspace-ai/langflow" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: ⛓️ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="chatgpt">ChatGPT&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/GanymedeNil/document.ai" target="_blank" rel="noopener">2023-document.ai
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/GanymedeNil/document.ai" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: 基于向量数据库与 GPT3.5 的通用本地知识库方案(A universal local knowledge base solution based on vector database and GPT3.5)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/acheong08/EdgeGPT" target="_blank" rel="noopener">2023-EdgeGPT
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/acheong08/EdgeGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: The reverse engineering the chat feature of the new version of Bing.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="chatglm">ChatGLM&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">2023-ChatGLM-6B
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/THUDM/ChatGLM-6B" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。&lt;/li>
&lt;/ul>
&lt;h2 id="llama">Llama&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/shawwn/llama-dl" target="_blank" rel="noopener">2023-llama-dl
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/shawwn/llama-dl" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: High-speed download of LLaMA, Facebook&amp;rsquo;s 65B parameter GPT model&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/jerryjliu/llama_index" target="_blank" rel="noopener">2023-LlamaIndex
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jerryjliu/llama_index" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM&amp;rsquo;s with external data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/cocktailpeanut/dalai" target="_blank" rel="noopener">2023-dalai
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cocktailpeanut/dalai" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: The simplest way to run LLaMA on your local machine&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/antimatter15/alpaca.cpp" target="_blank" rel="noopener">2023-Alpaca.cpp
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/antimatter15/alpaca.cpp" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Run a fast ChatGPT-like model locally on your device. The screencast below is not sped up and running on an M2 Macbook Air with 4GB of weights.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/Alpaca-LoRA" target="_blank" rel="noopener">2023-Alpaca-LoRA
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/Alpaca-LoRA" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Instruct-tuning LLaMA on consumer hardware.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/setzer22/llama-rs" target="_blank" rel="noopener">2023-llama-rs
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/setzer22/llama-rs" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: LLaMA-rs is a Rust port of the llama.cpp project. This allows running inference for Facebook&amp;rsquo;s LLaMA model on a CPU with good performance using full precision, f16 or 4-bit quantized versions of the model.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Prompt-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</guid><description>&lt;h1 id="prompt-list">Prompt List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/prompt-engine" target="_blank" rel="noopener">2022-prompt-engine
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/microsoft/prompt-engine" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Prompt engineering can be as simple as formatting a question and passing it to the model, but it can also get quite complex - requiring substantial code to manipulate and update strings. This library aims to make that easier. It also aims to codify patterns and practices around prompt engineering.&lt;/li>
&lt;/ul></description></item></channel></rss>
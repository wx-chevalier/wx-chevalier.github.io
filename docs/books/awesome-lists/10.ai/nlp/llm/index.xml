<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link><atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml"/><description>LLM</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>LLM</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link></image><item><title>GPT-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</guid><description>&lt;h1 id="gpt-list">GPT List&lt;/h1>
&lt;h1 id="resource">Resource&lt;/h1>
&lt;h2 id="course">Course&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/karpathy/ng-video-lecture" target="_blank" rel="noopener">2023-nanogpt-lecture ðŸŽ¥&lt;/a>: Code created in the Neural Networks: Zero To Hero video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the git log history of it, etc.&lt;/li>
&lt;/ul>
&lt;h1 id="chatgpt">ChatGPT&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/file/d/1UOfN0iB_A0rEGYc2CbYnpIF44FupQn2I/view" target="_blank" rel="noopener">2022-The ChatGPT Cheat Sheet&lt;/a>: This cheat sheet illustrates the diverse abilities of OpenAIâ€™s ChatGPT for developers and content creators to enhance their proficiency in large language model prompting across various domains including media content creation, natural language processing, and programming.&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/jaymody/picoGPT" target="_blank" rel="noopener">2023-picoGPT
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jaymody/picoGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/li>
&lt;/ul></description></item><item><title>LLM-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid><description>&lt;h1 id="llm-list">LLM List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/howl-anderson/unlocking-the-power-of-llms" target="_blank" rel="noopener">2023-ä½¿ç”¨ Prompts å’Œ Chains è®© ChatGPT æˆä¸ºç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼&lt;/a>: ChatGPT è¯žç”ŸåŽï¼Œå› å…¶éžå¸¸å¼ºå¤§çš„åˆéš¾ä»¥ç½®ä¿¡çš„çš„èƒ½åŠ›ï¼Œå¾—åˆ°äº†éžå¸¸å¹¿æ³›çš„å…³æ³¨ã€‚ç”¨æˆ·å°† ChatGPT è§†ä½œä¸€ç§æœ‰è¶£ä¸”çŸ¥è¯†æ¸Šåšçš„èŠå¤©å·¥å…·ã€‚ä½†äº‹å®žä¸Šï¼Œä½¿ç”¨åˆé€‚çš„ Prompts å’Œ Chainsï¼Œå¯ä»¥å°† ChatGPT ä½œä¸ºä¸€ä¸ªç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§å„æ ·å¤æ‚çš„ä»»åŠ¡ã€‚æœ¬ä»“åº“å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ ChatGPT å®Œæˆå„ç§ä»»åŠ¡ã€‚&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/cfortuner/promptable" target="_blank" rel="noopener">2023-Promptable
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cfortuner/promptable" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/amazon-science/mm-cot" target="_blank" rel="noopener">2023-mm-cot
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/amazon-science/mm-cot" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Prompt-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</guid><description>&lt;h1 id="prompt-list">Prompt List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/prompt-engine" target="_blank" rel="noopener">2022-prompt-engine
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/microsoft/prompt-engine" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Prompt engineering can be as simple as formatting a question and passing it to the model, but it can also get quite complex - requiring substantial code to manipulate and update strings. This library aims to make that easier. It also aims to codify patterns and practices around prompt engineering.&lt;/li>
&lt;/ul></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link><atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml"/><description>LLM</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>LLM</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link></image><item><title>GPT-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</guid><description>&lt;h1 id="gpt-list">GPT List&lt;/h1>
&lt;h1 id="resource">Resource&lt;/h1>
&lt;h2 id="course">Course&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/karpathy/ng-video-lecture" target="_blank" rel="noopener">2023-nanogpt-lecture ðŸŽ¥&lt;/a>: Code created in the Neural Networks: Zero To Hero video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the git log history of it, etc.&lt;/li>
&lt;/ul>
&lt;h1 id="chatgpt">ChatGPT&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/file/d/1UOfN0iB_A0rEGYc2CbYnpIF44FupQn2I/view" target="_blank" rel="noopener">2022-The ChatGPT Cheat Sheet&lt;/a>: This cheat sheet illustrates the diverse abilities of OpenAIâ€™s ChatGPT for developers and content creators to enhance their proficiency in large language model prompting across various domains including media content creation, natural language processing, and programming.&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/jaymody/picoGPT" target="_blank" rel="noopener">2023-picoGPT
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jaymody/picoGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/li>
&lt;/ul></description></item><item><title>LLM-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid><description>&lt;h1 id="llm-list">LLM List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/howl-anderson/unlocking-the-power-of-llms" target="_blank" rel="noopener">2023-ä½¿ç”¨ Prompts å’Œ Chains è®© ChatGPT æˆä¸ºç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼&lt;/a>: ChatGPT è¯žç”ŸåŽï¼Œå› å…¶éžå¸¸å¼ºå¤§çš„åˆéš¾ä»¥ç½®ä¿¡çš„çš„èƒ½åŠ›ï¼Œå¾—åˆ°äº†éžå¸¸å¹¿æ³›çš„å…³æ³¨ã€‚ç”¨æˆ·å°† ChatGPT è§†ä½œä¸€ç§æœ‰è¶£ä¸”çŸ¥è¯†æ¸Šåšçš„èŠå¤©å·¥å…·ã€‚ä½†äº‹å®žä¸Šï¼Œä½¿ç”¨åˆé€‚çš„ Prompts å’Œ Chainsï¼Œå¯ä»¥å°† ChatGPT ä½œä¸ºä¸€ä¸ªç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§å„æ ·å¤æ‚çš„ä»»åŠ¡ã€‚æœ¬ä»“åº“å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ ChatGPT å®Œæˆå„ç§ä»»åŠ¡ã€‚&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/cfortuner/promptable" target="_blank" rel="noopener">2023-Promptable
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cfortuner/promptable" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/amazon-science/mm-cot" target="_blank" rel="noopener">2023-mm-cot
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/amazon-science/mm-cot" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener">2023-LangChains
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/hwchase17/langchain" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/logspace-ai/langflow" target="_blank" rel="noopener">LangFlow
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/logspace-ai/langflow" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: â›“ï¸ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="chatgpt">ChatGPT&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/GanymedeNil/document.ai" target="_blank" rel="noopener">2023-document.ai
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/GanymedeNil/document.ai" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: åŸºäºŽå‘é‡æ•°æ®åº“ä¸Ž GPT3.5 çš„é€šç”¨æœ¬åœ°çŸ¥è¯†åº“æ–¹æ¡ˆ(A universal local knowledge base solution based on vector database and GPT3.5)ã€‚&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/acheong08/EdgeGPT" target="_blank" rel="noopener">2023-EdgeGPT
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/acheong08/EdgeGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: The reverse engineering the chat feature of the new version of Bing.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="chatglm">ChatGLM&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">2023-ChatGLM-6B
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/THUDM/ChatGLM-6B" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡åž‹ï¼ŒåŸºäºŽ General Language Model (GLM) æž¶æž„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡åž‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½Žåªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚ ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›žç­”ã€‚&lt;/li>
&lt;/ul>
&lt;h2 id="llama">Llama&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/shawwn/llama-dl" target="_blank" rel="noopener">2023-llama-dl
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/shawwn/llama-dl" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: High-speed download of LLaMA, Facebook&amp;rsquo;s 65B parameter GPT model&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/jerryjliu/llama_index" target="_blank" rel="noopener">2023-LlamaIndex
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jerryjliu/llama_index" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM&amp;rsquo;s with external data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/cocktailpeanut/dalai" target="_blank" rel="noopener">2023-dalai
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cocktailpeanut/dalai" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: The simplest way to run LLaMA on your local machine&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/antimatter15/alpaca.cpp" target="_blank" rel="noopener">2023-Alpaca.cpp
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/antimatter15/alpaca.cpp" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Run a fast ChatGPT-like model locally on your device. The screencast below is not sped up and running on an M2 Macbook Air with 4GB of weights.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/Alpaca-LoRA" target="_blank" rel="noopener">2023-Alpaca-LoRA
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/Alpaca-LoRA" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Instruct-tuning LLaMA on consumer hardware.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/setzer22/llama-rs" target="_blank" rel="noopener">2023-llama-rs
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/setzer22/llama-rs" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: LLaMA-rs is a Rust port of the llama.cpp project. This allows running inference for Facebook&amp;rsquo;s LLaMA model on a CPU with good performance using full precision, f16 or 4-bit quantized versions of the model.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Prompt-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</guid><description>&lt;h1 id="prompt-list">Prompt List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/prompt-engine" target="_blank" rel="noopener">2022-prompt-engine
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/microsoft/prompt-engine" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Prompt engineering can be as simple as formatting a question and passing it to the model, but it can also get quite complex - requiring substantial code to manipulate and update strings. This library aims to make that easier. It also aims to codify patterns and practices around prompt engineering.&lt;/li>
&lt;/ul></description></item></channel></rss>
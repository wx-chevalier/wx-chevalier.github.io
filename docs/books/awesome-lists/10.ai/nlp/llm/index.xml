<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml" />
    <description>LLM</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>LLM</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link>
    </image>
    
    <item>
      <title>LangChain-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/langchain-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/langchain-list/</guid>
      <description>&lt;h1 id=&#34;langchain-list&#34;&gt;LangChain List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gkamradt/langchain-tutorials&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-langchain-tutorials 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/gkamradt/langchain-tutorials&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Overview and tutorial of the LangChain library&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zilliztech/GPTCache&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-GPTCache 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/zilliztech/GPTCache&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Semantic cache for LLMs. Fully integrated with LangChain and llama_index.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>LLM-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid>
      <description>&lt;h1 id=&#34;llm-list&#34;&gt;LLM List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/howl-anderson/unlocking-the-power-of-llms&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-使用 Prompts 和 Chains 让 ChatGPT 成为神奇的生产力工具！&lt;/a&gt;: ChatGPT 诞生后，因其非常强大的又难以置信的的能力，得到了非常广泛的关注。用户将 ChatGPT 视作一种有趣且知识渊博的聊天工具。但事实上，使用合适的 Prompts 和 Chains，可以将 ChatGPT 作为一个神奇的生产力工具，能够处理各种各样复杂的任务。本仓库将详细介绍如何使用 ChatGPT 完成各种任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Mooler0410/LLMsPracticalGuide&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-LLMsPracticalGuide 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/Mooler0410/LLMsPracticalGuide&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A curated (still actively updated) list of practical guide resources of LLMs. It&amp;rsquo;s based on our survey paper: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. These sources aim to help practitioners navigate the vast landscape of large language models (LLMs) and their applications in natural language processing (NLP) applications. If you find any resources in our repository helpful, please feel free to use them (and don&amp;rsquo;t forget to cite our paper!)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>LLM-OpenSource-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-opensource-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-opensource-list/</guid>
      <description>&lt;h1 id=&#34;opensource&#34;&gt;OpenSource&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/amazon-science/mm-cot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-mm-cot 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/amazon-science/mm-cot&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-LangChains 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/hwchase17/langchain&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/logspace-ai/langflow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LangFlow 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/logspace-ai/langflow&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: ⛓️ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hpcaitech/ColossalAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-ColossalAI 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/hpcaitech/ColossalAI&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Making large AI models cheaper, faster and more accessible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/DeepSpeed&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-DeepSpeed Chat 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/microsoft/DeepSpeed&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: DeepSpeed empowers ChatGPT-like model training with a single click, offering 15x speedup over SOTA RLHF systems with unprecedented cost reduction at all scales;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/LAION-AI/Open-Assistant&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Open-Assistant 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/LAION-AI/Open-Assistant&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Vision-CAIR/MiniGPT-4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-MiniGPT-4 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Enhancing Vision-language Understanding with Advanced Large Language Models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Stability-AI/StableLM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-StableLM 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/Stability-AI/StableLM&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: This repository contains Stability AI&amp;rsquo;s ongoing development of the StableLM series of language models and will be continuously updated with new checkpoints. The following provides an overview of all currently available models. More coming soon.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/OpenLMLab/MOSS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-MOSS 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/OpenLMLab/MOSS&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An open-source tool-augmented conversational language model from Fudan University.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/nlpxucan/WizardLM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-WizardLM 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/nlpxucan/WizardLM&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Empowering Large Pre-Trained Language Models to Follow Complex Instructions Resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jaymody/picoGPT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-picoGPT 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/jaymody/picoGPT&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://vicuna.lmsys.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Vicuna 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An Open-Source Chatbot Impressing GPT-4 with &lt;code&gt;90%&lt;/code&gt; ChatGPT Quality.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-FastChat 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/lm-sys/FastChat&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: An open platform for training, serving, and evaluating large language model based chatbots.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chatglm&#34;&gt;ChatGLM&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-ChatGLM-6B 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/THUDM/ChatGLM-6B&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/imClumsyPanda/langchain-ChatGLM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-langchain-ChatGLM 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/imClumsyPanda/langchain-ChatGLM&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: 💡 受 GanymedeNil 的项目 document.ai 和 AlexZhangji 创建的 ChatGLM-6B Pull Request 启发，建立了全部基于开源模型实现的本地知识问答应用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;web-llm&#34;&gt;Web LLM&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mlc-ai/web-llm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-web-llm 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/mlc-ai/web-llm&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: This project brings language model chats directly onto web browsers. Everything runs inside the browser with no server support and accelerated with WebGPU. We can bring a lot of fun opportunities to build AI assistants for everyone and enable privacy while enjoying GPU acceleration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mlc-ai/mlc-llm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-MLC LLM 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/mlc-ai/mlc-llm&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: MLC LLM is a universal solution that allows any language models to be deployed natively on a diverse set of hardware backends and native applications, plus a productive framework for everyone to further optimize model performance for their own use cases.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chinese-llm&#34;&gt;Chinese LLM&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CVI-SZU/Linly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Linly 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/CVI-SZU/Linly&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Linly-ChatFlow 支持简繁体中文、英文、日文等多语言。 LLaMA 在预训练阶段主要使用英文，为了将其语言能力迁移到中文上，首先进行中文增量预训练， 使用的语料包括中英平行语料、中文维基、社区互动、新闻数据、科学文献等。再通过 Alpaca 指令微调得到 Linly-ChatFlow。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;prompt&#34;&gt;Prompt&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cfortuner/promptable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Promptable 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/cfortuner/promptable&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/1rgs/jsonformer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Jsonformer 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/1rgs/jsonformer&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A Bulletproof Way to Generate Structured JSON from Language Models.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;deployment&#34;&gt;Deployment&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/go-skynet/LocalAI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-LocalAI 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/go-skynet/LocalAI&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: 🤖 Self-hosted, community-driven simple local OpenAI-compatible API written in go. Can be used as a drop-in replacement for OpenAI, running on CPU with consumer-grade hardware. Supports ggml compatible models, for instance: LLaMA, alpaca, gpt4all, vicuna, koala, gpt4all-j, cerebras&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/modal-labs/quillman&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Quillman 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/modal-labs/quillman&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: A chat app that transcribes audio in real-time, streams back a response from a language model, and synthesizes this response as natural-sounding speech.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cache--proxy&#34;&gt;Cache &amp;amp; Proxy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/zilliztech/GPTCache&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-GPTCache 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/zilliztech/GPTCache&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: GPTCache is a library for creating semantic cache to store responses from LLM queries.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;llm-ui&#34;&gt;LLM UI&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Yidadaa/ChatGPT-Next-Web&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-ChatGPT-Next-Web 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/Yidadaa/ChatGPT-Next-Web&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: One-Click to deploy well-designed ChatGPT web UI on Vercel. 一键拥有你自己的 ChatGPT 网页服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/chathub-dev/chathub&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-chathub 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/chathub-dev/chathub&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: ChatHub is an all-in-one chatbot client.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llmops&#34;&gt;LLMOps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/langgenius/dify&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Dify 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/langgenius/dify&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Dify is an easy-to-use LLMOps platform designed to empower more people to create sustainable, AI-native applications. With visual orchestration for various application types, Dify offers out-of-the-box, ready-to-use applications that can also serve as Backend-as-a-Service APIs. Unify your development process with one API for plugins and datasets integration, and streamline your operations using a single interface for prompt engineering, visual analytics, and continuous improvement.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

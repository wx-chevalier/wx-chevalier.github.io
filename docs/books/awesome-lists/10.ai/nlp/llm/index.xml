<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link><atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/index.xml" rel="self" type="application/rss+xml"/><description>LLM</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>LLM</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/</link></image><item><title>GPT-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/gpt-list/</guid><description>&lt;h1 id="gpt-list">GPT List&lt;/h1>
&lt;h1 id="resource">Resource&lt;/h1>
&lt;h2 id="course">Course&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/karpathy/ng-video-lecture" target="_blank" rel="noopener">2023-nanogpt-lecture ðŸŽ¥&lt;/a>: Code created in the Neural Networks: Zero To Hero video lecture series, specifically on the first lecture on nanoGPT. Publishing here as a Github repo so people can easily hack it, walk through the git log history of it, etc.&lt;/li>
&lt;/ul>
&lt;h1 id="chatgpt">ChatGPT&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/file/d/1UOfN0iB_A0rEGYc2CbYnpIF44FupQn2I/view" target="_blank" rel="noopener">2022-The ChatGPT Cheat Sheet&lt;/a>: This cheat sheet illustrates the diverse abilities of OpenAIâ€™s ChatGPT for developers and content creators to enhance their proficiency in large language model prompting across various domains including media content creation, natural language processing, and programming.&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/jaymody/picoGPT" target="_blank" rel="noopener">2023-picoGPT
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/jaymody/picoGPT" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An unnecessarily tiny and minimal implementation of GPT-2 in NumPy.&lt;/li>
&lt;/ul></description></item><item><title>LLM-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/llm-list/</guid><description>&lt;h1 id="llm-list">LLM List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/howl-anderson/unlocking-the-power-of-llms" target="_blank" rel="noopener">2023-ä½¿ç”¨ Prompts å’Œ Chains è®© ChatGPT æˆä¸ºç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼&lt;/a>: ChatGPT è¯žç”ŸåŽï¼Œå› å…¶éžå¸¸å¼ºå¤§çš„åˆéš¾ä»¥ç½®ä¿¡çš„çš„èƒ½åŠ›ï¼Œå¾—åˆ°äº†éžå¸¸å¹¿æ³›çš„å…³æ³¨ã€‚ç”¨æˆ·å°† ChatGPT è§†ä½œä¸€ç§æœ‰è¶£ä¸”çŸ¥è¯†æ¸Šåšçš„èŠå¤©å·¥å…·ã€‚ä½†äº‹å®žä¸Šï¼Œä½¿ç”¨åˆé€‚çš„ Prompts å’Œ Chainsï¼Œå¯ä»¥å°† ChatGPT ä½œä¸ºä¸€ä¸ªç¥žå¥‡çš„ç”Ÿäº§åŠ›å·¥å…·ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§å„æ ·å¤æ‚çš„ä»»åŠ¡ã€‚æœ¬ä»“åº“å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ ChatGPT å®Œæˆå„ç§ä»»åŠ¡ã€‚&lt;/li>
&lt;/ul>
&lt;h1 id="opensource">OpenSource&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/cfortuner/promptable" target="_blank" rel="noopener">2023-Promptable
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/cfortuner/promptable" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/amazon-science/mm-cot" target="_blank" rel="noopener">2023-mm-cot
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/amazon-science/mm-cot" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener">2023-LangChains
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/hwchase17/langchain" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/logspace-ai/langflow" target="_blank" rel="noopener">LangFlow
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/logspace-ai/langflow" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: â›“ï¸ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="finetuning--inference">Finetuning &amp;amp; Inference&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/stochasticai/xturing" target="_blank" rel="noopener">2023-xturing
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/stochasticai/xturing" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: xturing provides fast, efficient and simple fine-tuning of LLMs, such as LLaMA, GPT-J, GPT-2, OPT, Cerebras-GPT, Galactica, and more. By providing an easy-to-use interface for personalizing LLMs to your own data and application, xTuring makes it simple to build and control LLMs. The entire process can be done inside your computer or in your private cloud, ensuring data privacy and security.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/OptimalScale/LMFlow" target="_blank" rel="noopener">2023-LMFlow
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/OptimalScale/LMFlow" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: An extensible, convenient, and efficient toolbox for finetuning large machine learning models, designed to be user-friendly, speedy and reliable, and accessible to the entire community.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="chatglm">ChatGLM&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">2023-ChatGLM-6B
&lt;img src="https://ng-tech.icu/assets/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/THUDM/ChatGLM-6B" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡åž‹ï¼ŒåŸºäºŽ General Language Model (GLM) æž¶æž„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡åž‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½Žåªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›žç­”ã€‚&lt;/li>
&lt;/ul></description></item><item><title>Prompt-List</title><link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/prompt-list/</guid><description>&lt;h1 id="prompt-list">Prompt List&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://github.com/microsoft/prompt-engine" target="_blank" rel="noopener">2022-prompt-engine
&lt;img src="https://martrix-usa.oss-accelerate.aliyuncs.com/logo/code.svg" style="max-width: 100px;display: inline-flex;"/>
&lt;img src="https://img.shields.io/github/stars/microsoft/prompt-engine" style="max-width: 100px;display: inline-flex;"/>&lt;/a>: Prompt engineering can be as simple as formatting a question and passing it to the model, but it can also get quite complex - requiring substantial code to manipulate and update strings. This library aims to make that easier. It also aims to codify patterns and practices around prompt engineering.&lt;/li>
&lt;/ul></description></item></channel></rss>
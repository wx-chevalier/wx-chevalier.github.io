<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CodeGeneration | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/codegeneration/</link>
      <atom:link href="https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/codegeneration/index.xml" rel="self" type="application/rss+xml" />
    <description>CodeGeneration</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>CodeGeneration</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/codegeneration/</link>
    </image>
    
    <item>
      <title>CodeGeneration-OpenSource-List</title>
      <link>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/codegeneration/codegeneration-opensource-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/awesome-lists/10.ai/nlp/llm/codegeneration/codegeneration-opensource-list/</guid>
      <description>&lt;h1 id=&#34;code-generation-opensource-list&#34;&gt;Code Generation OpenSource List&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/THUDM/CodeGeeX&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2022-CodeGeeX 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/THUDM/CodeGeeX&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: We introduce CodeGeeX, a large-scale multilingual code generation model with 13 billion parameters, pre-trained on a large code corpus of more than 20 programming languages. As of June 22, 2022, CodeGeeX has been trained on more than 850 billion tokens on a cluster of 1,536 Ascend 910 AI Processors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/TabbyML/tabby&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Tabby 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/TabbyML/tabby&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Self-hosted AI coding assistant. An opensource / on-prem alternative to GitHub Copilot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ravenscroftj/turbopilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-Turbopilot 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/ravenscroftj/turbopilot&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: Turbopilot is an open source large-language-model based code completion engine that runs locally on CPU&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/CodedotAl/gpt-code-clippy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023-GPT-Code-Clippy 
















  &lt;img src=&#34;https://ng-tech.icu/assets/code.svg&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt; 
















  &lt;img src=&#34;https://img.shields.io/github/stars/CodedotAl/gpt-code-clippy&#34; style=&#34;max-width: 100px;display: inline-flex;&#34;/&gt;&lt;/a&gt;: GPT-Code-Clippy (GPT-CC) is an open source version of GitHub Copilot, a language model &amp;ndash; based on GPT-3, called GPT-Codex &amp;ndash; that is fine-tuned on publicly available code from GitHub.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>设计理念 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/</link><atom:link href="https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/index.xml" rel="self" type="application/rss+xml"/><description>设计理念</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>设计理念</title><link>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/</link></image><item><title>场景分析</title><link>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90/</guid><description>&lt;h1 id="自动化运维场景分析">自动化运维场景分析&lt;/h1>
&lt;p>1）业务要升级某个业务规则，小二需要在若干系统管理后台里做新规则配置，如业务规则应用的系统，风控管理的系统等等，经常出现某新人不熟悉完整流程漏了某个系统的配置，导致完整的线上业务流程中断，由于业务中断的原因有多种，如何快速定位到并彻底解决这类问题成为痛点。&lt;/p>
&lt;p>2）现在大数据算法在业务中发挥着巨大的价值，除了常见的推荐搜索外，在订单路由和履行决策等场景也大量应用。当升级某个算法模型时，如何做到按照最小业务单元的控制粒度来执行灰度，在出现新模型召回率、准确率下跌时如何做到快速回滚并对受影响的订单快速定位、分析和修复。&lt;/p>
&lt;p>3）在分布式系统架构中，通过异步消息解耦复杂系统之间的强依赖是非常常见和优雅的架构设计策略，特别是一个 center/platform 级别系统通常会向依赖它的上下游系统发出一些自身业务单据操作或其他实体事件的 MQ 信息做为业务执行的触发条件与依据。为了避免引入过于复杂的系统设计，大家普遍采取非事务一致性消息模式，当遇到消费者系统故障或消息系统故障等各种因素导致某些消费者（consumer）出现消息丢失的情形时，作为 provider 或 consumer 如何快速发现并补全这类丢失的消息。&lt;/p>
&lt;p>4）某算法引擎是个 CPU 计算密集型系统，但是由于 VM 资源隔离不干净经常出现同一台宿主机上的 VM 相互干扰导致 st 持续飙高，一旦出现这种现象就会导致算法引擎无法基于承诺的 SAL 给上游返回计算结果，从而影响业务行为。每次遇到这种情况，引擎的开发同学会第一时间分析是否为 st 飙高导致，一旦确认则通过 kill jvm 来粗暴快速的解决此次问题。此类 case 非常频繁，大多数通过客户反馈来驱动问题排查，在虚拟化资源隔离问题未彻底解决之前，作为上游的业务系统如何更高效、及时、主动的解决这类问题；&lt;/p>
&lt;p>5）我们时常遇到线上突然告警，然后开发同学介入排查并执行预案（一般是几个配置变更）的场景，一般来说处理思路有如下几种：对上游做限流降级、对下游做依赖降级或启用备用方案、对某个变更做快速回滚。对于此类场景我们能否把其中有明确异常信号及处理流程的解决步骤流程化自动化，然后再去人工介入彻底解决呢？人的响应能力毕竟是有极限的，特别是非工作时段，如果能做到先“自动止血”尽可能降低影响面，然后再人工介入，业务上所受的影响会得到一定程度的降低。我们在业务上对异常的定义、识别、定位需要快速精准，要有备用解决方案，采用类似“熔断机制”的自主可控的处理思路来解决问题。&lt;/p></description></item><item><title>流水线即代码</title><link>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%8D%B3%E4%BB%A3%E7%A0%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%8D%B3%E4%BB%A3%E7%A0%81/</guid><description>&lt;h1 id="流水线即代码">流水线即代码&lt;/h1>
&lt;p>流水线即代码技术强调，用于构建、测试和部署我们应用程序或基础设施的交付流水线配置，都应以代码形式展现。这些代码应置于版本控制系统中，并切分成包含自动化测试和部署的可复用组件。随着组织逐渐演变为构建微服务或微前端的去中心化自治团队，人们越来越需要以代码形式管理流水线这种工程实践，来保证组织内部构建和部署软件的一致性。这种需求使得业界出现了很多交付流水线模板和工具，它们可以以标准的方式构建、部署服务和应用。这些工具用大多采用声明式交付流水线的形式，采用一个流水线蓝图，来执行一个交付生命周期中不同阶段的任务，如构建、测试和部署，而不用关心实现细节。以代码形式来完成构建、测试和部署流水线的能力，应该成为选择 CI/CD 工具的评估标准之一。&lt;/p></description></item><item><title>体系设计</title><link>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E4%BD%93%E7%B3%BB%E8%AE%BE%E8%AE%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/sre-series/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/%E4%BD%93%E7%B3%BB%E8%AE%BE%E8%AE%A1/</guid><description>&lt;h1 id="自动化运维的体系设计">自动化运维的体系设计&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/1tN421vc/image.png" alt="完整的自动化运维体系示意图" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="设计目标">设计目标&lt;/h1>
&lt;h2 id="指标精细透明">指标精细透明&lt;/h2>
&lt;p>能够对系统各指标（系统、业务）进行精准、细致、体系化、实时的监控。通常来讲，衡量一个系统的监控体系做的是否足够好在于我们能否基于这套指标监控体系讲清楚当前业务发生的行为以及行为（正常行为和异常行为）产生的原因，超出当前业务或系统体系则需结合上下游系统一起来诊断。因此，我们一般会从两个视角来定义应用系统关键指标：业务视角和系统视角，这两个视角密不可分（如接口调用量和业务单量）。我们将指标分为面向最终结果的指标和面向过程的指标，这些指标同样也需要精确无歧义的定义，只有这样我们才能做到既能直观了解到系统发生了什么，也能快速定位背后的原因。最后，指标数据采集和展现的实时性非常重要，关系到我们能否快速了解系统最新的行为。&lt;/p>
&lt;h2 id="问题快速发现">问题快速发现&lt;/h2>
&lt;p>能否及时主动的发现系统、业务异常。基于设计良好的监控指标体系，我们能快速掌握当前业务及系统运行情况，结合我们对业务或系统的专业了解能很快识别出当前系统运行是否正常。如果我们把这些业务或系统可能发生的异常行为通过相关的指标值来表达，则可以基于监控大盘与告警系统做到快速、主动的感知具体异常行为的发生。更近一步，若能再融入大数据算法模型，把告警升级为预警则效果更好。&lt;/p>
&lt;h2 id="预案自动执行">预案自动执行&lt;/h2>
&lt;p>能够自动执行系统容灾或备份链路等系统预设的应急方案。如果我们能用监控指标数据准确定义异常发生时的系统行为且能做到快速识别并有明确的异常处理系统化方案，则可以基于预设的异常条件与处理方案在异常发生时自动触发系统流程来解决异常或降低异常对系统影响面，为后续开发的介入创造主动性。&lt;/p>
&lt;h2 id="变更安全可控">变更安全可控&lt;/h2>
&lt;p>系统变更（业务规则、系统配置等）可灰度执行、数据影响可追溯、变更可快速回滚。通过分析线上故障发现，很大比例的故障是在系统发生变更时产生，针对变更（包括但不限于系统配置项变更、数据订正、业务规则切换、发布等），我们一定要有快速回滚方案。同时为了控制变更对系统可能产生的影响，一定要有变更灰度执行或灰度生效的机制，对于较常用的变更操作，特别是针对某类场景的组合类变更一定要有工具化、流程化、系统化的解决方案，尽可能降低因人为操作而导致出错的概率。&lt;/p>
&lt;h2 id="答疑高效支持">答疑高效支持&lt;/h2>
&lt;p>针对内部、外部的答疑（问题的定位、分析、排查）提供高效、自助的一站式解决方案。开发团队每天都会花费大量精力应对系统内部或外部的问题咨询与答疑，即使如此仍难免未能支持好所有人的需求。如果对系统的异常行为有清晰的定义和系统化排查与解决方案，则会极大的降低团队内部排查问题的工作量；再进一步，如果我们把常见的问题抽象成通用的问题分析、处理平台并提供一站式解决方案提供我们的客户，则不仅将极大降低开发团队在线上咨询方面处理的投入度，提升客户满意度，更重要的是避免了排查和解决问题时大量的线上操作行为，提升了系统安全与稳定性。&lt;/p>
&lt;h1 id="设计原则">设计原则&lt;/h1>
&lt;p>核心思路是把一切变更操作标准化、流程化、自助化、自动化，降低人工干预程度，提升操作效率。实现这张架构图并迭代演进是一个跨多个职能团队协作（Cross-Functional Autonomous Teams）的工作，一切要以客户需求出发，进行持续的抽象和迭代。&lt;/p>
&lt;p>一个好的自动化运维管控系统平台绝不仅仅是一个功能复杂的工具集，它应具备良好的系统化架构与设计，需要和业务系统密切配合又不关心业务处理的细节，基于（问题）场景为用户提供简单直接的解决方案。管控系统和业务系统最大的区别是管控系统需要为业务系统服务，帮助业务系统快速定位问题、解决问题，而不是替业务系统解决问题。一个极端的例子是管控系统里面包含大量直接操作业务系统库表的工具集并自定义组装业务变更的逻辑，这样一旦业务模型升级或逻辑发生变化时，该管控系统就失去了应用的意义。&lt;/p>
&lt;h2 id="监控数据采集">监控数据采集&lt;/h2>
&lt;p>监控大盘是观察系统的眼睛，一个系统的监控指标是否精细、完整和实时直接关系到这个系统的可运维性，监控指标又分为两大类：业务系统依赖的基础设施的运行时指标（系统类指标）和业务系统自身的业务指标（业务类指标，又分为业务结果数据数据和业务执行过程数据）。具体需要监控哪些数据主要从两个角度来梳理：系统类指标主要从可能会影响系统稳定的点来梳理哪些系统数据显性化有助于我们快速分析定位问题；业务类指标要从业务关心的目标结果数据以及影响这些目标结果达成的过程数据来梳理。目前集团内业务系统依赖的基础中间件、存储、VM 等关键系统指标数据非常全面，所以我们的侧重点在业务类指标的梳理和完善上。又由于指标采集的工具、数据分析计算平台都很完备，做好系统数据的监控采集并不难。&lt;/p>
&lt;h2 id="异常自动识别">异常自动识别&lt;/h2>
&lt;p>我们常从异常、失败的角度来做数据的埋点、采集和监控，很大一部分异常可以直接通过设定单维度监控预警阈值来进行识别，从而做到精准监控；部分异常需要结合上下文或上下游依赖的数据利用业务知识做二次分析判断，如监控到快递公司某条线路的包裹时效出现波动，由于快递网络包裹配送是一个多角色协同的场景，具体哪个环节出了问题还需要结合更细粒度的数据来分析，这里可能会引入一些算法模型。还有部分异常当前还做不到自动判断，需要人工干预。此外，目前还有一种高阶的做法是基于 AI 技术做异常预警，基于当前的数据可以预测异常即将发生。&lt;/p>
&lt;h2 id="根因分析定位">根因分析定位&lt;/h2>
&lt;p>这个领域基本上是模板驱动（Automated pattern discovery），前提是能够准确分析某类异常发生的根本原因且在对应的业务系统自动化体系里有现成的解决方案，否则就只能人工介入做决策。在依靠人工对异常问题处理的干预的同时，我们也能够沉淀更多的自动解决方案。&lt;/p>
&lt;h2 id="异常变更处理">异常/变更处理&lt;/h2>
&lt;p>整个体系最重要的环节，包含预设的解决方案（系统具备的自动处理能力）、变更安全管控模块、对外核心处理能力的集成与驱动。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>预设的解决方案：通过业务知识的沉淀形成所谓的专家库，这些沉淀一方面来自于系统业务逻辑设计时制定的规则，另外一方面来自于日常对各种问题处理时的积累，它是一个不断迭代优化的过程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>变更安全管控模块：自动化体系建设确实能够提升解决问题的效率，但也使线上系统变更的成本变得更低了，为保证线上变更的安全性，需要对关键的变更做好权限控制，配置类变更需要做好版本控制和灰度发布，同时也要具备变更暂停和快速回滚的能力。对于大数量的变更或大量任务重试等还需要考虑限速限流的能力，避免把下游系统“打垮”，同时基于“重监控、轻管控”的原则，系统也要做好变更操作的关键记录便于事后追溯，有些变更带来的影响具备较长的延时性，这时记录信息能够起到非常关键的作用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对外核心处理能力的集成与驱动：自动化管控系统不应涉及到太多的业务细节，它可能需要基于某个场景来协同多个系统单元来提供整体的自动化/自助化解决方案，但是每个系统单元的能力应该由各系统独自封装并以 API 的形式提供出来。自动化运维管控系统是目标驱动的，不关心 API 实现的细节，如：“我们需要修正某个电子面单包裹信息里面的路由分单规则并更新信息至快递公司”，业务运维管控系统里面对小二提供的是个一键修正的功能。在管控系统实现层面可能会分别依赖电子面单系统、分单系统提供的不同 API，如计算路由分单码的接口、更新电子面单单据信息的接口、信息下发合作伙伴的接口等，至于每个接口内部如何实现管控系统并不关心。业务系统需要保证每个独立 API 具备可重试和幂等的原则，并由管控系统来保证结果的最终执行，即使执行不成功原则上也不影响原有业务系统的数据和逻辑（由于非事物一致性）。基础系统也同样遵循这个原则，只不过当前阿里体系内部研发基础设施非常完备，基本上常用的中间件体系都有配套良好的运维控制系统，因此我们对这类系统的运维变更需求都是登录对应中间件管控平台操作，也有部分中间件产品对外开放了常用的 API（基本都是 RESTful 风格）供业务自动化运维管控系统来集成。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="安全机制">安全机制&lt;/h2>
&lt;p>这里的安全指系统或数据安全。在研发人员心中自动化管控系统的重要性通常低于其服务的业务系统的，因此在系统架构设计、代码质量、研发规范、安全等级等方面投入的精力和重视程度会打折扣。笔者曾见到一些系统的安全 Bug 在流程里面校验不通过利用安全白名单机制绕开，这其实是不可取的，一个功能齐全的自动化运维管控系统对线上数据、业务变更的权限很大，可视作一个内部超级账号，即使内网很安全，我们也要避免意外发生。&lt;/p></description></item></channel></rss>
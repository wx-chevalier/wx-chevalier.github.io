<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>线程池 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/concurrent-notes/01.%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E5%8D%95%E5%85%83/%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</link>
      <atom:link href="https://ng-tech.icu/books/concurrent-notes/01.%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E5%8D%95%E5%85%83/%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/index.xml" rel="self" type="application/rss+xml" />
    <description>线程池</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>线程池</title>
      <link>https://ng-tech.icu/books/concurrent-notes/01.%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E5%8D%95%E5%85%83/%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</link>
    </image>
    
    <item>
      <title>线程池调优</title>
      <link>https://ng-tech.icu/books/concurrent-notes/01.%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E5%8D%95%E5%85%83/%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%B0%83%E4%BC%98/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/concurrent-notes/01.%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E5%8D%95%E5%85%83/%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%B0%83%E4%BC%98/</guid>
      <description>&lt;h1 id=&#34;调优指标&#34;&gt;调优指标&lt;/h1&gt;
&lt;p&gt;线程池的大小依赖于所执行任务的特性以及程序运行的环境，线程池的大小应该应采取可配置的方式（写入配置文件）或者根据可用的 CPU 数量 &lt;code&gt;Runtime.availableProcessors()&lt;/code&gt; 来进行设置，其中 Ncpu 表示可用 CPU 数量，Nthreads 表示线程池工作线程数量，Ucpu 表示 CPU 的利用率 &lt;code&gt;0≤ Ucpu ≤1&lt;/code&gt;；W 表示资源等待时间，C 表示任务计算时间；Rtotal 表示有限资源的总量，Rper 表示每个任务需要的资源数量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于对于纯 CPU 计算的任务-即不依赖阻塞资源（外部接口调用）以及有限资源（线程池）的 CPU 密集型（compute-intensive）任务线程池的大小可以设置为：&lt;code&gt;Nthreads = Ncpu+1&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果执行的任务除了 cpu 计算还包括一些外部接口调用或其他会阻塞的计算，那么线程池的大小可以设置为 &lt;code&gt;Nthreads = Ncpu - Ucpu -（1 + W / C）&lt;/code&gt;。可以看出对于 IO 等待时间长于任务计算时间的情况，&lt;code&gt;W/C&lt;/code&gt; 大于 1，假设 cpu 利用率是 100%，那么 &lt;code&gt;W/C&lt;/code&gt; 结果越大，需要的工作线程也越多，因为如果没有足够的线程则会造成任务队列迅速膨胀。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果任务依赖于一些有限的资源比如内存，文件句柄，数据库连接等等，那么线程池最大可以设置为 &lt;code&gt;Nthreads ≤ Rtotal/Rper&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;单线程&#34;&gt;单线程&lt;/h2&gt;
&lt;p&gt;单线程情况下，服务接收到请求后开始初始化，资源准备，计算，返回结果，时间主要花在 CPU 计算和 CPU 外的 IO 等待时间，多个请求来也只能排队一个一个来，那么 RT 计算如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;RT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;cpu&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; + T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;io&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;QPS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 1000ms / RT
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;多线程&#34;&gt;多线程&lt;/h2&gt;
&lt;p&gt;单线程情况很好计算，多线程情况就复杂了，我们目标是计算出最佳并发量，也就是线程数 N：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单核情况：&lt;code&gt;N = [T(cpu) + T(io)] / T(cpu)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;M 核情况：&lt;code&gt;N = [T(cpu) + T(io)] / T(cpu) * M&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于多核情况 CPU 未必能全部使用，存在一个资源利用百分比 P，那么并发的最佳线程数 &lt;code&gt;N = [T(cpu) + T(io)] / T(cpu) * M * P&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;吞吐量&#34;&gt;吞吐量&lt;/h2&gt;
&lt;p&gt;我们知道单线程的 QPS 很容易算出来，那么多线程的 QPS：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;QPS&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 1000ms / RT * &lt;span class=&#34;nv&#34;&gt;N&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 1000ms / &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;cpu&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; + T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;io&lt;span class=&#34;o&#34;&gt;)]&lt;/span&gt; - &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;cpu&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; + T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;io&lt;span class=&#34;o&#34;&gt;)]&lt;/span&gt; / T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;cpu&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; * M * &lt;span class=&#34;nv&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 1000ms / T&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;cpu&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; * M * P
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在机器核数固定情况下，也即是并发模式下最大的吞吐量跟服务的 CPU 处理时间和 CPU 利用率有关。CPU 利用率不高，就是通常我们听到最多的抱怨，压测时候 qps 都打满了，但是 cpu 的 load 就是上不去。并发模型中多半个共享资源有关，而共享资源又跟锁息息相关，那么大部分时候我们想对节点服务做性能调优时就是对锁的优化，这个下一节会提到。&lt;/p&gt;
&lt;p&gt;前面我们是假设机器核数固定的情况下做优化的，那假如我们把缓存，IO，锁都优化了，剩下的还有啥空间去突破呢？回想一下我们谈基础理论的时候提到的 Amdahl 定律，公式之前已经给出，该定律想表达的结论是随着核数或者处理器个数的增加，可以增加优化加速比，但是会达到上限，而且增加趋势愈发不明显。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

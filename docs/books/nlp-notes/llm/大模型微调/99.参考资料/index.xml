<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>99.参考资料 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/</link><atom:link href="https://ng-tech.icu/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/index.xml" rel="self" type="application/rss+xml"/><description>99.参考资料</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>99.参考资料</title><link>https://ng-tech.icu/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/</link></image><item><title>2023-Finetuning Large Language Models</title><link>https://ng-tech.icu/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2023-finetuning-large-language-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2023-finetuning-large-language-models/</guid><description>&lt;blockquote>
&lt;p>&lt;a href="https://magazine.sebastianraschka.com/p/finetuning-large-language-models" target="_blank" rel="noopener">Origin&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="finetuning-large-language-models">Finetuning Large Language Models&lt;/h1></description></item></channel></rss>
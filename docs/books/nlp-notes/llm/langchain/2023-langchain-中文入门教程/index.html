<!DOCTYPE html><html lang="zh" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
    <meta name="google-site-verification" content="google69a5cccb61297807" />
    <meta name="baidu-site-verification" content="cqmZHEleVh" />
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="LangChain 中文入门教程 为了便于阅读，已生成 gitbook：https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/ github 地址：https://github.com/li" />

  
  <link rel="alternate" hreflang="zh" href="https://ng-tech.icu/books/nlp-notes/llm/langchain/2023-langchain-%E4%B8%AD%E6%96%87%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/" />

  
  
  
    <meta name="theme-color" content="#0a55a7" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css" integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin="anonymous">
    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0d97305106da5efa530e28b021b4c580.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', "G-40NYXJ8823");
</script>


  


  


  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://ng-tech.icu/books/nlp-notes/llm/langchain/2023-langchain-%E4%B8%AD%E6%96%87%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@wx-chevalier" />
    <meta property="twitter:creator" content="@wx-chevalier" />
  
  <meta property="og:site_name" content="Next-gen Tech Edu" />
  <meta property="og:url" content="https://ng-tech.icu/books/nlp-notes/llm/langchain/2023-langchain-%E4%B8%AD%E6%96%87%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/" />
  <meta property="og:title" content="2023-LangChain 中文入门教程 | Next-gen Tech Edu" />
  <meta property="og:description" content="LangChain 中文入门教程 为了便于阅读，已生成 gitbook：https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/ github 地址：https://github.com/li" /><meta property="og:image" content="https://ng-tech.icu/media/sharing.png" />
    <meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png" /><meta property="og:locale" content="zh" />
  
    
    
  

  



  

  

  





  <title>2023-LangChain 中文入门教程 | Next-gen Tech Edu</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="05e0bd271ab80a4e87e9eba02bc2688c" >
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden="true"></i></button>
  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6 search-title">
          <p>搜索</p>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="关闭"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

      
      

      
    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

      <div id="search-common-queries">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Next-gen Tech Edu</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="切换导航">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Next-gen Tech Edu</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/books-gallery"><span>笔记（万篇）</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#knowledge-map"><span>知识图谱</span></a>
          </li>

          
          

          
          <style>
            .dropdown-item{
              display: inline-flex;
            }
          </style>
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>实验室</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/galaxy-home/gh-craft"><span>Craft 方块世界</span></a>
              
                <a class="dropdown-item" href="/galaxy-home/glossary-cards"><span>3D 知识卡牌</span></a>
              
            </div>
          </li>

          
          

          
          <style>
            .dropdown-item{
              display: inline-flex;
            }
          </style>
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>其他阅读渠道</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="https://zhuanlan.zhihu.com/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png"></img><span>知乎</span></a>
              
                <a class="dropdown-item" href="https://segmentfault.com/blog/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png"></img><span>SegmentFault</span></a>
              
                <a class="dropdown-item" href="https://zhuanlan.zhihu.com/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png"></img><span>掘金</span></a>
              
            </div>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="搜索"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item">
            <a class="nav-link" href="https://github.com/wx-chevalier" aria-label="GitHub"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
        </li>
        

        
        
        

        
        
        
        <div></div>
        
        <style>
        @media only screen and (max-width: 600px) {
          .jimmysong-template {
            display: none!important;
          }
        }
        </style>
        
        <li class="jimmysong-template" style="color: white;font-size: 12px;">
          <a href="https://jimmysong.io" style="color: white">By Jimmy Song's Template</a>
        </li>
      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<link rel="stylesheet" href="//unpkg.com/heti/umd/heti.min.css">
<div class="container-xl docs">
  <div class="row flex-xl-nowrap">
    <div class="docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
          LangChain
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">搜索...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li style="display: inline-flex">
          <a style="cursor: pointer;" onclick="window.history.back()">
            <i class="fas fa-arrow-left pr-1"></i>
            Back
          </a>
          <span>|</span>
          <a href="/books/">
            <i class="fa-solid fa-house" style="margin-right: 4px"></i>
            Books
          </a>
        </li>
      </ul>

      
      
        
          
        
      



  
    
    
    
    
      
    
    

    
    
    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id0f3a2f251393fa53f2b45f59f11ba1dd&#34;)" href="#id0f3a2f251393fa53f2b45f59f11ba1dd" aria-expanded="false" aria-controls="id0f3a2f251393fa53f2b45f59f11ba1dd" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/">LLM</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id0f3a2f251393fa53f2b45f59f11ba1dd" aria-expanded="false" aria-controls="id0f3a2f251393fa53f2b45f59f11ba1dd">
    
    <i class="fa-solid fa-angle-down" id="caret-id0f3a2f251393fa53f2b45f59f11ba1dd"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  show " id="id0f3a2f251393fa53f2b45f59f11ba1dd">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-ide1ffcfcd52c4caed741dce5e8746afd5&#34;)" href="#ide1ffcfcd52c4caed741dce5e8746afd5" aria-expanded="false" aria-controls="ide1ffcfcd52c4caed741dce5e8746afd5" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">99.参考资料</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#ide1ffcfcd52c4caed741dce5e8746afd5" aria-expanded="false" aria-controls="ide1ffcfcd52c4caed741dce5e8746afd5">
    
        <i class="fa-solid fa-angle-right" id="caret-ide1ffcfcd52c4caed741dce5e8746afd5"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="ide1ffcfcd52c4caed741dce5e8746afd5">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-ida85c57d2b21e050d986bbfab7e370c48&#34;)" href="#ida85c57d2b21e050d986bbfab7e370c48" aria-expanded="false" aria-controls="ida85c57d2b21e050d986bbfab7e370c48" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/cohere-llm-university/">cohere-LLM University</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#ida85c57d2b21e050d986bbfab7e370c48" aria-expanded="false" aria-controls="ida85c57d2b21e050d986bbfab7e370c48">
    
        <i class="fa-solid fa-angle-right" id="caret-ida85c57d2b21e050d986bbfab7e370c48"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="ida85c57d2b21e050d986bbfab7e370c48">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-idaabcff728053a5c115fdedb4bca268be&#34;)" href="#idaabcff728053a5c115fdedb4bca268be" aria-expanded="false" aria-controls="idaabcff728053a5c115fdedb4bca268be" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/cohere-llm-university/01.what-are-large-language-models/">01.What are Large Language Models?</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#idaabcff728053a5c115fdedb4bca268be" aria-expanded="false" aria-controls="idaabcff728053a5c115fdedb4bca268be">
    
        <i class="fa-solid fa-angle-right" id="caret-idaabcff728053a5c115fdedb4bca268be"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="idaabcff728053a5c115fdedb4bca268be">
      



  <li class="child level "><a href="/books/nlp-notes/llm/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/cohere-llm-university/01.what-are-large-language-models/01.text-embeddings/">01.Text Embeddings</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id149c7b950ae4d982118ed83ec14d8b82&#34;)" href="#id149c7b950ae4d982118ed83ec14d8b82" aria-expanded="false" aria-controls="id149c7b950ae4d982118ed83ec14d8b82" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/gpt/">GPT</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id149c7b950ae4d982118ed83ec14d8b82" aria-expanded="false" aria-controls="id149c7b950ae4d982118ed83ec14d8b82">
    
        <i class="fa-solid fa-angle-right" id="caret-id149c7b950ae4d982118ed83ec14d8b82"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id149c7b950ae4d982118ed83ec14d8b82">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id42fecf3714ff279be906fb6a592e86f3&#34;)" href="#id42fecf3714ff279be906fb6a592e86f3" aria-expanded="false" aria-controls="id42fecf3714ff279be906fb6a592e86f3" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/gpt/chatgpt/">ChatGPT</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id42fecf3714ff279be906fb6a592e86f3" aria-expanded="false" aria-controls="id42fecf3714ff279be906fb6a592e86f3">
    
        <i class="fa-solid fa-angle-right" id="caret-id42fecf3714ff279be906fb6a592e86f3"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id42fecf3714ff279be906fb6a592e86f3">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id60444ffd5de140725f64e2ab6c082b4e&#34;)" href="#id60444ffd5de140725f64e2ab6c082b4e" aria-expanded="false" aria-controls="id60444ffd5de140725f64e2ab6c082b4e" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/gpt/chatgpt/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">99.参考资料</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id60444ffd5de140725f64e2ab6c082b4e" aria-expanded="false" aria-controls="id60444ffd5de140725f64e2ab6c082b4e">
    
        <i class="fa-solid fa-angle-right" id="caret-id60444ffd5de140725f64e2ab6c082b4e"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id60444ffd5de140725f64e2ab6c082b4e">
      



  <li class="child level "><a href="/books/nlp-notes/llm/gpt/chatgpt/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2023-gpt-4-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%A1%AC%E6%A0%B8%E8%A7%A3%E8%AF%BB/">2023-GPT-4 大模型硬核解读</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id687f58da131bb60cc891dad07da525ea&#34;)" href="#id687f58da131bb60cc891dad07da525ea" aria-expanded="false" aria-controls="id687f58da131bb60cc891dad07da525ea" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/langchain/">LangChain</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id687f58da131bb60cc891dad07da525ea" aria-expanded="false" aria-controls="id687f58da131bb60cc891dad07da525ea">
    
    <i class="fa-solid fa-angle-down" id="caret-id687f58da131bb60cc891dad07da525ea"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  show " id="id687f58da131bb60cc891dad07da525ea">
      



  <li class="child level active"><a href="/books/nlp-notes/llm/langchain/2023-langchain-%E4%B8%AD%E6%96%87%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/">2023-LangChain 中文入门教程</a></li>

      
        </ul>
      
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-ideb9cad914aac4b49afcfd297516b2f26&#34;)" href="#ideb9cad914aac4b49afcfd297516b2f26" aria-expanded="false" aria-controls="ideb9cad914aac4b49afcfd297516b2f26" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/">大模型微调</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#ideb9cad914aac4b49afcfd297516b2f26" aria-expanded="false" aria-controls="ideb9cad914aac4b49afcfd297516b2f26">
    
        <i class="fa-solid fa-angle-right" id="caret-ideb9cad914aac4b49afcfd297516b2f26"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="ideb9cad914aac4b49afcfd297516b2f26">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id9eb302593d7ed15f5e29932c77718a83&#34;)" href="#id9eb302593d7ed15f5e29932c77718a83" aria-expanded="false" aria-controls="id9eb302593d7ed15f5e29932c77718a83" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">99.参考资料</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id9eb302593d7ed15f5e29932c77718a83" aria-expanded="false" aria-controls="id9eb302593d7ed15f5e29932c77718a83">
    
        <i class="fa-solid fa-angle-right" id="caret-id9eb302593d7ed15f5e29932c77718a83"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id9eb302593d7ed15f5e29932c77718a83">
      



  <li class="child level "><a href="/books/nlp-notes/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2023-finetuning-large-language-models/">2023-Finetuning Large Language Models</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id13afe656bd21386067d1467721d4b42c&#34;)" href="#id13afe656bd21386067d1467721d4b42c" aria-expanded="false" aria-controls="id13afe656bd21386067d1467721d4b42c" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/">代码生成</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id13afe656bd21386067d1467721d4b42c" aria-expanded="false" aria-controls="id13afe656bd21386067d1467721d4b42c">
    
        <i class="fa-solid fa-angle-right" id="caret-id13afe656bd21386067d1467721d4b42c"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id13afe656bd21386067d1467721d4b42c">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id89d7dca74667bd0d84eab271e9702b9c&#34;)" href="#id89d7dca74667bd0d84eab271e9702b9c" aria-expanded="false" aria-controls="id89d7dca74667bd0d84eab271e9702b9c" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/nlp-notes/llm/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">99.参考资料</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id89d7dca74667bd0d84eab271e9702b9c" aria-expanded="false" aria-controls="id89d7dca74667bd0d84eab271e9702b9c">
    
        <i class="fa-solid fa-angle-right" id="caret-id89d7dca74667bd0d84eab271e9702b9c"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id89d7dca74667bd0d84eab271e9702b9c">
      



  <li class="child level "><a href="/books/nlp-notes/llm/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2023-an-example-of-llm-prompting-for-programming/">2023-An example of LLM prompting for programming</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
     
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">目录</a></li>
      </ul>
     

      <nav id="TableOfContents">
  <ul>
    <li><a href="#介绍">介绍</a></li>
    <li><a href="#heading"></a></li>
    <li><a href="#基础功能">基础功能</a></li>
    <li><a href="#必知概念">必知概念</a></li>
    <li><a href="#heading-1"></a>
      <ul>
        <li><a href="#loader-加载器">Loader 加载器</a></li>
        <li><a href="#heading-2"></a></li>
        <li><a href="#document-文档">Document 文档</a></li>
        <li><a href="#heading-3"></a></li>
        <li><a href="#text-spltters-文本分割">Text Spltters 文本分割</a></li>
        <li><a href="#heading-4"></a></li>
        <li><a href="#vectorstores-向量数据库">Vectorstores 向量数据库</a></li>
        <li><a href="#heading-5"></a></li>
        <li><a href="#chain-链">Chain 链</a></li>
        <li><a href="#heading-6"></a></li>
        <li><a href="#agent-代理">Agent 代理</a></li>
        <li><a href="#embedding">Embedding</a></li>
      </ul>
    </li>
    <li><a href="#heading-7"></a></li>
    <li><a href="#实战">实战</a>
      <ul>
        <li><a href="#完成一次问答">完成一次问答</a></li>
        <li><a href="#通过-google-搜索并返回答案">通过 Google 搜索并返回答案</a></li>
        <li><a href="#对超长文本进行总结">对超长文本进行总结</a></li>
        <li><a href="#构建本地知识库问答机器人">构建本地知识库问答机器人</a></li>
        <li><a href="#构建向量索引数据库">构建向量索引数据库</a></li>
        <li><a href="#使用-gpt35-模型构建油管频道问答机器人">使用 GPT3.5 模型构建油管频道问答机器人</a></li>
        <li><a href="#用-openai-连接万种工具">用 OpenAI 连接万种工具</a></li>
      </ul>
    </li>
    <li><a href="#小例子们">小例子们</a>
      <ul>
        <li><a href="#执行多个-chain"><strong>执行多个 chain</strong></a></li>
        <li><a href="#结构化输出"><strong>结构化输出</strong></a></li>
        <li><a href="#爬取网页并输出-json-数据"><strong>爬取网页并输出 JSON 数据</strong></a></li>
        <li><a href="#自定义-agent-中所使用的工具"><strong>自定义 agent 中所使用的工具</strong></a></li>
        <li><a href="#使用-memory-实现一个带记忆的对话机器人"><strong>使用 Memory 实现一个带记忆的对话机器人</strong></a></li>
        <li><a href="#使用-hugging-face-模型"><strong>使用 Hugging Face 模型</strong></a></li>
        <li><a href="#通过自然语言执行-sql-命令"><strong>通过自然语言执行 SQL 命令</strong></a></li>
      </ul>
    </li>
    <li><a href="#总结">总结</a></li>
  </ul>
</nav>

      
<div class="subscribe-module col-24 mt-1">
    <img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png" alt="image" title="王下邀月熊的微信公众号"/>
</div>



    </div>
    

    <main class="py-md-3 pl-md-3 docs-content col-xl-8" role="main">

      <article class="article">

          

          <h1>2023-LangChain 中文入门教程</h1>

          <div class="article-style">
            <h1 id="langchain-中文入门教程">LangChain 中文入门教程</h1>
<blockquote>
<p>为了便于阅读，已生成 gitbook：<a href="https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/" target="_blank" rel="noopener">https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/</a></p>
<p>github 地址：<a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide" target="_blank" rel="noopener">https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide</a></p>
</blockquote>
<blockquote>
<p>加了个 <a href="CHANGELOG.md">CHANGELOG</a>,更新了新的内容我会写在这里，方便之前看过的朋友快速查看新的更新内容</p>
</blockquote>
<blockquote>
<p>如果想把 OPENAI API 的请求根路由修改成自己的代理地址，可以通过设置环境变量 “OPENAI_API_BASE” 来进行修改。</p>
<p>相关参考代码：<a href="https://github.com/openai/openai-python/blob/d6fa3bfaae69d639b0dd2e9251b375d7070bbef1/openai/__init__.py#L48" target="_blank" rel="noopener">https://github.com/openai/openai-python/blob/d6fa3bfaae69d639b0dd2e9251b375d7070bbef1/openai/__init__.py#L48</a></p>
<p>或在初始化 OpenAI 相关模型对象时，传入“openai_api_base” 变量。</p>
<p>相关参考代码：<a href="https://github.com/hwchase17/langchain/blob/master/langchain/llms/openai.py#L148" target="_blank" rel="noopener">https://github.com/hwchase17/langchain/blob/master/langchain/llms/openai.py#L148</a></p>
</blockquote>
<h2 id="介绍">介绍</h2>
<p>众所周知 OpenAI 的 API 无法联网的，所以如果只使用自己的功能实现联网搜索并给出回答、总结 PDF 文档、基于某个 Youtube 视频进行问答等等的功能肯定是无法实现的。所以，我们来介绍一个非常强大的第三方开源库：<code>LangChain</code> 。</p>
<blockquote>
<p>文档地址：https://python.langchain.com/en/latest/</p>
</blockquote>
<p>这个库目前非常活跃，每天都在迭代，已经有 22k 的 star，更新速度飞快。</p>
<p>LangChain 是一个用于开发由语言模型驱动的应用程序的框架。他主要拥有 2 个能力：</p>
<ol>
<li>可以将 LLM 模型与外部数据源进行连接</li>
<li>允许与 LLM 模型进行交互</li>
</ol>
<blockquote>
<p>LLM 模型：Large Language Model，大型语言模型</p>
</blockquote>
<h2 id="heading"></h2>
<h2 id="基础功能">基础功能</h2>
<p>LLM 调用</p>
<ul>
<li>支持多种模型接口，比如 OpenAI、Hugging Face、AzureOpenAI &hellip;</li>
<li>Fake LLM，用于测试</li>
<li>缓存的支持，比如 in-mem（内存）、SQLite、Redis、SQL</li>
<li>用量记录</li>
<li>支持流模式（就是一个字一个字的返回，类似打字效果）</li>
</ul>
<p>Prompt 管理，支持各种自定义模板</p>
<p>拥有大量的文档加载器，比如 Email、Markdown、PDF、Youtube &hellip;</p>
<p>对索引的支持</p>
<ul>
<li>文档分割器</li>
<li>向量化</li>
<li>对接向量存储与搜索，比如 Chroma、Pinecone、Qdrand</li>
</ul>
<p>Chains</p>
<ul>
<li>LLMChain</li>
<li>各种工具 Chain</li>
<li>LangChainHub</li>
</ul>
<h2 id="必知概念">必知概念</h2>
<p>相信大家看完上面的介绍多半会一脸懵逼。不要担心，上面的概念其实在刚开始学的时候不是很重要，当我们讲完后面的例子之后，在回来看上面的内容会一下明白很多。</p>
<p>但是，这里有几个概念是必须知道的。</p>
<h2 id="heading-1"></h2>
<h3 id="loader-加载器">Loader 加载器</h3>
<p>顾名思义，这个就是从指定源进行加载数据的。比如：文件夹 <code>DirectoryLoader</code>、Azure 存储 <code>AzureBlobStorageContainerLoader</code>、CSV 文件 <code>CSVLoader</code>、印象笔记 <code>EverNoteLoader</code>、Google 网盘 <code>GoogleDriveLoader</code>、任意的网页 <code>UnstructuredHTMLLoader</code>、PDF <code>PyPDFLoader</code>、S3 <code>S3DirectoryLoader</code>/<code>S3FileLoader</code>、</p>
<p>Youtube <code>YoutubeLoader</code> 等等，上面只是简单的进行列举了几个，官方提供了超级的多的加载器供你使用。</p>
<blockquote>
<p><a href="https://python.langchain.com/en/latest/modules/indexes/document_loaders.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/indexes/document_loaders.html</a></p>
</blockquote>
<h3 id="heading-2"></h3>
<h3 id="document-文档">Document 文档</h3>
<p>当使用 loader 加载器读取到数据源后，数据源需要转换成 Document 对象后，后续才能进行使用。</p>
<h3 id="heading-3"></h3>
<h3 id="text-spltters-文本分割">Text Spltters 文本分割</h3>
<p>顾名思义，文本分割就是用来分割文本的。为什么需要分割文本？因为我们每次不管是做把文本当作 prompt 发给 openai api ，还是还是使用 openai api embedding 功能都是有字符限制的。</p>
<p>比如我们将一份 300 页的 pdf 发给 openai api，让他进行总结，他肯定会报超过最大 Token 错。所以这里就需要使用文本分割器去分割我们 loader 进来的 Document。</p>
<h3 id="heading-4"></h3>
<h3 id="vectorstores-向量数据库">Vectorstores 向量数据库</h3>
<p>因为数据相关性搜索其实是向量运算。所以，不管我们是使用 openai api embedding 功能还是直接通过向量数据库直接查询，都需要将我们的加载进来的数据 <code>Document</code> 进行向量化，才能进行向量运算搜索。转换成向量也很简单，只需要我们把数据存储到对应的向量数据库中即可完成向量的转换。</p>
<p>官方也提供了很多的向量数据库供我们使用。</p>
<blockquote>
<p><a href="https://python.langchain.com/en/latest/modules/indexes/vectorstores.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/indexes/vectorstores.html</a></p>
</blockquote>
<h3 id="heading-5"></h3>
<h3 id="chain-链">Chain 链</h3>
<p>我们可以把 Chain 理解为任务。一个 Chain 就是一个任务，当然也可以像链条一样，一个一个的执行多个链。</p>
<h3 id="heading-6"></h3>
<h3 id="agent-代理">Agent 代理</h3>
<p>我们可以简单的理解为他可以动态的帮我们选择和调用 chain 或者已有的工具。</p>
<p>执行过程可以参考下面这张图:</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406213322739.png" alt="image-20230406213322739" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<h3 id="embedding">Embedding</h3>
<p>用于衡量文本的相关性。这个也是 OpenAI API 能实现构建自己知识库的关键所在。</p>
<p>他相比 fine-tuning 最大的优势就是，不用进行训练，并且可以实时添加新的内容，而不用加一次新的内容就训练一次，并且各方面成本要比 fine-tuning 低很多。</p>
<blockquote>
<p>具体比较和选择可以参考这个视频：https://www.youtube.com/watch?v=9qq6HTr7Ocw</p>
</blockquote>
<h2 id="heading-7"></h2>
<h2 id="实战">实战</h2>
<p>通过上面的必备概念大家应该已经可以对 LangChain 有了一定的了解，但是可能还有有些懵。</p>
<p>这都是小问题，我相信看完后面的实战，你们就会彻底的理解上面的内容，并且能感受到这个库的真正强大之处。</p>
<p>因为我们 OpenAI API 进阶，所以我们后面的范例使用的 LLM 都是以 Open AI 为例，后面大家可以根据自己任务的需要换成自己需要的 LLM 模型即可。</p>
<p>当然，在这篇文章的末尾，全部的全部代码都会被保存为一个 colab 的 ipynb 文件提供给大家来学习。</p>
<blockquote>
<p>建议大家按顺序去看每个例子，因为下一个例子会用到上一个例子里面的知识点。</p>
<p>当然，如果有看不懂的也不用担心，可以继续往后看，第一次学习讲究的是不求甚解。</p>
</blockquote>
<h3 id="完成一次问答">完成一次问答</h3>
<p>第一个案例，我们就来个最简单的，用 LangChain 加载 OpenAI 的模型，并且完成一次问答。</p>
<p>在开始之前，我们需要先设置我们的 openai 的 key，这个 key 可以在用户管理里面创建，这里就不细说了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;OPENAI_API_KEY&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;你的api key&#39;</span>
</span></span></code></pre></div><p>然后，我们进行导入和执行</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;text-davinci-003&#34;</span><span class="p">,</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span><span class="p">(</span><span class="s2">&#34;怎么评价人工智能&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230404232621517.png" alt="image-20230404232621517" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>这时，我们就可以看到他给我们的返回结果了，怎么样，是不是很简单。</p>
<h3 id="通过-google-搜索并返回答案">通过 Google 搜索并返回答案</h3>
<p>接下来，我们就来搞点有意思的。我们来让我们的 OpenAI api 联网搜索，并返回答案给我们。</p>
<p>这里我们需要借助 Serpapi 来进行实现，Serpapi 提供了 google 搜索的 api 接口。</p>
<p>首先需要我们到 Serpapi 官网上注册一个用户，https://serpapi.com/ 并复制他给我们生成 api key。</p>
<p>然后我们需要像上面的 openai api key 一样设置到环境变量里面去。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;OPENAI_API_KEY&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;你的api key&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;SERPAPI_API_KEY&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;你的api key&#39;</span>
</span></span></code></pre></div><p>然后，开始编写我的代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">load_tools</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">AgentType</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载 OpenAI 模型</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="c1"># 加载 serpapi 工具</span>
</span></span><span class="line"><span class="cl"><span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&#34;serpapi&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 如果搜索完想再计算一下可以这么写</span>
</span></span><span class="line"><span class="cl"><span class="c1"># tools = load_tools([&#39;serpapi&#39;, &#39;llm-math&#39;], llm=llm)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 如果搜索完想再让他再用python的print做点简单的计算，可以这样写</span>
</span></span><span class="line"><span class="cl"><span class="c1"># tools=load_tools([&#34;serpapi&#34;,&#34;python_repl&#34;])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 工具加载后都需要初始化，verbose 参数为 True，会打印全部的执行详情</span>
</span></span><span class="line"><span class="cl"><span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">ZERO_SHOT_REACT_DESCRIPTION</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 运行 agent</span>
</span></span><span class="line"><span class="cl"><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&#34;What&#39;s the date today? What great events have taken place today in history?&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230404234236982.png" alt="image-20230404234236982" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>我们可以看到，他正确的返回了日期（有时差），并且返回了历史上的今天。</p>
<p>在 chain 和 agent 对象上都会有 <code>verbose</code> 这个参数，这个是个非常有用的参数，开启他后我们可以看到完整的 chain 执行过程。</p>
<p>可以在上面返回的结果看到，他将我们的问题拆分成了几个步骤，然后一步一步得到最终的答案。</p>
<p>关于 agent type 几个选项的含义（理解不了也不会影响下面的学习，用多了自然理解了）：</p>
<ul>
<li>zero-shot-react-description: 根据工具的描述和请求内容的来决定使用哪个工具（最常用）</li>
<li>react-docstore: 使用 ReAct 框架和 docstore 交互, 使用<code>Search</code> 和<code>Lookup</code> 工具, 前者用来搜, 后者寻找 term, 举例: <code>Wipipedia</code> 工具</li>
<li>self-ask-with-search 此代理只使用一个工具: Intermediate Answer, 它会为问题寻找事实答案(指的非 gpt 生成的答案, 而是在网络中,文本中已存在的), 如 <code>Google search API</code> 工具</li>
<li>conversational-react-description: 为会话设置而设计的代理, 它的 prompt 会被设计的具有会话性, 且还是会使用 ReAct 框架来决定使用来个工具, 并且将过往的会话交互存入内存</li>
</ul>
<blockquote>
<p>reAct 介绍可以看这个：https://arxiv.org/pdf/2210.03629.pdf</p>
<p>LLM 的 ReAct 模式的 Python 实现: <a href="https://til.simonwillison.net/llms/python-react-pattern" target="_blank" rel="noopener">https://til.simonwillison.net/llms/python-react-pattern</a></p>
<p>agent type 官方解释：</p>
<p><a href="https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html?highlight=zero-shot-react-description" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html?highlight=zero-shot-react-description</a></p>
</blockquote>
<blockquote>
<p>有一点要说明的是，这个 <code>serpapi</code> 貌似对中文不是很友好，所以提问的 prompt 建议使用英文。</p>
</blockquote>
<p>当然，官方已经写好了 <code>ChatGPT Plugins</code> 的 agent，未来 chatgpt 能用啥插件，我们在 api 里面也能用插件，想想都美滋滋。</p>
<p>不过目前只能使用不用授权的插件，期待未来官方解决这个。</p>
<p>感兴趣的可以看这个文档：https://python.langchain.com/en/latest/modules/agents/tools/examples/chatgpt_plugins.html</p>
<blockquote>
<p>Chatgpt 只能给官方赚钱，而 Openai API 能给我赚钱</p>
</blockquote>
<h3 id="对超长文本进行总结">对超长文本进行总结</h3>
<p>假如我们想要用 openai api 对一个段文本进行总结，我们通常的做法就是直接发给 api 让他总结。但是如果文本超过了 api 最大的 token 限制就会报错。</p>
<p>这时，我们一般会进行对文章进行分段，比如通过 tiktoken 计算并分割，然后将各段发送给 api 进行总结，最后将各段的总结再进行一个全部的总结。</p>
<p>如果，你用是 LangChain，他很好的帮我们处理了这个过程，使得我们编写代码变的非常简单。</p>
<p>废话不多说，直接上代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredFileLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains.summarize</span> <span class="kn">import</span> <span class="n">load_summarize_chain</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 导入文本</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">UnstructuredFileLoader</span><span class="p">(</span><span class="s2">&#34;/content/sample_data/data/lg_test.txt&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将文本转成 Document 对象</span>
</span></span><span class="line"><span class="cl"><span class="n">document</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;documents:</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">document</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化文本分割器</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 切分文本</span>
</span></span><span class="line"><span class="cl"><span class="n">split_documents</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;documents:</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">split_documents</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载 llm 模型</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;text-davinci-003&#34;</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建总结链</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s2">&#34;refine&#34;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行总结链，（为了快速演示，只总结前5段）</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">split_documents</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</span></span></code></pre></div><p>首先我们对切割前和切割后的 document 个数进行了打印，我们可以看到，切割前就是只有整篇的一个 document，切割完成后，会把上面一个 document 切成 317 个 document。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230405162631460.png" alt="image-20230405162631460" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>最终输出了对前 5 个 document 的总结。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230405162937249.png" alt="image-20230405162937249" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>这里有几个参数需要注意：</p>
<p><strong>文本分割器的 <code>chunk_overlap</code> 参数</strong></p>
<p>这个是指切割后的每个 document 里包含几个上一个 document 结尾的内容，主要作用是为了增加每个 document 的上下文关联。比如，<code>chunk_overlap=0</code>时， 第一个 document 为 aaaaaa，第二个为 bbbbbb；当 <code>chunk_overlap=2</code> 时，第一个 document 为 aaaaaa，第二个为 aabbbbbb。</p>
<p>不过，这个也不是绝对的，要看所使用的那个文本分割模型内部的具体算法。</p>
<blockquote>
<p>文本分割器可以参考这个文档：https://python.langchain.com/en/latest/modules/indexes/text_splitters.html</p>
</blockquote>
<p><strong>chain 的 <code>chain_type</code> 参数</strong></p>
<p>这个参数主要控制了将 document 传递给 llm 模型的方式，一共有 4 种方式：</p>
<p><code>stuff</code>: 这种最简单粗暴，会把所有的 document 一次全部传给 llm 模型进行总结。如果 document 很多的话，势必会报超出最大 token 限制的错，所以总结文本的时候一般不会选中这个。</p>
<p><code>map_reduce</code>: 这个方式会先将每个 document 进行总结，最后将所有 document 总结出的结果再进行一次总结。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230405165752743.png" alt="image-20230405165752743" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p><code>refine</code>: 这种方式会先总结第一个 document，然后在将第一个 document 总结出的内容和第二个 document 一起发给 llm 模型在进行总结，以此类推。这种方式的好处就是在总结后一个 document 的时候，会带着前一个的 document 进行总结，给需要总结的 document 添加了上下文，增加了总结内容的连贯性。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230405170617383.png" alt="image-20230405170617383" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p><code>map_rerank</code>: 这种一般不会用在总结的 chain 上，而是会用在问答的 chain 上，他其实是一种搜索答案的匹配方式。首先你要给出一个问题，他会根据问题给每个 document 计算一个这个 document 能回答这个问题的概率分数，然后找到分数最高的那个 document ，在通过把这个 document 转化为问题的 prompt 的一部分（问题+document）发送给 llm 模型，最后 llm 模型返回具体答案。</p>
<h3 id="构建本地知识库问答机器人">构建本地知识库问答机器人</h3>
<p>在这个例子中，我们会介绍如何从我们本地读取多个文档构建知识库，并且使用 Openai API 在知识库中进行搜索并给出答案。</p>
<p>这个是个很有用的教程，比如可以很方便的做一个可以介绍公司业务的机器人，或是介绍一个产品的机器人。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span><span class="p">,</span><span class="n">VectorDBQA</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">RetrievalQA</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载文件夹中的所有txt类型的文件</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s1">&#39;/content/sample_data/data/&#39;</span><span class="p">,</span> <span class="n">glob</span><span class="o">=</span><span class="s1">&#39;**/*.txt&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将数据转成 document 对象，每个文件会作为一个 document</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化加载器</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 切割加载的 document</span>
</span></span><span class="line"><span class="cl"><span class="n">split_docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 openai 的 embeddings 对象</span>
</span></span><span class="line"><span class="cl"><span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">split_docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建问答对象</span>
</span></span><span class="line"><span class="cl"><span class="n">qa</span> <span class="o">=</span> <span class="n">VectorDBQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">chain_type</span><span class="o">=</span><span class="s2">&#34;stuff&#34;</span><span class="p">,</span> <span class="n">vectorstore</span><span class="o">=</span><span class="n">docsearch</span><span class="p">,</span><span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 进行问答</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">qa</span><span class="p">({</span><span class="s2">&#34;query&#34;</span><span class="p">:</span> <span class="s2">&#34;科大讯飞今年第一季度收入是多少？&#34;</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230405173730382.png" alt="image-20230405173730382" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>我们可以通过结果看到，他成功的从我们的给到的数据中获取了正确的答案。</p>
<blockquote>
<p>关于 Openai embeddings 详细资料可以参看这个连接: <a href="https://platform.openai.com/docs/guides/embeddings" target="_blank" rel="noopener">https://platform.openai.com/docs/guides/embeddings</a></p>
</blockquote>
<h3 id="构建向量索引数据库">构建向量索引数据库</h3>
<p>我们上个案例里面有一步是将 document 信息转换成向量信息和 embeddings 的信息并临时存入 Chroma 数据库。</p>
<p>因为是临时存入，所以当我们上面的代码执行完成后，上面的向量化后的数据将会丢失。如果想下次使用，那么就还需要再计算一次 embeddings，这肯定不是我们想要的。</p>
<p>那么，这个案例我们就来通过 Chroma 和 Pinecone 这两个数据库来讲一下如何做向量数据持久化。</p>
<blockquote>
<p>因为 LangChain 支持的数据库有很多，所以这里就介绍两个用的比较多的，更多的可以参看文档:https://python.langchain.com/en/latest/modules/indexes/vectorstores/getting_started.html</p>
</blockquote>
<p><strong>Chroma</strong></p>
<p>chroma 是个本地的向量数据库，他提供的一个 <code>persist_directory</code> 来设置持久化目录进行持久化。读取时，只需要调取 <code>from_document</code> 方法加载即可。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 持久化数据</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">persist_directory</span><span class="o">=</span><span class="s2">&#34;D:/vector_store&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载数据</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">persist_directory</span><span class="o">=</span><span class="s2">&#34;D:/vector_store&#34;</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>Pinecone</strong></p>
<p>Pinecone 是一个在线的向量数据库。所以，我可以第一步依旧是注册，然后拿到对应的 api key。https://app.pinecone.io/</p>
<blockquote>
<p>免费版如果索引 14 天不使用会被自动清除。</p>
</blockquote>
<p>然后创建我们的数据库：</p>
<p>Index Name：这个随意</p>
<p>Dimensions：OpenAI 的 text-embedding-ada-002 模型为 OUTPUT DIMENSIONS 为 1536，所以我们这里填 1536</p>
<p>Metric：可以默认为 cosine</p>
<p>选择 starter plan</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/starter-plan.png" alt="image-20230405184646314" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>持久化数据和加载数据代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 持久化数据</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Pinecone</span><span class="o">.</span><span class="n">from_texts</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">split_docs</span><span class="p">],</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载数据</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Pinecone</span><span class="o">.</span><span class="n">from_existing_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</span></span></code></pre></div><p>一个简单从数据库获取 embeddings，并回答的代码如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">DirectoryLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span><span class="p">,</span> <span class="n">Pinecone</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pinecone</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 pinecone</span>
</span></span><span class="line"><span class="cl"><span class="n">pinecone</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">api_key</span><span class="o">=</span><span class="s2">&#34;你的api key&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">environment</span><span class="o">=</span><span class="s2">&#34;你的Environment&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">DirectoryLoader</span><span class="p">(</span><span class="s1">&#39;/content/sample_data/data/&#39;</span><span class="p">,</span> <span class="n">glob</span><span class="o">=</span><span class="s1">&#39;**/*.txt&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将数据转成 document 对象，每个文件会作为一个 document</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化加载器</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 切割加载的 document</span>
</span></span><span class="line"><span class="cl"><span class="n">split_docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">index_name</span><span class="o">=</span><span class="s2">&#34;liaokong-test&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 持久化数据</span>
</span></span><span class="line"><span class="cl"><span class="c1"># docsearch = Pinecone.from_texts([t.page_content for t in split_docs], embeddings, index_name=index_name)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载数据</span>
</span></span><span class="line"><span class="cl"><span class="n">docsearch</span> <span class="o">=</span> <span class="n">Pinecone</span><span class="o">.</span><span class="n">from_existing_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">,</span><span class="n">embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">query</span> <span class="o">=</span> <span class="s2">&#34;科大讯飞今年第一季度收入是多少？&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">docs</span> <span class="o">=</span> <span class="n">docsearch</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">include_metadata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s2">&#34;stuff&#34;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input_documents</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230407001803057.png" alt="image-20230407001803057" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<h3 id="使用-gpt35-模型构建油管频道问答机器人">使用 GPT3.5 模型构建油管频道问答机器人</h3>
<p>在 chatgpt api（也就是 GPT-3.5-Turbo）模型出来后，因钱少活好深受大家喜爱，所以 LangChain 也加入了专属的链和模型，我们来跟着这个例子看下如何使用他。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">YoutubeLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ChatVectorDBChain</span><span class="p">,</span> <span class="n">ConversationalRetrievalChain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.prompts.chat</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">ChatPromptTemplate</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">HumanMessagePromptTemplate</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 加载 youtube 频道</span>
</span></span><span class="line"><span class="cl"><span class="n">loader</span> <span class="o">=</span> <span class="n">YoutubeLoader</span><span class="o">.</span><span class="n">from_youtube_url</span><span class="p">(</span><span class="s1">&#39;https://www.youtube.com/watch?v=Dj60HHy-Kqk&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将数据转成 document</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化文本分割器</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 分割 youtube documents</span>
</span></span><span class="line"><span class="cl"><span class="n">documents</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 openai embeddings</span>
</span></span><span class="line"><span class="cl"><span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 将数据存入向量存储</span>
</span></span><span class="line"><span class="cl"><span class="n">vector_store</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 通过向量存储初始化检索器</span>
</span></span><span class="line"><span class="cl"><span class="n">retriever</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">system_template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">Use the following context to answer the user&#39;s question.
</span></span></span><span class="line"><span class="cl"><span class="s2">If you don&#39;t know the answer, say you don&#39;t, don&#39;t try to make it up. And answer in Chinese.
</span></span></span><span class="line"><span class="cl"><span class="s2">-----------
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{context}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">-----------
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{chat_history}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数</span>
</span></span><span class="line"><span class="cl"><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">  <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">system_template</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{question}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 prompt 对象</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化问答链</span>
</span></span><span class="line"><span class="cl"><span class="n">qa</span> <span class="o">=</span> <span class="n">ConversationalRetrievalChain</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">2048</span><span class="p">),</span><span class="n">retriever</span><span class="p">,</span><span class="n">condense_question_prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chat_history</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">question</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;问题：&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 开始发送问题 chat_history 为必须参数,用于存储对话历史</span>
</span></span><span class="line"><span class="cl">  <span class="n">result</span> <span class="o">=</span> <span class="n">qa</span><span class="p">({</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;chat_history&#39;</span><span class="p">:</span> <span class="n">chat_history</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">  <span class="n">chat_history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">question</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>我们可以看到他能很准确的围绕这个油管视频进行问答</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406211923672.png" alt="image-20230406211923672" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>使用流式回答也很方便</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.callbacks.base</span> <span class="kn">import</span> <span class="n">CallbackManager</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.callbacks.streaming_stdout</span> <span class="kn">import</span> <span class="n">StreamingStdOutCallbackHandler</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callback_manager</span><span class="o">=</span><span class="n">CallbackManager</span><span class="p">([</span><span class="n">StreamingStdOutCallbackHandler</span><span class="p">()]),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">resp</span> <span class="o">=</span> <span class="n">chat</span><span class="p">(</span><span class="n">chat_prompt_with_values</span><span class="o">.</span><span class="n">to_messages</span><span class="p">())</span>
</span></span></code></pre></div><h3 id="用-openai-连接万种工具">用 OpenAI 连接万种工具</h3>
<p>我们主要是结合使用 <code>zapier</code> 来实现将万种工具连接起来。</p>
<p>所以我们第一步依旧是需要申请账号和他的自然语言 api key。https://zapier.com/l/natural-language-actions</p>
<p>他的 api key 虽然需要填写信息申请。但是基本填入信息后，基本可以秒在邮箱里看到审核通过的邮件。</p>
<p>然后，我们通过右键里面的连接打开我们的 api 配置页面。我们点击右侧的 <code>Manage Actions</code> 来配置我们要使用哪些应用。</p>
<p>我在这里配置了 Gmail 读取和发邮件的 action，并且所有字段都选的是通过 AI 猜。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406233319250.png" alt="image-20230406233319250" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406234827815.png" alt="image-20230406234827815" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>配置好后，我们开始写代码</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;ZAPIER_NLA_API_KEY&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents.agent_toolkits</span> <span class="kn">import</span> <span class="n">ZapierToolkit</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.utilities.zapier</span> <span class="kn">import</span> <span class="n">ZapierNLAWrapper</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">.3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">zapier</span> <span class="o">=</span> <span class="n">ZapierNLAWrapper</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">toolkit</span> <span class="o">=</span> <span class="n">ZapierToolkit</span><span class="o">.</span><span class="n">from_zapier_nla_wrapper</span><span class="p">(</span><span class="n">zapier</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">toolkit</span><span class="o">.</span><span class="n">get_tools</span><span class="p">(),</span> <span class="n">llm</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="s2">&#34;zero-shot-react-description&#34;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 我们可以通过打印的方式看到我们都在 Zapier 里面配置了哪些可以用的工具</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">toolkit</span><span class="o">.</span><span class="n">get_tools</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span> <span class="p">(</span><span class="n">tool</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span> <span class="p">(</span><span class="n">tool</span><span class="o">.</span><span class="n">description</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span> <span class="p">(</span><span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;请用中文总结最后一封&#34;******@qq.com&#34;发给我的邮件。并将总结发送给&#34;******@qq.com&#34;&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406234712909.png" alt="image-20230406234712909" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>我们可以看到他成功读取了<code>******@qq.com</code>给他发送的最后一封邮件，并将总结的内容又发送给了<code>******@qq.com</code></p>
<p>这是我发送给 Gmail 的邮件。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406234017369.png" alt="image-20230406234017369" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>这是他发送给 QQ 邮箱的邮件。</p>
<p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406234800632.png" alt="image-20230406234800632" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>这只是个小例子，因为 <code>zapier</code> 有数以千计的应用，所以我们可以轻松结合 openai api 搭建自己的工作流。</p>
<h2 id="小例子们">小例子们</h2>
<p>一些比较大的知识点都已经讲完了，后面的内容都是一些比较有趣的小例子，当作拓展延伸。</p>
<h3 id="执行多个-chain"><strong>执行多个 chain</strong></h3>
<p>因为他是链式的，所以他也可以按顺序依次去执行多个 chain</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">SimpleSequentialChain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># location 链</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Your job is to come up with a classic dish from the area that the users suggests.
</span></span></span><span class="line"><span class="cl"><span class="s2">% USER LOCATION
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{user_location}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">YOUR RESPONSE:
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;user_location&#34;</span><span class="p">],</span> <span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">location_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># meal 链</span>
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Given a meal, give a short and simple recipe on how to make that dish at home.
</span></span></span><span class="line"><span class="cl"><span class="s2">% MEAL
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{user_meal}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">YOUR RESPONSE:
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;user_meal&#34;</span><span class="p">],</span> <span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">meal_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 通过 SimpleSequentialChain 串联起来，第一个答案会被替换第二个中的user_meal，然后再进行询问</span>
</span></span><span class="line"><span class="cl"><span class="n">overall_chain</span> <span class="o">=</span> <span class="n">SimpleSequentialChain</span><span class="p">(</span><span class="n">chains</span><span class="o">=</span><span class="p">[</span><span class="n">location_chain</span><span class="p">,</span> <span class="n">meal_chain</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">review</span> <span class="o">=</span> <span class="n">overall_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&#34;Rome&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406000133339.png" alt="image-20230406000133339" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<h3 id="结构化输出"><strong>结构化输出</strong></h3>
<p>有时候我们希望输出的内容不是文本，而是像 json 那样结构化的数据。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.output_parsers</span> <span class="kn">import</span> <span class="n">StructuredOutputParser</span><span class="p">,</span> <span class="n">ResponseSchema</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;text-davinci-003&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 告诉他我们生成的内容需要哪些字段，每个字段类型式啥</span>
</span></span><span class="line"><span class="cl"><span class="n">response_schemas</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">ResponseSchema</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;bad_string&#34;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&#34;This a poorly formatted user input string&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">ResponseSchema</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;good_string&#34;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&#34;This is your response, a reformatted response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化解析器</span>
</span></span><span class="line"><span class="cl"><span class="n">output_parser</span> <span class="o">=</span> <span class="n">StructuredOutputParser</span><span class="o">.</span><span class="n">from_response_schemas</span><span class="p">(</span><span class="n">response_schemas</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 生成的格式提示符</span>
</span></span><span class="line"><span class="cl"><span class="c1"># {</span>
</span></span><span class="line"><span class="cl"><span class="c1">#	&#34;bad_string&#34;: string  // This a poorly formatted user input string</span>
</span></span><span class="line"><span class="cl"><span class="c1">#	&#34;good_string&#34;: string  // This is your response, a reformatted response</span>
</span></span><span class="line"><span class="cl"><span class="c1">#}</span>
</span></span><span class="line"><span class="cl"><span class="n">format_instructions</span> <span class="o">=</span> <span class="n">output_parser</span><span class="o">.</span><span class="n">get_format_instructions</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">You will be given a poorly formatted string from a user.
</span></span></span><span class="line"><span class="cl"><span class="s2">Reformat it and make sure all the words are spelled correctly
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{format_instructions}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">% USER INPUT:
</span></span></span><span class="line"><span class="cl"><span class="s2"></span><span class="si">{user_input}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">YOUR RESPONSE:
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 将我们的格式描述嵌入到 prompt 中去，告诉 llm 我们需要他输出什么样格式的内容</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;user_input&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">partial_variables</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;format_instructions&#34;</span><span class="p">:</span> <span class="n">format_instructions</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="n">template</span><span class="o">=</span><span class="n">template</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">promptValue</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">user_input</span><span class="o">=</span><span class="s2">&#34;welcom to califonya!&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">llm_output</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">promptValue</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用解析器进行解析生成的内容</span>
</span></span><span class="line"><span class="cl"><span class="n">output_parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">llm_output</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406000017276.png" alt="image-20230406000017276" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<h3 id="爬取网页并输出-json-数据"><strong>爬取网页并输出 JSON 数据</strong></h3>
<p>有些时候我们需要爬取一些<mark style="color:red;"><strong>结构性比较强</strong></mark>的网页，并且需要将网页中的信息以 JSON 的方式返回回来。</p>
<p>我们就可以使用 <code>LLMRequestsChain</code> 类去实现，具体可以参考下面代码</p>
<blockquote>
<p>为了方便理解，我在例子中直接使用了 Prompt 的方法去格式化输出结果，而没用使用上个案例中用到的 <code>StructuredOutputParser</code>去格式化，也算是提供了另外一种格式化的思路</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMRequestsChain</span><span class="p">,</span> <span class="n">LLMChain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;gpt-3.5-turbo&#34;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;在 &gt;&gt;&gt; 和 &lt;&lt;&lt; 之间是网页的返回的HTML内容。
</span></span></span><span class="line"><span class="cl"><span class="s2">网页是新浪财经A股上市公司的公司简介。
</span></span></span><span class="line"><span class="cl"><span class="s2">请抽取参数请求的信息。
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt;&gt; </span><span class="si">{requests_result}</span><span class="s2"> &lt;&lt;&lt;
</span></span></span><span class="line"><span class="cl"><span class="s2">请使用如下的JSON格式返回数据
</span></span></span><span class="line"><span class="cl"><span class="s2">{{
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;company_name&#34;:&#34;a&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;company_english_name&#34;:&#34;b&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;issue_price&#34;:&#34;c&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;date_of_establishment&#34;:&#34;d&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;registered_capital&#34;:&#34;e&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;office_address&#34;:&#34;f&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;Company_profile&#34;:&#34;g&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">}}
</span></span></span><span class="line"><span class="cl"><span class="s2">Extracted:&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;requests_result&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">template</span><span class="o">=</span><span class="n">template</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="n">LLMRequestsChain</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">=</span><span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;url&#34;</span><span class="p">:</span> <span class="s2">&#34;https://vip.stock.finance.sina.com.cn/corp/go.php/vCI_CorpInfo/stockid/600519.phtml&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">chain</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">])</span>
</span></span></code></pre></div><p>我们可以看到，他很好的将格式化后的结果输出了出来</p>
<figure><img src="doc/image-20230510234934.png" alt=""><figcaption></figcaption></figure>
<h3 id="自定义-agent-中所使用的工具"><strong>自定义 agent 中所使用的工具</strong></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span><span class="p">,</span> <span class="n">Tool</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">AgentType</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.tools</span> <span class="kn">import</span> <span class="n">BaseTool</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">LLMMathChain</span><span class="p">,</span> <span class="n">SerpAPIWrapper</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化搜索链和计算链</span>
</span></span><span class="line"><span class="cl"><span class="n">search</span> <span class="o">=</span> <span class="n">SerpAPIWrapper</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">llm_math_chain</span> <span class="o">=</span> <span class="n">LLMMathChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建一个功能列表，指明这个 agent 里面都有哪些可用工具，agent 执行过程可以看必知概念里的 Agent 那张图</span>
</span></span><span class="line"><span class="cl"><span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">Tool</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;Search&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">func</span><span class="o">=</span><span class="n">search</span><span class="o">.</span><span class="n">run</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">description</span><span class="o">=</span><span class="s2">&#34;useful for when you need to answer questions about current events&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Tool</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">name</span><span class="o">=</span><span class="s2">&#34;Calculator&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">func</span><span class="o">=</span><span class="n">llm_math_chain</span><span class="o">.</span><span class="n">run</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">description</span><span class="o">=</span><span class="s2">&#34;useful for when you need to answer questions about math&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 agent</span>
</span></span><span class="line"><span class="cl"><span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">ZERO_SHOT_REACT_DESCRIPTION</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行 agent</span>
</span></span><span class="line"><span class="cl"><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&#34;Who is Leo DiCaprio&#39;s girlfriend? What is her current age raised to the 0.43 power?&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>
















  <figure  >
    <div class="d-flex justify-content-center">
      <div class="w-100" ><img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/LangChain-Chinese-Getting-Started-Guide/image-20230406002117283.png" alt="image-20230406002117283" loading="lazy" data-zoomable /></div>
    </div></figure></p>
<p>自定义工具里面有个比较有意思的地方，使用哪个工具的权重是靠 <code>工具中描述内容</code> 来实现的，和我们之前编程靠数值来控制权重完全不同。</p>
<p>比如 Calculator 在描述里面写到，如果你问关于数学的问题就用他这个工具。我们就可以在上面的执行过程中看到，他在我们请求的 prompt 中数学的部分，就选用了 Calculator 这个工具进行计算。</p>
<h3 id="使用-memory-实现一个带记忆的对话机器人"><strong>使用 Memory 实现一个带记忆的对话机器人</strong></h3>
<p>上一个例子我们使用的是通过自定义一个列表来存储对话的方式来保存历史的。</p>
<p>当然，你也可以使用自带的 memory 对象来实现这一点。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ChatMessageHistory</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化 MessageHistory 对象</span>
</span></span><span class="line"><span class="cl"><span class="n">history</span> <span class="o">=</span> <span class="n">ChatMessageHistory</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 给 MessageHistory 对象添加对话内容</span>
</span></span><span class="line"><span class="cl"><span class="n">history</span><span class="o">.</span><span class="n">add_ai_message</span><span class="p">(</span><span class="s2">&#34;你好！&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">history</span><span class="o">.</span><span class="n">add_user_message</span><span class="p">(</span><span class="s2">&#34;中国的首都是哪里？&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 执行对话</span>
</span></span><span class="line"><span class="cl"><span class="n">ai_response</span> <span class="o">=</span> <span class="n">chat</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">messages</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">ai_response</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="使用-hugging-face-模型"><strong>使用 Hugging Face 模型</strong></h3>
<p>使用 Hugging Face 模型之前，需要先设置环境变量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HUGGINGFACEHUB_API_TOKEN&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
</span></span></code></pre></div><p>使用在线的 Hugging Face 模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">HuggingFaceHub</span><span class="p">,</span> <span class="n">LLMChain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Question: </span><span class="si">{question}</span><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Answer: Let&#39;s think step by step.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;question&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">HuggingFaceHub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&#34;google/flan-t5-xl&#34;</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;temperature&#34;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&#34;max_length&#34;</span><span class="p">:</span><span class="mi">64</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="n">llm_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">question</span> <span class="o">=</span> <span class="s2">&#34;What NFL team won the Super Bowl in the year Justin Beiber was born?&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
</span></span></code></pre></div><p>将 Hugging Face 模型直接拉到本地使用</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">LLMChain</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model_id</span> <span class="o">=</span> <span class="s1">&#39;google/flan-t5-large&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;text2text-generation&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_length</span><span class="o">=</span><span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">local_llm</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="o">=</span><span class="n">pipe</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">local_llm</span><span class="p">(</span><span class="s1">&#39;What is the capital of France? &#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">template</span> <span class="o">=</span> <span class="s2">&#34;&#34;&#34;Question: </span><span class="si">{question}</span><span class="s2"> Answer: Let&#39;s think step by step.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;question&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">llm_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">local_llm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">question</span> <span class="o">=</span> <span class="s2">&#34;What is the capital of England?&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
</span></span></code></pre></div><p>将模型拉到本地使用的好处：</p>
<ul>
<li>训练模型</li>
<li>可以使用本地的 GPU</li>
<li>有些模型无法在 Hugging Face 运行</li>
</ul>
<h3 id="通过自然语言执行-sql-命令"><strong>通过自然语言执行 SQL 命令</strong></h3>
<p>我们通过 <code>SQLDatabaseToolkit</code> 或者 <code>SQLDatabaseChain</code> 都可以实现执行 SQL 命令的操作</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">create_sql_agent</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.agents.agent_toolkits</span> <span class="kn">import</span> <span class="n">SQLDatabaseToolkit</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.sql_database</span> <span class="kn">import</span> <span class="n">SQLDatabase</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.llms.openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">db</span> <span class="o">=</span> <span class="n">SQLDatabase</span><span class="o">.</span><span class="n">from_uri</span><span class="p">(</span><span class="s2">&#34;sqlite:///../notebooks/Chinook.db&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">toolkit</span> <span class="o">=</span> <span class="n">SQLDatabaseToolkit</span><span class="p">(</span><span class="n">db</span><span class="o">=</span><span class="n">db</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">agent_executor</span> <span class="o">=</span> <span class="n">create_sql_agent</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">toolkit</span><span class="o">=</span><span class="n">toolkit</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">agent_executor</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&#34;Describe the playlisttrack table&#34;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span><span class="p">,</span> <span class="n">SQLDatabase</span><span class="p">,</span> <span class="n">SQLDatabaseChain</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">db</span> <span class="o">=</span> <span class="n">SQLDatabase</span><span class="o">.</span><span class="n">from_uri</span><span class="p">(</span><span class="s2">&#34;mysql+pymysql://root:root@127.0.0.1/chinook&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">db_chain</span> <span class="o">=</span> <span class="n">SQLDatabaseChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">database</span><span class="o">=</span><span class="n">db</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">db_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&#34;How many employees are there?&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>这里可以参考这两篇文档：</p>
<p><a href="https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html</a></p>
<p><a href="https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html</a></p>
<h2 id="总结">总结</h2>
<p>所有的案例都基本已经结束了，希望大家能通过这篇文章的学习有所收获。这篇文章只是对 LangChain 一个初级的讲解，高级的功能希望大家继续探索。</p>
<p>并且因为 LangChain 迭代极快，所以后面肯定会随着 AI 继续的发展，还会迭代出更好用的功能，所以我非常看好这个开源库。</p>
<p>希望大家能结合 LangChain 开发出更有创意的产品，而不仅仅只搞一堆各种一键搭建 chatgpt 聊天客户端的那种产品。</p>
<p>这篇标题后面加了个 <code>01</code> 是我希望这篇文章只是一个开始，后面如何出现了更好的技术我还是希望能继续更新下去这个系列。</p>
<p>本文章的所有范例代码都在这里，祝大家学习愉快。</p>
<p><a href="https://colab.research.google.com/drive/1ArRVMiS-YkhUlobHrU6BeS8fF57UeaPQ?usp=sharing" target="_blank" rel="noopener">https://colab.research.google.com/drive/1ArRVMiS-YkhUlobHrU6BeS8fF57UeaPQ?usp=sharing</a></p>

          </div>

          



          
          
          <div class="article-widget">
            
<div class="container-xl row post-nav">
  
  
</div>

          </div>
          

        <div class="body-footer">
          <p>最近更新于 0001-01-01</p>

          



          


  
  
  

  

  
  <section id="comments" class="mb-3 pt-0">
    
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); 
    s.async = true;
    s.src = 'https://' + "ngte" + '.disqus.com/embed.js';
    
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </section>
  



          


        </div>

      </article>

      <footer class="site-footer">

  



  

  
  <div class="copyright py-4 bg-footer">
      <div class="row justify-content-center">
        <div class="text-center footer-color">
          <p class="mb-0">© 2017-2022 NGTE all rights reserved</p>
        </div>
    </div>
  </div>

  <script type="text/javascript" id="clstr_globe" async src="//clustrmaps.com/globe.js?d=kgpJG5sWZQpKujBmD-uW1B54-WBPol-DuDtrB2KFjKs"></script>
  
</footer>


    </main>
  </div>
</div>
<script src="//unpkg.com/heti/umd/heti-addon.min.js"></script>
<script>
  const heti = new Heti('.article');
  heti.autoSpacing();
</script>
<script type="text/javascript">
  window.$crisp = [];
  window.CRISP_WEBSITE_ID = "12adcc35-9621-4313-8262-62dc654b29d8";
  (function () {
    setTimeout(function() {
      d = document;
      s = d.createElement("script");
      s.src = "https://client.crisp.chat/l.js";
      s.async = 1;
      d.getElementsByTagName("head")[0].appendChild(s);
    }, 2500);
  })();
</script>
  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>

    
    
    
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
      

    

    
    
    

    
    
    
      
      <script id="search-hit-algolia-template" type="text/html">
        <div class="search-hit">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a>
            </div>
            <div class="article-metadata search-hit-type">{{type}}</div>
            <p class="search-hit-description">{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js" crossorigin="anonymous"></script>
      
      
    

    
    

    
    
    
    
      <script id="dsq-count-scr" src="https://ngte.disqus.com/count.js" async></script>
      
    

    
    
      
      
      
      
      
      
      
    

    
    <script src="/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js" type="module"></script>
    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
    <script src="/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js"></script>

    
    
    
    
    
    
    <script>

var mybutton = document.getElementById("backTopBtn");


window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}


function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>


    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    <script>



(function() {
  'use strict';

  if(!document.queryCommandSupported('copy')) {
    return;
  }

  function flashCopyMessage(el, msg) {
    el.className = "highlight-copy-btn";
    el.textContent = msg;
    setTimeout(function() {
      el.textContent = "";
      el.className = "highlight-copy-btn fa fa-copy";
    }, 1000);
  }

  function selectText(node) {
    var selection = window.getSelection();
    var range = document.createRange();
    range.selectNodeContents(node);
    selection.removeAllRanges();
    selection.addRange(range);
    return selection;
  }

  function addCopyButton(containerEl) {
    var copyBtn = document.createElement("button");
    copyBtn.className = "highlight-copy-btn fa fa-copy";
    copyBtn.textContent = "";

    var codeEl = containerEl.firstElementChild;
    copyBtn.addEventListener('click', function() {
      try {
        var selection = selectText(codeEl);
        document.execCommand('copy');
        selection.removeAllRanges();
        
        flashCopyMessage(copyBtn, '已复制')
        
      } catch(e) {
        console && console.log(e);
        flashCopyMessage(copyBtn, 'Failed :\'(')
      }
    });

    containerEl.appendChild(copyBtn);
  }

  
  var highlightBlocks = document.getElementsByClassName('highlight');
  Array.prototype.forEach.call(highlightBlocks, addCopyButton);
})();
</script>

    


</body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>设计与对比 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/</link>
      <atom:link href="https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/index.xml" rel="self" type="application/rss+xml" />
    <description>设计与对比</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>设计与对比</title>
      <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/</link>
    </image>
    
    <item>
      <title>Sidecar</title>
      <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/sidecar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/sidecar/</guid>
      <description>&lt;h1 id=&#34;sidecar挎斗&#34;&gt;Sidecar（挎斗）&lt;/h1&gt;
&lt;p&gt;其中，对于服务网格创建的通信层应该位于架构的位置，Aspen Mesh 的 Andrew Jenkins 就提出了三种可能的选择，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作为一个 Lib 库，让每个微服务可导入。&lt;/li&gt;
&lt;li&gt;部署在节点的代理服务中，为所在节点的全部容器提供服务。&lt;/li&gt;
&lt;li&gt;与应用容器相并行，运作在一个独立的 sidecar 容器内。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，基于 sidecar 模式是目前最流行的服务网格模式，以至于在某种程度上讲，它已经成等同于服务网格的模式。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2019/11/02/KLEbgf.png&#34; alt=&#34;Sidercar 架构&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;服务网格中的每个应用微服务容器都有一个对应匹配的代理容器。服务到服务的通信所需的所有逻辑请求都从微服务中抽象出来，放到了 sidecar 中处理。通过将所有网络和通信代码放到一个单独的容器中，使其成为基础设施的一部分，并使开发人员不必将如上的内容视为应用程序的一部分而投入精力处理。从本质上说，抽象后剩下的也是一个微服务，但它可以非常专注于其业务逻辑。在微服务所运行的复杂环境中，它不需要知道如何与其他的任何微服务实现通信的问题，它只需要知道如何与 sidecar 通信，然后由 sidecar 负责余下的工作。&lt;/p&gt;
&lt;h1 id=&#34;为什么需要-sidecar&#34;&gt;为什么需要 Sidecar？&lt;/h1&gt;
&lt;p&gt;在构建任何软件架构时，我们都会不可避免地引入通过在网络上发出请求来实现彼此通信的服务。例如，考虑任何与数据库通信以存储或检索数据的应用程序，或者考虑一个更复杂的面向微服务的应用程序，它们为了执行操作都要向不同的服务发出许多请求：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2019/10/27/KynxII.jpg&#34; alt=&#34;网络连接方式&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;每当我们的服务通过网络请求互连时，我们都将最终用户的体验置于风险之中。我们都知道，不同服务之间的连接可能很慢，而且无法预测。它可能不安全，难以跟踪，并会引发许多其他的问题（例如路由、版本控制、金丝雀部署）。&lt;/p&gt;
&lt;p&gt;针对这种情况，开发人员通常采取以下一种措施：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;编写更多代码：开发人员构建一个智能客户端，每个服务都必须以库的形式使用该客户端。通常，这种方法会带来以下几个新问题：导致了更多技术债务；通常特定于具体的语言，妨碍了创新；库有多种实现，长远来看会导致碎片化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;挎斗（Sidecar）代理：服务将所有连接性和可观察性关注点委托给进程外运行时，后者位于每个请求的执行路径上。它将代理所有发出的连接并接受所有传入的连接。使用这种方法，开发人员就不需要关心连接性，而只需要关注业务价值交付。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据平面与控制平面&#34;&gt;数据平面与控制平面&lt;/h2&gt;
&lt;p&gt;它之所以被称为挎斗代理，是因为它是同一主机上与我们的服务进程并行运行的另一个进程，就像摩托车跨斗一样。服务的每个运行实例都将有一个挎斗代理实例，由于所有传入和传出的请求——以及它们的数据——总是通过挎斗代理，所以它也被称为数据平面（DP）。&lt;/p&gt;
&lt;p&gt;挎斗代理模型需要一个控制平面，使团队可以配置数据平面的行为并跟踪其服务的状态。采用挎斗代理模型的团队要么从头开始构建一个控制平面，要么使用市场上现有的通用控制平面，比如 Kuma。&lt;/p&gt;
&lt;p&gt;与数据平面（DP）不同，控制平面（CP）并不位于服务交互请求的执行路径上，它用于配置数据平面并从中检索数据（如可观察性信息）。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2019/10/27/Kyyvin.jpg&#34; alt=&#34;数据平面与控制平面&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;服务网格：一种由数据平面（DP：和服务平行部署的挎斗代理）和控制 DP 的控制平面（CP）组成的架构。通常，服务网格出现在 Kubernetes 上下文中，但是任何人都可以在任何平台上构建服务网格（包括 VM 和裸机）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>背景分析</title>
      <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E8%83%8C%E6%99%AF%E5%88%86%E6%9E%90/</guid>
      <description>&lt;h1 id=&#34;背景分析&#34;&gt;背景分析&lt;/h1&gt;
&lt;h1 id=&#34;微服务带来的协同问题&#34;&gt;微服务带来的协同问题&lt;/h1&gt;
&lt;p&gt;微服务软件架构（microservices）已经被越来越多的企业作为规模分布式软件开发的首选架构。引入该架构之初是将一个单体应用拆解成多个更小粒度的微服务 (micro-service)，通过 HTTP API 或像 Dubbo 这样的 RPC 框架将这些服务组装起来作为整体去提供服务。由于每个微服务足够地小且功能内聚，因此能很好地解决以往单体应用的开发与发布困难的问题。即便如此，随着企业的业务发展和人员规模的壮大，不同业务所形成的微服务群之间的协同却面临新的挑战。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;服务调用的富客户端版本升级：RPC 框架由基础架构组统一开发与维护，以 SDK 形式提供给其他部门使用。由于 SDK 与应用逻辑是耦合在同一个进程中的，当 SDK 向前演进所增加的特性并不是某些业务方所需要的时，这些业务方就没有动力配合中间件事业部去同步升级自己应用中的 SDK 版本，使得 SDK 在整个集团存在多个版本甚至变成长尾而形成包袱。类似的包袱反过来制约了 RPC 框架自身的演进效率。SDK 中 lib 库的升级无法对业务系统做到完全透明：业务系统会因为和业务无关的 lib 库升级而不得不进行升级。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多编程语言支持：分布式架构技术的火热，使得一些额外的分布式能力比如：如负载均衡、熔断限流、链路监控等也开始集成到 SDK 中。带来的好处是屏蔽了底层的实现细节，但是却使得应用程序的依赖变得越来越臃肿且难以维护。并且一些主流的微服务框架通常都与某种特定开发语言进行绑定，这就很难做到语言无关。当微服务框架是单一编程语言独大、不能同步支持好其他多个主流编程语言时（比如 C++、Go、Node.js 等）, 就会出现非独大编程语言的 SDK 在特性上严重滞后于独大编程语言的，最终影响使用非独大编程语言的业务方以自己最为熟悉的编程语言去发展和探索业务。编程语言独大所带来的好处是多数人的技术栈是一样的而提高了技术层面的协作效率，但却无法收获编程语言多样性所带来的其他好处。即便同步地对多个编程语言的 SDK 进行维护，同样的特性需要用不同的编程语言去实现其成本着实很高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在微服务软件架构所主张的拆分手法下，确实可以将每个拆分出来的服务从监管控层面做到足够的精致，但这势必会因为概念抽象不同、团队成熟度不一致等原因而使得这些“精致的烟囱”难以高效无缝协同，最终的结果是软件功能的易用性、风险的可控性和适应业务变化的敏捷性无法做到全局最优。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ngte-superbed.oss-cn-beijing.aliyuncs.com/superbed/2021/07/14/60eeab4d5132923bf81174f7.jpg&#34; alt=&#34;Service Mesh 与传统架构对比&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>框架对比</title>
      <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/</guid>
      <description>&lt;h1 id=&#34;产品对比&#34;&gt;产品对比&lt;/h1&gt;
&lt;p&gt;在云原生技术蓬勃发展的今天，通过相关权威机构如 CNCF 的管理，国内外很多优秀的开源云原生技术都已面世。如 Conduit、Consul、Envoy、华为的 ServiceMesher、新浪微博 MotanMesh、Mosn 等等。国内的大型互联网厂商如 Alibaba、字节跳动，以及一些优秀的公司如中原银行、中移在线等，都在不遗余力的拥抱云原生，拥抱下一代 Mesh 化的微服务架构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Linkerd（读作“link-dee”）：2016 年发布的元老级项目。Linkerd 最初是从 Twitter 开发的一个库中分离出来的，在领域内的另一个重量级项目 Conduit 加入后，便形成了 Linkerd 2.0 的基础。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Envoy：由 Lyft 创建，Envoy 充当服务网格的“数据平面”，与“控制平面”相匹配，提供比较完整的服务网格服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Istio：由 Lyft、IBM 和谷歌联合开发而成，是服务于 Envoy 等代理的“控制平面”。虽然默认是与 Envoy 成对匹配，但是它们都可以与其他平台配对使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HashiCorp Consul：在 Consul 1.2 版本后，推出了名为 Connect 的功能，这个功能为 HashiCorp 的分布式系统的服务发现和配置部分，添加了服务加密和基于身份的授权的功能。这个使得使 HashiCorp Consul 成为非常完整的服务网格。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;istio&#34;&gt;Istio&lt;/h1&gt;
&lt;p&gt;Istio 是由 Google、IBM 和 Lyft 共同开发的一款开源 Service Mesh，通过 Istio 可以轻松的为已经部署的服务创建一个服务网格，而服务的代码只需要很少更改甚至无需更改。Istio 也是一个与 K8s 紧密结合的适用于云原生场景的 Service Mesh 产品，通过 Istio 平台可以更方便的进行服务治理。Istio 具有的强大特性提供了一种统一的、更有效的方式来保护、连接和监视服务。Istio 只需要进行简单的配置就可实现服务的负载均衡、服务到服务的身份验证等分布式功能。Isito 的控制平面非常强大，它可以对 Istio 进行配置和管理，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 TLS 加密、强身份认证和授权的集群内服务到服务的安全通信&lt;/li&gt;
&lt;li&gt;自动负载均衡的 HTTP、gRPC、WebSocket 和 TCP 流量&lt;/li&gt;
&lt;li&gt;通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制&lt;/li&gt;
&lt;li&gt;一个可插入的策略层和配置 API，支持访问控制、速率限制和配额&lt;/li&gt;
&lt;li&gt;对集群内的所有流量(包括集群入口和出口)进行自动度量、日志和跟踪&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ngte-superbed.oss-cn-beijing.aliyuncs.com/superbed/2021/07/14/60eeac335132923bf8162074.jpg&#34; alt=&#34;Istio 示意图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&#34;linkerd&#34;&gt;Linkerd&lt;/h1&gt;
&lt;p&gt;Linkerd 是运行在 Kubernetes 上的 Service Mesh，它提供了运行时服务调式、服务可观察性、可靠性和安全性的能力，并且服务的所有代码都无需进行修改。&lt;/p&gt;
&lt;p&gt;Linkerd 的工作原理是在每个服务实例所在的环境中部署一组超轻的透明代理，并且这些代理会自动处理所有来往于服务的流量。这些代理相对应用程序来说是透明的，他们可以高效的直接向控制平面发送遥测数据并接收控制信号，而不会被应用程序所感知。这种设计允许 Linkerd 在不引入过多延迟的情况下测量和操纵进出服务的流量。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://ngte-superbed.oss-cn-beijing.aliyuncs.com/superbed/2021/07/14/60eeac5e5132923bf816fed7.png&#34; alt=&#34;Linkerd 示意图&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>应用场景</title>
      <link>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/microcn-series/5.%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AF%B9%E6%AF%94/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>&lt;h1 id=&#34;应用场景&#34;&gt;应用场景&lt;/h1&gt;
&lt;h2 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h2&gt;
&lt;p&gt;服务网格提供的一个关键功能就是负载均衡。我们通常认为负载均衡是网络功能，因为它提供按规则的数据包路由转发，从而防止任何单台服务器或网络链接的流量过载。借用 Twain Taylor 的描述，服务网格就是在应用级别上做了类似的事情，我们可以将它理解为应用程序层的软件定义网络。&lt;/p&gt;
&lt;p&gt;本质上，服务网格的一个主要工作是对分布在基础设施中的各种微服务的实例，进行健康状态的持续跟踪。它可能会轮询这些实例的请求处理状态，或者跟踪服务请求响应较慢的实例，然后将后续请求发送给其他的实例。类似于网络路由，它还会关注消息到达目的地消耗时间过长的请求，并调整后续路由来补偿。这些用时过长可能是由于底层硬件的问题，或者仅仅是由于服务被请求过载或处理能力不足造成的。但重要的是，服务网格可以找到相同服务的其他实例来接替请求处理，从而最有效地利用整个应用程序的处理能力。&lt;/p&gt;
&lt;p&gt;每个微服务都将提供一个应用程序编程接口（API），用于与其他服务的通信。这就引出了服务网格与传统的 API 管理形式（如 API 网关）之间的差异比较。借用 IBM 的解释，API 网关是位于一组微服务和应用“外部”之间，根据需要路由服务请求，让请求者无需知道它所访问的应用程序是基于微服务架构的。但服务网格不仅有上述能力，它还在应用程序“内部”的微服务之间协调请求，且各个组件完全了解整个应用内部的环境。&lt;/p&gt;
&lt;h2 id=&#34;灰度发布&#34;&gt;灰度发布&lt;/h2&gt;
&lt;p&gt;Service Mesh 是用来处理各服务间通信的基础设施层。它主要通过构建云原生应用程序的各种复杂拓扑结构来完成传递请求。实际上，Service Mesh 通常与应用程序代码一起部署轻量级网络代理的阵列来实现请求。&lt;/p&gt;
&lt;p&gt;在 ServiceMesh 之前，我们已经采用了 APIGateway 来实现灰度发布，但 APIGateway 通常仅部署在用户流量的入口，完全灰度发布就需要完整地部署两套系统。但是在微服务时代，任何一个微服务发生变更都需要完整地部署两套系统，这不仅成本很高而且严重影响了产品变更的速度。&lt;/p&gt;
&lt;p&gt;而 ServiceMesh 正好可以解决这些问题，它的应用类似于将 APIGateway 部署到本地，同时提供了集中化控制，极大地简化了灰度发布的实现流程、降低了变更成本、同时加快了产品发布的进度。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>正则化项 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/</link>
      <atom:link href="https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/index.xml" rel="self" type="application/rss+xml" />
    <description>正则化项</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>正则化项</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/</link>
    </image>
    
    <item>
      <title>正则化</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/%E6%AD%A3%E5%88%99%E5%8C%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/%E6%AD%A3%E5%88%99%E5%8C%96/</guid>
      <description>&lt;h1 id=&#34;regularization正则化&#34;&gt;Regularization:正则化&lt;/h1&gt;
&lt;p&gt;我们都知道，在进行数据挖掘或者机器学习模 型建立的时候，因为在统计学习中，假设数据满足独立同分布(i.i.d，independently and identically distributed)，即当前已产生的数据可以对未来的数据进行推测与模拟，因此都是使用历史数据建立模型，即使用已经产生的数据去训练，然后使用该 模型去拟合未来的数据。但是一般独立同分布的假设往往不成立，即数据的分布可能会发生变化(distribution drift)，并且可能当前的数据量过少，不足以对整个数据集进行分布估计，因此往往需要防止模型过拟合，提高模型泛化能力。而为了达到该目的的最常见方 法便是：正则化，
正则化(Regularization)是机器学习中一个很重要的防止过拟合的手段，它会为模型的目标函数(objective function)或代价函数(cost function)加上正则项来避免模型参数过度拟合于测试数据。而 L1 正则与 L2 正则的区别在于 L1 是权重的直接和，而 L2 是权重的平方和。
规则化符合奥卡姆剃刀(Occam&amp;rsquo;s razor)原理，在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶 斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项 (regularizer)或惩罚项(penalty term)。加上正则化项之后的监督函数的目标函数为：&lt;/p&gt;
&lt;p&gt;$$
w^* = arg min_{w} \sum_i L(y_i,f(x_i;w)) + \lambda \Omega(w)
$$&lt;/p&gt;
&lt;p&gt;在上述表达式中，第一项$L(y_i,f(x_i;w))$即是衡量模型对第$i$个样本的预测值$f(x_i;w)$与真实的标签值$y_i$之间的误差。第二项$\lambda \Omega(w)$即是正则化项用于约束我们的模型能够尽量的简单。而 L1 正则化与 L2 正则化的差异在于：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;L2 Regularization&lt;/th&gt;
&lt;th&gt;L1 Regularization&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Computational efficient due to having analytical solutions&lt;/td&gt;
&lt;td&gt;Computational inefficient on non-sparse cases&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Non-sparse outputs&lt;/td&gt;
&lt;td&gt;Sparse outputs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;No feature selection&lt;/td&gt;
&lt;td&gt;Built-in feature selection&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这里简要解释下上面三个比较项的含义，具体的求值与应用在下文中进行阐述：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computational Efficiency:计算性能&lt;/li&gt;
&lt;li&gt;Sparsity:稀疏度&lt;/li&gt;
&lt;li&gt;Built-in Feature Selection:内建的特征选择&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;l1-regularization&#34;&gt;L1 Regularization&lt;/h1&gt;
&lt;h1 id=&#34;l2-regularization&#34;&gt;L2 Regularization&lt;/h1&gt;
</description>
    </item>
    
  </channel>
</rss>

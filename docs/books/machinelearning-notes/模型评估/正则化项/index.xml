<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>正则化项 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/</link><atom:link href="https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/index.xml" rel="self" type="application/rss+xml"/><description>正则化项</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>正则化项</title><link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/</link></image><item><title>正则化</title><link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/%E6%AD%A3%E5%88%99%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AD%A3%E5%88%99%E5%8C%96%E9%A1%B9/%E6%AD%A3%E5%88%99%E5%8C%96/</guid><description>&lt;h1 id="regularization正则化">Regularization:正则化&lt;/h1>
&lt;p>我们都知道，在进行数据挖掘或者机器学习模 型建立的时候，因为在统计学习中，假设数据满足独立同分布(i.i.d，independently and identically distributed)，即当前已产生的数据可以对未来的数据进行推测与模拟，因此都是使用历史数据建立模型，即使用已经产生的数据去训练，然后使用该 模型去拟合未来的数据。但是一般独立同分布的假设往往不成立，即数据的分布可能会发生变化(distribution drift)，并且可能当前的数据量过少，不足以对整个数据集进行分布估计，因此往往需要防止模型过拟合，提高模型泛化能力。而为了达到该目的的最常见方 法便是：正则化，
正则化(Regularization)是机器学习中一个很重要的防止过拟合的手段，它会为模型的目标函数(objective function)或代价函数(cost function)加上正则项来避免模型参数过度拟合于测试数据。而 L1 正则与 L2 正则的区别在于 L1 是权重的直接和，而 L2 是权重的平方和。
规则化符合奥卡姆剃刀(Occam&amp;rsquo;s razor)原理，在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶 斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项 (regularizer)或惩罚项(penalty term)。加上正则化项之后的监督函数的目标函数为：&lt;/p>
&lt;p>$$
w^* = arg min_{w} \sum_i L(y_i,f(x_i;w)) + \lambda \Omega(w)
$$&lt;/p>
&lt;p>在上述表达式中，第一项$L(y_i,f(x_i;w))$即是衡量模型对第$i$个样本的预测值$f(x_i;w)$与真实的标签值$y_i$之间的误差。第二项$\lambda \Omega(w)$即是正则化项用于约束我们的模型能够尽量的简单。而 L1 正则化与 L2 正则化的差异在于：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>L2 Regularization&lt;/th>
&lt;th>L1 Regularization&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Computational efficient due to having analytical solutions&lt;/td>
&lt;td>Computational inefficient on non-sparse cases&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Non-sparse outputs&lt;/td>
&lt;td>Sparse outputs&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>No feature selection&lt;/td>
&lt;td>Built-in feature selection&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>这里简要解释下上面三个比较项的含义，具体的求值与应用在下文中进行阐述：&lt;/p>
&lt;ul>
&lt;li>Computational Efficiency:计算性能&lt;/li>
&lt;li>Sparsity:稀疏度&lt;/li>
&lt;li>Built-in Feature Selection:内建的特征选择&lt;/li>
&lt;/ul>
&lt;h1 id="l1-regularization">L1 Regularization&lt;/h1>
&lt;h1 id="l2-regularization">L2 Regularization&lt;/h1></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>模型评估 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</link>
      <atom:link href="https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/index.xml" rel="self" type="application/rss+xml" />
    <description>模型评估</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>模型评估</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</link>
    </image>
    
    <item>
      <title>范式</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E8%8C%83%E5%BC%8F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E8%8C%83%E5%BC%8F/</guid>
      <description>&lt;h1 id=&#34;范式与正则化&#34;&gt;范式与正则化&lt;/h1&gt;
&lt;p&gt;正则化是为了防止过拟合&lt;/p&gt;
&lt;p&gt;交叉验证是为了选择 hyperparameter&lt;/p&gt;
&lt;h1 id=&#34;model-evaluation&#34;&gt;Model Evaluation&lt;/h1&gt;
&lt;h1 id=&#34;overfitting&#34;&gt;Overfitting&lt;/h1&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic2.zhimg.com/c3fca0a39141f16ae0700b10f44e4909_b.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;(1)对于机器来说，在使用学习算法学习数据的特征的时候，样本数据的特征可以分为局部特征和全局特征，全局特征就是任何你想学习的那个概念所对应的数据都具备的特征，而局部特征则是你用来训练机器的样本里头的数据专有的特征.
(2)在学习算法的作用下，机器在学习过程中是无法区别局部特征和全局特征的，于是机器在完成学习后，除了学习到了数据的全局特征，也可能习得一部分局部特征，而习得的局部特征比重越多，那么新样本中不具有这些局部特征但具有所有全局特征的样本也越多，于是机器无法正确识别符合概念定义的“正确”样本的几率也会上升，也就是所谓的“泛化性”变差，这是过拟合会造成的最大问题.
(3)所谓过拟合，就是指把学习进行的太彻底，把样本数据的所有特征几乎都习得了，于是机器学到了过多的局部特征，过多的由于噪声带来的假特征，造成模型的“泛化性”和识别正确率几乎达到谷点，于是你用你的机器识别新的样本的时候会发现就没几个是正确识别的.
(4)解决过拟合的方法，其基本原理就是限制机器的学习，使机器学习特征时学得不那么彻底，因此这样就可以降低机器学到局部特征和错误特征的几率，使得识别正确率得到优化.
(5)从上面的分析可以看出，要防止过拟合，训练数据的选取也是很关键的，良好的训练数据本身的局部特征应尽可能少，噪声也尽可能小.&lt;/p&gt;
&lt;p&gt;(1)打个形象的比方，给一群天鹅让机器来学习天鹅的特征，经过训练后，知道了天鹅是有翅膀的，天鹅的嘴巴是长长的弯曲的，天鹅的脖子是长长的有点曲度，天鹅的整个体型像一个“2”且略大于鸭子.这时候你的机器已经基本能区别天鹅和其他动物了。
(2)然后，很不巧你的天鹅全是白色的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅.
(3)好，来分析一下上面这个例子：(1)中的规律都是对的，所有的天鹅都有的特征，是全局特征；然而，(2)中的规律：天鹅的羽毛是白的.这实际上并不是所有天鹅都有的特征，只是局部样本的特征。机器在学习全局特征的同时，又学习了局部特征，这才导致了不能识别黑天鹅的情况.

















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic2.zhimg.com/afa034d52962681db09b4dc1060f8075_b.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;early-stopping&#34;&gt;Early stopping&lt;/h2&gt;
&lt;p&gt;对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降(Gradient descent)学习算法。Early stopping 便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。
  Early stopping 方法的具体做法是，在每一个 Epoch 结束时(一个 Epoch 集为对所有的训练数据的一轮遍历)计算 validation data 的 accuracy，当 accuracy 不再提高时，就停止训练。这种做法很符合直观感受，因为 accurary 都不再提高了，在继续训练也是无 益的，只会提高训练的时间。那么该做法的一个重点便是怎样才认为 validation accurary 不再提高了呢？并不是说 validation accuracy 一降下来便认为不再提高了，因为可能经过这个 Epoch 后，accuracy 降低了，但是随后的 Epoch 又让 accuracy 又上去 了，所以不能根据一两次的连续降低就判断不再提高。一般的做法是，在训练的过程中，记录到目前为止最好的 validation accuracy，当连续 10 次 Epoch(或者更多次)没达到最佳 accuracy 时，则可以认为 accuracy 不再提高了。此时便可以停止迭代了 (Early Stopping)。这种策略也称为“No-improvement-in-n”，n 即 Epoch 的次数，可以根据实际情况取，如 10、20、30……&lt;/p&gt;
&lt;h2 id=&#34;数据集扩增&#34;&gt;数据集扩增&lt;/h2&gt;
&lt;p&gt;在数据挖掘领域流行着这样的一句话，“有时候往往拥有更多的数据胜过一个好的模型”。因为我们在使用训练数据训练模型，通过这个模型对将来的数据进 行拟合，而在这之间又一个假设便是，训练数据与将来的数据是独立同分布的。即使用当前的训练数据来对将来的数据进行估计与模拟，而更多的数据往往估计与模 拟地更准确。因此，更多的数据有时候更优秀。但是往往条件有限，如人力物力财力的不足，而不能收集到更多的数据，如在进行分类的任务中，需要对数据进行打 标，并且很多情况下都是人工得进行打标，因此一旦需要打标的数据量过多，就会导致效率低下以及可能出错的情况。所以，往往在这时候，需要采取一些计算的方 式与策略在已有的数据集上进行手脚，以得到更多的数据。
   通俗得讲，数据机扩增即需要得到更多的符合要求的数据，即和已有的数据是独立同分布的，或者近似独立同分布的。一般有以下方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从数据源头采集更多数据&lt;/li&gt;
&lt;li&gt;复制原有数据并加上随机噪声&lt;/li&gt;
&lt;li&gt;重采样&lt;/li&gt;
&lt;li&gt;根据当前数据集估计数据分布参数，使用该分布产生更多数据等&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cross-validation交叉验证&#34;&gt;Cross Validation:交叉验证&lt;/h2&gt;
&lt;h1 id=&#34;norm范式&#34;&gt;Norm:范式&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rorasa.wordpress.com/2012/05/13/l0-norm-l1-norm-l2-norm-l-infinity-norm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;l0-norm-l1-norm-l2-norm-l-infinity-norm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一般在机器学习的实践中，我们常用的范式就是 L1 范式&lt;/p&gt;
&lt;h2 id=&#34;types范式类型&#34;&gt;Types:范式类型&lt;/h2&gt;
&lt;h3 id=&#34;l0-norm&#34;&gt;L0 Norm&lt;/h3&gt;
&lt;h3 id=&#34;l1-norm&#34;&gt;L1 Norm&lt;/h3&gt;
&lt;h3 id=&#34;l2-norm&#34;&gt;L2 Norm&lt;/h3&gt;
&lt;h3 id=&#34;l-infinity-norm&#34;&gt;L-Infinity Norm&lt;/h3&gt;
&lt;h2 id=&#34;losserror-function损失函数&#34;&gt;Loss/Error Function:损失函数&lt;/h2&gt;
&lt;p&gt;L1 范式与 L2 范式常用的场景就是作为损失函数或者代价函数，而使用 L1 范式的损失函数一般称为 LAD(Least Absolute Deviations)，即最小绝对值偏差或者 LAE(Least Absolute Errors)，即最小绝对值错误。LAD 的目标即是使得目标值$Y_i$与测量值$f(x_i)$之间的绝对值差和最小。&lt;/p&gt;
&lt;p&gt;$$
S = \sum_{i=1}^{n}|y_i - f(x_i)|
$$&lt;/p&gt;
&lt;p&gt;使用 L2 范式的损失函数一般又被称为 LSE(Least Squares Error)，即最小平方误差：&lt;/p&gt;
&lt;p&gt;$$
S = \sum^n_{i=1}(y_i - f(x_i))^2
$$&lt;/p&gt;
&lt;p&gt;而 LAE 与 LSE 的区别可以总结为：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;L2 loss function&lt;/th&gt;
&lt;th&gt;L1 loss function&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Not very robust&lt;/td&gt;
&lt;td&gt;Robust&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Stable solution&lt;/td&gt;
&lt;td&gt;Unstable solution&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Always one solution&lt;/td&gt;
&lt;td&gt;Possibly multiple solutions&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Solution uniqueness:是否唯一解

















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://7xiegq.com1.z0.glb.clouddn.com/L1-norm-and-L2-norm-distance.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;
上图中的绿色的线，即 L2 范式即是唯一的最短路径的解，而红色的、蓝色的以及黄色的线，即 L1 范式则是相同长度的解。将这个情况扩展到 N 维，即可以认为 L2 范式是有唯一解而 L1 范式则可以有多解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Robustness:鲁棒性，即异常值的影响能力
直观来说，因为 LSE 使用了 L2 范式，即将误差值平方求和，这就导致了模型会比 LAE 存在更大的误差，因此模型与 LAE 相比会更加地敏感于单个数据点。如果该数据点是个异常值，那么模型会为了更好地拟合这个异常值的情形而导致对于其他值的偏差增大。一般来说，正常的数据点造成的误差值都比较小，而异常数据点造成的误差值会比较大，在 LSE 中异常数据点对于拟合结果的影响会大于 LAE。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stable:稳定性，即异常值发生变化时候的影响
在 LAD 中，如果某个数据点发生了一点水平位移，都可能导致最后的拟合线发生较大的变化。而 LSE 与之相比则有较大的稳定性，对于数据点任何较小地变化，拟合线也只会变化一点点，即拟合地参数可以看做关于数据的一个持续函数的值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图就是一个使用真实的数据与真实的拟合模型构造的结果图：

















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://7xiegq.com1.z0.glb.clouddn.com/programmatic-L1-vs-L2-visualization.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;关于上图需要注意两点：
(1)在同一张图中，计入异常点与不计入异常点相比，LAE 的两条拟合线差异较大，而 LSE 则差异较小。
(2)在将异常点从左到右进行移动地过程中，LAE 与 LSE 相比会发生更多的变化。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>欠拟合与过拟合</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88/</guid>
      <description>&lt;h1 id=&#34;欠拟合与过拟合&#34;&gt;欠拟合与过拟合&lt;/h1&gt;
&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://zh.gluon.ai/chapter_deep-learning-basics/underfit-overfit.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://zh.gluon.ai/chapter_deep-learning-basics/underfit-overfit.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>误差与验证</title>
      <link>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E8%AF%AF%E5%B7%AE%E4%B8%8E%E9%AA%8C%E8%AF%81/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/machinelearning-notes/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E8%AF%AF%E5%B7%AE%E4%B8%8E%E9%AA%8C%E8%AF%81/</guid>
      <description>&lt;h1 id=&#34;误差与验证&#34;&gt;误差与验证&lt;/h1&gt;
&lt;h1 id=&#34;模型误差&#34;&gt;模型误差&lt;/h1&gt;
&lt;h1 id=&#34;cross-validation-交叉验证&#34;&gt;Cross-Validation: 交叉验证&lt;/h1&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic1.zhimg.com/v2-577bb114a1073273452cc1c73045e274_b.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;右边是十种不同的训练集和测试集划分方法得到的 test MSE，可以看到，在不同的划分方法下，test MSE 的变动是很大的，而且对应的最优 degree 也不一样。所以如果我们的训练集和测试集的划分方法不够好，很有可能无法选择到最好的模型与参数。&lt;/p&gt;
&lt;h2 id=&#34;loocv&#34;&gt;LOOCV&lt;/h2&gt;
&lt;p&gt;LOOCV(Leave-one-out cross-validation) 像 Test set approach 一样，LOOCV 方法也包含将数据集分为训练集和测试集这一步骤。但是不同的是，我们现在只用一个数据作为测试集，其他的数据都作为训练集，并将此步骤重复 N 次(N 为数据集的数据数量)。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic1.zhimg.com/v2-27f8c5989dd7790ccf6b626e6854e06c_b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;如上图所示，假设我们现在有 n 个数据组成的数据集，那么 LOOCV 的方法就是每次取出一个数据作为测试集的唯一元素，而其他 n-1 个数据都作为训练集用于训练模型和调参。结果就是我们最终训练了 n 个模型，每次都能得到一个 MSE。而计算最终 test MSE 则就是将这 n 个 MSE 取平均。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic1.zhimg.com/v2-c6a79e230f946da8aefd793ed57c0454_b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=y_i&#34; alt=&#34;y_i&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;比起 test set approach，LOOCV 有很多优点。首先它不受测试集合训练集划分方法的影响，因为每一个数据都单独的做过测试集。同时，其用了 n-1 个数据训练模型，也几乎用到了所有的数据，保证了模型的 bias 更小。不过 LOOCV 的缺点也很明显，那就是计算量过于大，是 test set approach 耗时的 n-1 倍。&lt;/p&gt;
&lt;p&gt;为了解决计算成本太大的弊端，又有人提供了下面的式子，使得 LOOCV 计算成本和只训练一个模型一样快。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic2.zhimg.com/v2-ec72b82d605902ddfa060c2fb5777a05_b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;其中
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=%5Chat%7By_i%7D&#34; alt=&#34;\hat{y_i}&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;表示第 i 个拟合值，而
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=h_i&#34; alt=&#34;h_i&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;则表示 leverage。关于
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=h_i&#34; alt=&#34;h_i&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;的计算方法详见线性回归的部分(以后会涉及)。&lt;/p&gt;
&lt;h2 id=&#34;k-fold-cross-validation&#34;&gt;K-fold Cross Validation&lt;/h2&gt;
&lt;p&gt;另外一种折中的办法叫做 K 折交叉验证，和 LOOCV 的不同在于，我们每次的测试集将不再只包含一个数据，而是多个，具体数目将根据 K 的选取决定。比如，如果 K=5，那么我们利用五折交叉验证的步骤就是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;将所有数据集分成 5 份&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不重复地每次取其中一份做测试集，用其他四份做训练集训练模型，之后计算该模型在测试集上的
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=MSE_i&#34; alt=&#34;MSE_i&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将 5 次的
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://zhihu.com/equation?tex=MSE_i&#34; alt=&#34;MSE_i&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;取平均得到最后的 MSE&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic4.zhimg.com/v2-fcb843dd06c15a515d03a543864bbb77_b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;不难理解，其实 LOOCV 是一种特殊的 K-fold Cross Validation(K=N )。再来看一组图：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://pic2.zhimg.com/v2-daf077823e7faa57c6f4014389fe12b9_b.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;每一幅图种蓝色表示的真实的 test MSE，而黑色虚线和橙线则分贝表示的是 LOOCV 方法和 10-fold CV 方法得到的 test MSE。我们可以看到事实上 LOOCV 和 10-fold CV 对 test MSE 的估计是很相似的，但是相比 LOOCV，10-fold CV 的计算成本却小了很多，耗时更少。&lt;/p&gt;
&lt;p&gt;最后，我们要说说 K 的选取。事实上，和开头给出的文章里的部分内容一样，K 的选取是一个 Bias 和 Variance 的 trade-off。&lt;/p&gt;
&lt;p&gt;K 越大，每次投入的训练集的数据越多，模型的 Bias 越小。但是 K 越大，又意味着每一次选取的训练集之前的相关性越大(考虑最极端的例子，当 k=N，也就是在 LOOCV 里，每次都训练数据几乎是一样的)。而这种大相关性会导致最终的 test error 具有更大的 Variance。&lt;/p&gt;
&lt;p&gt;一般来说，根据经验我们一般选择 k=5 或 10。&lt;/p&gt;
&lt;h1 id=&#34;混淆矩阵&#34;&gt;混淆矩阵&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://blog.rainy.im/2016/03/28/ml-model-selection/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;机器学习笔记 - 模型评估与模型选择&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;监督学习的主要任务就是用模型实现精准的预测。我们希望自己的机器学习模型在新数据(未被标注过的)上取得尽可能高的准确率。换句话说，也就是我们希望用 训练数据训练得到的模型能适用于待测试的新数据。正是这样，当实际开发中训练得到一个新模型时，我们才有把握用它预测出高质量的结果。现在，假设我们要使用一个简单的非参数回归模型来构建耕地农药使用率和谷物亩产量的模型。最简单的机器学习回归模型之一就是内核平滑技术。内核平滑即计算 局部平均：对于每一个新的数据来说，用与其特征值接近的训练数据点求平均值来对其目标变量建模。唯一一个参数：宽参数，是用来控制局部平均的窗口大小。内核平滑窗宽参数取值不同所产生的效果。窗宽值较大时，几乎是用所有训练数据的平均值来预测测试集里每个数据点的目标值。这导致模型很平坦，对训练数据分布的明显趋势欠拟合(under-fit )了。同样，窗宽值过小时，每次预测只用到了待测数据点周围一两个训练数据。因此，模型把训练数据点的起伏波动完完全全地反映出来。这种疑似拟合噪音数据而非真实信号的现象被称为过拟合(over-fitting )。我们的理想情况是处于一个平衡状态：既不欠拟合，也不过拟合。
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAughQO34EKthdtP0lj5eE2E7OykekrBrkAW1MoIGF0rJvmM6ibMH2nPMtW7v1hmJ4b4ODO7qIHhjCzA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt; 由此可见，我们机器学习模型评估的目标就是希望能够判断分析机器学习模型对预测新数据时候的泛化能力，上述场景中就是指判断分析机器学习模型对预测其它农场的谷物产量的泛化能力。对于回归问题，标准的评估方法是均方误差(MSE )，即目标变量的真实值与模型预测值的误差平方的平均值。&lt;/p&gt;
&lt;h2 id=&#34;交叉验证&#34;&gt;交叉验证&lt;/h2&gt;
&lt;p&gt;模型评估中一个难解之处在于模型在训练集数据上的误差不能反映其在新数据集上的误差情况。为了更好地估计模型在新数据集上的错误率，我们必须使用更复杂的方法，称作&lt;strong&gt;交叉验证(cross validation )&lt;/strong&gt;，它严格地使用训练集数据来评价模型在新数据集上的准确率。&lt;/p&gt;
&lt;h3 id=&#34;holdout-方法&#34;&gt;Holdout 方法&lt;/h3&gt;
&lt;p&gt;同一份训练数据既用于数据拟合又用于准确率评估，会导致过度乐观。最容易的规避方法是分别准备训练和测试的两个子数据集，训练子集仅用于拟合模型，测试子集仅用于评估模型的准确率。这个方法被称作是 holdout 方法，因为随机地选择一部分训练数据仅用于训练过程。通常保留 30% 的数据作为测试数据。
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAughQO34EKthdtP0lj5eE2E7tevaallxmsz753137Tzj1TQBd7FXCSMU2iaoWzyIiaxteSFEGwOw9FLg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt; 伪代码如下所示: 
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAughQO34EKthdtP0lj5eE2E72r5bVUaRKvuVuK7k7tjVMcEfh1ljKy3qSL1ASZfHoDUXMVZOcSZ5Jg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-fold-交叉验证&#34;&gt;K-Fold 交叉验证&lt;/h3&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAughQO34EKthdtP0lj5eE2E7SSicUVS7NN6E7R394TxW3AhstdbVQZmTz3G4Z7icRLs1ichccVPoFqrfg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt; 如同 Holdout 方法，K-fold 交叉验证也依赖于训练数据的若干个相互独立子集。主要的区别在于 K-fold 交叉验证一开始就随机把数据分割成 K 个 不相连的子集，成为 folds(一般称作 K 折交叉验证，K 的取值有 5、10 或者 20)。每次留一份数据作为测试集，其余数据用于训练模型。
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAughQO34EKthdtP0lj5eE2E7YRZpXTQ8FxIYtB4Ydxyx6ib57ODia2hNdn3rjP2ATSRxSSQfbTvkgAwg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;evaluation-metric-评价指标-&#34;&gt;Evaluation Metric( 评价指标 )&lt;/h2&gt;
</description>
    </item>
    
  </channel>
</rss>

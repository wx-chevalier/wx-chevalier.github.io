<!DOCTYPE html><html lang="zh" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
    <meta name="google-site-verification" content="google69a5cccb61297807" />
    <meta name="baidu-site-verification" content="cqmZHEleVh" />
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="长短期记忆网络 1.目录 2.长短期记忆网络： 忘记门：将值朝 0 减少 输入门：决定是不是忽略掉输入数据 输出门：决定是不是使用隐状态 可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。 长短期记忆网络引入了记忆" />

  
  <link rel="alternate" hreflang="zh" href="https://ng-tech.icu/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/57-lstm/" />

  
  
  
    <meta name="theme-color" content="#0a55a7" />
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    

    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css" integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin="anonymous">
    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0d97305106da5efa530e28b021b4c580.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', "G-40NYXJ8823");
</script>


  


  


  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://ng-tech.icu/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/57-lstm/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@wx-chevalier" />
    <meta property="twitter:creator" content="@wx-chevalier" />
  
  <meta property="og:site_name" content="Next-gen Tech Edu" />
  <meta property="og:url" content="https://ng-tech.icu/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/57-lstm/" />
  <meta property="og:title" content="57-LSTM | Next-gen Tech Edu" />
  <meta property="og:description" content="长短期记忆网络 1.目录 2.长短期记忆网络： 忘记门：将值朝 0 减少 输入门：决定是不是忽略掉输入数据 输出门：决定是不是使用隐状态 可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。 长短期记忆网络引入了记忆" /><meta property="og:image" content="https://ng-tech.icu/media/sharing.png" />
    <meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png" /><meta property="og:locale" content="zh" />
  
    
    
  

  



  

  

  





  <title>57-LSTM | Next-gen Tech Edu</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="d7fd294bc57b6dba667f8a070c926222" >
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden="true"></i></button>
  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6 search-title">
          <p>搜索</p>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="关闭"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

      
      

      
    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

      <div id="search-common-queries">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Next-gen Tech Edu</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="切换导航">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Next-gen Tech Edu</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/books-gallery"><span>笔记（万篇）</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#knowledge-map"><span>知识图谱</span></a>
          </li>

          
          

          
          <style>
            .dropdown-item{
              display: inline-flex;
            }
          </style>
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>实验室</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/galaxy-home/gh-craft"><span>Craft 方块世界</span></a>
              
                <a class="dropdown-item" href="/galaxy-home/glossary-cards"><span>3D 知识卡牌</span></a>
              
            </div>
          </li>

          
          

          
          <style>
            .dropdown-item{
              display: inline-flex;
            }
          </style>
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>其他阅读渠道</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="https://zhuanlan.zhihu.com/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png"></img><span>知乎</span></a>
              
                <a class="dropdown-item" href="https://segmentfault.com/blog/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png"></img><span>SegmentFault</span></a>
              
                <a class="dropdown-item" href="https://zhuanlan.zhihu.com/wxyyxc1992"><img style="width:16px;height:16px;display:inline-block;margin-right:8px" src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png"></img><span>掘金</span></a>
              
            </div>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="搜索"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        <li class="nav-item">
            <a class="nav-link" href="https://github.com/wx-chevalier" aria-label="GitHub"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
        </li>
        

        
        
        

        
        
        
        <div></div>
        
        <style>
        @media only screen and (max-width: 600px) {
          .jimmysong-template {
            display: none!important;
          }
        }
        </style>
        
        <li class="jimmysong-template" style="color: white;font-size: 12px;">
          <a href="https://jimmysong.io" style="color: white">By Jimmy Song's Template</a>
        </li>
      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<link rel="stylesheet" href="//unpkg.com/heti/umd/heti.min.css">
<div class="container-xl docs">
  <div class="row flex-xl-nowrap">
    <div class="docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
          2021-李沐-《动手学习深度学习》
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">搜索...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li style="display: inline-flex">
          <a style="cursor: pointer;" onclick="window.history.back()">
            <i class="fas fa-arrow-left pr-1"></i>
            Back
          </a>
          <span>|</span>
          <a href="/books/">
            <i class="fa-solid fa-house" style="margin-right: 4px"></i>
            Books
          </a>
        </li>
      </ul>

      
      
        
          
        
      



  
    
    
    
    
      
    
    

    
    
    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id1cb603993076354ae684c031037738c1&#34;)" href="#id1cb603993076354ae684c031037738c1" aria-expanded="false" aria-controls="id1cb603993076354ae684c031037738c1" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">99.参考资料</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id1cb603993076354ae684c031037738c1" aria-expanded="false" aria-controls="id1cb603993076354ae684c031037738c1">
    
    <i class="fa-solid fa-angle-down" id="caret-id1cb603993076354ae684c031037738c1"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  show " id="id1cb603993076354ae684c031037738c1">
      



  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id6d7da24804841595467ee06940ffadad&#34;)" href="#id6d7da24804841595467ee06940ffadad" aria-expanded="false" aria-controls="id6d7da24804841595467ee06940ffadad" aria-hidden="false" data-toggle="collapse">
    
    </div>
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id424867f26fc15069d5e95f339f8da715&#34;)" href="#id424867f26fc15069d5e95f339f8da715" aria-expanded="false" aria-controls="id424867f26fc15069d5e95f339f8da715" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">2019-Andrew Ng-深度学习课程</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id424867f26fc15069d5e95f339f8da715" aria-expanded="false" aria-controls="id424867f26fc15069d5e95f339f8da715">
    
        <i class="fa-solid fa-angle-right" id="caret-id424867f26fc15069d5e95f339f8da715"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  " id="id424867f26fc15069d5e95f339f8da715">
      



  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/interview/">interview</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson1-week1/">lesson1-week1</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson1-week2/">lesson1-week2</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson1-week3/">lesson1-week3</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson1-week4/">lesson1-week4</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson2-week1/">lesson2-week1</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson2-week2/">lesson2-week2</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson2-week3/">lesson2-week3</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson3-week1/">lesson3-week1</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson3-week2/">lesson3-week2</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson4-week1/">lesson4-week1</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson4-week2/">lesson4-week2</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson4-week3/">lesson4-week3</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson4-week4/">lesson4-week4</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson5-week1/">lesson5-week1</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson5-week2/">lesson5-week2</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/lesson5-week3/">lesson5-week3</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/math/">math</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/notation/">notation</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2019-andrew-ng-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/summary/">SUMMARY</a></li>

      
        </ul>
      
    

    
      </div>
    




  
    
    
    
    
      
    
    

    
    
    
    
    
    <div class="docs-toc-item has-child">
    <div class="parent-node d-flex justify-content-between" onClick="Collapse(&#34;caret-id6d61b824616f345f413069d041a91bcd&#34;)" href="#id6d61b824616f345f413069d041a91bcd" aria-expanded="false" aria-controls="id6d61b824616f345f413069d041a91bcd" aria-hidden="false" data-toggle="collapse">
    
    <a class="d-inline docs-toc-link " href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">2021-李沐-《动手学习深度学习》</a>
    <a class="nav-toogle d-inline level" aria-hidden="false" data-toggle="collapse" href="#id6d61b824616f345f413069d041a91bcd" aria-expanded="false" aria-controls="id6d61b824616f345f413069d041a91bcd">
    
    <i class="fa-solid fa-angle-down" id="caret-id6d61b824616f345f413069d041a91bcd"></i>
    
    </a>
    
    </div>
    
      
      <ul class="nav docs-sidenav collapse  show " id="id6d61b824616f345f413069d041a91bcd">
      



  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/00-%E9%A2%84%E5%91%8A/">00-预告</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01-%E8%AF%BE%E7%A8%8B%E5%AE%89%E6%8E%92/">01-课程安排</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/">02-深度学习介绍</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03-%E5%AE%89%E8%A3%85/">03-安装</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/04-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%92%8C%E6%93%8D%E4%BD%9C/">04-数据读取和操作</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">05-线性代数</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/06-%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/">06-矩阵计算</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/07-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/">07-自动求导</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/08-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92&#43;%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/">08-线性回归&#43;基础优化算法</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/09-softmax-%E5%9B%9E%E5%BD%92/">09-Softmax 回归</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/">10-多层感知机</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9&#43;%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/">11-模型选择&#43;过拟合和欠拟合</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12-%E6%9D%83%E9%87%8D%E8%A1%B0%E9%80%80/">12-权重衰退</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13-%E4%B8%A2%E5%BC%83%E6%B3%95/">13-丢弃法</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14-%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7/">14-数值稳定性</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15-%E5%AE%9E%E6%88%98kaggle%E6%AF%94%E8%B5%9B%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/">15-实战Kaggle比赛：预测房价</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16-pytorch%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">16-Pytorch神经网络基础</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/17-%E4%BD%BF%E7%94%A8%E5%92%8C%E8%B4%AD%E4%B9%B0gpu/">17-使用和购买GPU</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/18-%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%E7%AB%9E%E8%B5%9B%E6%80%BB%E7%BB%93/">18-预测房价竞赛总结</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/19-%E5%8D%B7%E7%A7%AF%E5%B1%82/">19-卷积层</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/20-%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85/">20-填充和步幅</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/21-%E5%A4%9A%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93/">21-多输入输出通道</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/22-%E6%B1%A0%E5%8C%96%E5%B1%82/">22-池化层</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/23-%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Clenet/">23-经典卷积神经网络LeNet</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/24-alexnet/">24-AlexNet</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/25-%E4%BD%BF%E7%94%A8%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9C-vgg/">25-使用块的网络 VGG</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/26-nin/">26-NiN</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/27-googlenet/">27-GoogLeNet</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/28-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/">28-批量归一化</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/29-%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9Cresnet/">29-残差网络ResNet</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/30-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E5%AE%8C%E7%BB%93%E7%AB%9E%E8%B5%9B%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/">30-第二部分完结竞赛：图片分类</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/31-cpu%E5%92%8Cgpu/">31-CPU和GPU</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/32-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%A1%AC%E4%BB%B6/">32-深度学习硬件</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/33-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C/">33-单机多卡并行</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/34-%E5%A4%9Agpu%E8%AE%AD%E7%BB%83%E5%AE%9E%E7%8E%B0only-qa/">34-多GPU训练实现(only QA)</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/35-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">35-分布式训练</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/36-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF/">36-数据增广</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/37-%E5%BE%AE%E8%B0%83/">37-微调</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/38-%E7%AC%AC%E4%BA%8C%E6%AC%A1%E7%AB%9E%E8%B5%9B%E6%A0%91%E5%8F%B6%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C/">38-第二次竞赛树叶分类结果</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/39-%E5%AE%9E%E6%88%98kaggle%E7%AB%9E%E8%B5%9Bcifar-10/">39-实战Kaggle竞赛：CIFAR-10</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/41-%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/">41-物体检测和数据集</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/43-%E6%A0%91%E5%8F%B6%E5%88%86%E7%B1%BB%E7%AB%9E%E8%B5%9B%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/">43-树叶分类竞赛技术总结</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/44-%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95r-cnnssdyolo/">44-物体检测算法：R-CNN,SSD,YOLO</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/46-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">46-语义分割</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/47-%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/">47-转置卷积</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/48-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cfcn/">48-全连接卷积神经网络（FCN）</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/49-%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB/">49-样式迁移</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/50-%E8%AF%BE%E7%A8%8B%E7%AB%9E%E8%B5%9B%E7%89%9B%E4%BB%94%E8%A1%8C%E5%A4%B4%E6%A3%80%E6%B5%8B/">50-课程竞赛：牛仔行头检测</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/51-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/">51-序列模型</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/53-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">53-语言模型</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/54-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crnn/">54-循环神经网络RNN</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/56-gru/">56-GRU</a></li>




  <li class="child level active"><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/57-lstm/">57-LSTM</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/58-%E6%B7%B1%E5%B1%82%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">58-深层循环神经网络</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/61-%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84/">61-编码器-解码器架构</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/62-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E5%AD%A6%E4%B9%A0/">62-序列到序列学习</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/63-%E6%9D%9F%E6%90%9C%E7%B4%A2/">63-束搜索</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/65-%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0/">65-注意力分数</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/68-transformer/">68-Transformer</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/69-bert-%E9%A2%84%E8%AE%AD%E7%BB%83/">69-BERT 预训练</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/70-bert-%E5%BE%AE%E8%B0%83/">70-BERT 微调</a></li>




  <li class="child level "><a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/72-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/">72-优化算法</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
     
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">目录</a></li>
      </ul>
     

      <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1目录">1.目录</a></li>
        <li><a href="#2长短期记忆网络">2.长短期记忆网络：</a></li>
        <li><a href="#3从零实现">3.从零实现</a></li>
        <li><a href="#qa">Q&amp;A</a></li>
      </ul>
    </li>
  </ul>
</nav>

      
<div class="subscribe-module col-24 mt-1">
    <img src="https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png" alt="image" title="王下邀月熊的微信公众号"/>
</div>



    </div>
    

    <main class="py-md-3 pl-md-3 docs-content col-xl-8" role="main">

      <article class="article">

          

          <h1>57-LSTM</h1>

          <div class="article-style">
            <h1 id="长短期记忆网络">长短期记忆网络</h1>
<h3 id="1目录">1.目录</h3>
<h3 id="2长短期记忆网络">2.长短期记忆网络：</h3>
<ul>
<li>忘记门：将值朝 0 减少</li>
<li>输入门：决定是不是忽略掉输入数据</li>
<li>输出门：决定是不是使用隐状态</li>
</ul>
<p>可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。 长短期记忆网络引入了<em>记忆元</em>（memory cell），或简称为<em>单元</em>（cell）。 有些文献认为记忆元是隐状态的一种特殊类型， 它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。 为了控制记忆元，我们需要许多门。 其中一个门用来从单元中输出条目，我们将其称为<em>输出门</em>（output gate）。 另外一个门用来决定何时将数据读入单元，我们将其称为<em>输入门</em>（input gate）。 我们还需要一种机制来重置单元的内容，由<em>遗忘门</em>（forget gate）来管理， 这种设计的动机与门控循环单元相同， 能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。 让我们看看这在实践中是如何运作的。</p>
<h4 id="21-门">2.1 门：</h4>
<p>输入门：<img src="https://latex.codecogs.com/svg.image?I_{t}=\sigma&space;(X_{t}W_{xi}&plus;H_{t-1}W_{hi}&plus;b_{i})" title="I_{t}=\sigma (X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i})" /></p>
<p>忘记门：<img src="https://latex.codecogs.com/svg.image?F_{t}=\sigma&space;(X_{t}W_{xf}&plus;H_{t-1}W_{hf}&plus;b_{f})" title="F_{t}=\sigma (X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f})" /></p>
<p>输出门：<img src="https://latex.codecogs.com/svg.image?O_{t}=\sigma&space;(X_{t}W_{xo}&plus;H_{t-1}W_{ho}&plus;b_{o})" title="O_{t}=\sigma (X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o})" /></p>
<p>这三个门的算式和普通 RNN 计算 Ht 算式相同。</p>
<div align="center">
    <img src="https://assets.ng-tech.icu/book/DeepLearning-MuLi-Notes/imgs/57/57-1.png" alt="image" align="center"width="500"/>
</div>
<h4 id="22-候选记忆单元">2.2 候选记忆单元</h4>
<img src="https://latex.codecogs.com/svg.image?\widetilde{C_{t}}=tanh(X_{t}W_{xc}&plus;H_{t-1}W_{hc}&plus;b_{c})" title="\widetilde{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c})" />
<p>相当于在 ht-1 到 ht 的预测中又加了一层隐藏单元</p>
<div align="center">
    <img src="https://assets.ng-tech.icu/book/DeepLearning-MuLi-Notes/imgs/57/57-2.png" alt="image" align="center"width="500"/>
</div>
<h4 id="22-记忆单元">2.2 记忆单元</h4>
<img src="https://latex.codecogs.com/svg.image?C_{t}=F_{t}\odot&space;C_{t-1}&plus;I_{t}\odot&space;\widetilde{C_{t}}" title="C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \widetilde{C_{t}}" />
<p>如果遗忘门始终为(1)且输入门始终为(0)， 则过去的记忆元 将随时间被保存并传递到当前时间步。 引入这种设计是为了缓解梯度消失问题， 并更好地捕获序列中的长距离依赖关系。</p>
<div align="center">
    <img src="https://assets.ng-tech.icu/book/DeepLearning-MuLi-Notes/imgs/57/57-3.png" alt="image" align="center"width="500"/>
</div>
<h4 id="23-隐状态">2.3 隐状态</h4>
<img src="https://latex.codecogs.com/svg.image?H_{t}=O_{t}\odot&space;tanh(C_{t})" title="H_{t}=O_{t}\odot tanh(C_{t})" />
<p>最后，我们需要定义如何计算隐状态， 这就是输出门发挥作用的地方。 在长短期记忆网络中，它仅仅是记忆元的的门控版本。 这就确保了 Ht 的值始终在区间((-1, 1))内.</p>
<p>只要输出门接近 1，我们就能够有效地将所有记忆信息传递给预测部分， 而对于输出门接近(0)，我们只保留记忆元内的所有信息，而不需要更新隐状态。</p>
<div align="center">
    <img src="https://assets.ng-tech.icu/book/DeepLearning-MuLi-Notes/imgs/57/57-4.png" alt="image" align="center"width="500"/>
</div>
<h4 id="24-总结">2.4 总结</h4>
<p>LSTM 的计算流程：</p>
<img src="https://latex.codecogs.com/svg.image?I_{t}=\sigma&space;(X_{t}W_{xi}&plus;H_{t-1}W_{hi}&plus;b_{i})" title="I_{t}=\sigma (X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i})" />
<img src="https://latex.codecogs.com/svg.image?F_{t}=\sigma&space;(X_{t}W_{xf}&plus;H_{t-1}W_{hf}&plus;b_{f})" title="F_{t}=\sigma (X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f})" />
<img src="https://latex.codecogs.com/svg.image?O_{t}=\sigma&space;(X_{t}W_{xo}&plus;H_{t-1}W_{ho}&plus;b_{o})" title="O_{t}=\sigma (X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o})" />
<img src="https://latex.codecogs.com/svg.image?\widetilde{C_{t}}=tanh(X_{t}W_{xc}&plus;H_{t-1}W_{hc}&plus;b_{c})" title="\widetilde{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c})" />
<img src="https://latex.codecogs.com/svg.image?C_{t}=F_{t}\odot&space;C_{t-1}&plus;I_{t}\odot&space;\widetilde{C_{t}}" title="C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \widetilde{C_{t}}" />
<img src="https://latex.codecogs.com/svg.image?H_{t}=O_{t}\odot&space;tanh(C_{t})" title="H_{t}=O_{t}\odot tanh(C_{t})" />
<h3 id="3从零实现">3.从零实现</h3>
<p>加载时光机器数据集</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
</span></span><span class="line"><span class="cl"><span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="31-初始化模型参数">3.1 初始化模型参数</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_lstm_params</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">three</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">(</span><span class="n">normal</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">                <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">W_xi</span><span class="p">,</span> <span class="n">W_hi</span><span class="p">,</span> <span class="n">b_i</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 输入门参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">W_xf</span><span class="p">,</span> <span class="n">W_hf</span><span class="p">,</span> <span class="n">b_f</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 遗忘门参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">W_xo</span><span class="p">,</span> <span class="n">W_ho</span><span class="p">,</span> <span class="n">b_o</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 输出门参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">W_xc</span><span class="p">,</span> <span class="n">W_hc</span><span class="p">,</span> <span class="n">b_c</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 候选记忆元参数</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 输出层参数</span>
</span></span><span class="line"><span class="cl">    <span class="n">W_hq</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">b_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 附加梯度</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W_xi</span><span class="p">,</span> <span class="n">W_hi</span><span class="p">,</span> <span class="n">b_i</span><span class="p">,</span> <span class="n">W_xf</span><span class="p">,</span> <span class="n">W_hf</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">W_xo</span><span class="p">,</span> <span class="n">W_ho</span><span class="p">,</span> <span class="n">b_o</span><span class="p">,</span> <span class="n">W_xc</span><span class="p">,</span> <span class="n">W_hc</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">b_c</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">params</span>
</span></span></code></pre></div><h4 id="32-定义模型">3.2 定义模型</h4>
<p>在初始化函数中， 长短期记忆网络的隐状态需要返回一个<em>额外</em>的记忆元， 单元的值为 0，形状为（批量大小，隐藏单元数）。 因此，我们得到以下的状态初始化。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">init_lstm_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span></code></pre></div><p>实际模型的定义与我们前面讨论的一样： 提供三个门和一个额外的记忆元。 请注意，只有隐状态才会传递到输出层， 而记忆元(\mathbf{C}_t)不直接参与输出计算。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">lstm</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="n">W_xi</span><span class="p">,</span> <span class="n">W_hi</span><span class="p">,</span> <span class="n">b_i</span><span class="p">,</span> <span class="n">W_xf</span><span class="p">,</span> <span class="n">W_hf</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">W_xo</span><span class="p">,</span> <span class="n">W_ho</span><span class="p">,</span> <span class="n">b_o</span><span class="p">,</span> <span class="n">W_xc</span><span class="p">,</span> <span class="n">W_hc</span><span class="p">,</span> <span class="n">b_c</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">     <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span> <span class="o">=</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xi</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hi</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">F</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xf</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hf</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">O</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xo</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_ho</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_o</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">C_tilda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xc</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hc</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_c</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">C</span> <span class="o">=</span> <span class="n">F</span> <span class="o">*</span> <span class="n">C</span> <span class="o">+</span> <span class="n">I</span> <span class="o">*</span> <span class="n">C_tilda</span>
</span></span><span class="line"><span class="cl">        <span class="n">H</span> <span class="o">=</span> <span class="n">O</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hq</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_q</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="33-训练和预测">3.3 训练和预测</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModelScratch</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">get_lstm_params</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="n">init_lstm_state</span><span class="p">,</span> <span class="n">lstm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span></code></pre></div><div align="center">
    <img src="https://assets.ng-tech.icu/book/DeepLearning-MuLi-Notes/imgs/57/57-5.png" alt="image" align="center"width="500"/>
</div>
<h3 id="qa">Q&amp;A</h3>
<h5 id="q1请问-lstm-如果不要-c把公式里的img-srchttpslatexcodecogscomsvgimagespacec_t-1-title-c_t-1-换成img-srchttpslatexcodecogscomsvgimagespaceh_t-1-title-h_t-1-好像可以实现隐藏状态往下传递">Q1：请问 LSTM 如果不要 C,把公式里的<img src="https://latex.codecogs.com/svg.image?&space;C_{t-1}" title=" C_{t-1}" />换成<img src="https://latex.codecogs.com/svg.image?&space;H_{t-1}" title=" H_{t-1}" />，好像可以实现隐藏状态往下传递？</h5>
<blockquote>
<p><img src="https://latex.codecogs.com/svg.image?&space;C_{t-1}" title=" C_{t-1}" />的可以约束<img src="https://latex.codecogs.com/svg.image?&space;H_{t-1}" title=" H_{t-1}" />的大小在 0-1 之间，避免梯度爆炸，而且使算式更加自然，c 换成 h 复杂度降低。</p>
</blockquote>
<h5 id="q2ifoc_tilda-的初始化为零">Q2：I,F,O,C_tilda 的初始化为零？</h5>
<blockquote>
<p>这些是计算的中间变量，不需要初始化</p>
</blockquote>
<h5 id="q3如何计算模型占用显存batch-占用的显存">Q3：如何计算模型占用显存，batch 占用的显存？</h5>
<blockquote>
<p>取决于框架和库，没法具体算</p>
</blockquote>

          </div>

          



          
          
          <div class="article-widget">
            
<div class="container-xl row post-nav">
  
  
  
  <div class="col-6 post-nav-item">
    <div class="meta-nav">上一页</div>
    <a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/56-gru/" rel="next">56-GRU</a>
  </div>
  
  
  
  <div class="col-6 post-nav-item">
    <div class="meta-nav">下一页</div>
    <a href="/books/deeplearning-notes/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%8E%E6%B2%90-%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/58-%E6%B7%B1%E5%B1%82%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="prev">58-深层循环神经网络</a>
  </div>
  
</div>

          </div>
          

        <div class="body-footer">
          <p>最近更新于 0001-01-01</p>

          



          


  
  
  

  

  
  <section id="comments" class="mb-3 pt-0">
    
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); 
    s.async = true;
    s.src = 'https://' + "ngte" + '.disqus.com/embed.js';
    
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </section>
  



          


        </div>

      </article>

      <footer class="site-footer">

  



  

  
  <div class="copyright py-4 bg-footer">
      <div class="row justify-content-center">
        <div class="text-center footer-color">
          <p class="mb-0">© 2017-2022 NGTE all rights reserved</p>
        </div>
    </div>
  </div>

  <script type="text/javascript" id="clstr_globe" async src="//clustrmaps.com/globe.js?d=kgpJG5sWZQpKujBmD-uW1B54-WBPol-DuDtrB2KFjKs"></script>
  
</footer>


    </main>
  </div>
</div>
<script src="//unpkg.com/heti/umd/heti-addon.min.js"></script>
<script>
  const heti = new Heti('.article');
  heti.autoSpacing();
</script>
<script type="text/javascript">
  window.$crisp = [];
  window.CRISP_WEBSITE_ID = "12adcc35-9621-4313-8262-62dc654b29d8";
  (function () {
    setTimeout(function() {
      d = document;
      s = d.createElement("script");
      s.src = "https://client.crisp.chat/l.js";
      s.async = 1;
      d.getElementsByTagName("head")[0].appendChild(s);
    }, 2500);
  })();
</script>
  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>

    
    
    
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
      

    

    
    
    

    
    
    
      
      <script id="search-hit-algolia-template" type="text/html">
        <div class="search-hit">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a>
            </div>
            <div class="article-metadata search-hit-type">{{type}}</div>
            <p class="search-hit-description">{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js" crossorigin="anonymous"></script>
      
      
    

    
    

    
    
    
    
      <script id="dsq-count-scr" src="https://ngte.disqus.com/count.js" async></script>
      
    

    
    
      
      
      
      
      
      
      
    

    
    <script src="/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js" type="module"></script>
    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
    <script src="/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js"></script>

    
    
    
    
    
    
    <script>

var mybutton = document.getElementById("backTopBtn");


window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    mybutton.style.display = "block";
  } else {
    mybutton.style.display = "none";
  }
}


function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>


    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    <script>



(function() {
  'use strict';

  if(!document.queryCommandSupported('copy')) {
    return;
  }

  function flashCopyMessage(el, msg) {
    el.className = "highlight-copy-btn";
    el.textContent = msg;
    setTimeout(function() {
      el.textContent = "";
      el.className = "highlight-copy-btn fa fa-copy";
    }, 1000);
  }

  function selectText(node) {
    var selection = window.getSelection();
    var range = document.createRange();
    range.selectNodeContents(node);
    selection.removeAllRanges();
    selection.addRange(range);
    return selection;
  }

  function addCopyButton(containerEl) {
    var copyBtn = document.createElement("button");
    copyBtn.className = "highlight-copy-btn fa fa-copy";
    copyBtn.textContent = "";

    var codeEl = containerEl.firstElementChild;
    copyBtn.addEventListener('click', function() {
      try {
        var selection = selectText(codeEl);
        document.execCommand('copy');
        selection.removeAllRanges();
        
        flashCopyMessage(copyBtn, '已复制')
        
      } catch(e) {
        console && console.log(e);
        flashCopyMessage(copyBtn, 'Failed :\'(')
      }
    });

    containerEl.appendChild(copyBtn);
  }

  
  var highlightBlocks = document.getElementsByClassName('highlight');
  Array.prototype.forEach.call(highlightBlocks, addCopyButton);
})();
</script>

    


</body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>神经网络 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link><atom:link href="https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml"/><description>神经网络</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>神经网络</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link></image><item><title>丢弃法</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E4%B8%A2%E5%BC%83%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E4%B8%A2%E5%BC%83%E6%B3%95/</guid><description>&lt;h1 id="丢弃法">丢弃法&lt;/h1>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="http://zh.gluon.ai/chapter_deep-learning-basics/dropout.html" target="_blank" rel="noopener">http://zh.gluon.ai/chapter_deep-learning-basics/dropout.html&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>多层神经网络</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid><description>&lt;h1 id="多层神经网络">多层神经网络&lt;/h1>
&lt;h1 id="隐藏层">隐藏层&lt;/h1></description></item><item><title>神经网络可视化</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96/</guid><description>&lt;h2 id="tools-to-design-or-visualize-architecture-of-neural-network">Tools to Design or Visualize Architecture of Neural Network&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://github.com/gwding/draw_convnet" target="_blank" rel="noopener">&lt;strong>draw_convnet&lt;/strong>&lt;/a> : Python script for illustrating Convolutional Neural Network (ConvNet)&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://raw.githubusercontent.com/gwding/draw_convnet/master/convnet_fig.png" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="2">
&lt;li>&lt;a href="http://alexlenail.me/NN-SVG/LeNet.html" target="_blank" rel="noopener">&lt;strong>NNSVG&lt;/strong>&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/Q0xOe.png" alt="AlexNet style" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/K9lmg.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/DlJ8J.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>&lt;a href="https://github.com/HarisIqbal88/PlotNeuralNet" target="_blank" rel="noopener">PlotNeuralNet&lt;/a>&lt;/strong> : Latex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/17570785/50308846-c2231880-049c-11e9-8763-3daa1024de78.png" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://user-images.githubusercontent.com/17570785/50308873-e2eb6e00-049c-11e9-9587-9da6bdec011b.png" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="4">
&lt;li>&lt;strong>&lt;a href="https://www.tensorflow.org/tensorboard/graphs" target="_blank" rel="noopener">Tensorboard&lt;/a>&lt;/strong> - TensorBoard’s &lt;strong>Graphs dashboard&lt;/strong> is a powerful tool for examining your TensorFlow model.&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/zJHpV.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="5">
&lt;li>&lt;strong>&lt;a href="https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py" target="_blank" rel="noopener">Caffe&lt;/a>&lt;/strong> - In Caffe you can use &lt;a href="https://github.com/BVLC/caffe/blob/master/python/caffe/draw.py" target="_blank" rel="noopener">caffe/draw.py&lt;/a> to draw the NetParameter protobuffer:&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/5Z1Cb.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="6">
&lt;li>&lt;strong>&lt;a href="http://www.mathworks.com/help/nnet/ref/view.html" target="_blank" rel="noopener">Matlab&lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/rPpfa.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="7">
&lt;li>&lt;a href="https://transcranial.github.io/keras-js/#/inception-v3" target="_blank" rel="noopener">&lt;strong>Keras.js&lt;/strong>&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/vEfTv.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="8">
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://github.com/stared/keras-sequential-ascii/" target="_blank" rel="noopener">keras-sequential-ascii&lt;/a>&lt;/strong> - A library for &lt;a href="https://keras.io/" target="_blank" rel="noopener">Keras&lt;/a> for investigating architectures and parameters of sequential models.&lt;/p>
&lt;p>&lt;strong>VGG 16 Architecture&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code> OPERATION DATA DIMENSIONS WEIGHTS(N) WEIGHTS(%)
Input ##### 3 224 224
InputLayer | ------------------- 0 0.0%
##### 3 224 224
Convolution2D \|/ ------------------- 1792 0.0%
relu ##### 64 224 224
Convolution2D \|/ ------------------- 36928 0.0%
relu ##### 64 224 224
MaxPooling2D Y max ------------------- 0 0.0%
##### 64 112 112
Convolution2D \|/ ------------------- 73856 0.1%
relu ##### 128 112 112
Convolution2D \|/ ------------------- 147584 0.1%
relu ##### 128 112 112
MaxPooling2D Y max ------------------- 0 0.0%
##### 128 56 56
Convolution2D \|/ ------------------- 295168 0.2%
relu ##### 256 56 56
Convolution2D \|/ ------------------- 590080 0.4%
relu ##### 256 56 56
Convolution2D \|/ ------------------- 590080 0.4%
relu ##### 256 56 56
MaxPooling2D Y max ------------------- 0 0.0%
##### 256 28 28
Convolution2D \|/ ------------------- 1180160 0.9%
relu ##### 512 28 28
Convolution2D \|/ ------------------- 2359808 1.7%
relu ##### 512 28 28
Convolution2D \|/ ------------------- 2359808 1.7%
relu ##### 512 28 28
MaxPooling2D Y max ------------------- 0 0.0%
##### 512 14 14
Convolution2D \|/ ------------------- 2359808 1.7%
relu ##### 512 14 14
Convolution2D \|/ ------------------- 2359808 1.7%
relu ##### 512 14 14
Convolution2D \|/ ------------------- 2359808 1.7%
relu ##### 512 14 14
MaxPooling2D Y max ------------------- 0 0.0%
##### 512 7 7
Flatten ||||| ------------------- 0 0.0%
##### 25088
Dense XXXXX ------------------- 102764544 74.3%
relu ##### 4096
Dense XXXXX ------------------- 16781312 12.1%
relu ##### 4096
Dense XXXXX ------------------- 4097000 3.0%
softmax ##### 1000
&lt;/code>&lt;/pre>&lt;ol start="9">
&lt;li>&lt;strong>&lt;a href="https://github.com/lutzroeder/Netron" target="_blank" rel="noopener"> Netron &lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://github.com/lutzroeder/netron/raw/master/.github/screenshot.png" alt="screenshot.png" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="10">
&lt;li>&lt;strong>&lt;a href="https://github.com/martisak/dotnets" target="_blank" rel="noopener">DotNet&lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://github.com/martisak/dotnets/raw/master/test.png" alt="Simple net" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="11">
&lt;li>&lt;a href="http://www.graphviz.org/" target="_blank" rel="noopener">&lt;strong>Graphviz&lt;/strong>&lt;/a> : &lt;strong>&lt;a href="https://tgmstat.wordpress.com/2013/06/12/draw-neural-network-diagrams-graphviz/" target="_blank" rel="noopener">Tutorial&lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://tgmstat.files.wordpress.com/2013/05/multiclass_neural_network_example.png" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="12">
&lt;li>&lt;strong>&lt;a href="https://keras.io/visualization/" target="_blank" rel="noopener">Keras Visualization&lt;/a>&lt;/strong> - The &lt;a href="https://keras.io/visualization/" target="_blank" rel="noopener">keras.utils.vis_utils module&lt;/a> provides utility functions to plot a Keras model (using graphviz)&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/o17GY.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="13">
&lt;li>&lt;strong>&lt;a href="https://conx.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">Conx&lt;/a>&lt;/strong> - The Python package &lt;code>conx&lt;/code> can visualize networks with activations with the function &lt;code>net.picture()&lt;/code> to produce SVG, PNG, or PIL Images like this:&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/nhHjO.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="14">
&lt;li>&lt;strong>&lt;a href="https://math.mit.edu/ennui/" target="_blank" rel="noopener">ENNUI&lt;/a>&lt;/strong> - Working on a drag-and-drop neural network visualizer (and more). Here&amp;rsquo;s an example of a visualization for a LeNet-like architecture.&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/pRLeG.png" alt="A visualization of a LeNet-like architecture" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="15">
&lt;li>&lt;strong>NNet - R Package&lt;/strong> - &lt;strong>&lt;a href="https://beckmw.wordpress.com/2013/03/04/visualizing-neural-networks-from-the-nnet-package/" target="_blank" rel="noopener">Tutorial&lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code>data(infert, package=&amp;#34;datasets&amp;#34;)
plot(neuralnet(case~parity+induced+spontaneous, infert))
&lt;/code>&lt;/pre>&lt;p>[
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/yyftd.png" alt="neuralnet" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>](https://&lt;/p>
&lt;ol start="16">
&lt;li>&lt;strong>&lt;a href="https://www.graphcore.ai/posts/what-does-machine-learning-look-like" target="_blank" rel="noopener">GraphCore&lt;/a>&lt;/strong> - These approaches are more oriented towards visualizing neural network operation, however, NN architecture is also somewhat visible on the resulting diagrams.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>AlexNet&lt;/strong>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.graphcore.ai/hubfs/images/alexnet_label%20logo.jpg" alt="alexnet_label logo.jpg" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>&lt;strong>ResNet50&lt;/strong>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.graphcore.ai/hubfs/images/resnet50_label_logo.jpg" alt="resnet50_label_logo.jpg" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="17">
&lt;li>&lt;a href="https://wagenaartje.github.io/neataptic/" target="_blank" rel="noopener">&lt;strong>Neataptic&lt;/strong>&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Neataptic offers flexible neural networks; neurons and synapses can be removed with a single line of code. No fixed architecture is required for neural networks to function at all. This flexibility allows networks to be shaped for your dataset through neuro-evolution, which is done using multiple threads.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://camo.githubusercontent.com/4326c3f603b828b61fd63d927acca2cfc152773f/68747470733a2f2f692e6779617a6f2e636f6d2f66353636643233363461663433646433613738633839323665643230346135312e706e67" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="18">
&lt;li>
&lt;p>&lt;strong>&lt;a href="https://tensorspace.org/" target="_blank" rel="noopener">TensorSpace&lt;/a>&lt;/strong> : TensorSpace is a neural network 3D visualization framework built by TensorFlow.js, Three.js and Tween.js. TensorSpace provides Layer APIs to build deep learning layers, load pre-trained models, and generate a 3D visualization in the browser. By applying TensorSpace API, it is more intuitive to visualize and understand any pre-trained models built by TensorFlow, Keras, TensorFlow.js, etc.&lt;/p>
&lt;p>&lt;strong>&lt;a href="https://www.freecodecamp.org/news/tensorspace-js-a-way-to-3d-visualize-neural-networks-in-browsers-2c0afd7648a8/" target="_blank" rel="noopener">Tutorial&lt;/a>&lt;/strong>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/ekF5v.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>​&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;a href="http://dgschwend.github.io/netscope/quickstart.html" target="_blank" rel="noopener">Netscope CNN Analyzer&lt;/a>&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.stack.imgur.com/VVDsg.png" alt="enter image description here" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="20">
&lt;li>&lt;strong>&lt;a href="https://github.com/mlajtos/moniel" target="_blank" rel="noopener">Monial&lt;/a>&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Interactive Notation for Computational Graphs &lt;a href="https://mlajtos.github.io/moniel/" target="_blank" rel="noopener">https://mlajtos.github.io/moniel/&lt;/a>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://miro.medium.com/max/819/1*u6uIQF4xTVe-ylJnAPoIDg.png" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ol start="21">
&lt;li>&lt;a href="http://www.texample.net/tikz/examples/neural-network/" target="_blank" rel="noopener">&lt;strong>Texample&lt;/strong>&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://www.texample.net/media/tikz/examples/PNG/neural-network.png" alt="Neural network" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;pre tabindex="0">&lt;code>\documentclass{article}
\usepackage{tikz}
\begin{document}
\pagestyle{empty}
\def\layersep{2.5cm}
\begin{tikzpicture}[shorten &amp;gt;=1pt,-&amp;gt;,draw=black!50, node distance=\layersep]
\tikzstyle{every pin edge}=[&amp;lt;-,shorten &amp;lt;=1pt]
\tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
\tikzstyle{input neuron}=[neuron, fill=green!50];
\tikzstyle{output neuron}=[neuron, fill=red!50];
\tikzstyle{hidden neuron}=[neuron, fill=blue!50];
\tikzstyle{annot} = [text width=4em, text centered]
% Draw the input layer nodes
\foreach \name / \y in {1,...,4}
% This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
% Draw the hidden layer nodes
\foreach \name / \y in {1,...,5}
\path[yshift=0.5cm]
node[hidden neuron] (H-\name) at (\layersep,-\y cm) {};
% Draw the output layer node
\node[output neuron,pin={[pin edge={-&amp;gt;}]right:Output}, right of=H-3] (O) {};
% Connect every node in the input layer with every node in the
% hidden layer.
\foreach \source in {1,...,4}
\foreach \dest in {1,...,5}
\path (I-\source) edge (H-\dest);
% Connect every node in the hidden layer with the output layer
\foreach \source in {1,...,5}
\path (H-\source) edge (O);
% Annotate the layers
\node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
\node[annot,left of=hl] {Input layer};
\node[annot,right of=hl] {Output layer};
\end{tikzpicture}
% End of code
\end{document}
&lt;/code>&lt;/pre>&lt;ol start="22">
&lt;li>&lt;a href="https://github.com/keplr-io/quiver" target="_blank" rel="noopener">&lt;strong>Quiver&lt;/strong>&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://cloud.githubusercontent.com/assets/5866348/20253975/f3d56f14-a9e4-11e6-9693-9873a18df5d3.gif" alt="gzqll3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>&lt;strong>References :&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;a href="https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures" target="_blank" rel="noopener">https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://datascience.stackexchange.com/questions/2670/visualizing-deep-neural-network-training" target="_blank" rel="noopener">https://datascience.stackexchange.com/questions/2670/visualizing-deep-neural-network-training&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>正向传播与反向传播</title><link>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/deeplearning-notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</guid><description>&lt;h1 id="正向传播与反向传播">正向传播与反向传播&lt;/h1>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="http://zh.gluon.ai/chapter_deep-learning-basics/backprop.html" target="_blank" rel="noopener">http://zh.gluon.ai/chapter_deep-learning-basics/backprop.html&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>
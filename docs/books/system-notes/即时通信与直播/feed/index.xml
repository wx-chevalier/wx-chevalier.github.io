<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Feed | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/</link><atom:link href="https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/index.xml" rel="self" type="application/rss+xml"/><description>Feed</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>Feed</title><link>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/</link></image><item><title>Feed 流方案</title><link>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/feed-%E6%B5%81%E6%96%B9%E6%A1%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/feed-%E6%B5%81%E6%96%B9%E6%A1%88/</guid><description>&lt;h1 id="feed-流方案">Feed 流方案&lt;/h1>
&lt;h1 id="读扩散">读扩散&lt;/h1>
&lt;p>读扩散也称为拉模式，这应该是最符合我们直觉的一种实现方式。如下图：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.ax1x.com/2020/11/16/DARUEj.png" alt="读扩散方式" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>每一个内容发布者都有一个自己的发件箱（“我发布的内容”），每当我们发出一个新帖子，都存入自己的发件箱中。当我们的粉丝来阅读时，系统首先需要拿到粉丝关注的所有人，然后遍历所有发布者的发件箱，取出他们所发布的帖子，然后依据发布时间排序，展示给阅读者。这种设计，阅读者读一次 Feed 流，后台会扩散为 N 次读操作（N 等于关注的人数）以及一次聚合操作，因此称为读扩散。每次读 Feed 流相当于去关注者的收件箱主动拉取帖子，因此也得名拉模式。&lt;/p>
&lt;p>这种模式的好处是底层存储简单，没有空间浪费。坏处是每次读操作会非常重，操作非常多。设想一下如果我关注的人数非常多，遍历一遍我所关注的所有人，并且再聚合一下，这个系统开销会非常大，时延上可能达到无法忍受的地步。因此读扩散主要适用系统中阅读者关注的人没那么多，并且刷 Feed 流并不频繁的场景。拉模式还有一个比较大的缺点就是分页不方便，我们刷微博或朋友圈，肯定是随着大拇指在屏幕不断划动，内容一页一页的从后台拉取。如果不做其他优化，只采用实时聚合的方式，下滑到比较靠后的页码时会非常麻烦。&lt;/p>
&lt;h1 id="写扩散">写扩散&lt;/h1>
&lt;p>据统计，大多数 Feed 流产品的读写比大概在 100:1，也就是说大部分情况都是刷 Feed 流看别人发的朋友圈和微博，只有很少情况是自己亲自发一条朋友圈或微博给别人看。因此，读扩散那种很重的读逻辑并不适合大多数场景。我们宁愿让发帖的过程复杂一些，也不愿影响用户读 Feed 流的体验，因此稍微改造一下前面方案就有了写扩散。写扩散也称为推模式，这种模式会对拉模式的一些缺点做改进。如下图：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.ax1x.com/2020/11/16/DAWIFs.png" alt="写扩散" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>系统中每个用户除了有发件箱，也会有自己的收件箱。当发布者发表一篇帖子的时候，除了往自己发件箱记录一下之外，还会遍历发布者的所有粉丝，往这些粉丝的收件箱也投放一份相同内容。这样阅读者来读 Feed 流时，直接从自己的收件箱读取即可。这种设计，每次发表帖子，都会扩散为 M 次写操作（M 等于自己的粉丝数），因此成为写扩散。每篇帖子都会主动推送到所有粉丝的收件箱，因此也得名推模式。&lt;/p>
&lt;p>这种模式可想而知，发一篇帖子，背后会涉及到很多次的写操作。通常为了发帖人的用户体验，当发布的帖子写到自己发件箱时，就可以返回发布成功。后台另外起一个异步任务，不慌不忙地往粉丝收件箱投递帖子即可。写扩散的好处在于通过数据冗余（一篇帖子会被存储 M 份副本），提升了阅读者的用户体验。通常适当的数据冗余不是什么问题，但是到了微博明星这里，完全行不通。比如目前微博粉丝量 Top2 的谢娜与何炅，两个人微博粉丝过亿。&lt;/p>
&lt;p>设想一下，如果单纯采用推模式，那每次谢娜何炅发一条微博，微博后台都要地震一次。一篇微博导致后台上亿次写操作，这显然是不可行的。另外由于写扩散是异步操作，写的太慢会导致帖子发出去半天，有些粉丝依然没能看见，这种体验也不太好。通常写扩散适用于好友量不大的情况，据悉微信朋友圈正是写扩散模式。每一名微信用户的好友上限为 5000 人，也就是说你发一条朋友圈最多也就扩散到 5000 次写操作，如果异步任务性能好一些，完全没有问题。&lt;/p>
&lt;h1 id="读写混合模式">读写混合模式&lt;/h1>
&lt;p>读写混合也可以称作推拉结合。这种方式可以兼具读扩散和写扩散的优点。我们首先来总结一下读扩散和写扩散的优缺点：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>优点&lt;/th>
&lt;th>缺点&lt;/th>
&lt;th>适用场景&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>读扩散&lt;/td>
&lt;td>节约存储空间发帖操作简单&lt;/td>
&lt;td>读帖操作复杂关注人数多时是灾难&lt;/td>
&lt;td>用户不活跃，很少读帖有大 V 粉丝量多，但每个粉丝关注的人少&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>写扩散&lt;/td>
&lt;td>读帖操作简单&lt;/td>
&lt;td>发帖操作复杂，浪费存储空间大 V 粉丝量多时是灾难&lt;/td>
&lt;td>用户非常活跃，经常刷帖无大 V，用户粉丝量都比较少&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>仔细比较一下读扩散与写扩散的优缺点，不难发现两者的适用场景是互补的。因此在设计后台存储的时候，我们如果能够区分一下场景，在不同场景下选择最适合的方案，并且动态调整策略，就实现了读写混合模式。如下图：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.ax1x.com/2020/11/16/DAWzk9.png" alt="读写混合模式" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>当何炅这种粉丝量超大的人发帖时，将帖子写入何炅的发件箱，另外提取出来何炅粉丝当中比较活跃的那一批（这已经可以筛掉大部分了），将何炅的帖子写入他们的收件箱。当一个粉丝量很小的路人甲发帖时，采用写扩散方式，遍历他的所有粉丝并将帖子写入粉丝收件箱。&lt;/p>
&lt;p>对于那些活跃用户登录刷 Feed 流时，他直接从自己的收件箱读取帖子即可，保证了活跃用户的体验。当一个非活跃的用户突然登录刷 Feed 流时，我们一方面需要读他的收件箱，另一方面需要遍历他所关注的大 V 用户的发件箱提取帖子，并且做一下聚合展示。在展示完后，系统还需要有个任务来判断是否有必要将该用户升级为活跃用户。因为有读扩散的场景存在，因此即使是混合模式，每个阅读者所能关注的人数也要设置上限，例如新浪微博限制每个账号最多可以关注 2000 人。如果不设上限，设想一下有一位用户把微博所有账号全部关注了，那他打开关注列表会读取到微博全站所有帖子，一旦出现读扩散，系统必然崩溃；即使是写扩散，他的收件箱也无法容纳这么多的微博。&lt;/p>
&lt;p>读写混合模式下，系统需要做两个判断。一个是哪些用户属于大 V，我们可以将粉丝量作为一个判断指标。另一个是哪些用户属于活跃粉丝，这个判断标准可以是最近一次登录时间等。这两处判断标准就需要在系统发展过程中动态地识别和调整，没有固定公式了。可以看出读写结合模式综合了两种模式的优点，属于最佳方案。然而他的缺点是系统机制非常复杂，给程序员带来无数烦恼。通常在项目初期，只有一两个开发人员，用户规模也很小的时候，一步到位地采用这种混合模式还是要慎重，容易出 bug。当项目规模逐渐发展到新浪微博的水平，有一个大团队专门来做 Feed 流时，读写混合模式才是必须的。&lt;/p></description></item><item><title>分页问题</title><link>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/%E5%88%86%E9%A1%B5%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/system-notes/%E5%8D%B3%E6%97%B6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%9B%B4%E6%92%AD/feed/%E5%88%86%E9%A1%B5%E9%97%AE%E9%A2%98/</guid><description>&lt;h1 id="分页问题">分页问题&lt;/h1>
&lt;p>前文已经叙述了基于时间线的 Feed 流常见设计方案，但实操起来会比理论要麻烦许多。接下来专门讨论一个困难点：Feed 流的分页。不管是读扩散还是写扩散，Feed 流本质上是一个动态列表，列表内容会随着时间不断变化。传统的前端分页参数使用 page_size 和 page_num，分表表示每页几条，以及当前是第几页。对于一个动态列表会有如下问题：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.ax1x.com/2020/11/16/DAfE0e.png" alt="动态列表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>在 T1 时刻读取了第一页，T2 时刻有人新发表了“内容 11”，在 T3 时刻如果来拉取第二页，会导致错位出现，“内容 6”在第一页和第二页都被返回了。事实上，但凡两页之间出现内容的添加或删除，都会导致错位问题。为了解决这一问题，通常 Feed 流的分页入参不会使用 page_size 和 page_num，而是使用 last_id 来记录上一页最后一条内容的 id。前端读取下一页的时候，必须将 last_id 作为入参，后台直接找到 last_id 对应数据，再往后偏移 page_size 条数据，返回给前端，这样就避免了错位问题。如下图：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.ax1x.com/2020/11/16/DAfmtA.png" alt="动态读取" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>采用 last_id 的方案有一个重要条件，就是 last_id 本身这条数据不可以被硬删除。设想一下上图中 T1 时刻返回 5 条数据，last_id 为内容 6；T2 时刻内容 6 被发布者删除；那么 T3 时刻再来请求第二页，我们根本找不到 last_id 对应的数据了，也就无法确认分页偏移量。通常碰到删除的场景，我们采用软删除方式，只是在内容上置一个标志位，表示内容已删除。由于已经删除的内容不应该再返回给前端，因此软删除模式下，找到 last_id 并往后偏移 page_size 条，如果其中有被删除的数据会导致获得足够的数据条数给前端。这里一个解决方案是找不够继续再往下找，另一种方案是与前端协商，允许返回条数少于 page_size 条，page_size 只是个建议值。甚至大家约定好了以后，可以不要 page_size 参数。&lt;/p></description></item></channel></rss>
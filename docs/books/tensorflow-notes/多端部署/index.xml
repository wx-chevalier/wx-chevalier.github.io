<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>多端部署 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/</link><atom:link href="https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml"/><description>多端部署</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>多端部署</title><link>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/</link></image><item><title>TensorFire</title><link>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorfire/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorfire/</guid><description>&lt;h1 id="tensorfire浏览器端的-tensorflow">TensorFire：浏览器端的 TensorFlow&lt;/h1>
&lt;h2 id="摘要">摘要：&lt;/h2>
&lt;p>TensorFire 是基于 WebGL 的运行在浏览器内的高性能神经网络框架，其执行速度甚至可以快于原生的 TensorFlow。&lt;/p>
&lt;h2 id="正文">正文：&lt;/h2>
&lt;p>深度学习与人工智能技术正在逐步地改变人们的生活，以 TensoFlow 为代表的一系列深度学习与神经网络框架也是如日中天，迅猛发展。TensorFire 则是基于 WebGL 的，运行在浏览器中的神经网络框架；使用 TensorFire 编写的应用能够在实现前沿深度学习算法的同时，不需要任何的安装或者配置就直接运行在现代浏览器中。与之前某些浏览器内的神经网络框架相比，TensorFire 有着近百倍的速度提升，甚至于能够与那些运行在本地 CPU 上的代码性能相媲美。现代的 PC、笔记本电脑与移动终端往往都被包含能够进行高性能并发计算的 GPU，通过将神经网络中的权重转化为 WebGL 中的纹理，TensorFire 将神经网络中的层转化为了片段着色器(Fragment Shaders)，从而利用原本设计来加速执行 3D 游戏的引擎来执行神经网络。另一方面，不同于其他的 WebGL 计算框架，TensorFire 支持 Low-precision Quantized Tensors，从而保证了模型的适用性。&lt;/p>
&lt;p>TensorFire 主要由两部分组成：底层基于 GLSL 的能够高效编写操作四维张量的并行 WebGLS 着色器的编程语言，以及上层的用于导入 Keras 与 TensorFlow 训练好的模型的接口。TensorFire 能够运行在任何的，无论是否支持 CUDA 的 GPU 上；这就意味着，譬如最新的 2016 Retina MacBook Pro 这样的使用 AMD 显卡的机器，也能顺畅地运行 TensorFire。TensorFire 能够帮助开发者构建不需要用户本地安装的智能应用，并且不同于传统的收集用户数据以统一训练的模式，直接将模型下发到用户端能够保障用户隐私权。TensorFire 官方正在着手提供多个范例，譬如复杂的 ResNet-152 网络、著名的基于 RNN 的文本生产与图片着色、基于 SqueeseNet 的物体识别与分类等等。开发者也可以使用 TensorFire 提供的底层接口来进行其他的高性能计算，譬如 PageRank、元胞自动机仿真、图片转化与过滤等等。&lt;/p>
&lt;p>TensorFire 项目由多位 MIT 的毕业生协作而成。其中 Kevin Kwok 与 Guillermo Webster 曾编写过 &lt;a href="https://projectnaptha.com/" target="_blank" rel="noopener">Project Naptha&lt;/a> 这样的将 JavaScript 与计算机视觉相结合的从图片中提取文字的 OCR 项目。Anish Athalye 与 Logan Engstrom 则编写过首个 &lt;a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">Gatys&amp;rsquo; Neural Artistic Style&lt;/a> 以及 &lt;a href="https://github.com/lengstrom/fast-style-transfer" target="_blank" rel="noopener">Johnson&amp;rsquo;s Fast Style Transfer&lt;/a> 算法的 TensorFlow 模型。&lt;/p>
&lt;p>该项目 Style Transfer Neural Network Demo 链接：&lt;a href="https://tenso.rs/demos/fast-neural-style/" target="_blank" rel="noopener">https://tenso.rs/demos/fast-neural-style/&lt;/a>&lt;/p>
&lt;p>查看英文原文: &lt;a href="https://tenso.rs/#wat" target="_blank" rel="noopener">TensorFire&lt;/a>&lt;/p></description></item><item><title>TensorFlow Serving</title><link>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorflow-serving/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorflow-serving/</guid><description>&lt;h1 id="tensorflow-serving">tensorflow-serving&lt;/h1>
&lt;p>TensorFlow 训练好的模型以 TensorFlow 原生方式保存成 protobuf 文件后可以用许多方式部署运行：&lt;/p>
&lt;ul>
&lt;li>通过 tensorflow-js 可以用 javascrip 脚本加载模型并在浏览器中运行模型。&lt;/li>
&lt;li>通过 tensorflow-lite 可以在移动和嵌入式设备上加载并运行 TensorFlow 模型。&lt;/li>
&lt;li>通过 tensorflow-serving 可以加载模型后提供网络接口 API 服务，通过任意编程语言发送网络请求都可以获取模型预测结果。&lt;/li>
&lt;li>通过 TensorFlow for Java 接口，可以在 Java 或者 spark(scala)中调用 TensorFlow 模型进行预测。&lt;/li>
&lt;/ul>
&lt;p>使用 tensorflow serving 部署模型要完成以下步骤：&lt;/p>
&lt;ul>
&lt;li>准备 protobuf 模型文件。&lt;/li>
&lt;li>安装 tensorflow serving。&lt;/li>
&lt;li>启动 tensorflow serving 服务。&lt;/li>
&lt;li>向 API 服务发送请求，获取预测结果。&lt;/li>
&lt;/ul>
&lt;p>详细的演示请参阅 &lt;a href="./tf_serving.ipynb">tf_serving.ipynb&lt;/a>&lt;/p></description></item><item><title>分布式集群</title><link>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</guid><description>&lt;p>本目录包括了运行时分布式 TensorFlow 的实现，其底层使用了&lt;a href="http://grpc.io" target="_blank" rel="noopener">gRPC&lt;/a> 作为进程内通信的支持库。&lt;/p>
&lt;h2 id="quick-start">Quick start&lt;/h2>
&lt;p>首先，需要构建一个 TensorFlow 的服务端可执行版本(&lt;code>grpc_tensorflow_server&lt;/code>) 以及一个基于 gRPC 的客户端。目前只能基于源代码进行自构建, 但是会包含在未来发布的二进制版本中。可以使用如下命令进行构建:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># CPU-only build.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build -c opt //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># GPU build.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel build -c opt --config&lt;span class="o">=&lt;/span>cuda //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果是从最新的源代码创建的 Python 依赖包，它会自动包含一个基于 gRPC 的客户端。如果使用的是一个之前发布的二进制版本，需要根据这个&lt;a href="https://www.tensorflow.org/versions/master/get_started/os_setup.html#create-the-pip-package-and-install" target="_blank" rel="noopener">安装说明&lt;/a>来重新编译安装。在你成功地构建了分布式的 TensorFlow 组件之后，可以通过如下方式来启动服务器并且判断你的安装是否成功：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Start a TensorFlow server as a single-process &amp;#34;cluster&amp;#34;.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --cluster_spec&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;local|localhost:2222&amp;#39;&lt;/span> --job_name&lt;span class="o">=&lt;/span>&lt;span class="nb">local&lt;/span> --task_index&lt;span class="o">=&lt;/span>&lt;span class="m">0&lt;/span> &lt;span class="p">&amp;amp;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后启动 Python 的交互器并且启动一个 Session：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">$&lt;/span> &lt;span class="n">python&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">constant&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Hello, distributed TensorFlow!&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">sess&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;grpc://localhost:2222&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">&amp;#39;Hello, distributed TensorFlow!&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="集群定义">集群定义&lt;/h2>
&lt;p>命令行参数 &lt;code>grpc_tensorflow_server&lt;/code> 定义了集群之间的关系. 参数 &lt;code>--cluster_spec&lt;/code> 决定了集群中工作对象的多少, 譬如有一系列的 &lt;em>jobs&lt;/em>, 而每个&lt;em>jobs&lt;/em>又包含了多个&lt;em>task&lt;/em> 终端。所有集群中的处理过程都必须设置相同的 &lt;code>--cluster_spec&lt;/code>参数，例子如下:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;code>--cluster_spec='...'&lt;/code>&lt;/th>
&lt;th>Available tasks&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>local|localhost:2222&lt;/code>&lt;/td>
&lt;td>&lt;code>/job:local/task:0&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>local|localhost:2222;localhost:2223&lt;/code>&lt;/td>
&lt;td>&lt;code>/job:local/task:0``/job:local/task:1&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>worker|worker0:2222;worker1:2222;worker2:2222,``ps|ps0:2222;ps1:2222&lt;/code>&lt;/td>
&lt;td>&lt;code>/job:worker/task:0``/job:worker/task:1``/job:worker/task:2``/job:ps/task:0``/job:ps/task:1&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>还有 &lt;code>--job_name&lt;/code> 与 &lt;code>--task_index&lt;/code> 标志位指明了哪些任务会运行在当前处理过程上。具体而言,
&lt;code>--job_name=local --task_index=0&lt;/code> 意思就是该过程会被标志为
&lt;code>/job:local/task:0&lt;/code>, 然后所有在该过程上的 TensorFlow 的设备都会使用这个前缀。&lt;/p>
&lt;p>&lt;strong>N.B.&lt;/strong>
手动来指明这些运行参数可能是非常冗长的，特别是对一个大型集群而言。我们正在研发可以程式化启动的工具，譬如使用一些类似于&lt;a href="http://kubernetes.io" target="_blank" rel="noopener">Kubernetes&lt;/a>集群管理器。如果有啥集群管理工具你觉得挺好的希望加入进来，可以在&lt;a href="https://github.com/tensorflow/tensorflow/issues" target="_blank" rel="noopener">GitHub issue&lt;/a>上提出你的建议。&lt;/p>
&lt;h2 id="标注模型中的分布式设备">标注模型中的分布式设备&lt;/h2>
&lt;p>为了将某个操作放在某个特殊的处理过程上,在分布式环境下依然可以使用
&lt;a href="https://www.tensorflow.org/versions/master/api_docs/python/framework.html#device" target="_blank" rel="noopener">&lt;code>tf.device()&lt;/code>&lt;/a>
函数，之前是用来指明是放在 CPU 还是 GPU 上的。譬如:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;/job:ps/task:0&amp;#34;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">weights_1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">biases_1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;/job:ps/task:1&amp;#34;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">weights_2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">biases_2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;/job:worker/task:7&amp;#34;&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">input&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layer_1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weights_1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">biases_1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">logits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">relu&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layer_1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weights_2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">biases_2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">train_op&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;grpc://worker7:2222&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10000&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_op&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在上面的例子中，Variables 在 job &lt;code>ps&lt;/code>的两个 task 上被创建，然后计算密集型的部分创建在 job &lt;code>work&lt;/code>上。TensorFlow 会自动地在不同的 job 之间传输数据。(从&lt;code>job&lt;/code>到&lt;code>work&lt;/code>是前向传递，而从&lt;code>worker&lt;/code>到&lt;code>ps&lt;/code>是梯度应用)。&lt;/p>
&lt;h2 id="replicated-computation">Replicated Computation&lt;/h2>
&lt;p>一个常见的训练配置(数据并行训练)包含了 job &lt;code>ps&lt;/code>上共享参数以及 job &lt;code>work&lt;/code>上的多个任务来训练相同的模型。每个 task 一般会运行在不同的机器上。现在还是有很多办法可以在 TensorFlow 中来实现这一种结构的，我们未来也会提供更简单的实现方式，主要途径有：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>构建单一的包含了一系列参数的图(in &lt;code>tf.Variable&lt;/code> nodes pinned to &lt;code>/job:ps&lt;/code>), 并且创建多个模型的副本来映射到&lt;code>/job:worker&lt;/code>中的不同 tasks。每个 model 的副本有一个不同的&lt;code>train_op&lt;/code>，并且对于每个 worker &lt;code>i&lt;/code>而言一个或者多个的客户端线程可以调用&lt;code>sess.run(train_ops[i])&lt;/code>。这种方法使用了单一的&lt;code>tf.Session&lt;/code>，它的工作目标是集群中的某个 workers。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As above, but where the gradients from all workers are averaged. See the
&lt;a href="https://www.tensorflow.org/code/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py" target="_blank" rel="noopener">CIFAR-10 multi-GPU trainer&lt;/a>
for an example of this form of replication. The implements &lt;em>synchronous&lt;/em> training&lt;/p>
&lt;/li>
&lt;li>
&lt;p>另一种分布式训练器的方法使用多张图，一张图对应一个 worker，并且每张图都包含了一系列的参数的集合(&lt;code>/job:ps&lt;/code>)和一份模型的赋值。而容器的机制就是在不同的图之间共享变量：一旦某个变量构造完成，可选的&lt;code>container&lt;/code>参数会由图中每份复制的相同值来决定。对于较大的模型而言，这种方法会更加有效，毕竟整个图更小了一点。
这种方法使用多个&lt;code>tf.Session&lt;/code>对象：每个 worker 过程都会包含一个，不过不同的 Session 会指向不同的目标 worker。这个&lt;code>tf.Session&lt;/code>对象即可以在单一的 Python 客户端中创建，也可以在多个客户端中创建。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="术语">术语&lt;/h2>
&lt;p>&lt;strong>Client&lt;/strong>
一个典型的客户端一般会构建一个 TensorFlow 的图并且使用&lt;code>tensorflow::Session&lt;/code>来完成与集群的交互。客户端一般会用 Python 或者 C++编写，一般来说一个客户端可以同时与多个服务端进行交互(参考上文的重复训练)，并且一个服务端也可以同时服务于多个客户端。&lt;/p>
&lt;p>&lt;strong>Cluster&lt;/strong>
一个 TensorFlow 集群会包含一个或者多个 TensorFlow 的服务端，被切分为一系列命名的 job，而每个 job 又会负责一系列的 tasks。一个集群一般会专注于一个相对高层的目标，譬如用多台机器并行地训练一个神经网络。&lt;/p>
&lt;p>&lt;strong>Job&lt;/strong>
一个 job 会包含一系列的致力于某个相同目标的 task。譬如，一个叫&lt;code>ps&lt;/code>(意思是参数服务)的 job 会用于处理存储于更新 Variables 相关的工作。而一个叫&lt;code>worker&lt;/code>的 job 会用于承载那些用于计算密集型的无状态节点。一般来说一个 job 中的 tasks 会运行在不同的机器中。&lt;/p>
&lt;p>&lt;strong>Master service&lt;/strong>
Master Service 是一个 RPC 服务用于与一系列远端的分布式设备进行交互。Master Service 实现了&lt;code>tensorflow::Session&lt;/code> 接口, 并且用来协调多个 worker service。&lt;/p>
&lt;p>&lt;strong>Task&lt;/strong>
一个 Task 一般会关联到某个单一的 TensorFlow 服务端的处理过程，属于一个特定的 job 并且在该 job 的任务列表中有个唯一的索引。&lt;/p>
&lt;p>&lt;strong>TensorFlow server&lt;/strong>
用于运行 grpc_tensorflow_server 的处理过程，是一个集群中的一员，并且想外暴露了一个 Master Service 与一个 Worker Service。&lt;/p>
&lt;p>&lt;strong>Worker service&lt;/strong>
一个执行部分 TensorFlow 图部分内容的 RPC 服务。
)&lt;/p></description></item></channel></rss>
<!doctype html><html lang=zh><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=google-site-verification content="google69a5cccb61297807"><meta name=baidu-site-verification content="cqmZHEleVh"><meta name=description content="模型层 深度学习模型一般由各种模型层组合而成。tf.keras.layers 内置了非常丰富的各种功能的模型层。例如，layers.Dense,layers.Flatten,layers.Input,la"><link rel=alternate hreflang=zh href=https://ng-tech.icu/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%A8%A1%E5%9E%8B%E5%B1%82/><meta name=theme-color content="#0a55a7"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin=anonymous><link rel=stylesheet href=/css/wowchemy.63df6ae9fc2b4cc71b83f1774d780209.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-40NYXJ8823")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://ng-tech.icu/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%A8%A1%E5%9E%8B%E5%B1%82/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wx-chevalier"><meta property="twitter:creator" content="@wx-chevalier"><meta property="og:site_name" content="Next-gen Tech Edu"><meta property="og:url" content="https://ng-tech.icu/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%A8%A1%E5%9E%8B%E5%B1%82/"><meta property="og:title" content="模型层 | Next-gen Tech Edu"><meta property="og:description" content="模型层 深度学习模型一般由各种模型层组合而成。tf.keras.layers 内置了非常丰富的各种功能的模型层。例如，layers.Dense,layers.Flatten,layers.Input,la"><meta property="og:image" content="https://ng-tech.icu/media/sharing.png"><meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png"><meta property="og:locale" content="zh"><title>模型层 | Next-gen Tech Edu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=ef3ee68af9068cd302f2ad1065a50829><button onclick=topFunction() id=backTopBtn title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden=true></i></button>
<script src=/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class="col-6 search-title"><p>搜索</p></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=关闭><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div><div id=search-common-queries></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/books-gallery><span>笔记（万篇）</span></a></li><li class=nav-item><a class=nav-link href=/#knowledge-map><span>知识图谱</span></a></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>实验室</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/galaxy-home/gh-craft><span>Craft 方块世界</span></a>
<a class=dropdown-item href=/galaxy-home/glossary-cards><span>3D 知识卡牌</span></a></div></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>其他阅读渠道</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png></img><span>知乎</span></a>
<a class=dropdown-item href=https://segmentfault.com/blog/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png></img><span>SegmentFault</span></a>
<a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png></img><span>掘金</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/wx-chevalier aria-label=GitHub><i class="fa-brands fa-github" aria-hidden=true></i></a></li><div></div><style>@media only screen and (max-width:600px){.jimmysong-template{display:none!important}}</style><li class=jimmysong-template style=color:#fff;font-size:12px><a href=https://jimmysong.io style=color:#fff>By Jimmy Song's Template</a></li></ul></div></nav></header></div><div class=page-body><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><div class="container-xl docs"><div class="row flex-xl-nowrap"><div class=docs-sidebar><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">模型构建</span>
<span><i class="fas fa-chevron-down"></i></span></div></button>
<button class="form-control sidebar-search js-search d-none d-md-flex">
<i class="fas fa-search pr-2"></i>
<span class=sidebar-search-text>搜索...</span>
<span class=sidebar-search-shortcut>/</span></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li style=display:inline-flex><a style=cursor:pointer onclick=window.history.back()><i class="fas fa-arrow-left pr-1"></i>
Back</a>
<span>|</span>
<a href=/books/><i class="fa-solid fa-house" style=margin-right:4px></i>
Books</a></li></ul><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idab8633f9fa49a77327d141734bac5cc2")' href=#idab8633f9fa49a77327d141734bac5cc2 aria-expanded=false aria-controls=idab8633f9fa49a77327d141734bac5cc2 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/>TensorFlow-Notes</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idab8633f9fa49a77327d141734bac5cc2 aria-expanded=false aria-controls=idab8633f9fa49a77327d141734bac5cc2><i class="fa-solid fa-angle-down" id=caret-idab8633f9fa49a77327d141734bac5cc2></i></a></div><ul class="nav docs-sidenav collapse show" id=idab8633f9fa49a77327d141734bac5cc2><li class="child level"><a href=/books/tensorflow-notes/introduction/>INTRODUCTION</a></li><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idc49728daaba7b6a74f2a2a760c92f5b9")' href=#idc49728daaba7b6a74f2a2a760c92f5b9 aria-expanded=false aria-controls=idc49728daaba7b6a74f2a2a760c92f5b9 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/>层次结构</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idc49728daaba7b6a74f2a2a760c92f5b9 aria-expanded=false aria-controls=idc49728daaba7b6a74f2a2a760c92f5b9><i class="fa-solid fa-angle-right" id=caret-idc49728daaba7b6a74f2a2a760c92f5b9></i></a></div><ul class="nav docs-sidenav collapse" id=idc49728daaba7b6a74f2a2a760c92f5b9><li class="child level"><a href=/books/tensorflow-notes/%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/%E8%AE%A1%E7%AE%97%E5%9B%BE/>计算图</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idc51f77c5834a909f64c201a60be5ad0a")' href=#idc51f77c5834a909f64c201a60be5ad0a aria-expanded=false aria-controls=idc51f77c5834a909f64c201a60be5ad0a aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/>多端部署</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idc51f77c5834a909f64c201a60be5ad0a aria-expanded=false aria-controls=idc51f77c5834a909f64c201a60be5ad0a><i class="fa-solid fa-angle-right" id=caret-idc51f77c5834a909f64c201a60be5ad0a></i></a></div><ul class="nav docs-sidenav collapse" id=idc51f77c5834a909f64c201a60be5ad0a><li class="child level"><a href=/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorfire/>TensorFire</a></li><li class="child level"><a href=/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorflow-serving/>TensorFlow Serving</a></li><li class="child level"><a href=/books/tensorflow-notes/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/>分布式集群</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-ida489ca1c4233849ae68492c6e827a6bd")' href=#ida489ca1c4233849ae68492c6e827a6bd aria-expanded=false aria-controls=ida489ca1c4233849ae68492c6e827a6bd aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/>模型构建</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#ida489ca1c4233849ae68492c6e827a6bd aria-expanded=false aria-controls=ida489ca1c4233849ae68492c6e827a6bd><i class="fa-solid fa-angle-down" id=caret-ida489ca1c4233849ae68492c6e827a6bd></i></a></div><ul class="nav docs-sidenav collapse show" id=ida489ca1c4233849ae68492c6e827a6bd><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/>回调函数</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/>激活函数</a></li><li class="child level active"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%A8%A1%E5%9E%8B%E5%B1%82/>模型层</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/>评估指标</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/>损失函数</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E7%89%B9%E5%BE%81%E5%88%97/>特征列</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E4%BC%98%E5%8C%96%E5%99%A8/>优化器</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id2a43fedcc43d45311243977a59ca894f")' href=#id2a43fedcc43d45311243977a59ca894f aria-expanded=false aria-controls=id2a43fedcc43d45311243977a59ca894f aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/>模型训练</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id2a43fedcc43d45311243977a59ca894f aria-expanded=false aria-controls=id2a43fedcc43d45311243977a59ca894f><i class="fa-solid fa-angle-right" id=caret-id2a43fedcc43d45311243977a59ca894f></i></a></div><ul class="nav docs-sidenav collapse" id=id2a43fedcc43d45311243977a59ca894f><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id261805210488693db2d9eb2b05905d6d")' href=#id261805210488693db2d9eb2b05905d6d aria-expanded=false aria-controls=id261805210488693db2d9eb2b05905d6d aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/gpu/>GPU</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id261805210488693db2d9eb2b05905d6d aria-expanded=false aria-controls=id261805210488693db2d9eb2b05905d6d><i class="fa-solid fa-angle-right" id=caret-id261805210488693db2d9eb2b05905d6d></i></a></div><ul class="nav docs-sidenav collapse" id=id261805210488693db2d9eb2b05905d6d><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/gpu/gpu-%E8%AE%BE%E7%BD%AE/>GPU 设置</a></li><li class="child level"><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/gpu/tpu-%E8%AE%BE%E7%BD%AE/>TPU 设置</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id0095bc40fdd259d31ce26afdcba42f59")' href=#id0095bc40fdd259d31ce26afdcba42f59 aria-expanded=false aria-controls=id0095bc40fdd259d31ce26afdcba42f59 aria-hidden=false data-toggle=collapse></div></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id4004a821cdb3abacf90e139830d8ebcb")' href=#id4004a821cdb3abacf90e139830d8ebcb aria-expanded=false aria-controls=id4004a821cdb3abacf90e139830d8ebcb aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E5%AE%9E%E8%B7%B5%E6%A1%88%E4%BE%8B/>实践案例</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id4004a821cdb3abacf90e139830d8ebcb aria-expanded=false aria-controls=id4004a821cdb3abacf90e139830d8ebcb><i class="fa-solid fa-angle-right" id=caret-id4004a821cdb3abacf90e139830d8ebcb></i></a></div><ul class="nav docs-sidenav collapse" id=id4004a821cdb3abacf90e139830d8ebcb><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id4d17624acbd525d3aa14e0ffeb530ec1")' href=#id4d17624acbd525d3aa14e0ffeb530ec1 aria-expanded=false aria-controls=id4d17624acbd525d3aa14e0ffeb530ec1 aria-hidden=false data-toggle=collapse></div></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id2fb88ff8192176604cb7172bb7dd852b")' href=#id2fb88ff8192176604cb7172bb7dd852b aria-expanded=false aria-controls=id2fb88ff8192176604cb7172bb7dd852b aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E5%A2%9E%E5%BC%BA%E6%A1%86%E6%9E%B6/>增强框架</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id2fb88ff8192176604cb7172bb7dd852b aria-expanded=false aria-controls=id2fb88ff8192176604cb7172bb7dd852b><i class="fa-solid fa-angle-right" id=caret-id2fb88ff8192176604cb7172bb7dd852b></i></a></div><ul class="nav docs-sidenav collapse" id=id2fb88ff8192176604cb7172bb7dd852b><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id4c7a05f1cd5d43a5d187e3a25a3664a1")' href=#id4c7a05f1cd5d43a5d187e3a25a3664a1 aria-expanded=false aria-controls=id4c7a05f1cd5d43a5d187e3a25a3664a1 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idac50ebbaad2db29c265d12dce8accc88")' href=#idac50ebbaad2db29c265d12dce8accc88 aria-expanded=false aria-controls=idac50ebbaad2db29c265d12dce8accc88 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id56e0b54ac5bf2d7e59d0c029f67c7ffa")' href=#id56e0b54ac5bf2d7e59d0c029f67c7ffa aria-expanded=false aria-controls=id56e0b54ac5bf2d7e59d0c029f67c7ffa aria-hidden=false data-toggle=collapse></div></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idccd16ac255750bd314ad43261fccc0cc")' href=#idccd16ac255750bd314ad43261fccc0cc aria-expanded=false aria-controls=idccd16ac255750bd314ad43261fccc0cc aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/tensorflow-notes/%E5%BC%A0%E9%87%8F%E4%B8%8E-autograph/>张量与 AutoGraph</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idccd16ac255750bd314ad43261fccc0cc aria-expanded=false aria-controls=idccd16ac255750bd314ad43261fccc0cc><i class="fa-solid fa-angle-right" id=caret-idccd16ac255750bd314ad43261fccc0cc></i></a></div><ul class="nav docs-sidenav collapse" id=idccd16ac255750bd314ad43261fccc0cc><li class="child level"><a href=/books/tensorflow-notes/%E5%BC%A0%E9%87%8F%E4%B8%8E-autograph/autograph-%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/>AutoGraph 编码规范</a></li></ul></div></ul></div></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>目录</a></li></ul><nav id=TableOfContents><ul><li><a href=#基础层>基础层</a></li><li><a href=#卷积网络相关层>卷积网络相关层</a></li><li><a href=#循环网络相关层>循环网络相关层</a></li></ul><ul><li><a href=#lambda>Lambda</a></li><li><a href=#layer>Layer</a></li></ul></nav><div class="subscribe-module col-24 mt-1"><img src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png alt=image title=王下邀月熊的微信公众号></div></div><main class="py-md-3 pl-md-3 docs-content col-xl-8" role=main><article class=article><h1>模型层</h1><div class=article-style><h1 id=模型层>模型层</h1><p>深度学习模型一般由各种模型层组合而成。tf.keras.layers 内置了非常丰富的各种功能的模型层。例如，layers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout,layers.Conv2D,layers.MaxPooling2D,layers.Conv1D,layers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional 等等。</p><p>如果这些内置模型层不能够满足需求，我们也可以通过编写 tf.keras.Lambda 匿名模型层或继承 tf.keras.layers.Layer 基类构建自定义的模型层。其中 tf.keras.Lambda 匿名模型层只适用于构造没有学习参数的模型层。</p><h1 id=内置模型层>内置模型层</h1><h2 id=基础层>基础层</h2><ul><li>Dense：密集连接层。参数个数 = 输入层特征数 × 输出层特征数(weight)＋ 输出层特征数(bias)</li><li>Activation：激活函数层。一般放在 Dense 层后面，等价于在 Dense 层中指定 activation。</li><li>Dropout：随机置零层。训练期间以一定几率将输入置 0，一种正则化手段。</li><li>BatchNormalization：批标准化层。通过线性变换将输入批次缩放平移到稳定的均值和标准差。可以增强模型对输入不同分布的适应性，加快模型训练速度，有轻微正则化效果。一般在激活函数之前使用。</li><li>SpatialDropout2D：空间随机置零层。训练期间以一定几率将整个特征图置 0，一种正则化手段，有利于避免特征图之间过高的相关性。</li><li>Input：输入层。通常使用 Functional API 方式构建模型时作为第一层。</li><li>DenseFeature：特征列接入层，用于接收一个特征列列表并产生一个密集连接层。</li><li>Flatten：压平层，用于将多维张量压成一维。</li><li>Reshape：形状重塑层，改变输入张量的形状。</li><li>Concatenate：拼接层，将多个张量在某个维度上拼接。</li><li>Add：加法层。</li><li>Subtract：减法层。</li><li>Maximum：取最大值层。</li><li>Minimum：取最小值层。</li></ul><h2 id=卷积网络相关层>卷积网络相关层</h2><ul><li>Conv1D：普通一维卷积，常用于文本。参数个数 = 输入通道数 × 卷积核尺寸(如 3)× 卷积核个数</li><li>Conv2D：普通二维卷积，常用于图像。参数个数 = 输入通道数 × 卷积核尺寸(如 3 乘 3)× 卷积核个数</li><li>Conv3D：普通三维卷积，常用于视频。参数个数 = 输入通道数 × 卷积核尺寸(如 3 乘 3 乘 3)× 卷积核个数</li><li>SeparableConv2D：二维深度可分离卷积层。不同于普通卷积同时对区域和通道操作，深度可分离卷积先操作区域，再操作通道。即先对每个通道做独立卷积操作区域，再用 1 乘 1 卷积跨通道组合操作通道。参数个数 = 输入通道数 × 卷积核尺寸 + 输入通道数 ×1×1× 输出通道数。深度可分离卷积的参数数量一般远小于普通卷积，效果一般也更好。</li><li>DepthwiseConv2D：二维深度卷积层。仅有 SeparableConv2D 前半部分操作，即只操作区域，不操作通道，一般输出通道数和输入通道数相同，但也可以通过设置 depth_multiplier 让输出通道为输入通道的若干倍数。输出通道数 = 输入通道数 × depth_multiplier。参数个数 = 输入通道数 × 卷积核尺寸 × depth_multiplier。</li><li>Conv2DTranspose：二维卷积转置层，俗称反卷积层。并非卷积的逆操作，但在卷积核相同的情况下，当其输入尺寸是卷积操作输出尺寸的情况下，卷积转置的输出尺寸恰好是卷积操作的输入尺寸。</li><li>LocallyConnected2D: 二维局部连接层。类似 Conv2D，唯一的差别是没有空间上的权值共享，所以其参数个数远高于二维卷积。</li><li>MaxPool2D: 二维最大池化层。也称作下采样层。池化层无可训练参数，主要作用是降维。</li><li>AveragePooling2D: 二维平均池化层。</li><li>GlobalMaxPool2D: 全局最大池化层。每个通道仅保留一个值。一般从卷积层过渡到全连接层时使用，是 Flatten 的替代方案。</li><li>GlobalAvgPool2D: 全局平均池化层。每个通道仅保留一个值。</li></ul><h2 id=循环网络相关层>循环网络相关层</h2><ul><li>Embedding：嵌入层。一种比 Onehot 更加有效的对离散特征进行编码的方法。一般用于将输入中的单词映射为稠密向量。嵌入层的参数需要学习。</li><li>LSTM：长短记忆循环网络层。最普遍使用的循环网络层。具有携带轨道，遗忘门，更新门，输出门。可以较为有效地缓解梯度消失问题，从而能够适用长期依赖问题。设置 return_sequences = True 时可以返回各个中间步骤输出，否则只返回最终输出。</li><li>GRU：门控循环网络层。LSTM 的低配版，不具有携带轨道，参数数量少于 LSTM，训练速度更快。</li><li>SimpleRNN：简单循环网络层。容易存在梯度消失，不能够适用长期依赖问题。一般较少使用。</li><li>ConvLSTM2D：卷积长短记忆循环网络层。结构上类似 LSTM，但对输入的转换操作和对状态的转换操作都是卷积运算。</li><li>Bidirectional：双向循环网络包装器。可以将 LSTM，GRU 等层包装成双向循环网络。从而增强特征提取能力。</li><li>RNN：RNN 基本层。接受一个循环网络单元或一个循环单元列表，通过调用 tf.keras.backend.rnn 函数在序列上进行迭代从而转换成循环网络层。</li><li>LSTMCell：LSTM 单元。和 LSTM 在整个序列上迭代相比，它仅在序列上迭代一步。可以简单理解 LSTM 即 RNN 基本层包裹 LSTMCell。</li><li>GRUCell：GRU 单元。和 GRU 在整个序列上迭代相比，它仅在序列上迭代一步。</li><li>SimpleRNNCell：SimpleRNN 单元。和 SimpleRNN 在整个序列上迭代相比，它仅在序列上迭代一步。</li><li>AbstractRNNCell：抽象 RNN 单元。通过对它的子类化用户可以自定义 RNN 单元，再通过 RNN 基本层的包裹实现用户自定义循环网络层。</li><li>Attention：Dot-product 类型注意力机制层。可以用于构建注意力模型。</li><li>AdditiveAttention：Additive 类型注意力机制层。可以用于构建注意力模型。</li><li>TimeDistributed：时间分布包装器。包装后可以将 Dense、Conv2D 等作用到每一个时间片段上。</li></ul><h1 id=自定义模型层>自定义模型层</h1><p>如果自定义模型层没有需要被训练的参数，一般推荐使用 Lamda 层实现，如果自定义模型层有需要被训练的参数，则可以通过对 Layer 基类子类化实现。</p><h2 id=lambda>Lambda</h2><p>Lambda 层由于没有需要被训练的参数，只需要定义正向传播逻辑即可，使用比 Layer 基类子类化更加简单；Lambda 层的正向逻辑可以使用 Python 的 lambda 函数来表达，也可以用 def 关键字定义函数来表达。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow.keras</span> <span class=kn>import</span> <span class=n>layers</span><span class=p>,</span><span class=n>models</span><span class=p>,</span><span class=n>regularizers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mypower</span> <span class=o>=</span> <span class=n>layers</span><span class=o>.</span><span class=n>Lambda</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span><span class=n>tf</span><span class=o>.</span><span class=n>math</span><span class=o>.</span><span class=n>pow</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>mypower</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=n>tf</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>int32</span><span class=p>,</span> <span class=n>numpy</span><span class=o>=</span><span class=n>array</span><span class=p>([</span> <span class=mi>0</span><span class=p>,</span>  <span class=mi>1</span><span class=p>,</span>  <span class=mi>4</span><span class=p>,</span>  <span class=mi>9</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>int32</span><span class=p>)</span><span class=o>&gt;</span>
</span></span></code></pre></div><h2 id=layer>Layer</h2><p>Layer 的子类化一般需要重新实现初始化方法，Build 方法和 Call 方法。下面是一个简化的线性层的范例，类似 Dense.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>class</span> <span class=nc>Linear</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>units</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Linear</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>units</span> <span class=o>=</span> <span class=n>units</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>#build方法一般定义Layer需要被训练的参数。</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>build</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_shape</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>w</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s2>&#34;w&#34;</span><span class=p>,</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>input_shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>units</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                 <span class=n>initializer</span><span class=o>=</span><span class=s1>&#39;random_normal&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                 <span class=n>trainable</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1>#注意必须要有参数名称&#34;w&#34;,否则会报错</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s2>&#34;b&#34;</span><span class=p>,</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>units</span><span class=p>,),</span>
</span></span><span class=line><span class=cl>                                 <span class=n>initializer</span><span class=o>=</span><span class=s1>&#39;random_normal&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                 <span class=n>trainable</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Linear</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=n>build</span><span class=p>(</span><span class=n>input_shape</span><span class=p>)</span> <span class=c1># 相当于设置self.built = True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>#call方法一般定义正向传播运算逻辑，__call__方法调用了它。</span>
</span></span><span class=line><span class=cl>    <span class=nd>@tf.function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tf</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>w</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>#如果要让自定义的Layer通过Functional API 组合成模型时可以被保存成h5模型，需要自定义get_config方法。</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_config</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span> <span class=o>=</span> <span class=nb>super</span><span class=p>(</span><span class=n>Linear</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=n>get_config</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>.</span><span class=n>update</span><span class=p>({</span><span class=s1>&#39;units&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>units</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>config</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>linear</span> <span class=o>=</span> <span class=n>Linear</span><span class=p>(</span><span class=n>units</span> <span class=o>=</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>built</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#指定input_shape，显式调用build方法，第0维代表样本数量，用None填充</span>
</span></span><span class=line><span class=cl><span class=n>linear</span><span class=o>.</span><span class=n>build</span><span class=p>(</span><span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=kc>None</span><span class=p>,</span><span class=mi>16</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>built</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>linear</span> <span class=o>=</span> <span class=n>Linear</span><span class=p>(</span><span class=n>units</span> <span class=o>=</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>built</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>linear</span><span class=o>.</span><span class=n>build</span><span class=p>(</span><span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=kc>None</span><span class=p>,</span><span class=mi>16</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>compute_output_shape</span><span class=p>(</span><span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=kc>None</span><span class=p>,</span><span class=mi>16</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>linear</span> <span class=o>=</span> <span class=n>Linear</span><span class=p>(</span><span class=n>units</span> <span class=o>=</span> <span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>built</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#如果built = False，调用__call__时会先调用build方法, 再调用call方法。</span>
</span></span><span class=line><span class=cl><span class=n>linear</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>((</span><span class=mi>100</span><span class=p>,</span><span class=mi>64</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>linear</span><span class=o>.</span><span class=n>built</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>config</span> <span class=o>=</span> <span class=n>linear</span><span class=o>.</span><span class=n>get_config</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;linear_3&#39;</span><span class=p>,</span> <span class=s1>&#39;trainable&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span> <span class=s1>&#39;dtype&#39;</span><span class=p>:</span> <span class=s1>&#39;float32&#39;</span><span class=p>,</span> <span class=s1>&#39;units&#39;</span><span class=p>:</span> <span class=mi>16</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>backend</span><span class=o>.</span><span class=n>clear_session</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>models</span><span class=o>.</span><span class=n>Sequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1>#注意该处的input_shape会被模型加工，无需使用None代表样本数量维</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Linear</span><span class=p>(</span><span class=n>units</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span><span class=n>input_shape</span> <span class=o>=</span> <span class=p>(</span><span class=mi>2</span><span class=p>,)))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;model.input_shape: &#34;</span><span class=p>,</span><span class=n>model</span><span class=o>.</span><span class=n>input_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;model.output_shape: &#34;</span><span class=p>,</span><span class=n>model</span><span class=o>.</span><span class=n>output_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>input_shape</span><span class=p>:</span>  <span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>output_shape</span><span class=p>:</span>  <span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Model</span><span class=p>:</span> <span class=s2>&#34;sequential&#34;</span>
</span></span><span class=line><span class=cl><span class=n>_________________________________________________________________</span>
</span></span><span class=line><span class=cl><span class=n>Layer</span> <span class=p>(</span><span class=nb>type</span><span class=p>)</span>                 <span class=n>Output</span> <span class=n>Shape</span>              <span class=n>Param</span> <span class=c1>#</span>
</span></span><span class=line><span class=cl><span class=o>=================================================================</span>
</span></span><span class=line><span class=cl><span class=n>linear</span> <span class=p>(</span><span class=n>Linear</span><span class=p>)</span>              <span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>                 <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=o>=================================================================</span>
</span></span><span class=line><span class=cl><span class=n>Total</span> <span class=n>params</span><span class=p>:</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=n>Trainable</span> <span class=n>params</span><span class=p>:</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=n>Non</span><span class=o>-</span><span class=n>trainable</span> <span class=n>params</span><span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>_________________________________________________________________</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span> <span class=o>=</span> <span class=s2>&#34;sgd&#34;</span><span class=p>,</span><span class=n>loss</span> <span class=o>=</span> <span class=s2>&#34;mse&#34;</span><span class=p>,</span><span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;mae&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>constant</span><span class=p>([[</span><span class=mf>3.0</span><span class=p>,</span><span class=mf>2.0</span><span class=p>],[</span><span class=mf>4.0</span><span class=p>,</span><span class=mf>5.0</span><span class=p>]])))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 保存成 h5模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&#34;./data/linear_model.h5&#34;</span><span class=p>,</span><span class=n>save_format</span> <span class=o>=</span> <span class=s2>&#34;h5&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_loaded_keras</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;./data/linear_model.h5&#34;</span><span class=p>,</span><span class=n>custom_objects</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;Linear&#34;</span><span class=p>:</span><span class=n>Linear</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>model_loaded_keras</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>constant</span><span class=p>([[</span><span class=mf>3.0</span><span class=p>,</span><span class=mf>2.0</span><span class=p>],[</span><span class=mf>4.0</span><span class=p>,</span><span class=mf>5.0</span><span class=p>]])))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 保存成 tf 模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&#34;./data/linear_model&#34;</span><span class=p>,</span><span class=n>save_format</span> <span class=o>=</span> <span class=s2>&#34;tf&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_loaded_tf</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;./data/linear_model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>model_loaded_tf</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>constant</span><span class=p>([[</span><span class=mf>3.0</span><span class=p>,</span><span class=mf>2.0</span><span class=p>],[</span><span class=mf>4.0</span><span class=p>,</span><span class=mf>5.0</span><span class=p>]])))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[[</span><span class=o>-</span><span class=mf>0.04092304</span><span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=o>-</span><span class=mf>0.06150477</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=p>[[</span><span class=o>-</span><span class=mf>0.04092304</span><span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=o>-</span><span class=mf>0.06150477</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>INFO</span><span class=p>:</span><span class=n>tensorflow</span><span class=p>:</span><span class=n>Assets</span> <span class=n>written</span> <span class=n>to</span><span class=p>:</span> <span class=o>./</span><span class=n>data</span><span class=o>/</span><span class=n>linear_model</span><span class=o>/</span><span class=n>assets</span>
</span></span><span class=line><span class=cl><span class=p>[[</span><span class=o>-</span><span class=mf>0.04092304</span><span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=o>-</span><span class=mf>0.06150477</span><span class=p>]]</span>
</span></span></code></pre></div></div><div class=article-widget><div class="container-xl row post-nav"><div class="col-6 post-nav-item"><div class=meta-nav>上一页</div><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/ rel=next>激活函数</a></div><div class="col-6 post-nav-item"><div class=meta-nav>下一页</div><a href=/books/tensorflow-notes/%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/ rel=prev>评估指标</a></div></div></div><div class=body-footer><p>最近更新于 0001-01-01</p><section id=comments class="mb-3 pt-0"><div id=disqus_thread></div><script>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="https://ngte.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><footer class=site-footer><div class="copyright py-4 bg-footer"><div class="row justify-content-center"><div class="text-center footer-color"><p class=mb-0>© 2017-2022 NGTE all rights reserved</p></div></div></div><script type=text/javascript id=clstr_globe async src="//clustrmaps.com/globe.js?d=kgpJG5sWZQpKujBmD-uW1B54-WBPol-DuDtrB2KFjKs"></script></footer></main></div></div><script src=//unpkg.com/heti/umd/heti-addon.min.js></script>
<script>const heti=new Heti(".article");heti.autoSpacing()</script><script type=text/javascript>window.$crisp=[],window.CRISP_WEBSITE_ID="12adcc35-9621-4313-8262-62dc654b29d8",function(){setTimeout(function(){d=document,s=d.createElement("script"),s.src="https://client.crisp.chat/l.js",s.async=1,d.getElementsByTagName("head")[0].appendChild(s)},2500)}()</script></div><div class=page-footer></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script id=search-hit-algolia-template type=text/html><div class=search-hit><div class=search-hit-content><div class=search-hit-name><a href={{relpermalink}}>{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a></div><div class="article-metadata search-hit-type">{{type}}</div><p class=search-hit-description>{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p></div></div></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js crossorigin=anonymous></script>
<script id=dsq-count-scr src=https://ngte.disqus.com/count.js async></script>
<script src=/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js type=module></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js></script>
<script>var mybutton=document.getElementById("backTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.style.display="block":mybutton.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script src=https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin=anonymous></script>
<script>anchors.add()</script><script>(function(){"use strict";if(!document.queryCommandSupported("copy"))return;function e(e,t){e.className="highlight-copy-btn",e.textContent=t,setTimeout(function(){e.textContent="",e.className="highlight-copy-btn fa fa-copy"},1e3)}function t(e){var t=window.getSelection(),n=document.createRange();return n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n),t}function n(n){var o,s=document.createElement("button");s.className="highlight-copy-btn fa fa-copy",s.textContent="",o=n.firstElementChild,s.addEventListener("click",function(){try{var n=t(o);document.execCommand("copy"),n.removeAllRanges(),e(s,"已复制")}catch(t){console&&console.log(t),e(s,"Failed :'(")}}),n.appendChild(s)}var s=document.getElementsByClassName("highlight");Array.prototype.forEach.call(s,n)})()</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>集群部署 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link><atom:link href="https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml"/><description>集群部署</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>集群部署</title><link>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link></image><item><title>部署配置</title><link>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE/</guid><description>&lt;h1 id="kafka-集群的配置与部署">Kafka 集群的配置与部署&lt;/h1>
&lt;p>本假设你本机还没有安装任何的 Zookeeper 节点或者 Kafka 节点，首先我们需要下载 Kafka 源代码然后将其解压缩:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&amp;gt; tar -xzf kafka_2.11-0.9.0.0.tgz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;gt; &lt;span class="nb">cd&lt;/span> kafka_2.11-0.9.0.0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Kafka 默认使用 ZooKeeper 作为服务协调器，并且 Kafka 内置了一个 ZooKeeper 的运行脚本，可以让你快速地启动允许一个单节点的 ZooKeeper 实例:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&amp;gt; bin/zookeeper-server-start.sh config/zookeeper.properties
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">[&lt;/span>2013-04-22 15:01:37,495&lt;span class="o">]&lt;/span> INFO Reading configuration from: config/zookeeper.properties &lt;span class="o">(&lt;/span>org.apache.zookeeper.server.quorum.QuorumPeerConfig&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后启动 Kafka 服务器:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&amp;gt; bin/kafka-server-start.sh config/server.properties
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">[&lt;/span>2013-04-22 15:01:47,028&lt;span class="o">]&lt;/span> INFO Verifying properties &lt;span class="o">(&lt;/span>kafka.utils.VerifiableProperties&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">[&lt;/span>2013-04-22 15:01:47,051&lt;span class="o">]&lt;/span> INFO Property socket.send.buffer.bytes is overridden to &lt;span class="m">1048576&lt;/span> &lt;span class="o">(&lt;/span>kafka.utils.VerifiableProperties&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="使用">使用&lt;/h1>
&lt;p>在启动了 Kafka 服务器之后，我们首先来尝试创建一个名为&lt;code>test&lt;/code>的主题，设置只有一个 Partition 与一个 Replica。&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
&lt;/code>&lt;/pre>&lt;p>然后我们在查询主题列表的时候就可以看到该主题了:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; bin/kafka-topics.sh --list --zookeeper localhost:2181
test
&lt;/code>&lt;/pre>&lt;p>除了手动地指定创建主题，我们也可以配置 Brokers 在收到不存在的主题的时候自动创建该主题。在 Topics 创建好之后，就可以通过其来发送消息。Kafka 为我们提供了一个命令行工具，可以允许我们从某个文件或者其他标准的输入流中抓取数据然后将其以消息形式发送到 Kafka 集群，默认情况下每个单独的行会被认为是一条单独的消息。&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
&lt;/code>&lt;/pre>&lt;p>消息发送完毕之后，我们需要设置 Consumer 端来读取消息，Kafka 同样为我们提供了这样一个便捷的命令行工具，&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
This is a message
This is another message
&lt;/code>&lt;/pre>&lt;p>如果你在不同的命令行中分别运行上述命令，那么你的 Consumer 已经能够接收到这些数据了。&lt;/p></description></item><item><title>参数配置</title><link>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE/</guid><description>&lt;h1 id="kafka-参数配置分析">Kafka 参数配置分析&lt;/h1>
&lt;h1 id="生产者参数">生产者参数&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>key.serializer&lt;/strong>：用于 key 键的序列化，它实现了 &lt;code>org.apache.kafka.common.serialization.Serializer&lt;/code> 接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>value.serializer&lt;/strong>：用于 value 值的序列化，实现了 &lt;code>org.apache.kafka.common.serialization.Serializer&lt;/code> 接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>acks&lt;/strong>：acks 参数指定了要有多少个分区副本接收消息，生产者才认为消息是写入成功的。此参数对消息丢失的影响较大&lt;/p>
&lt;ul>
&lt;li>如果 acks = 0，就表示生产者也不知道自己产生的消息是否被服务器接收了，它才知道它写成功了。如果发送的途中产生了错误，生产者也不知道，它也比较懵逼，因为没有返回任何消息。这就类似于 UDP 的运输层协议，只管发，服务器接受不接受它也不关心。&lt;/li>
&lt;li>如果 acks = 1，只要集群的 Leader 接收到消息，就会给生产者返回一条消息，告诉它写入成功。如果发送途中造成了网络异常或者 Leader 还没选举出来等其他情况导致消息写入失败，生产者会受到错误消息，这时候生产者往往会再次重发数据。因为消息的发送也分为 &lt;code>同步&lt;/code> 和 &lt;code>异步&lt;/code>，Kafka 为了保证消息的高效传输会决定是同步发送还是异步发送。如果让客户端等待服务器的响应（通过调用 &lt;code>Future&lt;/code> 中的 &lt;code>get()&lt;/code> 方法），显然会增加延迟，如果客户端使用回调，就会解决这个问题。&lt;/li>
&lt;li>如果 acks = all，这种情况下是只有当所有参与复制的节点都收到消息时，生产者才会接收到一个来自服务器的消息。不过，它的延迟比 acks =1 时更高，因为我们要等待不只一个服务器节点接收消息。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>buffer.memory&lt;/strong>：此参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候，send() 方法调用要么被阻塞，要么抛出异常，具体取决于 &lt;code>block.on.buffer.null&lt;/code> 参数的设置。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>compression.type&lt;/strong>：此参数来表示生产者启用何种压缩算法，默认情况下，消息发送时不会被压缩。该参数可以设置为 snappy、gzip 和 lz4，它指定了消息发送给 broker 之前使用哪一种压缩算法进行压缩。下面是各压缩算法的对比&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://pic.imgdb.cn/item/6076fc828322e6675c1a1f29.jpg" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://pic.imgdb.cn/item/6076fc968322e6675c1a5330.jpg" alt="img" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>retries&lt;/strong>：生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领），在这种情况下，&lt;code>reteis&lt;/code> 参数的值决定了生产者可以重发的消息次数，如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者在每次重试之间等待 100ms，这个等待参数可以通过 &lt;code>retry.backoff.ms&lt;/code> 进行修改。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>batch.size&lt;/strong>：当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。当批次被填满，批次里的所有消息会被发送出去。不过生产者井不一定都会等到批次被填满才发送，任意条数的消息都可能被发送。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>client.id&lt;/strong>：此参数可以是任意的字符串，服务器会用它来识别消息的来源，一般配置在日志里&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>max.in.flight.requests.per.connection&lt;/strong>：此参数指定了生产者在收到服务器响应之前可以发送多少消息，它的值越高，就会占用越多的内存，不过也会提高吞吐量。把它设为 1 可以保证消息是按照发送的顺序写入服务器。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms&lt;/strong>：request.timeout.ms 指定了生产者在发送数据时等待服务器返回的响应时间，metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待时间超时，生产者要么重试发送数据，要么返回一个错误。timeout.ms 指定了 broker 等待同步副本返回消息确认的时间，与 asks 的配置相匹配&amp;mdash;-如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>max.block.ms&lt;/strong>：此参数指定了在调用 send() 方法或使用 partitionFor() 方法获取元数据时生产者的阻塞时间当生产者的发送缓冲区已捕，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>max.request.size&lt;/strong>：该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息的总大小。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>receive.buffer.bytes 和 send.buffer.bytes&lt;/strong>：Kafka 是基于 TCP 实现的，为了保证可靠的消息传输，这两个参数分别指定了 TCP Socket 接收和发送数据包的缓冲区的大小。如果它们被设置为 -1，就使用操作系统的默认值。如果生产者或消费者与 broker 处于不同的数据中心，那么可以适当增大这些值。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="消费者配置">消费者配置&lt;/h1>
&lt;p>到目前为止，我们学习了如何使用消费者 API，不过只介绍了几个最基本的属性，Kafka 文档列出了所有与消费者相关的配置说明。大部分参数都有合理的默认值，一般不需要修改它们，下面我们就来介绍一下这些参数。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>fetch.min.bytes：该属性指定了消费者从服务器获取记录的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于 &lt;code>fetch.min.bytes&lt;/code> 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。这样可以降低消费者和 broker 的工作负载，因为它们在主题使用频率不是很高的时候就不用来回处理消息。如果没有很多可用数据，但消费者的 CPU 使用率很高，那么就需要把该属性的值设得比默认值大。如果消费者的数量比较多，把该属性的值调大可以降低 broker 的工作负载。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>fetch.max.wait.ms：我们通过上面的 &lt;strong>fetch.min.bytes&lt;/strong> 告诉 Kafka，等到有足够的数据时才会把它返回给消费者。而 &lt;strong>fetch.max.wait.ms&lt;/strong> 则用于指定 broker 的等待时间，默认是 500 毫秒。如果没有足够的数据流入 kafka 的话，消费者获取的最小数据量要求就得不到满足，最终导致 500 毫秒的延迟。如果要降低潜在的延迟，就可以把参数值设置的小一些。如果 fetch.max.wait.ms 被设置为 100 毫秒的延迟，而 fetch.min.bytes 的值设置为 1MB，那么 Kafka 在收到消费者请求后，要么返回 1MB 的数据，要么在 100 ms 后返回所有可用的数据。就看哪个条件首先被满足。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>max.partition.fetch.bytes：该属性指定了服务器从每个分区里返回给消费者的&lt;code>最大字节数&lt;/code>。它的默认值时 1MB，也就是说，&lt;code>KafkaConsumer.poll()&lt;/code> 方法从每个分区里返回的记录最多不超过 max.partition.fetch.bytes 指定的字节。如果一个主题有 20 个分区和 5 个消费者，那么每个消费者需要&lt;code>至少&lt;/code>4 MB 的可用内存来接收记录。在为消费者分配内存时，可以给它们多分配一些，因为如果群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区。max.partition.fetch.bytes 的值必须比 broker 能够接收的最大消息的字节数(通过 max.message.size 属性配置大)，&lt;strong>否则消费者可能无法读取这些消息，导致消费者一直挂起重试&lt;/strong>。在设置该属性时，另外一个考量的因素是消费者处理数据的时间。消费者需要频繁的调用 poll() 方法来避免会话过期和发生分区再平衡，如果单次调用 poll() 返回的数据太多，消费者需要更多的时间进行处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况，可以把 max.partition.fetch.bytes 值改小，或者延长会话过期时间。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>session.timeout.ms：这个属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。如果消费者没有在 &lt;strong>session.timeout.ms&lt;/strong> 指定的时间内发送心跳给群组协调器，就会被认定为死亡，协调器就会触发重平衡。把它的分区分配给消费者群组中的其它消费者，此属性与 &lt;code>heartbeat.interval.ms&lt;/code> 紧密相关。heartbeat.interval.ms 指定了 poll() 方法向群组协调器发送心跳的频率，session.timeout.ms 则指定了消费者可以多久不发送心跳。所以，这两个属性一般需要同时修改，heartbeat.interval.ms 必须比 session.timeout.ms 小，一般是 session.timeout.ms 的三分之一。如果 session.timeout.ms 是 3s，那么 heartbeat.interval.ms 应该是 1s。把 session.timeout.ms 值设置的比默认值小，可以更快地检测和恢复崩愤的节点，不过长时间的轮询或垃圾收集可能导致非预期的重平衡。把该属性的值设置得大一些，可以减少意外的重平衡，不过检测节点崩溃需要更长的时间。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>auto.offset.reset：该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下的该如何处理。它的默认值是 &lt;code>latest&lt;/code>，意思指的是，在偏移量无效的情况下，消费者将从最新的记录开始读取数据。另一个值是 &lt;code>earliest&lt;/code>，意思指的是在偏移量无效的情况下，消费者将从起始位置处开始读取分区的记录。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>enable.auto.commit：我们稍后将介绍几种不同的提交偏移量的方式。该属性指定了消费者是否自动提交偏移量，默认值是 true，为了尽量避免出现重复数据和数据丢失，可以把它设置为 false，由自己控制何时提交偏移量。如果把它设置为 true，还可以通过 &lt;strong>auto.commit.interval.ms&lt;/strong> 属性来控制提交的频率&lt;/p>
&lt;/li>
&lt;li>
&lt;p>partition.assignment.strategy：我们知道，分区会分配给群组中的消费者。&lt;code>PartitionAssignor&lt;/code> 会根据给定的消费者和主题，决定哪些分区应该被分配给哪个消费者，Kafka 有两个默认的分配策略&lt;code>Range&lt;/code> 和 &lt;code>RoundRobin&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>client.id：该属性可以是任意字符串，broker 用他来标识从客户端发送过来的消息，通常被用在日志、度量指标和配额中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>max.poll.records：该属性用于控制单次调用 call() 方法能够返回的记录数量，可以帮你控制在轮询中需要处理的数据量。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>receive.buffer.bytes 和 send.buffer.bytes：socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。如果它们被设置为 -1，就使用操作系统默认值。如果生产者或消费者与 broker 处于不同的数据中心内，可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>集群与高可用</title><link>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/messagequeue-series/03.kafka/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%AB%98%E5%8F%AF%E7%94%A8/</guid><description/></item></channel></rss>
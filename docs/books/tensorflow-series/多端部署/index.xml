<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>多端部署 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/</link>
      <atom:link href="https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml" />
    <description>多端部署</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>多端部署</title>
      <link>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/</link>
    </image>
    
    <item>
      <title>TensorFire</title>
      <link>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorfire/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorfire/</guid>
      <description>&lt;h1 id=&#34;tensorfire浏览器端的-tensorflow&#34;&gt;TensorFire：浏览器端的 TensorFlow&lt;/h1&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要：&lt;/h2&gt;
&lt;p&gt;TensorFire 是基于 WebGL 的运行在浏览器内的高性能神经网络框架，其执行速度甚至可以快于原生的 TensorFlow。&lt;/p&gt;
&lt;h2 id=&#34;正文&#34;&gt;正文：&lt;/h2&gt;
&lt;p&gt;深度学习与人工智能技术正在逐步地改变人们的生活，以 TensoFlow 为代表的一系列深度学习与神经网络框架也是如日中天，迅猛发展。TensorFire 则是基于 WebGL 的，运行在浏览器中的神经网络框架；使用 TensorFire 编写的应用能够在实现前沿深度学习算法的同时，不需要任何的安装或者配置就直接运行在现代浏览器中。与之前某些浏览器内的神经网络框架相比，TensorFire 有着近百倍的速度提升，甚至于能够与那些运行在本地 CPU 上的代码性能相媲美。现代的 PC、笔记本电脑与移动终端往往都被包含能够进行高性能并发计算的 GPU，通过将神经网络中的权重转化为 WebGL 中的纹理，TensorFire 将神经网络中的层转化为了片段着色器(Fragment Shaders)，从而利用原本设计来加速执行 3D 游戏的引擎来执行神经网络。另一方面，不同于其他的 WebGL 计算框架，TensorFire 支持 Low-precision Quantized Tensors，从而保证了模型的适用性。&lt;/p&gt;
&lt;p&gt;TensorFire 主要由两部分组成：底层基于 GLSL 的能够高效编写操作四维张量的并行 WebGLS 着色器的编程语言，以及上层的用于导入 Keras 与 TensorFlow 训练好的模型的接口。TensorFire 能够运行在任何的，无论是否支持 CUDA 的 GPU 上；这就意味着，譬如最新的 2016 Retina MacBook Pro 这样的使用 AMD 显卡的机器，也能顺畅地运行 TensorFire。TensorFire 能够帮助开发者构建不需要用户本地安装的智能应用，并且不同于传统的收集用户数据以统一训练的模式，直接将模型下发到用户端能够保障用户隐私权。TensorFire 官方正在着手提供多个范例，譬如复杂的 ResNet-152 网络、著名的基于 RNN 的文本生产与图片着色、基于 SqueeseNet 的物体识别与分类等等。开发者也可以使用 TensorFire 提供的底层接口来进行其他的高性能计算，譬如 PageRank、元胞自动机仿真、图片转化与过滤等等。&lt;/p&gt;
&lt;p&gt;TensorFire 项目由多位 MIT 的毕业生协作而成。其中 Kevin Kwok 与 Guillermo Webster 曾编写过 &lt;a href=&#34;https://projectnaptha.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Project Naptha&lt;/a&gt; 这样的将 JavaScript 与计算机视觉相结合的从图片中提取文字的 OCR 项目。Anish Athalye 与 Logan Engstrom 则编写过首个 &lt;a href=&#34;https://github.com/anishathalye/neural-style&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gatys&amp;rsquo; Neural Artistic Style&lt;/a&gt; 以及 &lt;a href=&#34;https://github.com/lengstrom/fast-style-transfer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Johnson&amp;rsquo;s Fast Style Transfer&lt;/a&gt; 算法的 TensorFlow 模型。&lt;/p&gt;
&lt;p&gt;该项目 Style Transfer Neural Network Demo 链接：&lt;a href=&#34;https://tenso.rs/demos/fast-neural-style/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tenso.rs/demos/fast-neural-style/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;查看英文原文: &lt;a href=&#34;https://tenso.rs/#wat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TensorFire&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TensorFlow Serving</title>
      <link>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorflow-serving/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/tensorflow-serving/</guid>
      <description>&lt;h1 id=&#34;tensorflow-serving&#34;&gt;tensorflow-serving&lt;/h1&gt;
&lt;p&gt;TensorFlow 训练好的模型以 TensorFlow 原生方式保存成 protobuf 文件后可以用许多方式部署运行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过 tensorflow-js 可以用 javascrip 脚本加载模型并在浏览器中运行模型。&lt;/li&gt;
&lt;li&gt;通过 tensorflow-lite 可以在移动和嵌入式设备上加载并运行 TensorFlow 模型。&lt;/li&gt;
&lt;li&gt;通过 tensorflow-serving 可以加载模型后提供网络接口 API 服务，通过任意编程语言发送网络请求都可以获取模型预测结果。&lt;/li&gt;
&lt;li&gt;通过 TensorFlow for Java 接口，可以在 Java 或者 spark(scala)中调用 TensorFlow 模型进行预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用 tensorflow serving 部署模型要完成以下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;准备 protobuf 模型文件。&lt;/li&gt;
&lt;li&gt;安装 tensorflow serving。&lt;/li&gt;
&lt;li&gt;启动 tensorflow serving 服务。&lt;/li&gt;
&lt;li&gt;向 API 服务发送请求，获取预测结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细的演示请参阅 &lt;a href=&#34;./tf_serving.ipynb&#34;&gt;tf_serving.ipynb&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分布式集群</title>
      <link>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/tensorflow-series/%E5%A4%9A%E7%AB%AF%E9%83%A8%E7%BD%B2/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</guid>
      <description>&lt;p&gt;本目录包括了运行时分布式 TensorFlow 的实现，其底层使用了&lt;a href=&#34;http://grpc.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gRPC&lt;/a&gt; 作为进程内通信的支持库。&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick start&lt;/h2&gt;
&lt;p&gt;首先，需要构建一个 TensorFlow 的服务端可执行版本(&lt;code&gt;grpc_tensorflow_server&lt;/code&gt;) 以及一个基于 gRPC 的客户端。目前只能基于源代码进行自构建, 但是会包含在未来发布的二进制版本中。可以使用如下命令进行构建:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# CPU-only build.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ bazel build -c opt //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# GPU build.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ bazel build -c opt --config&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cuda //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果是从最新的源代码创建的 Python 依赖包，它会自动包含一个基于 gRPC 的客户端。如果使用的是一个之前发布的二进制版本，需要根据这个&lt;a href=&#34;https://www.tensorflow.org/versions/master/get_started/os_setup.html#create-the-pip-package-and-install&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;安装说明&lt;/a&gt;来重新编译安装。在你成功地构建了分布式的 TensorFlow 组件之后，可以通过如下方式来启动服务器并且判断你的安装是否成功：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Start a TensorFlow server as a single-process &amp;#34;cluster&amp;#34;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;    --cluster_spec&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;local|localhost:2222&amp;#39;&lt;/span&gt; --job_name&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;local&lt;/span&gt; --task_index&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后启动 Python 的交互器并且启动一个 Session：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tf&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;constant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Hello, distributed TensorFlow!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sess&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Session&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;grpc://localhost:2222&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sess&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Hello, distributed TensorFlow!&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;集群定义&#34;&gt;集群定义&lt;/h2&gt;
&lt;p&gt;命令行参数 &lt;code&gt;grpc_tensorflow_server&lt;/code&gt; 定义了集群之间的关系. 参数 &lt;code&gt;--cluster_spec&lt;/code&gt; 决定了集群中工作对象的多少, 譬如有一系列的 &lt;em&gt;jobs&lt;/em&gt;, 而每个&lt;em&gt;jobs&lt;/em&gt;又包含了多个&lt;em&gt;task&lt;/em&gt; 终端。所有集群中的处理过程都必须设置相同的 &lt;code&gt;--cluster_spec&lt;/code&gt;参数，例子如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;--cluster_spec=&#39;...&#39;&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;Available tasks&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;local|localhost:2222&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/job:local/task:0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;local|localhost:2222;localhost:2223&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/job:local/task:0``/job:local/task:1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;worker|worker0:2222;worker1:2222;worker2:2222,``ps|ps0:2222;ps1:2222&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/job:worker/task:0``/job:worker/task:1``/job:worker/task:2``/job:ps/task:0``/job:ps/task:1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;还有 &lt;code&gt;--job_name&lt;/code&gt; 与 &lt;code&gt;--task_index&lt;/code&gt; 标志位指明了哪些任务会运行在当前处理过程上。具体而言,
&lt;code&gt;--job_name=local --task_index=0&lt;/code&gt; 意思就是该过程会被标志为
&lt;code&gt;/job:local/task:0&lt;/code&gt;, 然后所有在该过程上的 TensorFlow 的设备都会使用这个前缀。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt;
手动来指明这些运行参数可能是非常冗长的，特别是对一个大型集群而言。我们正在研发可以程式化启动的工具，譬如使用一些类似于&lt;a href=&#34;http://kubernetes.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;集群管理器。如果有啥集群管理工具你觉得挺好的希望加入进来，可以在&lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub issue&lt;/a&gt;上提出你的建议。&lt;/p&gt;
&lt;h2 id=&#34;标注模型中的分布式设备&#34;&gt;标注模型中的分布式设备&lt;/h2&gt;
&lt;p&gt;为了将某个操作放在某个特殊的处理过程上,在分布式环境下依然可以使用
&lt;a href=&#34;https://www.tensorflow.org/versions/master/api_docs/python/framework.html#device&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;tf.device()&lt;/code&gt;&lt;/a&gt;
函数，之前是用来指明是放在 CPU 还是 GPU 上的。譬如:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/job:ps/task:0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;weights_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;biases_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/job:ps/task:1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;weights_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;biases_2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/job:worker/task:7&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;layer_1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;relu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;input&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weights_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;biases_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;relu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layer_1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;weights_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;biases_2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;# ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;train_op&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Session&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;grpc://worker7:2222&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sess&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sess&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;train_op&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在上面的例子中，Variables 在 job &lt;code&gt;ps&lt;/code&gt;的两个 task 上被创建，然后计算密集型的部分创建在 job &lt;code&gt;work&lt;/code&gt;上。TensorFlow 会自动地在不同的 job 之间传输数据。(从&lt;code&gt;job&lt;/code&gt;到&lt;code&gt;work&lt;/code&gt;是前向传递，而从&lt;code&gt;worker&lt;/code&gt;到&lt;code&gt;ps&lt;/code&gt;是梯度应用)。&lt;/p&gt;
&lt;h2 id=&#34;replicated-computation&#34;&gt;Replicated Computation&lt;/h2&gt;
&lt;p&gt;一个常见的训练配置(数据并行训练)包含了 job &lt;code&gt;ps&lt;/code&gt;上共享参数以及 job &lt;code&gt;work&lt;/code&gt;上的多个任务来训练相同的模型。每个 task 一般会运行在不同的机器上。现在还是有很多办法可以在 TensorFlow 中来实现这一种结构的，我们未来也会提供更简单的实现方式，主要途径有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;构建单一的包含了一系列参数的图(in &lt;code&gt;tf.Variable&lt;/code&gt; nodes pinned to &lt;code&gt;/job:ps&lt;/code&gt;), 并且创建多个模型的副本来映射到&lt;code&gt;/job:worker&lt;/code&gt;中的不同 tasks。每个 model 的副本有一个不同的&lt;code&gt;train_op&lt;/code&gt;，并且对于每个 worker &lt;code&gt;i&lt;/code&gt;而言一个或者多个的客户端线程可以调用&lt;code&gt;sess.run(train_ops[i])&lt;/code&gt;。这种方法使用了单一的&lt;code&gt;tf.Session&lt;/code&gt;，它的工作目标是集群中的某个 workers。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As above, but where the gradients from all workers are averaged. See the
&lt;a href=&#34;https://www.tensorflow.org/code/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CIFAR-10 multi-GPU trainer&lt;/a&gt;
for an example of this form of replication. The implements &lt;em&gt;synchronous&lt;/em&gt; training&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一种分布式训练器的方法使用多张图，一张图对应一个 worker，并且每张图都包含了一系列的参数的集合(&lt;code&gt;/job:ps&lt;/code&gt;)和一份模型的赋值。而容器的机制就是在不同的图之间共享变量：一旦某个变量构造完成，可选的&lt;code&gt;container&lt;/code&gt;参数会由图中每份复制的相同值来决定。对于较大的模型而言，这种方法会更加有效，毕竟整个图更小了一点。
这种方法使用多个&lt;code&gt;tf.Session&lt;/code&gt;对象：每个 worker 过程都会包含一个，不过不同的 Session 会指向不同的目标 worker。这个&lt;code&gt;tf.Session&lt;/code&gt;对象即可以在单一的 Python 客户端中创建，也可以在多个客户端中创建。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;术语&#34;&gt;术语&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Client&lt;/strong&gt;
一个典型的客户端一般会构建一个 TensorFlow 的图并且使用&lt;code&gt;tensorflow::Session&lt;/code&gt;来完成与集群的交互。客户端一般会用 Python 或者 C++编写，一般来说一个客户端可以同时与多个服务端进行交互(参考上文的重复训练)，并且一个服务端也可以同时服务于多个客户端。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cluster&lt;/strong&gt;
一个 TensorFlow 集群会包含一个或者多个 TensorFlow 的服务端，被切分为一系列命名的 job，而每个 job 又会负责一系列的 tasks。一个集群一般会专注于一个相对高层的目标，譬如用多台机器并行地训练一个神经网络。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Job&lt;/strong&gt;
一个 job 会包含一系列的致力于某个相同目标的 task。譬如，一个叫&lt;code&gt;ps&lt;/code&gt;(意思是参数服务)的 job 会用于处理存储于更新 Variables 相关的工作。而一个叫&lt;code&gt;worker&lt;/code&gt;的 job 会用于承载那些用于计算密集型的无状态节点。一般来说一个 job 中的 tasks 会运行在不同的机器中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Master service&lt;/strong&gt;
Master Service 是一个 RPC 服务用于与一系列远端的分布式设备进行交互。Master Service 实现了&lt;code&gt;tensorflow::Session&lt;/code&gt; 接口, 并且用来协调多个 worker service。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Task&lt;/strong&gt;
一个 Task 一般会关联到某个单一的 TensorFlow 服务端的处理过程，属于一个特定的 job 并且在该 job 的任务列表中有个唯一的索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TensorFlow server&lt;/strong&gt;
用于运行 grpc_tensorflow_server 的处理过程，是一个集群中的一员，并且想外暴露了一个 Master Service 与一个 Worker Service。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Worker service&lt;/strong&gt;
一个执行部分 TensorFlow 图部分内容的 RPC 服务。
)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

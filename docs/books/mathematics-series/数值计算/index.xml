<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>数值计算 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</link><atom:link href="https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml"/><description>数值计算</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>数值计算</title><link>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</link></image><item><title>数值稳定性</title><link>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7/</guid><description>&lt;h1 id="数值稳定性">数值稳定性&lt;/h1>
&lt;p>在计算机中执行数学运算需要使用有限的比特位来表达实数，这会引入近似误差。近似误差可以在多步数值运算中传递、积累，从而导致理论上成功的算法失败。因此数值算法设计时要考虑将累计误差最小化。当从头开始实现一个数值算法时，需要考虑数值稳定性。当使用现有的数值计算库（如 tensorflow）时，不需要考虑数值稳定性。&lt;/p></description></item><item><title>梯度下降</title><link>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</guid><description>&lt;h1 id="梯度下降">梯度下降&lt;/h1>
&lt;h1 id="gradient-descent--梯度下降">Gradient Descent | 梯度下降&lt;/h1>
&lt;p>梯度下降法 Gradient Descent 是一种常用的一阶(first-order)优化方法，是求解无约束优化问题最简单、最经典的方法之一。考虑无约束优化问题$min_xf(x)$，其中$f(x)$为连续可微函数。如果能构造出一个序列$x^0,x^1,&amp;hellip;,x^t$满足：&lt;/p>
&lt;p>$$
f(x^{t+1}) &amp;lt; f(x^t),t=0,1,2&amp;hellip;
$$&lt;/p>
&lt;p>则不断执行该过程即可以收敛到局部极小点。而根据泰勒展示我们可以知道:&lt;/p>
&lt;p>$$
f(x+\Delta x) \simeq f(x) + \Delta x^T \nabla f(x)
$$&lt;/p>
&lt;p>于是，如果要满足 $f(x+\Delta x) &amp;lt; f(x)$，可以选择:&lt;/p>
&lt;p>$$
\Delta x = -{step} \nabla f(x)
$$&lt;/p>
&lt;p>其中$step$是一个小常数，表示步长。以求解目标函数最小化为例，梯度下降算法可能存在一下几种情况：&lt;/p>
&lt;ul>
&lt;li>当目标函数为凸函数时，局部极小点就对应着函数全局最小值时，这种方法可以快速的找到最优解；&lt;/li>
&lt;li>当目标函数存在多个局部最小值时，可能会陷入局部最优解。因此需要从多个随机的起点开始解的搜索。&lt;/li>
&lt;li>当目标函数不存在最小值点，则可能陷入无限循环。因此，有必要设置最大迭代次数。&lt;/li>
&lt;/ul>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/VvdbyvUDIGUiIct8k0trvQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/VvdbyvUDIGUiIct8k0trvQ&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2.线性代数 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</link><atom:link href="https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/index.xml" rel="self" type="application/rss+xml"/><description>2.线性代数</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>2.线性代数</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</link></image><item><title>距离与相似性</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/</guid><description>&lt;ul>
&lt;li>&lt;a href="https://github.com/tdebatty/java-string-similarity" target="_blank" rel="noopener">java-string-similarity&lt;/a> &amp;gt; &lt;a href="https://dzone.com/articles/machine-learning-measuring" target="_blank" rel="noopener">Machine Learning: Measuring Similarity and Distance&lt;/a> &amp;gt; &lt;a href="http://www.cnblogs.com/daniel-D/p/3244718.html" target="_blank" rel="noopener">漫谈：机器学习中距离和相似性度量方法&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="数值点距离numeric-data-points-numeric-data-points">数值点距离:numeric data points Numeric Data Points&lt;/h1>
&lt;h3 id="闵可夫斯基距离">闵可夫斯基距离&lt;/h3>
&lt;p>&lt;strong>闵可夫斯基距离&lt;/strong>(Minkowski distance)是衡量数值点之间距离的一种非常常见的方法，假设数值点 P 和 Q 坐标如下：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220422-b6c5a38eccb74824b92ba1b40c9dd92f.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>那么，闵可夫斯基距离定义为：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220504-12655edb08dc45ae8a036d8028743042.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>该距离最常用的 p 是 2 和 1, 前者是&lt;strong>欧几里得距离&lt;/strong>(Euclidean distance)，后者是&lt;strong>曼哈顿距离&lt;/strong>(Manhattan distance)。假设在曼哈顿街区乘坐出租车从 P 点到 Q 点，白色表示高楼大厦，灰色表示街道：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220530-1c87c470c5984305932cb5f5fc91656f.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>绿色的斜线表示欧几里得距离，在现实中是不可能的。其他三条折线表示了曼哈顿距离，这三条折线的长度是相等的。&lt;/p>
&lt;p>当 p 趋近于无穷大时，闵可夫斯基距离转化成&lt;strong>切比雪夫距离&lt;/strong>(Chebyshev distance)：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220549-4fb4c30e7fb84ca290d04f44f75dea7b.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>我们知道平面上到原点欧几里得距离(p = 2)为 1 的点所组成的形状是一个圆，当 p 取其他数值的时候呢？&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220559-ae662025d1394f90bfd62f7c21c3d895.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>注意，当 &lt;code>p &amp;lt; 1&lt;/code> 时，闵可夫斯基距离不再符合三角形法则，举个例子：当 p &lt;code>&amp;lt;&lt;/code> 1, (0,0) 到 (1,1) 的距离等于&lt;code>(1+1)^{1/p} &amp;gt; 2&lt;/code>, 而 (0,1) 到这两个点的距离都是 1。&lt;/p>
&lt;p>闵可夫斯基距离比较直观，但是它与数据的分布无关，具有一定的局限性，如果 x 方向的幅值远远大于 y 方向的值，这个距离公式就会过度放大 x 维度的作用。所以，在计算距离之前，我们可能还需要对数据进行 &lt;strong>z-transform&lt;/strong> 处理，即减去均值，除以标准差：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%28x_1,%20y_1%29%5Cmapsto%20%28%5Cfrac%7Bx_1%20-%20%5Cmu%20_x%7D%7B%5Csigma%20_x%7D,%20%5Cfrac%7By_1%20-%20%5Cmu%20_y%7D%7B%5Csigma%20_y%7D%29" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;blockquote>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%5Cmu" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure> : 该维度上的均值&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%5Csigma" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure> : 该维度上的标准差&lt;/p>
&lt;/blockquote>
&lt;p>可以看到，上述处理开始体现数据的统计特性了。这种方法在假设数据各个维度不相关的情况下利用数据分布的特性计算出不同的距离。如果维度相互之间数据相关(例如：身高较高的信息很有可能会带来体重较重的信息，因为两者是有关联的)，这时候就要用到&lt;strong>马氏距离&lt;/strong>(Mahalanobis distance)了。&lt;/p>
&lt;h3 id="马氏距离">马氏距离&lt;/h3>
&lt;p>考虑下面这张图，椭圆表示等高线，从欧几里得的距离来算，绿黑距离大于红黑距离，但是从马氏距离，结果恰好相反：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220637-f472bb13a779481bbfa45a9d79bd2175.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>马氏距离实际上是利用 Cholesky transformation 来消除不同维度之间的&lt;strong>相关性&lt;/strong>和&lt;strong>尺度不同&lt;/strong>的性质。假设样本点(列向量)之间的协方差对称矩阵是
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%5CSigma" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>，通过 Cholesky Decomposition(实际上是对称矩阵 LU 分解的一种特殊形式，可参考之前的&lt;a href="http://www.cnblogs.com/daniel-D/p/3204508.html" target="_blank" rel="noopener">博客&lt;/a>)可以转化为下三角矩阵和上三角矩阵的乘积:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%5CSigma%20=%20LL%5ET" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>。消除不同维度之间的相关性和尺度不同，只需要对样本点 x 做如下处理：
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?z%20=%20L%5E%7B-1%7D%28x%20-%20%5Cmu%20%29" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>。处理之后的欧几里得距离就是原样本的马氏距离：为了书写方便，这里求马氏距离的平方)：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220659-e3270d8a52ef45c1b457d9af19b1aad1.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>下图蓝色表示原样本点的分布，两颗红星坐标分别是(3, 3)，(2, -2):&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220711-7c326cd8835a446d94684e6adb7ff75a.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>由于 x，y 方向的尺度不同，不能单纯用欧几里得的方法测量它们到原点的距离。并且，由于 x 和 y 是相关的(大致可以看出斜向右上)，也不能简单地在 x 和 y 方向上分别减去均值，除以标准差。最恰当的方法是对原始数据进行 Cholesky 变换，即求马氏距离(可以看到，右边的红星离原点较近)：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07220737-b9ab6c4b19d64590998685325ae49bd1.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>将上面两个图的绘制代码和求马氏距离的代码贴在这里，以备以后查阅：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding=utf-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># code related at: http://www.cnblogs.com/daniel-D/&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">pylab&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">pl&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">scipy.spatial.distance&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">dist&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">plotSamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">z&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">None&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">stars&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matrix&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mf">3.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mf">2.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">3.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">2.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">z&lt;/span> &lt;span class="ow">is&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="kc">None&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">z&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matrix&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">stars&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">z&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">stars&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">scatter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 画 gaussian 随机点&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">scatter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stars&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stars&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">200&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">marker&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;*&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">color&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;r&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 画三个指定点&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axhline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">linewidth&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">color&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;g&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 画 x 轴&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axvline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">linewidth&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">color&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;g&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 画 y 轴&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;equal&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pl&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 产生高斯分布的随机点&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">mean&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># 平均值&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cov&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">]]&lt;/span> &lt;span class="c1"># 协方差&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">multivariate_normal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mean&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cov&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1000&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plotSamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">covMat&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cov&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># 求 x 与 y 的协方差矩阵&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Z&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linalg&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cholesky&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">covMat&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">I&lt;/span> &lt;span class="c1"># 仿射矩阵&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plotSamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">Z&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 求马氏距离&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span> &lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s1">到原点的马氏距离分别是：&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mahalanobis&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">covMat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">I&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mahalanobis&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">covMat&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">I&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 求变换后的欧几里得距离&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dots&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">Z&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matrix&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">]]))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span> &lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s1">变换后到原点的欧几里得距离分别是：&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">minkowski&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dots&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">minkowski&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dots&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>马氏距离的变换和 PCA 分解的&lt;a href="http://deeplearning.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96" target="_blank" rel="noopener">白化处理&lt;/a>颇有异曲同工之妙，不同之处在于：就二维来看，PCA 是将数据主成分旋转到 x 轴(正交矩阵的酉变换)，再在尺度上缩放(对角矩阵)，实现尺度相同。而马氏距离的 L 逆矩阵是一个下三角，先在 x 和 y 方向进行缩放，再在 y 方向进行错切(想象矩形变平行四边形)，总体来说是一个没有旋转的仿射变换。&lt;/p>
&lt;h2 id="类别点距离categorical-data-points">类别点距离(categorical data points)&lt;/h2>
&lt;p>$distance_{final} = α.distance_{numeric} + (1- α).distance_{categorical}$&lt;/p>
&lt;h3 id="汉明距离">汉明距离&lt;/h3>
&lt;p>&lt;strong>汉明距离&lt;/strong>(Hamming distance)是指，两个等长字符串 s1 与 s2 之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。举个维基百科上的例子：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07221109-c683a8f31c9a4e31a93e5d04fdab3443.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>还可以用简单的&lt;strong>匹配系数&lt;/strong>来表示两点之间的相似度——匹配字符数/总字符数。在一些情况下，某些特定的值相等并不能代表什么。举个例子，用 1 表示用户看过该电影，用 0 表示用户没有看过，那么用户看电影的的信息就可用 0,1 表示成一个序列。考虑到电影基数非常庞大，用户看过的电影只占其中非常小的一部分，如果两个用户都没有看过某一部电影(两个都是 0)，并不能说明两者相似。反而言之，如果两个用户都看过某一部电影(序列中都是 1)，则说明用户有很大的相似度。在这个例子中，序列中等于 1 所占的权重应该远远大于 0 的权重，这就引出下面要说的&lt;strong>杰卡德相似系数&lt;/strong>(Jaccard similarity)。&lt;/p>
&lt;h3 id="jacard-相似度">Jacard 相似度&lt;/h3>
&lt;p>Jacard 相似性直观的概念来自，两个集合有多相似，显然，Jacard 最好是应用在离散的变量几何上。先看公式：&lt;/p>
&lt;pre>&lt;code> ![ J(A,B) = {{|A /cap B|}/over{|A /cup B|}}.](http://upload.wikimedia.org/math/1/8/6/186c7f4e83da32e889d606140fae25a0.png)
&lt;/code>&lt;/pre>
&lt;p>分子是集合交集，分母是集合并集，画个图，马上就明白咋回事了。&lt;/p>
&lt;p>和 Jacard index 相似的一个公式是 Dice‘ coefficient, 它也很直观，
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://upload.wikimedia.org/math/2/3/5/2354a9c697d2bf4ae114b8f1f72d5090.png" alt="s = /frac{2 | X /cap Y |}{| X | &amp;#43; | Y |} " loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="向量内积">向量内积&lt;/h2>
&lt;p>向量内积是线性代数里最为常见的计算，实际上它还是一种有效并且直观的相似性测量手段。向量内积的定义如下：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?Inner%28x,y%29%20=%20%5Clangle%20x,%20y%20%5Crangle%20=%20%5Csum_i%20x_i%20y_i" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>直观的解释是：如果 x 高的地方 y 也比较高，x 低的地方 y 也比较低，那么整体的内积是偏大的，也就是说 x 和 y 是相似的。举个例子，在一段长的序列信号 A 中寻找哪一段与短序列信号 a 最匹配，只需要将 a 从 A 信号开头逐个向后平移，每次平移做一次内积，内积最大的相似度最大。信号处理中 DFT 和 DCT 也是基于这种内积运算计算出不同频域内的信号组分(DFT 和 DCT 是正交标准基，也可以看做投影)。向量和信号都是离散值，如果是连续的函数值，比如求区间&lt;code>[-1, 1]&lt;/code> 两个函数之间的相似度，同样也可以得到(系数)组分，这种方法可以应用于多项式逼近连续函数，也可以用到连续函数逼近离散样本点(最小二乘问题，&lt;strong>OLS coefficients&lt;/strong>)中，扯得有点远了- -!。&lt;/p>
&lt;h3 id="余弦相似度">余弦相似度&lt;/h3>
&lt;p>向量内积的结果是没有界限的，一种解决办法是除以长度之后再求内积，这就是应用十分广泛的&lt;strong>余弦相似度&lt;/strong>(Cosine similarity)：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?CosSim%28x,y%29%20=%20%5Cfrac%7B%5Csum_i%20x_i%20y_i%7D%7B%20%5Csqrt%7B%20%5Csum_i%20x_i%5E2%7D%20%5Csqrt%7B%20%5Csum_i%20y_i%5E2%20%7D%20%7D%20=%20%5Cfrac%7B%20%5Clangle%20x,y%20%5Crangle%20%7D%7B%20%7C%7Cx%7C%7C%5C%20%7C%7Cy%7C%7C%20%7D" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>余弦相似度与向量的幅值无关，只与向量的方向相关，在文档相似度(&lt;a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html" target="_blank" rel="noopener">TF-IDF&lt;/a>)和图片相似性(&lt;a href="http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html" target="_blank" rel="noopener">histogram&lt;/a>)计算上都有它的身影。&lt;/p>
&lt;h3 id="皮尔逊相关系数pearson-correlation-coefficient">皮尔逊相关系数(Pearson Correlation Coefficient)&lt;/h3>
&lt;p>需要注意一点的是，余弦相似度受到向量的平移影响，上式如果将 x 平移到 x+1, 余弦值就会改变。怎样才能实现平移不变性？这就是下面要说的&lt;strong>皮尔逊相关系数&lt;/strong>(Pearson correlation)，有时候也直接叫&lt;strong>相关系数&lt;/strong>。皮尔逊相关系数是一种度量两个变量间相关程度的方法。它是一个介于 1 和 -1 之间的值，其中，1 表示变量完全正相关，0 表示无关，-1 表示完全负相关。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?%5Cbegin%7Balign%7D%20Corr%28x,y%29%20&amp;amp;=%20%5Cfrac%7B%20%5Csum_i%20%28x_i-%5Cbar%7Bx%7D%29%20%28y_i-%5Cbar%7By%7D%29%20%7D%7B%20%5Csqrt%7B%5Csum%20%28x_i-%5Cbar%7Bx%7D%29%5E2%7D%20%5Csqrt%7B%20%5Csum%20%28y_i-%5Cbar%7By%7D%29%5E2%20%7D%20%7D%20&amp;amp;=%20%5Cfrac%7B%5Clangle%20x-%5Cbar%7Bx%7D,%5C%20y-%5Cbar%7By%7D%20%5Crangle%7D%7B%20%7C%7Cx-%5Cbar%7Bx%7D%7C%7C%5C%20%7C%7Cy-%5Cbar%7By%7D%7C%7C%7D%20%20%20&amp;amp;=%20CosSim%28x-%5Cbar%7Bx%7D,%20y-%5Cbar%7By%7D%29%20%5Cend%7Balign%7D" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>=&lt;/p>
&lt;p>$\frac{\sum x_iy_i-\frac{\sum x_i\sum y_i}{n}}{\sqrt{\sum x_i^2-\frac{(\sum x_i)^2}{n}}\sqrt{\sum y_i^2-\frac{(\sum y_i)^2}{n}}}$&lt;/p>
&lt;p>在推荐系统中，我们常用皮尔逊相关系数来衡量两个用户兴趣的相似度，它是判断两组数据与某一直线拟合程度的一种度量。它在用户对物品的评分数据差别大时(如有些用户评分普遍较高，有些用户评分普遍偏低)时的效果更好。也即它修正了“夸大分值”的情况，如果某个用户总是倾向于给出比另一个人更高的分值，而两者的分值之差又始终保持一致，则两者间依然可能存在很好地相关性。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://7xlv6k.com1.z0.glb.clouddn.com/cdn_chapter2_2.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>在&lt;a href="http://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6" target="_blank" rel="noopener">统计学&lt;/a>中，&lt;strong>皮尔逊积矩相关系数&lt;/strong>(Pearson product-moment correlation coefficient)用于度量两个变量 X 和 Y 之间的&lt;a href="http://zh.wikipedia.org/wiki/%E7%9B%B8%E5%85%B3" target="_blank" rel="noopener">相关&lt;/a>(线性相关)，其值介于-1 与 1 之间。系数的值为 1 意味着&lt;em>X&lt;/em> 和 &lt;em>Y&lt;/em>可以很好的由直线方程来描述，所有的数据点都很好的落在一条 &lt;a href="http://zh.wikipedia.org/w/index.php?title=Line_%28mathematics%29&amp;amp;action=edit&amp;amp;redlink=1" target="_blank" rel="noopener">直线&lt;/a>上，且 &lt;em>Y&lt;/em> 随着 &lt;em>X&lt;/em> 的增加而增加。系数的值为?1 意味着所有的数据点都落在直线上，且 &lt;em>Y&lt;/em> 随着 &lt;em>X&lt;/em> 的增加而减少。系数的值为 0 意味着两个变量之间没有线性关系。当两个变量独立时，相关系数为 0.但反之并不成立。这是因为相关系数仅仅反映了两个变量之间是否线性相关。比如说，&lt;em>X&lt;/em>是区间［－１，１］上的一个均匀分布的随机变量。&lt;em>Y&lt;/em> = &lt;em>X&lt;/em>2. 那么&lt;em>Y&lt;/em>是完全由&lt;em>X&lt;/em>确定。因此&lt;em>Y&lt;/em> 和&lt;em>X&lt;/em>是不独立的。但是相关系数为 0。或者说他们是不相关的。当&lt;em>Y&lt;/em> 和&lt;em>X&lt;/em>服从联合正态分布时，其相互独立和不相关是等价的。当且仅当 &lt;em>X**i&lt;/em> and &lt;em>Y**i&lt;/em> 均落在他们各自的均值的同一侧，则(&lt;em>X**i&lt;/em> ? &lt;em>X&lt;/em>)(&lt;em>Y**i&lt;/em> ? &lt;em>Y&lt;/em>) 的值为正。也就是说，如果&lt;em>X**i&lt;/em> 和 &lt;em>Y**i&lt;/em> 同时趋向于大于, 或同时趋向于小于他们各自的均值，则相关系数为正。如果 &lt;em>X**i&lt;/em> 和 &lt;em>Y**i&lt;/em> 趋向于落在他们均值的相反一侧，则相关系数为负。&lt;/p>
&lt;p>皮尔逊相关系数具有平移不变性和尺度不变性，计算出了两个向量(维度)的相关性。不过，一般我们在谈论相关系数的时候，将 x 与 y 对应位置的两个数值看作一个样本点，皮尔逊系数用来表示这些样本点分布的相关性。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07221044-45cc00fed26d4c6796f4d9b9072dc177.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>由于皮尔逊系数具有的良好性质，在各个领域都应用广泛，例如，在推荐系统根据为某一用户查找喜好相似的用户,进而&lt;a href="http://www.cnblogs.com/daniel-D/p/3192180.html" target="_blank" rel="noopener">提供推荐&lt;/a>，优点是可以不受每个用户评分标准不同和观看影片数量不一样的影响。&lt;/p>
&lt;blockquote>
&lt;p>例如，假设五个国家的国民生产总值分别是 1、2、3、5、8(单位 10 亿美元)，又假设这五个国家的贫困比例分别是 11%、12%、13%、15%、18%。&lt;/p>
&lt;/blockquote>
&lt;p>创建 2 个向量.(R 语言)&lt;/p>
&lt;pre tabindex="0">&lt;code>x&amp;lt;-c(1,2,3,5,8)
y&amp;lt;-c(0.11,0.12,0.13,0.15,0.18)
&lt;/code>&lt;/pre>&lt;p>按照维基的例子,应计算出相关系数为 1 出来.我们看看如何一步一步计算出来的.&lt;/p>
&lt;p>x 的平均数是:3.8&lt;/p>
&lt;p>y 的平均数是 0.138&lt;/p>
&lt;p>所以,&lt;/p>
&lt;pre tabindex="0">&lt;code>sum((x-mean(x))*(y-mean(y)))=0.308
&lt;/code>&lt;/pre>&lt;p>用大白话来写就是:&lt;/p>
&lt;p>(1-3.8)*(0.11-0.138)=0.0784&lt;/p>
&lt;p>(2-3.8)*(0.12-0.138)=0.0324&lt;/p>
&lt;p>(3-3.8)*(0.13-0.138)=0.0064&lt;/p>
&lt;p>(5-3.8)*(0.15-0.138)=0.0144&lt;/p>
&lt;p>(8-3.8)*(0.18-0.138)=0.1764&lt;/p>
&lt;p>0.0784+0.0324+0.0064+0.0144+0.1764=0.308&lt;/p>
&lt;p>同理, 分号下面的,分别是:&lt;/p>
&lt;p>sum((x-mean(x))^2)=30.8&lt;/p>
&lt;p>sum((y-mean(y))^2)= 0.00308&lt;/p>
&lt;p>用大白话来写,分别是:&lt;/p>
&lt;p>(1-3.8)^2=7.84 #平方&lt;/p>
&lt;p>(2-3.8)^2=3.24 #平方&lt;/p>
&lt;p>(3-3.8)^2=0.64 #平方&lt;/p>
&lt;p>(5-3.8)^2=1.44 #平方&lt;/p>
&lt;p>(8-3.8)^2=17.64 #平方&lt;/p>
&lt;p>7.84+3.24+0.64+1.44+17.64=30.8&lt;/p>
&lt;p>同理,求得:&lt;/p>
&lt;pre tabindex="0">&lt;code>sum((y-mean(y))^2)= 0.00308
&lt;/code>&lt;/pre>&lt;p>然后再开平方根,分别是:&lt;/p>
&lt;p>30.8^0.5=5.549775&lt;/p>
&lt;p>0.00308^0.5=0.05549775&lt;/p>
&lt;p>用分子除以分母,就计算出最终结果:&lt;/p>
&lt;p>0.308/(5.549775*0.05549775)=1&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#皮尔逊相关度&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">sim_pearson&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">si&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">item&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">item&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">item&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">si&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">n&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">si&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">#计算开始&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sum1&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">it&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sum2&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">it&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sum1Sq&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">pow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">],&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">it&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sum2Sq&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="nb">pow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">],&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">it&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pSum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nb">sum&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">prefs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">it&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">it&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">si&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">num&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">pSum&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sum1&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">sum2&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">den&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">sqrt&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">sum1Sq&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nb">pow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sum1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sum2Sq&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nb">pow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sum2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">#计算结束&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">den&lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">r&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">num&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">den&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">r&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="序列距离stringtimeseries">序列距离(String,TimeSeries)&lt;/h2>
&lt;h3 id="dtwdynamic-time-warp">DTW(Dynamic Time Warp)&lt;/h3>
&lt;p>汉明距离可以度量两个长度相同的字符串之间的相似度，如果要比较两个不同长度的字符串，不仅要进行替换，而且要进行插入与删除的运算，在这种场合下，通常使用更加复杂的&lt;strong>编辑距离&lt;/strong>(Edit distance, Levenshtein distance)等算法。编辑距离是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。编辑距离求的是最少编辑次数，这是一个动态规划的问题，有兴趣的同学可以自己研究研究。&lt;/p>
&lt;p>时间序列是序列之间距离的另外一个例子。&lt;strong>DTW 距离&lt;/strong>(Dynamic Time Warp)是序列信号在时间或者速度上不匹配的时候一种衡量相似度的方法。神马意思？举个例子，两份原本一样声音样本 A、B 都说了“你好”，A 在时间上发生了扭曲，“你”这个音延长了几秒。最后 A:“你~~~~~~~好”，B：“你好”。DTW 正是这样一种可以用来匹配 A、B 之间的最短距离的算法。&lt;/p>
&lt;p>DTW 距离在保持信号先后顺序的限制下对时间信号进行“膨胀”或者“收缩”，找到最优的匹配，与编辑距离相似，这其实也是一个动态规划的问题:&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07221153-ea76b098f70a4a68b4929789c032ef69.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="ch">#!/usr/bin/python2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># -*- coding:UTF-8 -*-&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># code related at: http://blog.mckelv.in/articles/1453.html&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">distance&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">lambda&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">b&lt;/span> &lt;span class="p">:&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="n">b&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">dtw&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sa&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">sb&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1"> &amp;gt;&amp;gt;&amp;gt;dtw(u&amp;#34;干啦今今今今今天天气气气气气好好好好啊啊啊&amp;#34;, u&amp;#34;今天天气好好啊&amp;#34;)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1"> 2
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1"> &amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">MAX_COST&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">&amp;lt;&amp;lt;&lt;/span>&lt;span class="mi">32&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">#初始化一个len(sb) 行(i)，len(sa)列(j)的二维矩阵&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">len_sa&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sa&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">len_sb&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sb&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># BUG:这样是错误的(浅拷贝): dtw_array = [[MAX_COST]*len(sa)]*len(sb)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtw_array&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[[&lt;/span>&lt;span class="n">MAX_COST&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">len_sa&lt;/span>&lt;span class="p">)]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">len_sb&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">distance&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sa&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span>&lt;span class="n">sb&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">xrange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">len_sb&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">xrange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">len_sa&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="o">==&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">nb&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">nb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">nb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">nb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">min_route&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nb&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cost&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">distance&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sa&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">],&lt;/span>&lt;span class="n">sb&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cost&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">min_route&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dtw_array&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">len_sb&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">len_sa&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">s1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">u&lt;/span>&lt;span class="s1">&amp;#39;干啦今今今今今天天气气气气气好好好好啊啊啊&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">s2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">u&lt;/span>&lt;span class="s1">&amp;#39;今天天气好好啊&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">d&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dtw&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">s2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span> &lt;span class="n">d&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="vm">__name__&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;__main__&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="网络节点距离">网络节点距离&lt;/h2>
&lt;h2 id="分布距离">分布距离&lt;/h2>
&lt;p>前面我们谈论的都是两个数值点之间的距离，实际上两个概率分布之间的距离是可以测量的。在统计学里面经常需要测量两组样本分布之间的距离，进而判断出它们是否出自同一个 population，常见的方法有&lt;strong>卡方检验&lt;/strong>(Chi-Square)和 &lt;strong>KL 散度&lt;/strong>( KL-Divergence)，下面说一说 KL 散度吧。&lt;/p>
&lt;p>先从信息熵说起，假设一篇文章的标题叫做“黑洞到底吃什么”，包含词语分别是 {黑洞, 到底, 吃什么}, 我们现在要根据一个词语推测这篇文章的类别。哪个词语给予我们的信息最多？很容易就知道是“黑洞”，因为“黑洞”这个词语在所有的文档中出现的概率太低啦，一旦出现，就表明这篇文章很可能是在讲科普知识。而其他两个词语“到底”和“吃什么”出现的概率很高，给予我们的信息反而越少。如何用一个函数 h(x) 表示词语给予的信息量呢？第一，肯定是与 p(x) 相关，并且是负相关。第二，假设 x 和 y 是独立的(黑洞和宇宙不相互独立，谈到黑洞必然会说宇宙),即 p(x,y) = p(x)p(y), 那么获得的信息也是叠加的，即 h(x, y) = h(x) + h(y)。满足这两个条件的函数肯定是负对数形式：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?h%28x%29%20=%20-ln%5C%20p%28x%29" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>对假设一个发送者要将随机变量 X 产生的一长串随机值传送给接收者，接受者获得的平均信息量就是求它的数学期望：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?H[x]%20=%20-%5Csum%20_x%7Bp%28x%29%5Cln%20p%28x%29%7D" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://latex.codecogs.com/gif.latex?H[x]%20=%20-%5Cint%20%7B%20p%28x%29%5Cln%20%7B%20p%28x%29%20%7D%20dx%20%7D" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>这就是熵的概念。另外一个重要特点是，熵的大小与字符平均最短编码长度是一样的(shannon)。设有一个未知的分布 p(x), 而 q(x) 是我们所获得的一个对 p(x) 的近似，按照 q(x) 对该随机变量的各个值进行编码，平均长度比按照真实分布的 p(x) 进行编码要额外长一些，多出来的长度这就是 KL 散度(之所以不说距离，是因为不满足对称性和三角形法则)，即：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnitblog.com/blog/533521/201308/07221311-03bee2dca7e040e4889582d8182f4dde.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>KL 散度又叫&lt;strong>相对熵&lt;/strong>(relative entropy)。了解机器学习的童鞋应该都知道，在 Softmax 回归(或者 Logistic 回归)，最后的输出节点上的值表示这个样本分到该类的概率，这就是一个概率分布。对于一个带有标签的样本，我们期望的概率分布是：分到标签类的概率是 1，其他类概率是 0。但是理想很丰满，现实很骨感，我们不可能得到完美的概率输出，能做的就是尽量减小总样本的 KL 散度之和(目标函数)。这就是 Softmax 回归或者 Logistic 回归中 Cost function 的优化过程啦。(PS：因为概率和为 1，一般的 logistic 二分类的图只画了一个输出节点，隐藏了另外一个)&lt;/p></description></item><item><title>矩阵分解</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/</guid><description>&lt;h1 id="特征分解">特征分解&lt;/h1></description></item><item><title>矩阵运算</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/</guid><description>&lt;h1 id="矩阵运算">矩阵运算&lt;/h1>
&lt;h1 id="基础">基础&lt;/h1>
&lt;h2 id="相加">相加&lt;/h2>
&lt;p>只要矩阵的形状一样，我们可以把两个矩阵相加。两个矩阵相加是指对应位置的元素相加，比如 $C_{i, j}=A_{i, j}+B_{i, j}$。&lt;/p>
&lt;h2 id="转置transpose">转置（Transpose）&lt;/h2>
&lt;p>转置（transpose）是矩阵的重要操作之一。矩阵的转置是以对角线为轴的镜像，这条从左上角到右下角的对角线被称为主对角线（main diagonal）。&lt;/p>
&lt;p>$$
\left(A^{\top}\right)&lt;em>{i, j}=A&lt;/em>{j, i}
$$&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/NFpZfywp/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>向量可以看作只有一列的矩阵。对应地，向量的转置可以看作是只有一行的矩阵。有时，我们通过将向量元素作为行矩阵写在文本行中，然后使用转置操作将其变为标准的列向量，来定义一个向量，比如：&lt;/p>
&lt;p>$$
\boldsymbol{x}=\left[x_{1}, x_{2}, x_{3}\right]^{\top}
$$&lt;/p>
&lt;p>标量可以看作是只有一个元素的矩阵。因此，标量的转置等于它本身，$a=a^{\top}$&lt;/p>
&lt;h2 id="标准乘积">标准乘积&lt;/h2>
&lt;p>标量和矩阵相乘，或是和矩阵相加时，我们只需将其与矩阵的每个元素相乘或相加，比如 $D=a \cdot B+c$，其中 $D_{i, j}=a \cdot B_{i, j}+c$。两个矩阵 $A$ 和 $B$ 的矩阵乘积
（matrix product）是第三个矩阵 $C$。，矩阵 $A$ 的列数必须和矩阵 $B$ 的行数相等。如果矩阵 $A$ 的形状是 $m \times n$，矩阵 $B$ 的形状是 $n \times p$，那么矩阵 $C$ 的形状就是 $m \times p$。&lt;/p>
&lt;p>$$
C=A B
\
C_{i, j}=\sum_{k} A_{i, k} B_{k, j}
$$&lt;/p>
&lt;p>矩阵乘积服从分配律、结合律，以及简单的转置：&lt;/p>
&lt;p>$$
A(B+C)=A B+A C
\
A(B C)=(A B) C
\
(A B)^{\top}=B^{\top} A^{\top}
$$&lt;/p>
&lt;p>但是不满足与交换律。&lt;/p>
&lt;h2 id="hadamard-product--逐元素积">Hadamard Product | 逐元素积&lt;/h2>
&lt;p>$$
\mathbf{A} \circ \mathbf{B}=\left[\begin{array}{cccc}{a_{1,1} b_{1,1}} &amp;amp; {a_{1,2} b_{1,2}} &amp;amp; {\cdots} &amp;amp; {a_{1, n} b_{1, n}} \ {a_{2,1} b_{2,1}} &amp;amp; {a_{2,2} b_{2,2}} &amp;amp; {\cdots} &amp;amp; {a_{2, n} b_{2, n}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {a_{m, 1} b_{m, 1}} &amp;amp; {a_{m, 2} b_{m, 2}} &amp;amp; {\cdots} &amp;amp; {a_{m, n} b_{m, n}}\end{array}\right]
$$&lt;/p>
&lt;h2 id="kronnecker-product--克罗内积">Kronnecker Product | 克罗内积&lt;/h2>
&lt;p>$$
\mathbf{A} \otimes \mathbf{B}=\left[\begin{array}{cccc}{a_{1,1} \mathbf{B}} &amp;amp; {a_{1,2} \mathbf{B}} &amp;amp; {\cdots} &amp;amp; {a_{1, n} \mathbf{B}} \ {a_{2,1} \mathbf{B}} &amp;amp; {a_{2,2} \mathbf{B}} &amp;amp; {\cdots} &amp;amp; {a_{2, n} \mathbf{B}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {a_{m, 1} \mathbf{B}} &amp;amp; {a_{m, 2} \mathbf{B}} &amp;amp; {\cdots} &amp;amp; {a_{m, n} \mathbf{B}}\end{array}\right]
$$&lt;/p>
&lt;h1 id="矩阵逆">矩阵逆&lt;/h1>
&lt;h2 id="单位矩阵">单位矩阵&lt;/h2>
&lt;h1 id="范数与迹">范数与迹&lt;/h1>
&lt;h2 id="f-范数">F 范数&lt;/h2>
&lt;p>矩阵 $\mathbf{A}=\left(a_{i, j}\right)_{m \times n}$，那么其 $F$ 范数的定义为：&lt;/p>
&lt;p>$$
|\mathbf{A}|&lt;em>{F}=\sqrt{\sum&lt;/em>{i, j} a_{i, j}^{2}}
$$&lt;/p>
&lt;p>$F$ 范数可以看做向量的 $L_2$ 范数的推广。&lt;/p>
&lt;h1 id="迹">迹&lt;/h1>
&lt;p>矩阵 $\mathbf{A}=\left(a_{i, j}\right)_{m \times n}$，那么 $A$ 的迹为：&lt;/p>
&lt;p>$$
\operatorname{tr}(\mathbf{A})=\sum_{i} a_{i, i}
$$&lt;/p>
&lt;p>一般来说，迹会满足如下性质：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>$A$ 的 F 范数等于 $AA^T$ 的迹的平方根：$|\mathbf{A}|_{F}=\sqrt{\operatorname{tr}\left(\mathbf{A} \mathbf{A}^{T}\right)}$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A$ 的迹等于 $A^T$ 的迹，$\operatorname{tr}(\mathbf{A})=\operatorname{tr}\left(\mathbf{A}^{T}\right)$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>交换律：假设 $\mathbf{A} \in \mathbb{R}^{m \times n}, \mathbf{B} \in \mathbb{R}^{n \times m}$，则有：$\operatorname{tr}(\mathbf{A} \mathbf{B})=\operatorname{tr}(\mathbf{B} \mathbf{A})$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>结合律：$\operatorname{tr}(\mathbf{A} \mathbf{B} \mathbf{C})=\operatorname{tr}(\mathbf{C} \mathbf{A} \mathbf{B})=\operatorname{tr}(\mathbf{B} \mathbf{C} \mathbf{A})$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="函数与导数">函数与导数&lt;/h1>
&lt;h2 id="函数计算">函数计算&lt;/h2>
&lt;p>如果 $f$ 是一元函数，则其逐向量函数为：&lt;/p>
&lt;p>$$
f(\overrightarrow{\mathbf{x}})=\left(f\left(x_{1}\right), f\left(x_{2}\right), \cdots, f\left(x_{n}\right)\right)^{T}
$$&lt;/p>
&lt;p>其逐矩阵函数为：&lt;/p>
&lt;p>$$
f(\mathbf{X})=\left[\begin{array}{cccc}{f\left(x_{1,1}\right)} &amp;amp; {f\left(x_{1,2}\right)} &amp;amp; {\cdots} &amp;amp; {f\left(x_{1, n}\right)} \ {f\left(x_{2,1}\right)} &amp;amp; {f\left(x_{2,2}\right)} &amp;amp; {\cdots} &amp;amp; {f\left(x_{2, n}\right)} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {f\left(x_{m, 1}\right)} &amp;amp; {f\left(x_{m, 2}\right)} &amp;amp; {\cdots} &amp;amp; {f\left(x_{m, n}\right)}\end{array}\right]
$$&lt;/p>
&lt;p>其逐元导数分别为：&lt;/p>
&lt;p>$$
f^{\prime}(\overrightarrow{\mathbf{x}})=\left(f^{\prime}(x 1), f^{\prime}(x 2), \cdots, f^{\prime}\left(x_{n}\right)\right)^{T}
$$&lt;/p>
&lt;p>$$
f^{\prime}(\mathbf{X})=\left[\begin{array}{cccc}{f^{\prime}\left(x_{1,1}\right)} &amp;amp; {f^{\prime}\left(x_{1,2}\right)} &amp;amp; {\cdots} &amp;amp; {f^{\prime}\left(x_{1, n}\right)} \ {f^{\prime}\left(x_{2,1}\right)} &amp;amp; {f^{\prime}\left(x_{2,2}\right)} &amp;amp; {\cdots} &amp;amp; {f^{\prime}\left(x_{2, n}\right)} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {f^{\prime}\left(x_{m, 1}\right)} &amp;amp; {f^{\prime}\left(x_{m, 2}\right)} &amp;amp; {\cdots} &amp;amp; {f^{\prime}\left(x_{m, n}\right)}\end{array}\right]
$$&lt;/p>
&lt;h2 id="偏导数">偏导数&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>标量对标量的偏导数：$\frac{\partial u}{\partial v}$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>标量对向量（$n$ 维向量）的偏导数：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial u}{\partial \overrightarrow{\mathbf{v}}}=\left(\frac{\partial u}{\partial v_{1}}, \frac{\partial u}{\partial v_{2}}, \cdots, \frac{\partial u}{\partial v_{n}}\right)^{T}
$$&lt;/p>
&lt;ul>
&lt;li>标量对矩阵 $m \times n$ 的偏导数：&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial u}{\partial \mathbf{V}}=\left[\begin{array}{cccc}{\frac{\partial u}{\partial V_{1,1}}} &amp;amp; {\frac{\partial u}{\partial V_{1,2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u}{\partial V_{1, n}}} \ {\frac{\partial u}{\partial V_{2,1}}} &amp;amp; {\frac{\partial u}{\partial V_{2,2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u}{\partial V_{2, n}}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {\frac{\partial u}{\partial V_{m, 1}}} &amp;amp; {\frac{\partial u}{\partial V_{m, 2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u}{\partial V_{m, n}}}\end{array}\right]
$$&lt;/p>
&lt;ul>
&lt;li>$m$ 维向量对标量的偏导数：&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial \overrightarrow{\mathbf{u}}}{\partial v}=\left(\frac{\partial u_{1}}{\partial v}, \frac{\partial u_{2}}{\partial v}, \cdots, \frac{\partial u_{m}}{\partial v}\right)^{T}
$$&lt;/p>
&lt;ul>
&lt;li>$m$ 维向量对 $n$ 维向量的偏导数（雅可比矩阵，行优先）：&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial \overrightarrow{\mathbf{u}}}{\partial \overrightarrow{\mathbf{v}}}=\left[\begin{array}{cccc}{\frac{\partial u_{1}}{\partial v_{1}}} &amp;amp; {\frac{\partial u_{1}}{\partial v_{2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u_{1}}{\partial v_{n}}} \ {\frac{\partial u_{2}}{\partial v_{1}}} &amp;amp; {\frac{\partial u_{2}}{\partial v_{2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u_{2}}{\partial v_{n}}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {\frac{\partial u_{m}}{\partial v_{1}}} &amp;amp; {\frac{\partial u_{m}}{\partial v_{2}}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial u_{m}}{\partial v_{n}}}\end{array}\right]
$$&lt;/p>
&lt;ul>
&lt;li>$m \times n$ 阶矩阵对于标量的偏导数：&lt;/li>
&lt;/ul>
&lt;p>$$
\frac{\partial \mathbf{U}}{\partial v}=\left[\begin{array}{cccc}{\frac{\partial U_{1,1}}{\partial v}} &amp;amp; {\frac{\partial U_{1,2}}{\partial v}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial U_{1, n}}{\partial v}} \ {\frac{\partial U_{2,1}}{\partial v}} &amp;amp; {\frac{\partial U_{2,2}}{\partial v}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial U_{2, n}}{\partial v}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {\frac{\partial U_{m, 1}}{\partial v}} &amp;amp; {\frac{\partial U_{m, 2}}{\partial v}} &amp;amp; {\cdots} &amp;amp; {\frac{\partial U_{m, n}}{\partial v}}\end{array}\right]
$$&lt;/p></description></item><item><title>特殊函数</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E5%87%BD%E6%95%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E5%87%BD%E6%95%B0/</guid><description>&lt;h1 id="特殊函数">特殊函数&lt;/h1>
&lt;h1 id="sigmoid-函数">sigmoid 函数&lt;/h1>
&lt;p>$$
\sigma(x)=\frac{1}{1+\exp (-x)}
$$&lt;/p>
&lt;p>该函数可以用于生成二项分布的 $\phi$ 参数，当 $x$ 很大或者很小时，该函数处于饱和状态。此时函数的曲线非常平坦，并且自变量的一个较大的变化只能带来函数值的一个微小的变化，即：导数很小。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/tCbcnGRF/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>sigmoid 函数遵循以下性质：&lt;/p>
&lt;p>$$
\sigma(x)=\frac{\exp (x)}{\exp (x)+\exp (0)}&lt;/p>
&lt;p>\ {\frac{d}{d x} \sigma(x)=\sigma(x)(1-\sigma(x))}&lt;/p>
&lt;p>\ {1-\sigma(x)=\sigma(-x)}
$$&lt;/p>
&lt;h1 id="softplus-函数">softplus 函数&lt;/h1>
&lt;p>$$
\zeta(x)=\log (1+\exp (x))
$$&lt;/p>
&lt;p>该函数可以生成正态分布的 $\sigma^{2}$ 参数，该函数之所以被称为 softplus，是因为其是 $x^{+}=\max (0, x)$ 函数的光滑逼近：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/Y0Lt4Kt5/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>对于函数 $x^{+}=\max (0, x)$ 以及 $x^{-}=\max (0, -x)$，它们分别获取了 $y=x$ 的正部门和负部分。根据定义有 $x = x^{+} - x^{-}$，而 $\zeta(x)$ 逼近的是 $x^{+}$，$\zeta(-x)$ 逼近的是 $x^{-}$，于是有：&lt;/p>
&lt;p>$$
\zeta(x)-\zeta(-x)=x
$$&lt;/p>
&lt;p>softplus 与 sigmoid 有很多相通的性质：&lt;/p>
&lt;p>$$
{\log \sigma(x)=-\zeta(-x)} \ {\frac{d}{d x} \zeta(x)=\sigma(x)} \ {\forall x \in(0,1), \sigma^{-1}(x)=\log \left(\frac{x}{1-x}\right)} \ {\forall x&amp;gt;0, \zeta^{-1}(x)=\log (\exp (x)-1)} \ {\zeta(x)=\int_{-\infty}^{x} \sigma(y) d y} \ {\zeta(x)-\zeta(-x)=x}
$$&lt;/p>
&lt;p>其中 $f^{-1}(\cdot)$ 为反函数，$\sigma^{-1}(x)$ 也称作 logit 函数：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/YCDGmk79/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="伽马函数">伽马函数&lt;/h1>
&lt;p>伽马函数定义为：&lt;/p>
&lt;p>$$
\begin{array}{c}{\Gamma(x)=\int_{0}^{+\infty} t^{x-1} e^{-t} d t \quad, x \in \mathbb{R}} \ {\text { or. } \quad \Gamma(z)=\int_{0}^{+\infty} t^{z-1} e^{-t} d t \quad, z \in \mathbb{Z}}\end{array}
$$&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/G2GHNyy8/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>$\Gamma$ 函数的性质有：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对于正整数 $n$ 有：$\Gamma(n)=(n-1) !$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\Gamma(x+1)=x \Gamma(x)$，伽马函数是阶乘在实数域上的扩展。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>与 Beta 函数的关系：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
B(m, n)=\frac{\Gamma(m) \Gamma(n)}{\Gamma(m+n)}
$$&lt;/p>
&lt;ul>
&lt;li>对于 $x \in(0,1)$ 有：&lt;/li>
&lt;/ul>
&lt;p>$$
\Gamma(1-x) \Gamma(x)=\frac{\pi}{\sin \pi x}
$$&lt;/p>
&lt;p>即 $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$，当 $x$ 足够大时，可以使用 &lt;code>Stirling&lt;/code> 公式来计算 Gamma 函数值：$\Gamma(x) \sim \sqrt{2 \pi} e^{-x} x^{x+1 / 2}$。&lt;/p>
&lt;h1 id="beta-函数">Beta 函数&lt;/h1>
&lt;p>对于任意实数 $m, n&amp;gt;0$，Beta 函数的定义为：&lt;/p>
&lt;p>$$
B(m, n)=\int_{0}^{1} x^{m-1}(1-x)^{n-1} d x
$$&lt;/p>
&lt;p>其他形式的定义还包含：&lt;/p>
&lt;p>$$
\begin{array}{c}{B(m, n)=2 \int_{0}^{\frac{\pi}{2}} \sin ^{2 m-1}(x) \cos ^{2 n-1}(x) d x} \ {B(m, n)=\int_{0}^{+\infty} \frac{x^{m-1}}{(1+x)^{m+n}} d x} \ {B(m, n)=\int_{0}^{1} \frac{x^{m-1}+x^{n-1}}{(1+x)^{m+n}} d x}\end{array}
$$&lt;/p>
&lt;h2 id="性质">性质&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>连续性，Beta 函数在定义域 $m, n&amp;gt;0$ 内连续&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对称性，$B(m, n)=B(n, m)$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>递推公式：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{array}{l}{B(m, n)=\frac{n-1}{m+n-1} B(m, n-1), \quad m&amp;gt;0, n&amp;gt;1} \ {B(m, n)=\frac{m-1}{m+n-1} B(m-1, n), \quad m&amp;gt;1, n&amp;gt;0} \ {B(m, n)=\frac{(m-1)(n-1)}{(m+n-1)(m+n-2)} B(m-1, n-1), \quad m&amp;gt;1, n&amp;gt;1}\end{array}
$$&lt;/p>
&lt;ul>
&lt;li>当 $m,n$ 较大时，有近似公式：&lt;/li>
&lt;/ul>
&lt;p>$$
B(m, n)=\frac{\sqrt{(2 \pi) m^{m-1 / 2} n^{n-1 / 2}}}{(m+n)^{m+n-1 / 2}}
$$&lt;/p>
&lt;ul>
&lt;li>与 Gamma 函数关系&lt;/li>
&lt;/ul>
&lt;p>对于任意正实数 $m, n&amp;gt;0$，有&lt;/p>
&lt;p>$$
B(m, n)=\frac{\Gamma(m) \Gamma(n)}{\Gamma(m+n)}
$$&lt;/p>
&lt;p>且 $B(m, 1-m)=\Gamma(m) \Gamma(1-m)$。&lt;/p></description></item><item><title>特殊矩阵</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%98%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%98%B5/</guid><description>&lt;h1 id="特殊矩阵">特殊矩阵&lt;/h1>
&lt;h1 id="方阵">方阵&lt;/h1>
&lt;p>方阵的行列式定义如下：&lt;/p>
&lt;ul>
&lt;li>$1$ 阶方阵的行列式为该元素本身&lt;/li>
&lt;li>$n$ 阶方阵的行列式等于它的任一行或者列的各元素与其对应的代数余子式乘积之和。&lt;/li>
&lt;/ul>
&lt;h1 id="稀疏矩阵">稀疏矩阵&lt;/h1>
&lt;p>对于那些零元素数目远远多于非零元素数目，并且非零元素的分布没有规律的矩阵称为稀疏矩阵（sparse）。人们无法给出稀疏矩阵的确切定义，一般都只是凭个人的直觉来理解这个概念，即矩阵中非零元素的个数远远小于矩阵元素的总数，并且非零元素没有分布规律。&lt;/p>
&lt;p>由于稀疏矩阵中非零元素较少，零元素较多，因此可以采用只存储非零元素的方法来进行压缩存储。由于非零元素分布没有任何规律，所以在进行压缩存储的时侯需要存储非零元素值的同时还要存储非零元素在矩阵中的位置，即非零元素所在的行号和列号，也就是在存储某个元素比如 $a_(ij)$ 的值的同时，还需要存储该元素所在的行号 i 和它的列号 j，这样就构成了一个三元组 &lt;code>(i,j,aij)&lt;/code> 的线性表。&lt;/p>
&lt;p>三元组可以采用顺序表示方法，也可以采用链式表示方法，这样就产生了对稀疏矩阵的不同压缩存储方式。&lt;/p>
&lt;h2 id="稀疏矩阵的顺序实现">稀疏矩阵的顺序实现&lt;/h2>
&lt;p>若把稀疏矩阵的三元组线性表按顺序存储结构存储，则称为稀疏矩阵的三元组顺序表。顺序表中除了存储三元组外，还应该存储矩阵行数、列数和总的非零元素数目，这样才能唯一的确定一个矩阵。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnblogs.com/cnblogs_com/xiaosuo/DataStructure/37.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="稀疏矩阵的十字链表实现">稀疏矩阵的十字链表实现&lt;/h2>
&lt;p>十字链表结点分为三类：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>表结点，它由五个域组成，其中 i 和 j 存储的是结点所在的行和列，right 和 down 存储的是指向十字链表中该结点所有行和列的下一个结点的指针，v 用于存放元素值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>行头和列头结点，这类结点也有域组成，其中行和列的值均为零，没有实际意义，right 和 down 的域用于在行方向和列方向上指向表结点，next 用于指向下一个行或列的表头结点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>总表头结点，这类结点与表头结点的结构和形式一样，只是它的 i 和 j 存放的是矩阵的行和列数。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnblogs.com/cnblogs_com/xiaosuo/DataStructure/38.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>十字链表可以看作是由各个行链表和列链表共同搭建起来的一个综合链表，每个结点 aij 既是处在第 i 行链表的一个结点，同时也是处在第 j 列链表上的一个结点，就你是处在十字交叉路口上的一个结点一样，这就是十字链表的由来。十字链表中的每一行和每一列链表都是一个循环链表，都有一个表头结点。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://images.cnblogs.com/cnblogs_com/xiaosuo/DataStructure/39.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p></description></item><item><title>向量运算</title><link>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E8%BF%90%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/mathematics-series/2.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E8%BF%90%E7%AE%97/</guid><description>&lt;h1 id="向量运算">向量运算&lt;/h1>
&lt;h1 id="基本运算">基本运算&lt;/h1>
&lt;h2 id="加法">加法&lt;/h2>
&lt;h2 id="点积">点积&lt;/h2>
&lt;p>三维向量的点积定义如下：&lt;/p>
&lt;p>$$
\overrightarrow{\mathbf{u}} \cdot \overrightarrow{\mathbf{v}}=u_{x} v_{x}+u_{y} v_{y}+u_{z} v_{z}=|\overrightarrow{\mathbf{u}} || \overrightarrow{\mathbf{v}} | \cos (\overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}})
$$&lt;/p>
&lt;h2 id="叉积">叉积&lt;/h2>
&lt;p>三维向量的叉积定义如下：&lt;/p>
&lt;p>$$
\overrightarrow{\mathbf{w}}=\overrightarrow{\mathbf{u}} \times \overrightarrow{\mathbf{v}}=\left[\begin{array}{ccc}{\overrightarrow{\mathbf{i}}} &amp;amp; {\overrightarrow{\mathbf{j}}} &amp;amp; {\overrightarrow{\mathbf{k}}} \ {u_{x}} &amp;amp; {u_{y}} &amp;amp; {u_{z}} \ {v_{x}} &amp;amp; {v_{y}} &amp;amp; {v_{z}}\end{array}\right]
$$&lt;/p>
&lt;p>其中 $\overrightarrow{\mathbf{i}}, \overrightarrow{\mathbf{j}}, \overrightarrow{\mathbf{k}}$ 分别为 $x,y,z$ 轴的单位向量：&lt;/p>
&lt;p>$$
\overrightarrow{\mathbf{u}}=u_{x} \overrightarrow{\mathbf{i}}+u_{y} \overrightarrow{\mathbf{j}}+u_{z} \overrightarrow{\mathbf{k}}, \quad \overrightarrow{\mathbf{v}}=v_{x} \overrightarrow{\mathbf{i}}+v_{y} \overrightarrow{\mathbf{j}}+v_{z} \overrightarrow{\mathbf{k}}
$$&lt;/p>
&lt;p>$\overrightarrow{\mathbf{u}}$ 和 $\overrightarrow{\mathbf{v}}$ 的叉积垂直于 $\overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}}$ 构成的平面，其方向符合右手规则。叉积的模等于 $\overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}}$ 构成的平行四边形的面积，且符合如下的条件：&lt;/p>
&lt;p>$$
\begin{array}{l}{\overrightarrow{\mathbf{u}} \times \overrightarrow{\mathbf{v}}=-\overrightarrow{\mathbf{v}} \times \overrightarrow{\mathbf{u}}} \ {\overrightarrow{\mathbf{u}} \times(\overrightarrow{\mathbf{v}} \times \overrightarrow{\mathbf{w}})=(\overrightarrow{\mathbf{u}} \cdot \overrightarrow{\mathbf{w}}) \overrightarrow{\mathbf{v}}-(\overrightarrow{\mathbf{u}} \cdot \overrightarrow{\mathbf{v}}) \overrightarrow{\mathbf{w}}}\end{array}
$$&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://i.postimg.cc/qBDr87Y2/image.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="混合积">混合积&lt;/h2>
&lt;p>$$
\begin{array}{rl}{[\overrightarrow{\mathbf{u}} \overrightarrow{\mathbf{v}}} &amp;amp; {\overrightarrow{\mathbf{w}} ]=(\overrightarrow{\mathbf{u}} \times \overrightarrow{\mathbf{v}}) \cdot \overrightarrow{\mathbf{w}}=\overrightarrow{\mathbf{u}} \cdot(\overrightarrow{\mathbf{v}} \times \overrightarrow{\mathbf{w}})}&lt;/p>
&lt;p>= \left|\begin{array}{lll}{u_{x}} &amp;amp; {u_{y}} &amp;amp; {u_{z}} \ {v_{x}} &amp;amp; {v_{y}} &amp;amp; {v_{z}} \ {w_{x}} &amp;amp; {w_{y}} &amp;amp; {w_{z}}\end{array}\right|&lt;/p>
&lt;p>= \left|\begin{array}{lll}{u_{x}} &amp;amp; {v_{x}} &amp;amp; {w_{x}} \ {u_{y}} &amp;amp; {v_{y}} &amp;amp; {w_{y}} \ {u_{z}} &amp;amp; {v_{z}} &amp;amp; {w_{z}}\end{array}\right|&lt;/p>
&lt;p>\end{array}
$$&lt;/p>
&lt;p>其物理意义为：以 $\overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}}, \overrightarrow{\mathbf{w}}$ 为三个棱边所围成的平行六面体的体积。当 $\overrightarrow{\mathbf{u}}, \overrightarrow{\mathbf{v}}, \overrightarrow{\mathbf{w}}$&lt;/p>
&lt;h2 id="并矢">并矢&lt;/h2>
&lt;p>给定两个向量 $\overrightarrow{\mathbf{x}}=\left(x_{1}, x_{2}, \cdots, x_{n}\right)^{T}, \overrightarrow{\mathbf{y}}=\left(y_{1}, y_{2}, \cdots, y_{m}\right)^{T}$，则向量的并矢记作：&lt;/p>
&lt;p>$$
\overrightarrow{\mathbf{x}} \overrightarrow{\mathbf{y}}=\left[\begin{array}{cccc}{x_{1} y_{1}} &amp;amp; {x_{1} y_{2}} &amp;amp; {\cdots} &amp;amp; {x_{1} y_{m}} \ {x_{2} y_{1}} &amp;amp; {x_{2} y_{2}} &amp;amp; {\cdots} &amp;amp; {x_{2} y_{m}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {x_{n} y_{1}} &amp;amp; {x_{n} y_{2}} &amp;amp; {\cdots} &amp;amp; {x_{n} y_{m}}\end{array}\right]
$$&lt;/p>
&lt;p>也记作 $\overrightarrow{\mathbf{x}} \otimes \overrightarrow{\mathbf{y}}$ 或者 $\overrightarrow{\mathrm{x}} \overrightarrow{\mathbf{y}}^{T}$。&lt;/p>
&lt;h1 id="线性相关">线性相关&lt;/h1>
&lt;p>一组向量 $\overrightarrow{\mathbf{v}}&lt;em>{1}, \overrightarrow{\mathbf{v}}&lt;/em>{2}, \cdots, \overrightarrow{\mathbf{v}}&lt;em>{n}$ 如果是线性相关的，那么值存在一组不全为零的实数，$a&lt;/em>{1}, a_{2}, \cdots, a_{n}$，使得 $\sum_{i=1}^{n} a_{i} \overrightarrow{\mathbf{v}}_{i}=\overrightarrow{\mathbf{0}}$。&lt;/p>
&lt;p>反之，一组向量 $\overrightarrow{\mathbf{v}}&lt;em>{1}, \overrightarrow{\mathbf{v}}&lt;/em>{2}, \cdots, \overrightarrow{\mathbf{v}}&lt;em>{n}$ 如果是线性无关的，当且仅当 $a&lt;/em>{i}=0, i=1,2, \cdots, n$ 才有 $\sum_{i=1}^{n} a_{i} \overrightarrow{\mathbf{v}}_{i}=\overrightarrow{\mathbf{0}}$。&lt;/p>
&lt;h1 id="向量性质">向量性质&lt;/h1>
&lt;h2 id="维数">维数&lt;/h2>
&lt;p>一个向量空间所包含的最大线性无关向量的数目，称作该向量空间的维数。&lt;/p>
&lt;h2 id="范数">范数&lt;/h2></description></item></channel></rss>
<!doctype html><html lang=zh><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=google-site-verification content="google69a5cccb61297807"><meta name=baidu-site-verification content="cqmZHEleVh"><meta name=description content="java-string-similarity > Machine Learning: Measuring Similarity and Distance > 漫谈：机器学习中距离和相似性度量方法 数值点距离:numeric data points Numeric Data Points 闵可夫斯基距离 闵可夫斯基距离(Minkowski distance)是衡量数值点之间距离的一种非常常见的方法，假"><link rel=alternate hreflang=zh href=https://ng-tech.icu/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/><meta name=theme-color content="#0a55a7"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin=anonymous><link rel=stylesheet href=/css/wowchemy.63df6ae9fc2b4cc71b83f1774d780209.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-40NYXJ8823")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://ng-tech.icu/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wx-chevalier"><meta property="twitter:creator" content="@wx-chevalier"><meta property="og:site_name" content="Next-gen Tech Edu"><meta property="og:url" content="https://ng-tech.icu/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/"><meta property="og:title" content="距离与相似性 | Next-gen Tech Edu"><meta property="og:description" content="java-string-similarity > Machine Learning: Measuring Similarity and Distance > 漫谈：机器学习中距离和相似性度量方法 数值点距离:numeric data points Numeric Data Points 闵可夫斯基距离 闵可夫斯基距离(Minkowski distance)是衡量数值点之间距离的一种非常常见的方法，假"><meta property="og:image" content="https://ng-tech.icu/media/sharing.png"><meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png"><meta property="og:locale" content="zh"><title>距离与相似性 | Next-gen Tech Edu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=7921d3ad78bd0ce286c5943f1386d706><button onclick=topFunction() id=backTopBtn title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden=true></i></button>
<script src=/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class="col-6 search-title"><p>搜索</p></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=关闭><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div><div id=search-common-queries></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/books-gallery><span>笔记（万篇）</span></a></li><li class=nav-item><a class=nav-link href=/#knowledge-map><span>知识图谱</span></a></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>实验室</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/galaxy-home/gh-craft><span>Craft 方块世界</span></a>
<a class=dropdown-item href=/galaxy-home/glossary-cards><span>3D 知识卡牌</span></a></div></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>其他阅读渠道</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png></img><span>知乎</span></a>
<a class=dropdown-item href=https://segmentfault.com/blog/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png></img><span>SegmentFault</span></a>
<a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png></img><span>掘金</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/wx-chevalier aria-label=GitHub><i class="fa-brands fa-github" aria-hidden=true></i></a></li><div></div><style>@media only screen and (max-width:600px){.jimmysong-template{display:none!important}}</style><li class=jimmysong-template style=color:#fff;font-size:12px><a href=https://jimmysong.io style=color:#fff>By Jimmy Song's Template</a></li></ul></div></nav></header></div><div class=page-body><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><div class="container-xl docs"><div class="row flex-xl-nowrap"><div class=docs-sidebar><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">线性代数</span>
<span><i class="fas fa-chevron-down"></i></span></div></button>
<button class="form-control sidebar-search js-search d-none d-md-flex">
<i class="fas fa-search pr-2"></i>
<span class=sidebar-search-text>搜索...</span>
<span class=sidebar-search-shortcut>/</span></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li style=display:inline-flex><a style=cursor:pointer onclick=window.history.back()><i class="fas fa-arrow-left pr-1"></i>
Back</a>
<span>|</span>
<a href=/books/><i class="fa-solid fa-house" style=margin-right:4px></i>
Books</a></li></ul><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-ida7ad54e0fa62d43091a3bef2b05c71f9")' href=#ida7ad54e0fa62d43091a3bef2b05c71f9 aria-expanded=false aria-controls=ida7ad54e0fa62d43091a3bef2b05c71f9 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/>Mathematics-Series</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#ida7ad54e0fa62d43091a3bef2b05c71f9 aria-expanded=false aria-controls=ida7ad54e0fa62d43091a3bef2b05c71f9><i class="fa-solid fa-angle-down" id=caret-ida7ad54e0fa62d43091a3bef2b05c71f9></i></a></div><ul class="nav docs-sidenav collapse show" id=ida7ad54e0fa62d43091a3bef2b05c71f9><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id0e10d898d163eb75cf570e98a5fe15fb")' href=#id0e10d898d163eb75cf570e98a5fe15fb aria-expanded=false aria-controls=id0e10d898d163eb75cf570e98a5fe15fb aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/>999.参考资料</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id0e10d898d163eb75cf570e98a5fe15fb aria-expanded=false aria-controls=id0e10d898d163eb75cf570e98a5fe15fb><i class="fa-solid fa-angle-right" id=caret-id0e10d898d163eb75cf570e98a5fe15fb></i></a></div><ul class="nav docs-sidenav collapse" id=id0e10d898d163eb75cf570e98a5fe15fb><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id9fe84e6d98bcbe8168989901d0a72734")' href=#id9fe84e6d98bcbe8168989901d0a72734 aria-expanded=false aria-controls=id9fe84e6d98bcbe8168989901d0a72734 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%95%B0%E5%AD%A6/>程序员数学</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id9fe84e6d98bcbe8168989901d0a72734 aria-expanded=false aria-controls=id9fe84e6d98bcbe8168989901d0a72734><i class="fa-solid fa-angle-right" id=caret-id9fe84e6d98bcbe8168989901d0a72734></i></a></div><ul class="nav docs-sidenav collapse" id=id9fe84e6d98bcbe8168989901d0a72734><li class="child level"><a href=/books/mathematics-series/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%95%B0%E5%AD%A6/%E5%A4%9A%E5%85%83%E5%87%BD%E6%95%B0%E5%BE%AE%E5%88%86%E5%AD%A6/>多元函数微分学</a></li><li class="child level"><a href=/books/mathematics-series/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86%E5%9F%BA%E7%A1%80/>微积分基础</a></li><li class="child level"><a href=/books/mathematics-series/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/>线性代数基础</a></li></ul></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idd2160dfb8c2300110c5b0b2230417a0a")' href=#idd2160dfb8c2300110c5b0b2230417a0a aria-expanded=false aria-controls=idd2160dfb8c2300110c5b0b2230417a0a aria-hidden=false data-toggle=collapse></div></div><li class="child level"><a href=/books/mathematics-series/introduction/>INTRODUCTION</a></li><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idb2374ba179cf6b1ae498a0aa96284b05")' href=#idb2374ba179cf6b1ae498a0aa96284b05 aria-expanded=false aria-controls=idb2374ba179cf6b1ae498a0aa96284b05 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/>贝叶斯理论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idb2374ba179cf6b1ae498a0aa96284b05 aria-expanded=false aria-controls=idb2374ba179cf6b1ae498a0aa96284b05><i class="fa-solid fa-angle-right" id=caret-idb2374ba179cf6b1ae498a0aa96284b05></i></a></div><ul class="nav docs-sidenav collapse" id=idb2374ba179cf6b1ae498a0aa96284b05><li class="child level"><a href=/books/mathematics-series/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-series/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>变分贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-series/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/>朴素贝叶斯</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-iddcc4378ef01fadd51c4f0c2af04f6818")' href=#iddcc4378ef01fadd51c4f0c2af04f6818 aria-expanded=false aria-controls=iddcc4378ef01fadd51c4f0c2af04f6818 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id54b5d383e397246e89bf4f5f828d21a1")' href=#id54b5d383e397246e89bf4f5f828d21a1 aria-expanded=false aria-controls=id54b5d383e397246e89bf4f5f828d21a1 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/>常见概率分布</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id54b5d383e397246e89bf4f5f828d21a1 aria-expanded=false aria-controls=id54b5d383e397246e89bf4f5f828d21a1><i class="fa-solid fa-angle-right" id=caret-id54b5d383e397246e89bf4f5f828d21a1></i></a></div><ul class="nav docs-sidenav collapse" id=id54b5d383e397246e89bf4f5f828d21a1><li class="child level"><a href=/books/mathematics-series/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E5%A4%9A%E9%A1%B9%E5%88%86%E5%B8%83/>多项分布</a></li><li class="child level"><a href=/books/mathematics-series/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83/>泊松分布</a></li><li class="child level"><a href=/books/mathematics-series/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/>正态分布</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id6024f0dbd144c9256f0814ad12077dcd")' href=#id6024f0dbd144c9256f0814ad12077dcd aria-expanded=false aria-controls=id6024f0dbd144c9256f0814ad12077dcd aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/>概率论基础</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id6024f0dbd144c9256f0814ad12077dcd aria-expanded=false aria-controls=id6024f0dbd144c9256f0814ad12077dcd><i class="fa-solid fa-angle-right" id=caret-id6024f0dbd144c9256f0814ad12077dcd></i></a></div><ul class="nav docs-sidenav collapse" id=id6024f0dbd144c9256f0814ad12077dcd><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83/>概率与分布</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE/>期望与方差</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/>中心极限与大数定理</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/>最小二乘法</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idbf4adf7583c4667c0c38dd576046588e")' href=#idbf4adf7583c4667c0c38dd576046588e aria-expanded=false aria-controls=idbf4adf7583c4667c0c38dd576046588e aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/>概率论与数理统计</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idbf4adf7583c4667c0c38dd576046588e aria-expanded=false aria-controls=idbf4adf7583c4667c0c38dd576046588e><i class="fa-solid fa-angle-right" id=caret-idbf4adf7583c4667c0c38dd576046588e></i></a></div><ul class="nav docs-sidenav collapse" id=idbf4adf7583c4667c0c38dd576046588e><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id1fbc56cc4d4cf78883e691f7aaa0e6c5")' href=#id1fbc56cc4d4cf78883e691f7aaa0e6c5 aria-expanded=false aria-controls=id1fbc56cc4d4cf78883e691f7aaa0e6c5 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/>贝叶斯理论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id1fbc56cc4d4cf78883e691f7aaa0e6c5 aria-expanded=false aria-controls=id1fbc56cc4d4cf78883e691f7aaa0e6c5><i class="fa-solid fa-angle-right" id=caret-id1fbc56cc4d4cf78883e691f7aaa0e6c5></i></a></div><ul class="nav docs-sidenav collapse" id=id1fbc56cc4d4cf78883e691f7aaa0e6c5><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>变分贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/>朴素贝叶斯</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id687cb6de49fba0afe98e13b6c833ede0")' href=#id687cb6de49fba0afe98e13b6c833ede0 aria-expanded=false aria-controls=id687cb6de49fba0afe98e13b6c833ede0 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idbd07a8033701263e5f1a7ae4c6115ff7")' href=#idbd07a8033701263e5f1a7ae4c6115ff7 aria-expanded=false aria-controls=idbd07a8033701263e5f1a7ae4c6115ff7 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/>常见概率分布</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idbd07a8033701263e5f1a7ae4c6115ff7 aria-expanded=false aria-controls=idbd07a8033701263e5f1a7ae4c6115ff7><i class="fa-solid fa-angle-right" id=caret-idbd07a8033701263e5f1a7ae4c6115ff7></i></a></div><ul class="nav docs-sidenav collapse" id=idbd07a8033701263e5f1a7ae4c6115ff7><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E5%A4%9A%E9%A1%B9%E5%88%86%E5%B8%83/>多项分布</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83/>泊松分布</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/>正态分布</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idc19b5a894ddf5e48c5ac3b2acef03948")' href=#idc19b5a894ddf5e48c5ac3b2acef03948 aria-expanded=false aria-controls=idc19b5a894ddf5e48c5ac3b2acef03948 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/>概率论基础</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idc19b5a894ddf5e48c5ac3b2acef03948 aria-expanded=false aria-controls=idc19b5a894ddf5e48c5ac3b2acef03948><i class="fa-solid fa-angle-right" id=caret-idc19b5a894ddf5e48c5ac3b2acef03948></i></a></div><ul class="nav docs-sidenav collapse" id=idc19b5a894ddf5e48c5ac3b2acef03948><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83/>概率与分布</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE/>期望与方差</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/>中心极限与大数定理</a></li><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/>最小二乘法</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id1e7621e7e0583d0826e6d83612b3eebc")' href=#id1e7621e7e0583d0826e6d83612b3eebc aria-expanded=false aria-controls=id1e7621e7e0583d0826e6d83612b3eebc aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/>概率图模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id1e7621e7e0583d0826e6d83612b3eebc aria-expanded=false aria-controls=id1e7621e7e0583d0826e6d83612b3eebc><i class="fa-solid fa-angle-right" id=caret-id1e7621e7e0583d0826e6d83612b3eebc></i></a></div><ul class="nav docs-sidenav collapse" id=id1e7621e7e0583d0826e6d83612b3eebc><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/>条件随机场</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id6fcdb1870f48792a03d4f4e856ebdf1f")' href=#id6fcdb1870f48792a03d4f4e856ebdf1f aria-expanded=false aria-controls=id6fcdb1870f48792a03d4f4e856ebdf1f aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>马尔科夫模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id6fcdb1870f48792a03d4f4e856ebdf1f aria-expanded=false aria-controls=id6fcdb1870f48792a03d4f4e856ebdf1f><i class="fa-solid fa-angle-right" id=caret-id6fcdb1870f48792a03d4f4e856ebdf1f></i></a></div><ul class="nav docs-sidenav collapse" id=id6fcdb1870f48792a03d4f4e856ebdf1f><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>隐马尔科夫模型</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-ide616362d3c0764903932e83382f8d5cb")' href=#ide616362d3c0764903932e83382f8d5cb aria-expanded=false aria-controls=ide616362d3c0764903932e83382f8d5cb aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/>蒙特卡洛</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#ide616362d3c0764903932e83382f8d5cb aria-expanded=false aria-controls=ide616362d3c0764903932e83382f8d5cb><i class="fa-solid fa-angle-right" id=caret-ide616362d3c0764903932e83382f8d5cb></i></a></div><ul class="nav docs-sidenav collapse" id=ide616362d3c0764903932e83382f8d5cb><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/>蒙特卡罗方法</a></li></ul></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id142b6ea4cd6747fe7c13e8b3028d7f41")' href=#id142b6ea4cd6747fe7c13e8b3028d7f41 aria-expanded=false aria-controls=id142b6ea4cd6747fe7c13e8b3028d7f41 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/>概率图模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id142b6ea4cd6747fe7c13e8b3028d7f41 aria-expanded=false aria-controls=id142b6ea4cd6747fe7c13e8b3028d7f41><i class="fa-solid fa-angle-right" id=caret-id142b6ea4cd6747fe7c13e8b3028d7f41></i></a></div><ul class="nav docs-sidenav collapse" id=id142b6ea4cd6747fe7c13e8b3028d7f41><li class="child level"><a href=/books/mathematics-series/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/>条件随机场</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id0c3059e3abdbd6146f1e9abfa4a7b2a8")' href=#id0c3059e3abdbd6146f1e9abfa4a7b2a8 aria-expanded=false aria-controls=id0c3059e3abdbd6146f1e9abfa4a7b2a8 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>马尔科夫模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id0c3059e3abdbd6146f1e9abfa4a7b2a8 aria-expanded=false aria-controls=id0c3059e3abdbd6146f1e9abfa4a7b2a8><i class="fa-solid fa-angle-right" id=caret-id0c3059e3abdbd6146f1e9abfa4a7b2a8></i></a></div><ul class="nav docs-sidenav collapse" id=id0c3059e3abdbd6146f1e9abfa4a7b2a8><li class="child level"><a href=/books/mathematics-series/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>隐马尔科夫模型</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idc88a55acaa8dbb6299bf1037258495d0")' href=#idc88a55acaa8dbb6299bf1037258495d0 aria-expanded=false aria-controls=idc88a55acaa8dbb6299bf1037258495d0 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/>蒙特卡洛</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idc88a55acaa8dbb6299bf1037258495d0 aria-expanded=false aria-controls=idc88a55acaa8dbb6299bf1037258495d0><i class="fa-solid fa-angle-right" id=caret-idc88a55acaa8dbb6299bf1037258495d0></i></a></div><ul class="nav docs-sidenav collapse" id=idc88a55acaa8dbb6299bf1037258495d0><li class="child level"><a href=/books/mathematics-series/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/>蒙特卡罗方法</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idd253460f3731cc578da5b77311cc49e9")' href=#idd253460f3731cc578da5b77311cc49e9 aria-expanded=false aria-controls=idd253460f3731cc578da5b77311cc49e9 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/>数据分析</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idd253460f3731cc578da5b77311cc49e9 aria-expanded=false aria-controls=idd253460f3731cc578da5b77311cc49e9><i class="fa-solid fa-angle-right" id=caret-idd253460f3731cc578da5b77311cc49e9></i></a></div><ul class="nav docs-sidenav collapse" id=idd253460f3731cc578da5b77311cc49e9><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id61497896cec7c2aba976ae77ba391287")' href=#id61497896cec7c2aba976ae77ba391287 aria-expanded=false aria-controls=id61497896cec7c2aba976ae77ba391287 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idf81ca56b01d83c0bd53b4619b2f72767")' href=#idf81ca56b01d83c0bd53b4619b2f72767 aria-expanded=false aria-controls=idf81ca56b01d83c0bd53b4619b2f72767 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id60b272af1c88b5de3531c6d4b98bd1b6")' href=#id60b272af1c88b5de3531c6d4b98bd1b6 aria-expanded=false aria-controls=id60b272af1c88b5de3531c6d4b98bd1b6 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/>遗传算法</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id60b272af1c88b5de3531c6d4b98bd1b6 aria-expanded=false aria-controls=id60b272af1c88b5de3531c6d4b98bd1b6><i class="fa-solid fa-angle-right" id=caret-id60b272af1c88b5de3531c6d4b98bd1b6></i></a></div><ul class="nav docs-sidenav collapse" id=id60b272af1c88b5de3531c6d4b98bd1b6><li class="child level"><a href=/books/mathematics-series/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/%E8%BF%9B%E5%8C%96%E8%BF%87%E7%A8%8B/>进化过程</a></li><li class="child level"><a href=/books/mathematics-series/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/%E7%94%9F%E7%89%A9%E5%AD%A6%E8%83%8C%E6%99%AF/>生物学背景</a></li></ul></div></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id753d52cd7be86b28f45acc5fd3466082")' href=#id753d52cd7be86b28f45acc5fd3466082 aria-expanded=false aria-controls=id753d52cd7be86b28f45acc5fd3466082 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/>数值计算</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id753d52cd7be86b28f45acc5fd3466082 aria-expanded=false aria-controls=id753d52cd7be86b28f45acc5fd3466082><i class="fa-solid fa-angle-right" id=caret-id753d52cd7be86b28f45acc5fd3466082></i></a></div><ul class="nav docs-sidenav collapse" id=id753d52cd7be86b28f45acc5fd3466082><li class="child level"><a href=/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%95%B0%E5%80%BC%E7%A8%B3%E5%AE%9A%E6%80%A7/>数值稳定性</a></li><li class="child level"><a href=/books/mathematics-series/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/>梯度下降</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id80147bf54cf04a654f07a6b389b49a60")' href=#id80147bf54cf04a654f07a6b389b49a60 aria-expanded=false aria-controls=id80147bf54cf04a654f07a6b389b49a60 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idb1d1e8648d03a2be8d7e588534eba1a7")' href=#idb1d1e8648d03a2be8d7e588534eba1a7 aria-expanded=false aria-controls=idb1d1e8648d03a2be8d7e588534eba1a7 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E5%BE%AE%E7%A7%AF%E5%88%86/>微积分</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idb1d1e8648d03a2be8d7e588534eba1a7 aria-expanded=false aria-controls=idb1d1e8648d03a2be8d7e588534eba1a7><i class="fa-solid fa-angle-right" id=caret-idb1d1e8648d03a2be8d7e588534eba1a7></i></a></div><ul class="nav docs-sidenav collapse" id=idb1d1e8648d03a2be8d7e588534eba1a7><li class="child level"><a href=/books/mathematics-series/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%B8%B8%E8%A7%81%E5%AF%BC%E6%95%B0/>常见导数</a></li><li class="child level"><a href=/books/mathematics-series/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%AF%BC%E6%95%B0/>导数</a></li><li class="child level"><a href=/books/mathematics-series/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%87%BD%E6%95%B0%E6%9E%81%E9%99%90%E4%B8%8E%E8%BF%9E%E7%BB%AD/>函数、极限与连续</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id78785b31e36af3d3c14f3a4c2d01d9d7")' href=#id78785b31e36af3d3c14f3a4c2d01d9d7 aria-expanded=false aria-controls=id78785b31e36af3d3c14f3a4c2d01d9d7 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/>线性代数</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id78785b31e36af3d3c14f3a4c2d01d9d7 aria-expanded=false aria-controls=id78785b31e36af3d3c14f3a4c2d01d9d7><i class="fa-solid fa-angle-down" id=caret-id78785b31e36af3d3c14f3a4c2d01d9d7></i></a></div><ul class="nav docs-sidenav collapse show" id=id78785b31e36af3d3c14f3a4c2d01d9d7><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id8671b6b5aa5d40e2d851e753f7062354")' href=#id8671b6b5aa5d40e2d851e753f7062354 aria-expanded=false aria-controls=id8671b6b5aa5d40e2d851e753f7062354 aria-hidden=false data-toggle=collapse></div></div><li class="child level active"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/>距离与相似性</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>矩阵分解</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/>矩阵运算</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E5%87%BD%E6%95%B0/>特殊函数</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%98%B5/>特殊矩阵</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E8%BF%90%E7%AE%97/>向量运算</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id3bee51418abb4319b80d41a4e300c176")' href=#id3bee51418abb4319b80d41a4e300c176 aria-expanded=false aria-controls=id3bee51418abb4319b80d41a4e300c176 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/>线性代数基础</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id3bee51418abb4319b80d41a4e300c176 aria-expanded=false aria-controls=id3bee51418abb4319b80d41a4e300c176><i class="fa-solid fa-angle-right" id=caret-id3bee51418abb4319b80d41a4e300c176></i></a></div><ul class="nav docs-sidenav collapse" id=id3bee51418abb4319b80d41a4e300c176><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E8%B7%9D%E7%A6%BB%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7/>距离与相似性</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>矩阵分解</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/>矩阵运算</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E7%89%B9%E6%AE%8A%E5%87%BD%E6%95%B0/>特殊函数</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%98%B5/>特殊矩阵</a></li><li class="child level"><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/%E5%90%91%E9%87%8F%E8%BF%90%E7%AE%97/>向量运算</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-ide2cb99b50669e766f6186d01cf363850")' href=#ide2cb99b50669e766f6186d01cf363850 aria-expanded=false aria-controls=ide2cb99b50669e766f6186d01cf363850 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E4%BF%A1%E6%81%AF%E8%AE%BA/>信息论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#ide2cb99b50669e766f6186d01cf363850 aria-expanded=false aria-controls=ide2cb99b50669e766f6186d01cf363850><i class="fa-solid fa-angle-right" id=caret-ide2cb99b50669e766f6186d01cf363850></i></a></div><ul class="nav docs-sidenav collapse" id=ide2cb99b50669e766f6186d01cf363850><li class="child level"><a href=/books/mathematics-series/%E4%BF%A1%E6%81%AF%E8%AE%BA/kl-%E6%95%A3%E5%BA%A6/>KL 散度</a></li><li class="child level"><a href=/books/mathematics-series/%E4%BF%A1%E6%81%AF%E8%AE%BA/%E7%86%B5/>熵</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idd5cb59202e98935081cf93655fad9069")' href=#idd5cb59202e98935081cf93655fad9069 aria-expanded=false aria-controls=idd5cb59202e98935081cf93655fad9069 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/>优化理论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idd5cb59202e98935081cf93655fad9069 aria-expanded=false aria-controls=idd5cb59202e98935081cf93655fad9069><i class="fa-solid fa-angle-right" id=caret-idd5cb59202e98935081cf93655fad9069></i></a></div><ul class="nav docs-sidenav collapse" id=idd5cb59202e98935081cf93655fad9069><li class="child level"><a href=/books/mathematics-series/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/>代价函数</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id4deed74c5170332cf6f6daecffb54ad8")' href=#id4deed74c5170332cf6f6daecffb54ad8 aria-expanded=false aria-controls=id4deed74c5170332cf6f6daecffb54ad8 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/>最优化方法</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id4deed74c5170332cf6f6daecffb54ad8 aria-expanded=false aria-controls=id4deed74c5170332cf6f6daecffb54ad8><i class="fa-solid fa-angle-right" id=caret-id4deed74c5170332cf6f6daecffb54ad8></i></a></div><ul class="nav docs-sidenav collapse" id=id4deed74c5170332cf6f6daecffb54ad8><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idafeaaccca076e7ba3739b8aae81d9913")' href=#idafeaaccca076e7ba3739b8aae81d9913 aria-expanded=false aria-controls=idafeaaccca076e7ba3739b8aae81d9913 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id735a07b31ac58855090c320629b31405")' href=#id735a07b31ac58855090c320629b31405 aria-expanded=false aria-controls=id735a07b31ac58855090c320629b31405 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id368db30784d98da9c6b367d5d924312a")' href=#id368db30784d98da9c6b367d5d924312a aria-expanded=false aria-controls=id368db30784d98da9c6b367d5d924312a aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-series/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/>优化理论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id368db30784d98da9c6b367d5d924312a aria-expanded=false aria-controls=id368db30784d98da9c6b367d5d924312a><i class="fa-solid fa-angle-right" id=caret-id368db30784d98da9c6b367d5d924312a></i></a></div><ul class="nav docs-sidenav collapse" id=id368db30784d98da9c6b367d5d924312a><li class="child level"><a href=/books/mathematics-series/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/>代价函数</a></li></ul></div></ul></div></ul></div></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>目录</a></li></ul><nav id=TableOfContents><ul><li><ul><li><a href=#闵可夫斯基距离>闵可夫斯基距离</a></li><li><a href=#马氏距离>马氏距离</a></li></ul></li><li><a href=#类别点距离categorical-data-points>类别点距离(categorical data points)</a><ul><li><a href=#汉明距离>汉明距离</a></li><li><a href=#jacard-相似度>Jacard 相似度</a></li></ul></li><li><a href=#向量内积>向量内积</a><ul><li><a href=#余弦相似度>余弦相似度</a></li><li><a href=#皮尔逊相关系数pearson-correlation-coefficient>皮尔逊相关系数(Pearson Correlation Coefficient)</a></li></ul></li><li><a href=#序列距离stringtimeseries>序列距离(String,TimeSeries)</a><ul><li><a href=#dtwdynamic-time-warp>DTW(Dynamic Time Warp)</a></li></ul></li><li><a href=#网络节点距离>网络节点距离</a></li><li><a href=#分布距离>分布距离</a></li></ul></nav><div class="subscribe-module col-24 mt-1"><img src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png alt=image title=王下邀月熊的微信公众号></div></div><main class="py-md-3 pl-md-3 docs-content col-xl-8" role=main><article class=article><h1>距离与相似性</h1><div class=article-style><ul><li><a href=https://github.com/tdebatty/java-string-similarity target=_blank rel=noopener>java-string-similarity</a> > <a href=https://dzone.com/articles/machine-learning-measuring target=_blank rel=noopener>Machine Learning: Measuring Similarity and Distance</a> > <a href=http://www.cnblogs.com/daniel-D/p/3244718.html target=_blank rel=noopener>漫谈：机器学习中距离和相似性度量方法</a></li></ul><h1 id=数值点距离numeric-data-points-numeric-data-points>数值点距离:numeric data points Numeric Data Points</h1><h3 id=闵可夫斯基距离>闵可夫斯基距离</h3><p><strong>闵可夫斯基距离</strong>(Minkowski distance)是衡量数值点之间距离的一种非常常见的方法，假设数值点 P 和 Q 坐标如下：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220422-b6c5a38eccb74824b92ba1b40c9dd92f.png alt loading=lazy data-zoomable></div></div></figure></p><p>那么，闵可夫斯基距离定义为：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220504-12655edb08dc45ae8a036d8028743042.png alt loading=lazy data-zoomable></div></div></figure></p><p>该距离最常用的 p 是 2 和 1, 前者是<strong>欧几里得距离</strong>(Euclidean distance)，后者是<strong>曼哈顿距离</strong>(Manhattan distance)。假设在曼哈顿街区乘坐出租车从 P 点到 Q 点，白色表示高楼大厦，灰色表示街道：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220530-1c87c470c5984305932cb5f5fc91656f.png alt loading=lazy data-zoomable></div></div></figure></p><p>绿色的斜线表示欧几里得距离，在现实中是不可能的。其他三条折线表示了曼哈顿距离，这三条折线的长度是相等的。</p><p>当 p 趋近于无穷大时，闵可夫斯基距离转化成<strong>切比雪夫距离</strong>(Chebyshev distance)：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220549-4fb4c30e7fb84ca290d04f44f75dea7b.png alt loading=lazy data-zoomable></div></div></figure></p><p>我们知道平面上到原点欧几里得距离(p = 2)为 1 的点所组成的形状是一个圆，当 p 取其他数值的时候呢？</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220559-ae662025d1394f90bfd62f7c21c3d895.png alt loading=lazy data-zoomable></div></div></figure></p><p>注意，当 <code>p &lt; 1</code> 时，闵可夫斯基距离不再符合三角形法则，举个例子：当 p <code>&lt;</code> 1, (0,0) 到 (1,1) 的距离等于<code>(1+1)^{1/p} > 2</code>, 而 (0,1) 到这两个点的距离都是 1。</p><p>闵可夫斯基距离比较直观，但是它与数据的分布无关，具有一定的局限性，如果 x 方向的幅值远远大于 y 方向的值，这个距离公式就会过度放大 x 维度的作用。所以，在计算距离之前，我们可能还需要对数据进行 <strong>z-transform</strong> 处理，即减去均值，除以标准差：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://latex.codecogs.com/gif.latex?%28x_1,%20y_1%29%5Cmapsto%20%28%5Cfrac%7Bx_1%20-%20%5Cmu%20_x%7D%7B%5Csigma%20_x%7D,%20%5Cfrac%7By_1%20-%20%5Cmu%20_y%7D%7B%5Csigma%20_y%7D%29 alt loading=lazy data-zoomable></div></div></figure></p><blockquote><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://latex.codecogs.com/gif.latex?%5Cmu alt loading=lazy data-zoomable></div></div></figure>: 该维度上的均值</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://latex.codecogs.com/gif.latex?%5Csigma alt loading=lazy data-zoomable></div></div></figure>: 该维度上的标准差</p></blockquote><p>可以看到，上述处理开始体现数据的统计特性了。这种方法在假设数据各个维度不相关的情况下利用数据分布的特性计算出不同的距离。如果维度相互之间数据相关(例如：身高较高的信息很有可能会带来体重较重的信息，因为两者是有关联的)，这时候就要用到<strong>马氏距离</strong>(Mahalanobis distance)了。</p><h3 id=马氏距离>马氏距离</h3><p>考虑下面这张图，椭圆表示等高线，从欧几里得的距离来算，绿黑距离大于红黑距离，但是从马氏距离，结果恰好相反：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220637-f472bb13a779481bbfa45a9d79bd2175.png alt loading=lazy data-zoomable></div></div></figure></p><p>马氏距离实际上是利用 Cholesky transformation 来消除不同维度之间的<strong>相关性</strong>和<strong>尺度不同</strong>的性质。假设样本点(列向量)之间的协方差对称矩阵是<figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://latex.codecogs.com/gif.latex?%5CSigma alt loading=lazy data-zoomable></div></div></figure>，通过 Cholesky Decomposition(实际上是对称矩阵 LU 分解的一种特殊形式，可参考之前的<a href=http://www.cnblogs.com/daniel-D/p/3204508.html target=_blank rel=noopener>博客</a>)可以转化为下三角矩阵和上三角矩阵的乘积:<figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?%5CSigma%20=%20LL%5ET" alt loading=lazy data-zoomable></div></div></figure>。消除不同维度之间的相关性和尺度不同，只需要对样本点 x 做如下处理：<figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?z%20=%20L%5E%7B-1%7D%28x%20-%20%5Cmu%20%29" alt loading=lazy data-zoomable></div></div></figure>。处理之后的欧几里得距离就是原样本的马氏距离：为了书写方便，这里求马氏距离的平方)：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220659-e3270d8a52ef45c1b457d9af19b1aad1.png alt loading=lazy data-zoomable></div></div></figure></p><p>下图蓝色表示原样本点的分布，两颗红星坐标分别是(3, 3)，(2, -2):</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220711-7c326cd8835a446d94684e6adb7ff75a.png alt loading=lazy data-zoomable></div></div></figure></p><p>由于 x，y 方向的尺度不同，不能单纯用欧几里得的方法测量它们到原点的距离。并且，由于 x 和 y 是相关的(大致可以看出斜向右上)，也不能简单地在 x 和 y 方向上分别减去均值，除以标准差。最恰当的方法是对原始数据进行 Cholesky 变换，即求马氏距离(可以看到，右边的红星离原点较近)：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07220737-b9ab6c4b19d64590998685325ae49bd1.png alt loading=lazy data-zoomable></div></div></figure></p><p>将上面两个图的绘制代码和求马氏距离的代码贴在这里，以备以后查阅：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding=utf-8 -*-</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># code related at: http://www.cnblogs.com/daniel-D/</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pylab</span> <span class=k>as</span> <span class=nn>pl</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>scipy.spatial.distance</span> <span class=k>as</span> <span class=nn>dist</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>plotSamples</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>stars</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>matrix</span><span class=p>([[</span><span class=mf>3.</span><span class=p>,</span> <span class=o>-</span><span class=mf>2.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>],</span> <span class=p>[</span><span class=mf>3.</span><span class=p>,</span> <span class=mf>2.</span><span class=p>,</span> <span class=mf>0.</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>z</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>z</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>matrix</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>stars</span> <span class=o>=</span> <span class=n>z</span> <span class=o>*</span> <span class=n>stars</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>    <span class=c1># 画 gaussian 随机点</span>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>stars</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>stars</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span> <span class=n>s</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;*&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>)</span>  <span class=c1># 画三个指定点</span>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;g&#39;</span><span class=p>)</span> <span class=c1># 画 x 轴</span>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;g&#39;</span><span class=p>)</span>  <span class=c1># 画 y 轴</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;equal&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>axis</span><span class=p>([</span><span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>pl</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 产生高斯分布的随机点</span>
</span></span><span class=line><span class=cl><span class=n>mean</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>      <span class=c1># 平均值</span>
</span></span><span class=line><span class=cl><span class=n>cov</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]]</span>   <span class=c1># 协方差</span>
</span></span><span class=line><span class=cl><span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>multivariate_normal</span><span class=p>(</span><span class=n>mean</span><span class=p>,</span> <span class=n>cov</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl><span class=n>plotSamples</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>covMat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>matrix</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>cov</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>))</span>    <span class=c1># 求 x 与 y 的协方差矩阵</span>
</span></span><span class=line><span class=cl><span class=n>Z</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>cholesky</span><span class=p>(</span><span class=n>covMat</span><span class=p>)</span><span class=o>.</span><span class=n>I</span>  <span class=c1># 仿射矩阵</span>
</span></span><span class=line><span class=cl><span class=n>plotSamples</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>Z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 求马氏距离</span>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=s1>&#39;</span><span class=se>\n</span><span class=s1>到原点的马氏距离分别是：&#39;</span>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=n>dist</span><span class=o>.</span><span class=n>mahalanobis</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>],</span> <span class=n>covMat</span><span class=o>.</span><span class=n>I</span><span class=p>),</span> <span class=n>dist</span><span class=o>.</span><span class=n>mahalanobis</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>],</span> <span class=n>covMat</span><span class=o>.</span><span class=n>I</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 求变换后的欧几里得距离</span>
</span></span><span class=line><span class=cl><span class=n>dots</span> <span class=o>=</span> <span class=p>(</span><span class=n>Z</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>matrix</span><span class=p>([[</span><span class=mi>3</span><span class=p>,</span> <span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>]]))</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=s1>&#39;</span><span class=se>\n</span><span class=s1>变换后到原点的欧几里得距离分别是：&#39;</span>
</span></span><span class=line><span class=cl><span class=nb>print</span> <span class=n>dist</span><span class=o>.</span><span class=n>minkowski</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>dots</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=mi>2</span><span class=p>),</span> <span class=n>dist</span><span class=o>.</span><span class=n>minkowski</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>dots</span><span class=p>[</span><span class=mi>1</span><span class=p>]),</span> <span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></div><p>马氏距离的变换和 PCA 分解的<a href=http://deeplearning.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96 target=_blank rel=noopener>白化处理</a>颇有异曲同工之妙，不同之处在于：就二维来看，PCA 是将数据主成分旋转到 x 轴(正交矩阵的酉变换)，再在尺度上缩放(对角矩阵)，实现尺度相同。而马氏距离的 L 逆矩阵是一个下三角，先在 x 和 y 方向进行缩放，再在 y 方向进行错切(想象矩形变平行四边形)，总体来说是一个没有旋转的仿射变换。</p><h2 id=类别点距离categorical-data-points>类别点距离(categorical data points)</h2><p>$distance_{final} = α.distance_{numeric} + (1- α).distance_{categorical}$</p><h3 id=汉明距离>汉明距离</h3><p><strong>汉明距离</strong>(Hamming distance)是指，两个等长字符串 s1 与 s2 之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。举个维基百科上的例子：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07221109-c683a8f31c9a4e31a93e5d04fdab3443.png alt loading=lazy data-zoomable></div></div></figure></p><p>还可以用简单的<strong>匹配系数</strong>来表示两点之间的相似度——匹配字符数/总字符数。在一些情况下，某些特定的值相等并不能代表什么。举个例子，用 1 表示用户看过该电影，用 0 表示用户没有看过，那么用户看电影的的信息就可用 0,1 表示成一个序列。考虑到电影基数非常庞大，用户看过的电影只占其中非常小的一部分，如果两个用户都没有看过某一部电影(两个都是 0)，并不能说明两者相似。反而言之，如果两个用户都看过某一部电影(序列中都是 1)，则说明用户有很大的相似度。在这个例子中，序列中等于 1 所占的权重应该远远大于 0 的权重，这就引出下面要说的<strong>杰卡德相似系数</strong>(Jaccard similarity)。</p><h3 id=jacard-相似度>Jacard 相似度</h3><p>Jacard 相似性直观的概念来自，两个集合有多相似，显然，Jacard 最好是应用在离散的变量几何上。先看公式：</p><pre><code>                            ![ J(A,B) = {{|A /cap B|}/over{|A /cup B|}}.](http://upload.wikimedia.org/math/1/8/6/186c7f4e83da32e889d606140fae25a0.png)
</code></pre><p>分子是集合交集，分母是集合并集，画个图，马上就明白咋回事了。</p><p>和 Jacard index 相似的一个公式是 Dice‘ coefficient, 它也很直观，<figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://upload.wikimedia.org/math/2/3/5/2354a9c697d2bf4ae114b8f1f72d5090.png alt="s = /frac{2 | X /cap Y |}{| X | + | Y |} " loading=lazy data-zoomable></div></div></figure></p><h2 id=向量内积>向量内积</h2><p>向量内积是线性代数里最为常见的计算，实际上它还是一种有效并且直观的相似性测量手段。向量内积的定义如下：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?Inner%28x,y%29%20=%20%5Clangle%20x,%20y%20%5Crangle%20=%20%5Csum_i%20x_i%20y_i" alt loading=lazy data-zoomable></div></div></figure></p><p>直观的解释是：如果 x 高的地方 y 也比较高，x 低的地方 y 也比较低，那么整体的内积是偏大的，也就是说 x 和 y 是相似的。举个例子，在一段长的序列信号 A 中寻找哪一段与短序列信号 a 最匹配，只需要将 a 从 A 信号开头逐个向后平移，每次平移做一次内积，内积最大的相似度最大。信号处理中 DFT 和 DCT 也是基于这种内积运算计算出不同频域内的信号组分(DFT 和 DCT 是正交标准基，也可以看做投影)。向量和信号都是离散值，如果是连续的函数值，比如求区间<code>[-1, 1]</code> 两个函数之间的相似度，同样也可以得到(系数)组分，这种方法可以应用于多项式逼近连续函数，也可以用到连续函数逼近离散样本点(最小二乘问题，<strong>OLS coefficients</strong>)中，扯得有点远了- -!。</p><h3 id=余弦相似度>余弦相似度</h3><p>向量内积的结果是没有界限的，一种解决办法是除以长度之后再求内积，这就是应用十分广泛的<strong>余弦相似度</strong>(Cosine similarity)：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?CosSim%28x,y%29%20=%20%5Cfrac%7B%5Csum_i%20x_i%20y_i%7D%7B%20%5Csqrt%7B%20%5Csum_i%20x_i%5E2%7D%20%5Csqrt%7B%20%5Csum_i%20y_i%5E2%20%7D%20%7D%20=%20%5Cfrac%7B%20%5Clangle%20x,y%20%5Crangle%20%7D%7B%20%7C%7Cx%7C%7C%5C%20%7C%7Cy%7C%7C%20%7D" alt loading=lazy data-zoomable></div></div></figure></p><p>余弦相似度与向量的幅值无关，只与向量的方向相关，在文档相似度(<a href=http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html target=_blank rel=noopener>TF-IDF</a>)和图片相似性(<a href=http://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html target=_blank rel=noopener>histogram</a>)计算上都有它的身影。</p><h3 id=皮尔逊相关系数pearson-correlation-coefficient>皮尔逊相关系数(Pearson Correlation Coefficient)</h3><p>需要注意一点的是，余弦相似度受到向量的平移影响，上式如果将 x 平移到 x+1, 余弦值就会改变。怎样才能实现平移不变性？这就是下面要说的<strong>皮尔逊相关系数</strong>(Pearson correlation)，有时候也直接叫<strong>相关系数</strong>。皮尔逊相关系数是一种度量两个变量间相关程度的方法。它是一个介于 1 和 -1 之间的值，其中，1 表示变量完全正相关，0 表示无关，-1 表示完全负相关。</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?%5Cbegin%7Balign%7D%20Corr%28x,y%29%20&=%20%5Cfrac%7B%20%5Csum_i%20%28x_i-%5Cbar%7Bx%7D%29%20%28y_i-%5Cbar%7By%7D%29%20%7D%7B%20%5Csqrt%7B%5Csum%20%28x_i-%5Cbar%7Bx%7D%29%5E2%7D%20%5Csqrt%7B%20%5Csum%20%28y_i-%5Cbar%7By%7D%29%5E2%20%7D%20%7D%20&=%20%5Cfrac%7B%5Clangle%20x-%5Cbar%7Bx%7D,%5C%20y-%5Cbar%7By%7D%20%5Crangle%7D%7B%20%7C%7Cx-%5Cbar%7Bx%7D%7C%7C%5C%20%7C%7Cy-%5Cbar%7By%7D%7C%7C%7D%20%20%20&=%20CosSim%28x-%5Cbar%7Bx%7D,%20y-%5Cbar%7By%7D%29%20%5Cend%7Balign%7D" alt loading=lazy data-zoomable></div></div></figure></p><p>=</p><p>$\frac{\sum x_iy_i-\frac{\sum x_i\sum y_i}{n}}{\sqrt{\sum x_i^2-\frac{(\sum x_i)^2}{n}}\sqrt{\sum y_i^2-\frac{(\sum y_i)^2}{n}}}$</p><p>在推荐系统中，我们常用皮尔逊相关系数来衡量两个用户兴趣的相似度，它是判断两组数据与某一直线拟合程度的一种度量。它在用户对物品的评分数据差别大时(如有些用户评分普遍较高，有些用户评分普遍偏低)时的效果更好。也即它修正了“夸大分值”的情况，如果某个用户总是倾向于给出比另一个人更高的分值，而两者的分值之差又始终保持一致，则两者间依然可能存在很好地相关性。</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://7xlv6k.com1.z0.glb.clouddn.com/cdn_chapter2_2.png alt loading=lazy data-zoomable></div></div></figure></p><p>在<a href=http://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6 target=_blank rel=noopener>统计学</a>中，<strong>皮尔逊积矩相关系数</strong>(Pearson product-moment correlation coefficient)用于度量两个变量 X 和 Y 之间的<a href=http://zh.wikipedia.org/wiki/%E7%9B%B8%E5%85%B3 target=_blank rel=noopener>相关</a>(线性相关)，其值介于-1 与 1 之间。系数的值为 1 意味着<em>X</em> 和 <em>Y</em>可以很好的由直线方程来描述，所有的数据点都很好的落在一条 <a href="http://zh.wikipedia.org/w/index.php?title=Line_%28mathematics%29&action=edit&redlink=1" target=_blank rel=noopener>直线</a>上，且 <em>Y</em> 随着 <em>X</em> 的增加而增加。系数的值为?1 意味着所有的数据点都落在直线上，且 <em>Y</em> 随着 <em>X</em> 的增加而减少。系数的值为 0 意味着两个变量之间没有线性关系。当两个变量独立时，相关系数为 0.但反之并不成立。这是因为相关系数仅仅反映了两个变量之间是否线性相关。比如说，<em>X</em>是区间［－１，１］上的一个均匀分布的随机变量。<em>Y</em> = <em>X</em>2. 那么<em>Y</em>是完全由<em>X</em>确定。因此<em>Y</em> 和<em>X</em>是不独立的。但是相关系数为 0。或者说他们是不相关的。当<em>Y</em> 和<em>X</em>服从联合正态分布时，其相互独立和不相关是等价的。当且仅当 <em>X**i</em> and <em>Y**i</em> 均落在他们各自的均值的同一侧，则(<em>X**i</em> ? <em>X</em>)(<em>Y**i</em> ? <em>Y</em>) 的值为正。也就是说，如果<em>X**i</em> 和 <em>Y**i</em> 同时趋向于大于, 或同时趋向于小于他们各自的均值，则相关系数为正。如果 <em>X**i</em> 和 <em>Y**i</em> 趋向于落在他们均值的相反一侧，则相关系数为负。</p><p>皮尔逊相关系数具有平移不变性和尺度不变性，计算出了两个向量(维度)的相关性。不过，一般我们在谈论相关系数的时候，将 x 与 y 对应位置的两个数值看作一个样本点，皮尔逊系数用来表示这些样本点分布的相关性。</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07221044-45cc00fed26d4c6796f4d9b9072dc177.png alt loading=lazy data-zoomable></div></div></figure></p><p>由于皮尔逊系数具有的良好性质，在各个领域都应用广泛，例如，在推荐系统根据为某一用户查找喜好相似的用户,进而<a href=http://www.cnblogs.com/daniel-D/p/3192180.html target=_blank rel=noopener>提供推荐</a>，优点是可以不受每个用户评分标准不同和观看影片数量不一样的影响。</p><blockquote><p>例如，假设五个国家的国民生产总值分别是 1、2、3、5、8(单位 10 亿美元)，又假设这五个国家的贫困比例分别是 11%、12%、13%、15%、18%。</p></blockquote><p>创建 2 个向量.(R 语言)</p><pre tabindex=0><code>x&lt;-c(1,2,3,5,8)
y&lt;-c(0.11,0.12,0.13,0.15,0.18)
</code></pre><p>按照维基的例子,应计算出相关系数为 1 出来.我们看看如何一步一步计算出来的.</p><p>x 的平均数是:3.8</p><p>y 的平均数是 0.138</p><p>所以,</p><pre tabindex=0><code>sum((x-mean(x))*(y-mean(y)))=0.308
</code></pre><p>用大白话来写就是:</p><p>(1-3.8)*(0.11-0.138)=0.0784</p><p>(2-3.8)*(0.12-0.138)=0.0324</p><p>(3-3.8)*(0.13-0.138)=0.0064</p><p>(5-3.8)*(0.15-0.138)=0.0144</p><p>(8-3.8)*(0.18-0.138)=0.1764</p><p>0.0784+0.0324+0.0064+0.0144+0.1764=0.308</p><p>同理, 分号下面的,分别是:</p><p>sum((x-mean(x))^2)=30.8</p><p>sum((y-mean(y))^2)= 0.00308</p><p>用大白话来写,分别是:</p><p>(1-3.8)^2=7.84 #平方</p><p>(2-3.8)^2=3.24 #平方</p><p>(3-3.8)^2=0.64 #平方</p><p>(5-3.8)^2=1.44 #平方</p><p>(8-3.8)^2=17.64 #平方</p><p>7.84+3.24+0.64+1.44+17.64=30.8</p><p>同理,求得:</p><pre tabindex=0><code>sum((y-mean(y))^2)= 0.00308
</code></pre><p>然后再开平方根,分别是:</p><p>30.8^0.5=5.549775</p><p>0.00308^0.5=0.05549775</p><p>用分子除以分母,就计算出最终结果:</p><p>0.308/(5.549775*0.05549775)=1</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#皮尔逊相关度</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sim_pearson</span><span class=p>(</span><span class=n>prefs</span><span class=p>,</span><span class=n>p1</span><span class=p>,</span><span class=n>p2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>si</span><span class=o>=</span><span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>prefs</span><span class=p>[</span><span class=n>p1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>prefs</span><span class=p>[</span><span class=n>p2</span><span class=p>]:</span> <span class=n>si</span><span class=p>[</span><span class=n>item</span><span class=p>]</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>si</span><span class=p>)</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span> <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>n</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>si</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>#计算开始</span>
</span></span><span class=line><span class=cl>    <span class=n>sum1</span><span class=o>=</span><span class=nb>sum</span><span class=p>([</span><span class=n>prefs</span><span class=p>[</span><span class=n>p1</span><span class=p>][</span><span class=n>it</span><span class=p>]</span> <span class=k>for</span> <span class=n>it</span> <span class=ow>in</span> <span class=n>si</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>sum2</span><span class=o>=</span><span class=nb>sum</span><span class=p>([</span><span class=n>prefs</span><span class=p>[</span><span class=n>p2</span><span class=p>][</span><span class=n>it</span><span class=p>]</span> <span class=k>for</span> <span class=n>it</span> <span class=ow>in</span> <span class=n>si</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>sum1Sq</span><span class=o>=</span><span class=nb>sum</span><span class=p>([</span><span class=nb>pow</span><span class=p>(</span><span class=n>prefs</span><span class=p>[</span><span class=n>p1</span><span class=p>][</span><span class=n>it</span><span class=p>],</span><span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>it</span> <span class=ow>in</span> <span class=n>si</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>sum2Sq</span><span class=o>=</span><span class=nb>sum</span><span class=p>([</span><span class=nb>pow</span><span class=p>(</span><span class=n>prefs</span><span class=p>[</span><span class=n>p2</span><span class=p>][</span><span class=n>it</span><span class=p>],</span><span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>it</span> <span class=ow>in</span> <span class=n>si</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pSum</span><span class=o>=</span><span class=nb>sum</span><span class=p>([</span><span class=n>prefs</span><span class=p>[</span><span class=n>p1</span><span class=p>][</span><span class=n>it</span><span class=p>]</span><span class=o>*</span><span class=n>prefs</span><span class=p>[</span><span class=n>p2</span><span class=p>][</span><span class=n>it</span><span class=p>]</span> <span class=k>for</span> <span class=n>it</span> <span class=ow>in</span> <span class=n>si</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num</span><span class=o>=</span><span class=n>pSum</span><span class=o>-</span><span class=p>(</span><span class=n>sum1</span><span class=o>*</span><span class=n>sum2</span><span class=o>/</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>den</span><span class=o>=</span><span class=n>sqrt</span><span class=p>((</span><span class=n>sum1Sq</span><span class=o>-</span><span class=nb>pow</span><span class=p>(</span><span class=n>sum1</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span><span class=o>/</span><span class=n>n</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=n>sum2Sq</span><span class=o>-</span><span class=nb>pow</span><span class=p>(</span><span class=n>sum2</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span><span class=o>/</span><span class=n>n</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1>#计算结束</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>den</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span> <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>r</span><span class=o>=</span><span class=n>num</span><span class=o>/</span><span class=n>den</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>r</span>
</span></span></code></pre></div><h2 id=序列距离stringtimeseries>序列距离(String,TimeSeries)</h2><h3 id=dtwdynamic-time-warp>DTW(Dynamic Time Warp)</h3><p>汉明距离可以度量两个长度相同的字符串之间的相似度，如果要比较两个不同长度的字符串，不仅要进行替换，而且要进行插入与删除的运算，在这种场合下，通常使用更加复杂的<strong>编辑距离</strong>(Edit distance, Levenshtein distance)等算法。编辑距离是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。编辑距离求的是最少编辑次数，这是一个动态规划的问题，有兴趣的同学可以自己研究研究。</p><p>时间序列是序列之间距离的另外一个例子。<strong>DTW 距离</strong>(Dynamic Time Warp)是序列信号在时间或者速度上不匹配的时候一种衡量相似度的方法。神马意思？举个例子，两份原本一样声音样本 A、B 都说了“你好”，A 在时间上发生了扭曲，“你”这个音延长了几秒。最后 A:“你~~~~~~~好”，B：“你好”。DTW 正是这样一种可以用来匹配 A、B 之间的最短距离的算法。</p><p>DTW 距离在保持信号先后顺序的限制下对时间信号进行“膨胀”或者“收缩”，找到最优的匹配，与编辑距离相似，这其实也是一个动态规划的问题:</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07221153-ea76b098f70a4a68b4929789c032ef69.png alt loading=lazy data-zoomable></div></div></figure></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=ch>#!/usr/bin/python2</span>
</span></span><span class=line><span class=cl><span class=c1># -*- coding:UTF-8 -*-</span>
</span></span><span class=line><span class=cl><span class=c1># code related at: http://blog.mckelv.in/articles/1453.html</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>distance</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>a</span><span class=p>,</span><span class=n>b</span> <span class=p>:</span> <span class=mi>0</span> <span class=k>if</span> <span class=n>a</span><span class=o>==</span><span class=n>b</span> <span class=k>else</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>dtw</span><span class=p>(</span><span class=n>sa</span><span class=p>,</span><span class=n>sb</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>    &gt;&gt;&gt;dtw(u&#34;干啦今今今今今天天气气气气气好好好好啊啊啊&#34;, u&#34;今天天气好好啊&#34;)
</span></span></span><span class=line><span class=cl><span class=s1>    2
</span></span></span><span class=line><span class=cl><span class=s1>    &#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>MAX_COST</span> <span class=o>=</span> <span class=mi>1</span><span class=o>&lt;&lt;</span><span class=mi>32</span>
</span></span><span class=line><span class=cl>    <span class=c1>#初始化一个len(sb) 行(i)，len(sa)列(j)的二维矩阵</span>
</span></span><span class=line><span class=cl>    <span class=n>len_sa</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sa</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>len_sb</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># BUG:这样是错误的(浅拷贝): dtw_array = [[MAX_COST]*len(sa)]*len(sb)</span>
</span></span><span class=line><span class=cl>    <span class=n>dtw_array</span> <span class=o>=</span> <span class=p>[[</span><span class=n>MAX_COST</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>len_sa</span><span class=p>)]</span> <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>len_sb</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>dtw_array</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>distance</span><span class=p>(</span><span class=n>sa</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span><span class=n>sb</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>xrange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>len_sb</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=n>xrange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>len_sa</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>i</span><span class=o>+</span><span class=n>j</span><span class=o>==</span><span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=n>nb</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>i</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span> <span class=n>nb</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dtw_array</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>j</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>j</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span> <span class=n>nb</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dtw_array</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>i</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=ow>and</span> <span class=n>j</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span> <span class=n>nb</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dtw_array</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>j</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>min_route</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>nb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>cost</span> <span class=o>=</span> <span class=n>distance</span><span class=p>(</span><span class=n>sa</span><span class=p>[</span><span class=n>j</span><span class=p>],</span><span class=n>sb</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>dtw_array</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>cost</span> <span class=o>+</span> <span class=n>min_route</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>dtw_array</span><span class=p>[</span><span class=n>len_sb</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=n>len_sa</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>(</span><span class=n>argv</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>s1</span> <span class=o>=</span> <span class=sa>u</span><span class=s1>&#39;干啦今今今今今天天气气气气气好好好好啊啊啊&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>s2</span> <span class=o>=</span> <span class=sa>u</span><span class=s1>&#39;今天天气好好啊&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>d</span> <span class=o>=</span> <span class=n>dtw</span><span class=p>(</span><span class=n>s1</span><span class=p>,</span> <span class=n>s2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span> <span class=n>d</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>sys</span><span class=o>.</span><span class=n>exit</span><span class=p>(</span><span class=n>main</span><span class=p>(</span><span class=n>sys</span><span class=o>.</span><span class=n>argv</span><span class=p>))</span>
</span></span></code></pre></div><h2 id=网络节点距离>网络节点距离</h2><h2 id=分布距离>分布距离</h2><p>前面我们谈论的都是两个数值点之间的距离，实际上两个概率分布之间的距离是可以测量的。在统计学里面经常需要测量两组样本分布之间的距离，进而判断出它们是否出自同一个 population，常见的方法有<strong>卡方检验</strong>(Chi-Square)和 <strong>KL 散度</strong>( KL-Divergence)，下面说一说 KL 散度吧。</p><p>先从信息熵说起，假设一篇文章的标题叫做“黑洞到底吃什么”，包含词语分别是 {黑洞, 到底, 吃什么}, 我们现在要根据一个词语推测这篇文章的类别。哪个词语给予我们的信息最多？很容易就知道是“黑洞”，因为“黑洞”这个词语在所有的文档中出现的概率太低啦，一旦出现，就表明这篇文章很可能是在讲科普知识。而其他两个词语“到底”和“吃什么”出现的概率很高，给予我们的信息反而越少。如何用一个函数 h(x) 表示词语给予的信息量呢？第一，肯定是与 p(x) 相关，并且是负相关。第二，假设 x 和 y 是独立的(黑洞和宇宙不相互独立，谈到黑洞必然会说宇宙),即 p(x,y) = p(x)p(y), 那么获得的信息也是叠加的，即 h(x, y) = h(x) + h(y)。满足这两个条件的函数肯定是负对数形式：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?h%28x%29%20=%20-ln%5C%20p%28x%29" alt loading=lazy data-zoomable></div></div></figure></p><p>对假设一个发送者要将随机变量 X 产生的一长串随机值传送给接收者，接受者获得的平均信息量就是求它的数学期望：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?H[x]%20=%20-%5Csum%20_x%7Bp%28x%29%5Cln%20p%28x%29%7D" alt loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src="http://latex.codecogs.com/gif.latex?H[x]%20=%20-%5Cint%20%7B%20p%28x%29%5Cln%20%7B%20p%28x%29%20%7D%20dx%20%7D" alt loading=lazy data-zoomable></div></div></figure></p><p>这就是熵的概念。另外一个重要特点是，熵的大小与字符平均最短编码长度是一样的(shannon)。设有一个未知的分布 p(x), 而 q(x) 是我们所获得的一个对 p(x) 的近似，按照 q(x) 对该随机变量的各个值进行编码，平均长度比按照真实分布的 p(x) 进行编码要额外长一些，多出来的长度这就是 KL 散度(之所以不说距离，是因为不满足对称性和三角形法则)，即：</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=http://images.cnitblog.com/blog/533521/201308/07221311-03bee2dca7e040e4889582d8182f4dde.png alt loading=lazy data-zoomable></div></div></figure></p><p>KL 散度又叫<strong>相对熵</strong>(relative entropy)。了解机器学习的童鞋应该都知道，在 Softmax 回归(或者 Logistic 回归)，最后的输出节点上的值表示这个样本分到该类的概率，这就是一个概率分布。对于一个带有标签的样本，我们期望的概率分布是：分到标签类的概率是 1，其他类概率是 0。但是理想很丰满，现实很骨感，我们不可能得到完美的概率输出，能做的就是尽量减小总样本的 KL 散度之和(目标函数)。这就是 Softmax 回归或者 Logistic 回归中 Cost function 的优化过程啦。(PS：因为概率和为 1，一般的 logistic 二分类的图只画了一个输出节点，隐藏了另外一个)</p></div><div class=article-widget><div class="container-xl row post-nav"><div class="col-6 post-nav-item"><div class=meta-nav>下一页</div><a href=/books/mathematics-series/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/ rel=prev>矩阵分解</a></div></div></div><div class=body-footer><p>最近更新于 0001-01-01</p><section id=comments class="mb-3 pt-0"><div id=disqus_thread></div><script>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="https://ngte.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><footer class=site-footer><div class="copyright py-4 bg-footer"><div class="row justify-content-center"><div class="text-center footer-color"><p class=mb-0>© 2017-2022 NGTE all rights reserved</p></div></div></div></footer></main></div></div><script src=//unpkg.com/heti/umd/heti-addon.min.js></script>
<script>const heti=new Heti(".article");heti.autoSpacing()</script><script type=text/javascript>window.$crisp=[],window.CRISP_WEBSITE_ID="12adcc35-9621-4313-8262-62dc654b29d8",function(){setTimeout(function(){d=document,s=d.createElement("script"),s.src="https://client.crisp.chat/l.js",s.async=1,d.getElementsByTagName("head")[0].appendChild(s)},2500)}()</script></div><div class=page-footer></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script id=search-hit-algolia-template type=text/html><div class=search-hit><div class=search-hit-content><div class=search-hit-name><a href={{relpermalink}}>{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a></div><div class="article-metadata search-hit-type">{{type}}</div><p class=search-hit-description>{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p></div></div></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js crossorigin=anonymous></script>
<script id=dsq-count-scr src=https://ngte.disqus.com/count.js async></script>
<script src=/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js type=module></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js></script>
<script>var mybutton=document.getElementById("backTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.style.display="block":mybutton.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script src=https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin=anonymous></script>
<script>anchors.add()</script><script>(function(){"use strict";if(!document.queryCommandSupported("copy"))return;function e(e,t){e.className="highlight-copy-btn",e.textContent=t,setTimeout(function(){e.textContent="",e.className="highlight-copy-btn fa fa-copy"},1e3)}function t(e){var t=window.getSelection(),n=document.createRange();return n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n),t}function n(n){var o,s=document.createElement("button");s.className="highlight-copy-btn fa fa-copy",s.textContent="",o=n.firstElementChild,s.addEventListener("click",function(){try{var n=t(o);document.execCommand("copy"),n.removeAllRanges(),e(s,"已复制")}catch(t){console&&console.log(t),e(s,"Failed :'(")}}),n.appendChild(s)}var s=document.getElementsByClassName("highlight");Array.prototype.forEach.call(s,n)})()</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>概率论基础 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</link>
      <atom:link href="https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/index.xml" rel="self" type="application/rss+xml" />
    <description>概率论基础</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>概率论基础</title>
      <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</link>
    </image>
    
    <item>
      <title>概率与分布</title>
      <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83/</guid>
      <description>&lt;h1 id=&#34;概率与分布&#34;&gt;概率与分布&lt;/h1&gt;
&lt;p&gt;概率分布（Probability Distribution）用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。我们描述概率分布的方式取决于随机变量是离散的还是连续的。&lt;/p&gt;
&lt;h1 id=&#34;离散型变量和概率质量函数&#34;&gt;离散型变量和概率质量函数&lt;/h1&gt;
&lt;p&gt;离散型变量的概率分布可以用概率质量函数（Probability mass function, PMF）来描述。我们通常用大写字母 $P$ 来表示概率质量函数。通常每一个随机变量都会有一个不同的概率质量函数，并且必须根据随机变量来推断所使用的 PMF，而不是根据函数的名称来推断；例如，$P(x)$ 通常和 $P(y)$ 不一样。&lt;/p&gt;
&lt;p&gt;概率质量函数将随机变量能够取得的每个状态映射到随机变量取得该状态的概率。$\mathrm{x} = x$ 的概率用 $P(x)$ 来表示，概率为 1 表示 $\mathrm{x} = x$ 是确定的，概率为 0 表示 $\mathrm{x} = x$ 是不可能发生的。有时我们会定义一个随机变量，然后用 $\sim$ 符号来说明分布：$\mathrm{x} \sim P(\mathrm{x})$。&lt;/p&gt;
&lt;p&gt;概率质量函数可以同时作用于多个随机变量，这种多个变量的概率分布被称为联合概率分布（joint probability distribution）。$P(\mathrm{x}=x, \mathrm{y}=y)$ 表示 $\mathrm{x} = x$ 和 $\mathrm{y} = y$ 同时发生的概率，可以简写为 $P(x,y)$。&lt;/p&gt;
&lt;p&gt;如果一个函数 $P$ 是随机变量 $\mathrm{x}$ 的 PMF，必须满足以下条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$P$ 的定义域必须是 $\mathrm{x}$ 所有可能状态的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\forall x \in \mathrm{x}, 0 \leq P(x) \leq 1$ 不可能发生的事件概率为 0，并且不存在比这概率更低的状态。类似的，能够确保一定发生的事件概率为 1，而且不存在比这概率更高的状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sum_{x \in \mathrm{x}} P(x)=1$ 我们把这条性质称之为归一化的（normalized）。如果没有这条性质，当我们计算很多事件其中之一发生的概率时可能会得到大于 1 的概率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如，考虑一个离散型随机变量 $\mathrm{x}$ 有 $k$ 个不同的状态。我们可以假设 $\mathrm{x}$ 是均匀分布（Uniform Distribution）的，也就是将它的每个状态视为等可能的，其 PMF 可以为：&lt;/p&gt;
&lt;p&gt;$$
P\left(\mathrm{x}=x_{i}\right)=\frac{1}{k}
$$&lt;/p&gt;
&lt;p&gt;对于所有的 $i$ 都成立。我们可以看出这满足上述成为概率质量函数的条件。因为 $k$ 是一个正整数，所以 $\frac{1}{k}$ 是正的，并且：&lt;/p&gt;
&lt;p&gt;$$
\sum_{i} P\left(\mathrm{x}=x_{i}\right)=\sum_{i} \frac{1}{k}=\frac{k}{k}=1
$$&lt;/p&gt;
&lt;p&gt;因此分布也满足归一化条件。&lt;/p&gt;
&lt;h1 id=&#34;连续型变量和概率密度函数&#34;&gt;连续型变量和概率密度函数&lt;/h1&gt;
&lt;p&gt;当我们研究的对象是连续型随机变量时，我们用概率密度函数（Probability density function, PDF）而不是概率质量函数来描述它的概率分布。如果一个函数 $p$ 是概率密度函数，必须满足下面这几个条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$p$ 的定义域必须是 $\mathrm{x}$ 所有可能状态的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\forall x \in \mathrm{x}, p(x) \geq 0$，值得一提的是，并不要求：$p(x) \leq 1$。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\int p(x) d x=1$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;概率密度函数 $p(x)$ 并没有直接对特定的状态给出概率，相对的，它给出了落在面积为 $\delta x$ 的无限小的区域内的概率为 $p(x) \delta x$。我们可以对概率密度函数求积分来获得点集的真实概率质量，$x$ 落在区间 $[a, b]$ 的概率是 $\int_{[a, b]} p(x) d x$。&lt;/p&gt;
&lt;p&gt;为了给出一个连续型随机变量的 PDF 的例子，我们可以考虑实数区间上的均匀分布。我们可以使用函数 $u(x ; a, b)$，其中 $a$ 和 $b$ 是区间的端点且满足 $b &amp;gt; a$。符号 $;$ 表示以什么为参数。一般将 $x$ 作为函数的自变量，$a$ 和 $b$ 作为定义函数的参数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了确保区间外没有概率，我们对所有的 $x \notin[a, b]$，令 $u(x ; a, b)=0$。&lt;/li&gt;
&lt;li&gt;在 $[a,b]$ 内，有 $u(x ; a, b)=\frac{1}{b-a}$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述函数中，任何一点都非负，并且其积分为 1，通常可以使用 $\mathrm{x} \sim U(a, b)$ 表示 $x$ 在 $[a,b]$ 上是均匀分布的。&lt;/p&gt;
&lt;h1 id=&#34;条件概率与独立事件&#34;&gt;条件概率与独立事件&lt;/h1&gt;
&lt;p&gt;所谓条件概率，已知 $A$ 事件发生的条件下 $B$ 发生的概率，记作 $P(B|A)$，它等于事件 $AB$ 的概率相对于事件 $A$ 的概率，即：$P(B | A)=\frac{P(A B)}{P(A)}$，其中必须有 $P(A)&amp;gt;0$。&lt;/p&gt;
&lt;p&gt;条件概率分布满足链式法则，对于 $n$ 个随机变量 $X_{1}, X_{2}, \cdots, X_{n}$，存在有&lt;/p&gt;
&lt;p&gt;$$
P\left(X_{1}, X_{2}, \cdots, X_{n}\right)=P\left(X_{1}\right) \prod_{i=2}^{n} P\left(X_{i} | X_{1}, \cdots, X_{i-1}\right)
$$&lt;/p&gt;
&lt;h2 id=&#34;独立&#34;&gt;独立&lt;/h2&gt;
&lt;p&gt;两个随机变量 $X,Y$ 相互独立的数学描述如下，记作 $X \perp Y$：&lt;/p&gt;
&lt;p&gt;$$
P(X, Y)=P(X) P(Y)
$$&lt;/p&gt;
&lt;p&gt;两个随机变量 $X,Y$ 关于随机变量 $Z$ 条件独立的数学描述，记作 $X \perp Y | Z$：&lt;/p&gt;
&lt;p&gt;$$
P(X, Y | Z)=P(X | Z) P(Y | Z)
$$&lt;/p&gt;
&lt;h2 id=&#34;联合概率分布&#34;&gt;联合概率分布&lt;/h2&gt;
&lt;p&gt;定义 $X$ 和 $Y$ 的联合分布为：&lt;/p&gt;
&lt;p&gt;$$
P(a, b)=P{X \leq a, Y \leq b}, \quad-\infty&amp;lt;a, b&amp;lt;+\infty
$$&lt;/p&gt;
&lt;p&gt;$X$ 的分布可以从联合分布中得到：&lt;/p&gt;
&lt;p&gt;$$
P_{X}(a)=P{X \leq a}=P{X \leq a, Y \leq \infty}=P(a, \infty), \quad-\infty&amp;lt;a&amp;lt;+\infty
$$&lt;/p&gt;
&lt;p&gt;$Y$ 的分布可以从联合分布中得到：&lt;/p&gt;
&lt;p&gt;$$
P_{Y}(b)=P{Y \leq b}=P{X \leq \infty, Y \leq b}=P(\infty, b), \quad-\infty&amp;lt;b&amp;lt;+\infty
$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>期望与方差</title>
      <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE/</guid>
      <description>&lt;h1 id=&#34;期望与方差&#34;&gt;期望与方差&lt;/h1&gt;
&lt;h1 id=&#34;期望&#34;&gt;期望&lt;/h1&gt;
&lt;p&gt;期望描述了随机变量的平均情况，衡量了随机变量 $X$ 的均值，它是概率分布的泛函。离散型随机变量 $X$ 的期望如下：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[X]=\sum_{i=1}^{\infty} x_{i} p_{i}
$$&lt;/p&gt;
&lt;p&gt;若右侧级数不收敛，则期望不存在。连续性随机变量 $X$ 的期望如下：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[X]=\int_{-\infty}^{\infty} x p(x) d x
$$&lt;/p&gt;
&lt;p&gt;若右侧极限不收敛，则期望不存在。&lt;/p&gt;
&lt;h2 id=&#34;期望的性质&#34;&gt;期望的性质&lt;/h2&gt;
&lt;p&gt;常数的期望就是常数本身，对常数 $C$ 有：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[C X]=C \mathbb{E}[X]
$$&lt;/p&gt;
&lt;p&gt;对两个随机变量 $X,Y$，存在：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]
$$&lt;/p&gt;
&lt;p&gt;该结论可以推广到任意有限个随机变量之和的情况。对两个相互独立的随机变量，有：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[X Y]=\mathbb{E}[X] \mathbb{E}[Y]
$$&lt;/p&gt;
&lt;p&gt;该结论可以推广到任意有限个相互独立的随机变量之积的情况。这里以离散型随机变量为例，设二元随机变量 $X,Y$ 的联合分布 $P\left(X=x_{i}, Y=y_{j}\right)$ 已知，则 $P\left(X=x_{i}, Y=y_{j}\right)=P\left(X=x_{i}\right) \cdot P\left(Y=y_{j}\right), \quad(i=1,2, \cdots, m ; j=1,2, \cdots, n)$：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned} E(X Y) &amp;amp;=\sum_{i=1}^{m} \sum_{j=1}^{n} x_{i} y_{j} P\left(X=x_{i}, Y=y_{j}\right)=\sum_{i=1}^{m} \sum_{j=1}^{n} x_{i} y_{j} P\left(X=x_{i}\right) P\left(Y=y_{j}\right) \ &amp;amp;=\sum_{i=1}^{m} x_{i} P\left(X=x_{i}\right) \sum_{j=1}^{n} y_{j} P\left(Y=y_{j}\right)=E(X) E(Y) \end{aligned}
$$&lt;/p&gt;
&lt;h2 id=&#34;复合函数期望&#34;&gt;复合函数期望&lt;/h2&gt;
&lt;p&gt;对于随机变量 $X$，设 $Y=g(X)$ 也为随机变量，$g(\cdot)$ 是连续函数。&lt;/p&gt;
&lt;p&gt;若 $X$ 为离散型随机变量，且 $Y$ 的期望存在，则：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[Y]=\mathbb{E}[g(X)]=\sum_{i=1}^{\infty} g\left(x_{i}\right) p_{i}
$$&lt;/p&gt;
&lt;p&gt;也记作：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}&lt;em&gt;{X \sim P(X)}[g(X)]=\sum&lt;/em&gt;{x} g(x) p(x)
$$&lt;/p&gt;
&lt;p&gt;同样，若 $X$ 为连续型随机变量，且 $Y$ 的期望存在，则：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[Y]=\mathbb{E}[g(X)]=\int_{-\infty}^{\infty} g(x) p(x) d x
$$&lt;/p&gt;
&lt;p&gt;也记作：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}_{X \sim P(X)}[g(X)]=\int g(x) p(x) d x
$$&lt;/p&gt;
&lt;p&gt;该定理的意义在于：当求 $\mathbb{E}(Y)$ 时，不必计算出 $Y$ 的分布，只需要利用 $X$ 的分布即可。该定理可以推广至两个或两个以上随机变量的情况，对于随机变量 $X, Y$，假设 $Z=g(X, Y)$ 也是随机变量，$g(\cdot)$ 是连续函数，则有：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}[Z]=\mathbb{E}[g(X, Y)]=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) p(x, y) d x d y
$$&lt;/p&gt;
&lt;p&gt;也记作：&lt;/p&gt;
&lt;p&gt;$$
\mathbb{E}_{X, Y \sim P(X, Y)}\left[g(X, Y) \int g(x, y) p(x, y) d x d y\right.
$$&lt;/p&gt;
&lt;h1 id=&#34;方差&#34;&gt;方差&lt;/h1&gt;
&lt;p&gt;对随机变量 $X$，若 $\mathbb{E}\left[(X-\mathbb{E}[X])^{2}\right]$ 存在，则称它为 $X$ 的方差，记作 $\operatorname{Var}[X]$。$X$ 的标准差为方差的开平方，即：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned} \operatorname{Var}[X] &amp;amp;=\mathbb{E}\left[(X-\mathbb{E}[X])^{2}\right] \ \sigma &amp;amp;=\sqrt{\operatorname{Var}[X]} \end{aligned}
$$&lt;/p&gt;
&lt;p&gt;方差度量了随机变量 $X$ 与期望值偏离的程度，衡量了 $X$ 取值分散程度的一个尺度。由于绝对值 $|X-\mathbb{E}[X]|$ 带有绝对值，不方便运算，因此采用平方来计算。又因为 $|X-\mathbb{E}[X]|^{2}$ 是一个随机变量，因此对它取期望，即得 $X$ 与期望值偏离的均值。&lt;/p&gt;
&lt;p&gt;根据定义可知：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{\operatorname{Var}[X]=\mathbb{E}\left[(X-\mathbb{E}[X])^{2}\right]=\mathbb{E}\left[X^{2}\right]-(\mathbb{E}[X])^{2}} \ {\operatorname{Var}[f(X)]=\mathbb{E}\left[(f(X)-\mathbb{E}[f(X)])^{2}\right]}\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;方差的性质&#34;&gt;方差的性质&lt;/h2&gt;
&lt;p&gt;常数的方差恒为 0，且 $\operatorname{Var}[X]=0$ 的充要条件是 $X$ 以概率 1 取常数。对常数 $C$，存在 $\operatorname{Var}[C X]=C^{2} \operatorname{Var}[X]$。对两个随机变量 $X,Y$，存在有：&lt;/p&gt;
&lt;p&gt;$$
\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]+2 \mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
$$&lt;/p&gt;
&lt;p&gt;当 $X$ 和 $Y$ 相互独立时，有：&lt;/p&gt;
&lt;p&gt;$$
\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]
$$&lt;/p&gt;
&lt;p&gt;证明如下：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned} \operatorname{Var}(X+Y) &amp;amp;=E\left[(X+Y)^{2}\right]-E(X+Y)^{2} \ &amp;amp;=E\left(X^{2}+2 X Y+Y^{2}\right)-\left[E(X)^{2}+2 E(X) E(Y)+E(Y)^{2}\right] \ &amp;amp;=E\left(X^{2}\right)-E(X)^{2}+E\left(Y^{2}\right)-E(Y)^{2}+2 E(X Y)-2 E(X) E(Y) \ &amp;amp;=E\left(X^{2}\right)-E(X)^{2}+E\left(Y^{2}\right)-E(Y)^{2}=\operatorname{Var}(X)+\operatorname{Var}(Y) \end{aligned}
$$&lt;/p&gt;
&lt;p&gt;这可以推广至任意有限多个相互独立的随机变量之和的情况。若 $X_{1}, X_{2}, \cdots, X_{n}$ 相互独立，且都存在方差，则：&lt;/p&gt;
&lt;p&gt;$$
\operatorname{Var}\left(X_{1}+X_{2}+\cdots+X_{m}\right)=\sum_{k=1}^{n} \operatorname{Var}\left(X_{k}\right)
$$&lt;/p&gt;
&lt;h2 id=&#34;标准化变量&#34;&gt;标准化变量&lt;/h2&gt;
&lt;p&gt;对于一个期望为 $\mu$，方差为 $\sigma^{2}, \sigma \neq 0$ 的随机变量 $X$，随机变量 $X^{&lt;em&gt;}=\frac{X-\mu}{\sigma}$ 的数学期望为 0，方差为 1，则称 $X^{&lt;/em&gt;}$ 为 $X$ 的标准化变量。&lt;/p&gt;
&lt;h1 id=&#34;协方差&#34;&gt;协方差&lt;/h1&gt;
&lt;p&gt;对于二维随机变量 $(X, Y)$，可以讨论描述 $X$ 与 $Y$ 之间相互关系的数字特征。定义 $\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]$ 为随机变量 $X$ 和 $Y$ 的协方差，记作：&lt;/p&gt;
&lt;p&gt;$$
\operatorname{Cov}[X, Y]=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
$$&lt;/p&gt;
&lt;p&gt;在有协方差定义的情况下，我们可以将前文方差的定义修改为：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{\operatorname{Cov}[X, Y]=\operatorname{Cov}[Y, X]} \ {\operatorname{Cov}[X, X]=\operatorname{Var}[X]} \ {\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]+2 \operatorname{Cov}[X, Y]}\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;协方差的性质&#34;&gt;协方差的性质&lt;/h2&gt;
&lt;p&gt;$$
\begin{array}{l}{\circ \operatorname{Cov}[a X, b Y]=a b \operatorname{Cov}[X, Y]} \ {\circ \operatorname{Cov}\left[X_{1}+X_{2}, Y\right]=\operatorname{Cov}\left[X_{1}, Y\right]+\operatorname{Cov}\left[X_{2}, Y\right]} \ {\circ \operatorname{Cov}[f(X), g(Y)]=\mathbb{E}[(f(X)-\mathbb{E}[f(X)])(g(Y)-\mathbb{E}[g(Y)])]} \ {\circ \rho[f(X), g(Y)]=\frac{\operatorname{Covlf}(X), g(Y) ]}{\sqrt{\operatorname{Var}[f(X)] \sqrt{\operatorname{Var}[g(Y)]}}}}\end{array}
$$&lt;/p&gt;
&lt;p&gt;协方差的绝对值越大，说明两个随机变量都远离它们的均值。协方差如果为正，则说明两个随机变量同时趋向于取较大的值或者同时趋向于取较小的值；如果为负，则说明一个随变量趋向于取较大的值，另一个随机变量趋向于取较小的值。&lt;/p&gt;
&lt;p&gt;两个随机变量的独立性可以导出协方差为零。但是两个随机变量的协方差为零无法导出独立性。因为独立性也包括：没有非线性关系。有可能两个随机变量是非独立的，但是协方差为零。如：假设随机变量 $X \sim U[-1,1]$，定义随机变量 $S$ 的概率分布函数为：&lt;/p&gt;
&lt;p&gt;$$
P(S=1)=\frac{1}{2} P(S=-1)=\frac{1}{2}
$$&lt;/p&gt;
&lt;p&gt;定义随机变量 $Y=SX$，则随机变量 $X,Y$ 是非独立的，但是有：$\operatorname{Cov}[X, Y]=0$。&lt;/p&gt;
&lt;h2 id=&#34;相关系数&#34;&gt;相关系数&lt;/h2&gt;
&lt;p&gt;随机变量 $X$ 与 $Y$ 的相关系数，定义为：&lt;/p&gt;
&lt;p&gt;$$
\rho_{X Y}=\frac{\operatorname{Cov}[X, Y]}{\sqrt{\operatorname{Var}[X]} \sqrt{\operatorname{Var}[Y]}}
$$&lt;/p&gt;
&lt;p&gt;它可以看做协方差的归一化。其物理意义在于，如果考虑以随机变量 $X$ 的线性函数 $a+bX$ 来近似表示 $Y$，以均方误差：&lt;/p&gt;
&lt;p&gt;$$
e=\mathbb{E}\left[(Y-(a+b X))^{2}\right]=\mathbb{E}\left[Y^{2}\right]+b^{2} \mathbb{E}\left[X^{2}\right]+a^{2}-2 b \mathbb{E}[X Y]+2 a b \mathbb{E}[X]-2 a \mathbb{E}[Y]
$$&lt;/p&gt;
&lt;p&gt;来衡量以 $a+bX$ 近似表达 $Y$ 的好坏程度，$e$ 越小则表示近似程度越高。为求得最好的近似，则对 $a,b$ 分别取偏导数，得到：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{a_{0}=\mathbb{E}[Y]-b_{0} \mathbb{E}[X]=\mathbb{E}[Y]-\mathbb{E}[X] \frac{\operatorname{Cov}[X, Y]}{\operatorname{Var}[X]}} \ {b_{0}=\frac{\operatorname{Cov}[X, Y]}{\operatorname{Var}[X]}} \ {\min (e)=\mathbb{E}\left[\left(Y-\left(a_{0}+b_{0} X\right)\right)^{2}\right]=\left(1-\rho_{X Y}^{2}\right) \operatorname{Var}[Y]}\end{array}
$$&lt;/p&gt;
&lt;p&gt;因此可以得到如下定理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\left|\rho_{X Y}\right| \leq 1$&lt;/li&gt;
&lt;li&gt;$\left|\rho_{X Y}\right|=1$ 的充要条件是：存在常数 $a,b$ 使得 $P{Y=a+b X}=1$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 $\left|\rho_{X Y}\right|$ 较大时，$e$ 较小，意味着随机变量 $X$ 和 $Y$ 联系较为紧密，于是 $\left|\rho_{X Y}\right|$ 是一个表征 $X, Y$ 之间线性关系紧密程度的量。&lt;/p&gt;
&lt;p&gt;当 $\rho_{X Y}=0$ 时，称 $X,Y$ 不相关，不相关是就线性关系来讲的，而相互独立是一般关系而言的；相互独立一定不相关，不相关则未必独立。&lt;/p&gt;
&lt;h1 id=&#34;协方差矩阵&#34;&gt;协方差矩阵&lt;/h1&gt;
&lt;p&gt;假设 $X$ 和 $Y$ 是随机变量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;假如 $\mathbb{E}\left[X^{k}\right], k=1,2, \cdots$ 存在，则称它为 $X$ 的 $k$ 阶原点矩，简称 $k$ 阶矩。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假如 $\mathbb{E}\left[(X-\mathbb{E}&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; )^{k}\right], k=2,3, \cdots$ 存在，则称它为 $X$ 的 $k$ 阶中心矩。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假如 $\mathbb{E}\left[X^{k} Y^{l}\right], k, l=1,2, \cdots$ 存在，则称它为 $X$ 和 $Y$ 的 $k+l$ 阶混合矩。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假如 $\mathbb{E}\left[(X-\mathbb{E}&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; )^{k}(Y-\mathbb{E}[Y])^{l}\right], k, l=1,2, \cdots$ 存在，则称它为 $X$ 和 $Y$ 的 $k+l$ 阶混合中心矩。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此期望是一阶原点矩，方差是二阶中心矩，协方差是二阶混合中心矩。而协方差矩阵，就定义为二维随机变量 $X_1,X_2$ 的四个二阶中心矩：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{c_{11}=\mathbb{E}\left[\left(X_{1}-\mathbb{E}\left[X_{1}\right]\right)^{2}\right]} \ {c_{12}=\mathbb{E}\left[\left(X_{1}-\mathbb{E}\left[X_{1}\right]\right)\left(X_{2}-\mathbb{E}\left[X_{2}\right]\right)\right]} \ {c_{21}=\mathbb{E}\left[\left(X_{2}-\mathbb{E}\left[X_{2}\right]\right)\left(X_{1}-\mathbb{E}\left[X_{1}\right]\right)\right]} \ {c_{22}=\mathbb{E}\left[\left(X_{2}-\mathbb{E}\left[X_{2}\right]\right)^{2}\right]}\end{array}
$$&lt;/p&gt;
&lt;p&gt;称矩阵：&lt;/p&gt;
&lt;p&gt;$$
\mathbf{C}=\left[\begin{array}{ll}{c_{11}} &amp;amp; {c_{12}} \ {c_{21}} &amp;amp; {c_{22}}\end{array}\right]
$$&lt;/p&gt;
&lt;p&gt;为随机变量 $X_1,X_2$ 的协方差矩阵。设 $n$ 维随机变量 $\left(X_{1}, X_{2}, \cdots, X_{n}\right)$ 的二阶混合中心矩 $c_{i j}=\operatorname{Cov}\left[X_{i}, X_{j}\right]=\mathbb{E}\left[\left(X_{i}-\mathbb{E}\left[X_{i}\right]\right)\left(X_{j}-\mathbb{E}\left[X_{j}\right]\right)\right]$ 存在，则矩阵：&lt;/p&gt;
&lt;p&gt;$$
\mathbf{C}=\left[\begin{array}{cccc}{c_{11}} &amp;amp; {c_{12}} &amp;amp; {\cdots} &amp;amp; {c_{1 n}} \ {c_{21}} &amp;amp; {c_{22}} &amp;amp; {\cdots} &amp;amp; {c_{2 n}} \ {\vdots} &amp;amp; {\vdots} &amp;amp; {\ddots} &amp;amp; {\vdots} \ {c_{n 1}} &amp;amp; {c_{n 2}} &amp;amp; {\cdots} &amp;amp; {c_{n n}}\end{array}\right]
$$&lt;/p&gt;
&lt;p&gt;为 $\left(X_{1}, X_{2}, \cdots, X_{n}\right)$ 的协方差矩阵。鉴于 $c_{i j}=c_{j i}, i \neq j, i, j=1,2, \cdots, n$，协方差矩阵是对称阵。通常 $n$ 维随机变量的分布是不知道的，或者太复杂以致数学上不容易处理，因此实际中协方差矩阵非常重要。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>中心极限与大数定理</title>
      <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;大数定律及中心极限定理&#34;&gt;大数定律及中心极限定理&lt;/h1&gt;
&lt;h1 id=&#34;切比雪夫不等式&#34;&gt;切比雪夫不等式&lt;/h1&gt;
&lt;p&gt;假设随机变量 $X$ 具有期望 $\mathbb{E}[X]=\mu$，方差 $\operatorname{Var}(X)=\sigma^{2}$，则对于任意正数 $\varepsilon$，下列不等式成立：&lt;/p&gt;
&lt;p&gt;$$
P{|X-\mu| \geq \varepsilon} \leq \frac{\sigma^{2}}{\varepsilon^{2}}
$$&lt;/p&gt;
&lt;p&gt;其意义在于，对于距离 $\mathbb{E}[X]$ 足够远的地方（距离大于等于 $\varepsilon$），事件出现的概率是小于等于 $\frac{\sigma^{2}}{\varepsilon^{2}}$，即事件出现在区间 $[\mu-\varepsilon, \mu+\varepsilon]$ 的概率大于等于 $1-\frac{\sigma^{2}}{\varepsilon^{2}}$。该不等式给出了随机变量 $X$ 在分布未知的情况下，事件 ${|X-\mu| \leq \varepsilon}$ 的下限估计，如：&lt;/p&gt;
&lt;p&gt;$$
P{|X-\mu|&amp;lt;3 \sigma} \geq 0.8889
$$&lt;/p&gt;
&lt;p&gt;该不等式的证明为：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned} P{|X-\mu| \geq \varepsilon&amp;amp; }=\int_{|x-\mu| \geq \varepsilon} p(x) d x \leq \int_{|x-\mu| \geq \varepsilon} \frac{|x-\mu|^{2}}{\varepsilon^{2}} p(x) d x \ &amp;amp; \leq \frac{1}{\varepsilon^{2}} \int_{-\infty}^{\infty}(x-\mu)^{2} p(x) d x=\frac{\sigma^{2}}{\varepsilon^{2}} \end{aligned}
$$&lt;/p&gt;
&lt;p&gt;切比雪夫不等式的特殊情况：假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，且具有相同的数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$。作前 $n$ 个随机变量的算术平均：$\overline{X}=\frac{1}{n} \sum_{k=1}^{n} X_{k}$，则对于任意正数 $\varepsilon$ 有：&lt;/p&gt;
&lt;p&gt;$$
\lim &lt;em&gt;{n \rightarrow \infty} P{|\overline{X}-\mu|&amp;lt;\varepsilon}=\lim &lt;em&gt;{n \rightarrow \infty} P\left{\left|\frac{1}{n} \sum&lt;/em&gt;{k=1}^{n} X&lt;/em&gt;{k}-\mu\right|&amp;lt;\varepsilon\right}=1
$$&lt;/p&gt;
&lt;p&gt;证明过程为，根据期望和方差的性质有：$\mathbb{E}[\overline{X}]=\mu, \quad \operatorname{Var}[\overline{X}]=\frac{\sigma^{2}}{n}$，根据切比雪夫不等式有：&lt;/p&gt;
&lt;p&gt;$$
P{|\overline{X}-\mu| \geq \varepsilon} \leq \frac{\sigma^{2}}{n \varepsilon^{2}}
$$&lt;/p&gt;
&lt;p&gt;则有 $\lim _{n \rightarrow \infty} P{|\overline{X}-\mu| \geq \varepsilon}=0$，因此有 $\lim _{n \rightarrow \infty} P{|\overline{X}-\mu|&amp;lt;\varepsilon}=1$。&lt;/p&gt;
&lt;h1 id=&#34;大数定理&#34;&gt;大数定理&lt;/h1&gt;
&lt;p&gt;假设 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 是一个随机变量序列，$a$ 是一个常数，如果对于任意正数 $\varepsilon$ 存在：&lt;/p&gt;
&lt;p&gt;$$
\lim &lt;em&gt;{n \rightarrow \infty} P\left{\left|Y&lt;/em&gt;{n}-a\right| \leq \varepsilon\right}=1
$$&lt;/p&gt;
&lt;p&gt;则称序列 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 依概率收敛于 $a$，记作：$Y_{n} \stackrel{P}{\rightarrow} a$。&lt;/p&gt;
&lt;p&gt;依概率收敛包含两层意思，收敛表明这是一个随机变量序列，而不是某个随机变量；且序列是无限长，而不是有限长。依概率则表明序列无穷远处的随机变量 $Y_{\infty}$ 的分布规律为：绝大部分分布于点 $a$，极少数位于 $a$ 之外。且分布于 $a$ 之外的事件发生的概率之和为 0。&lt;/p&gt;
&lt;h2 id=&#34;大数定理一&#34;&gt;大数定理一&lt;/h2&gt;
&lt;p&gt;假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，且具有相同的数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$。则序列：&lt;/p&gt;
&lt;p&gt;$$
\overline{X}=\frac{1}{n} \sum_{k=1}^{n} X_{k}
$$&lt;/p&gt;
&lt;p&gt;依概率收敛于 $\mu$，即 $\overline{X} \stackrel{P}{\rightarrow} \mu$。值得一提的是，这里并没有要求随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 同分布。&lt;/p&gt;
&lt;h2 id=&#34;伯努利大数定理&#34;&gt;伯努利大数定理&lt;/h2&gt;
&lt;p&gt;假设 $n_{A}$ 为 $n$ 次独立重复实验中事件 $A$ 发生的次数，$p$ 是事件 $A$ 在每次试验中发生的概率。则对于任意正数 $\varepsilon$ 有：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{\lim &lt;em&gt;{n \rightarrow \infty} P\left{\left|\frac{n&lt;/em&gt;{A}}{n}-p\right|&amp;lt;\varepsilon\right}=1} \ {\text { or: } \quad \lim &lt;em&gt;{n \rightarrow \infty} P\left{\left|\frac{n&lt;/em&gt;{A}}{n}-p\right| \geq \varepsilon\right}=0}\end{array}
$$&lt;/p&gt;
&lt;p&gt;即当独立重复实验执行非常大的次数时，事件 $A$ 发生的频率逼近于它的概率。&lt;/p&gt;
&lt;h2 id=&#34;辛钦定理&#34;&gt;辛钦定理&lt;/h2&gt;
&lt;p&gt;假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，服从同一分布，且具有相同的数学期望：$\mathbb{E}\left[X_{k}\right]=\mu$，则对于任意正数 $\varepsilon$ 存在：&lt;/p&gt;
&lt;p&gt;$$
\lim &lt;em&gt;{n \rightarrow \infty} P\left{\left|\frac{1}{n} \sum&lt;/em&gt;{k=1}^{n} X_{k}-\mu\right|&amp;lt;\varepsilon\right}=1
$$&lt;/p&gt;
&lt;p&gt;注意：这里并没有要求随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 的方差存在，伯努利大数定理是亲钦定理的特殊情况。&lt;/p&gt;
&lt;h1 id=&#34;中心极限定理&#34;&gt;中心极限定理&lt;/h1&gt;
&lt;h2 id=&#34;独立同分布的中心极限定理&#34;&gt;独立同分布的中心极限定理&lt;/h2&gt;
&lt;p&gt;假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 独立同分布，且具有数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$，则随机变量之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量：&lt;/p&gt;
&lt;p&gt;$$
Y_{n}=\frac{\overline{S X_{n}}-\mathbb{E}\left[\overline{S X_{n}}\right]}{\sqrt{\operatorname{Var}\left[\overline{S X_{n}}\right]}}=\frac{\overline{S X_{n}}-n \mu}{\sqrt{n} \sigma}
$$&lt;/p&gt;
&lt;p&gt;的概率分布函数 $F_{n}(x)$ 对于任意 $x$ 满足：&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c}{\lim &lt;em&gt;{n \rightarrow \infty} F&lt;/em&gt;{n}(x)=\lim &lt;em&gt;{n \rightarrow \infty} P\left{Y&lt;/em&gt;{n} \leq x\right}=\lim &lt;em&gt;{n \rightarrow \infty} P\left{\frac{\sum&lt;/em&gt;{k=1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma} \leq x\right}} \ {=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} / 2} d t=\Phi(x)}\end{array}
$$&lt;/p&gt;
&lt;p&gt;其物理意义在于，均值方差为 $\mu, \sigma^{2}$ 的独立同分布的随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量 $Y_n$，当 $n$ 充分大时，其分布近似于标准正态分布。&lt;/p&gt;
&lt;p&gt;即 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 在 $n$ 充分大时，其分布近似于 $N\left(n \mu, n \sigma^{2}\right)$。一般情况下，很难求出 $n$ 个随机变量之和的分布函数。因此当 $n$ 充分大时，可以通过正态分布来做理论上的分析或者计算。&lt;/p&gt;
&lt;h2 id=&#34;liapunov-定理&#34;&gt;Liapunov 定理&lt;/h2&gt;
&lt;p&gt;假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，具有数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu_{k}, \operatorname{Var}\left[X_{k}\right]=\sigma_{k}^{2}$。&lt;/p&gt;
&lt;p&gt;记 $B_{n}^{2}=\sum_{k=1}^{n} \sigma_{k}^{2}$，如果存在正数 $\delta$，使得 $n \rightarrow \infty$ 时：&lt;/p&gt;
&lt;p&gt;$$
\frac{1}{B_{n}^{2+\delta}} \sum_{k=1}^{n} \mathbb{E}\left[\left|X_{k}-\mu_{k}\right|^{2+\delta}\right] \rightarrow 0
$$&lt;/p&gt;
&lt;p&gt;则随机变量之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量：&lt;/p&gt;
&lt;p&gt;$$
Z_{n}=\frac{\overline{S X_{n}}-\mathbb{E}\left[\overline{S X_{n}}\right]}{\sqrt{\operatorname{Var}\left[\overline{S X_{n}}\right]}}=\frac{\overline{S X_{n}}-\sum_{k=1}^{n} \mu_{k}}{B_{n}}
$$&lt;/p&gt;
&lt;p&gt;的概率分布函数 $F_{n}(x)$ 对于任意 $x$ 满足：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned} \lim &lt;em&gt;{n \rightarrow \infty} F&lt;/em&gt;{n}(x)=\lim &lt;em&gt;{n \rightarrow \infty} &amp;amp; P\left{Z&lt;/em&gt;{n} \leq x\right}=\lim &lt;em&gt;{n \rightarrow \infty} P\left{\frac{\sum&lt;/em&gt;{k=1}^{n} X_{k}-\sum_{k=1}^{n} \mu_{k}}{B_{n}} \leq x\right} \ &amp;amp;=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} / 2} d t=\Phi(x) \end{aligned}
$$&lt;/p&gt;
&lt;p&gt;其物理意义在于，相互独立的随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的衍生随机变量序列 $Z_{n}=\frac{\overline{S X_{n}}-\sum_{k=1}^{n} \mu_{k}}{B_{n}}$，当 $n$ 充分大时，其分布近似于标准正态分布。注意，这里同样不要求 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 同分布。&lt;/p&gt;
&lt;h2 id=&#34;demoiver-laplace-定理&#34;&gt;Demoiver-Laplace 定理&lt;/h2&gt;
&lt;p&gt;假设随机变量序列 $\eta_{n}, n=1,2, \dots$ 服从参数为 $(n, p)$ 的二项分布，其中 $0&amp;lt;p&amp;lt;1$。则对于任意 $x$ 有：&lt;/p&gt;
&lt;p&gt;$$
\lim &lt;em&gt;{n \rightarrow \infty} P\left{\frac{\eta&lt;/em&gt;{n}-n p}{\sqrt{n p(1-p)}} \leq x\right}=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} | 2} d t=\Phi(x)
$$&lt;/p&gt;
&lt;p&gt;该定理表明，正态分布是二项分布的极限分布。当 $n$ 充分大时，可以利用正态分布来计算二项分布的概率。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>最小二乘法</title>
      <link>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/mathematics-series/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/</guid>
      <description>&lt;h1 id=&#34;最小二乘法&#34;&gt;最小二乘法&lt;/h1&gt;
&lt;p&gt;最小平方法是十九世纪统计学的主题曲。从许多方面来看, 它之于统计学就相当于十八世纪的微积分之于数学。&lt;/p&gt;
&lt;h1 id=&#34;案例尺子估算&#34;&gt;案例：尺子估算&lt;/h1&gt;
&lt;p&gt;来看一个生活中的例子。比如说，有五把尺子：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s1.ax1x.com/2020/10/11/0cJbvV.png&#34; alt=&#34;五把尺子&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;用它们来分别测量一线段的长度，得到的数值分别为（颜色指不同的尺子）：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s1.ax1x.com/2020/10/11/0cJXbF.png&#34; alt=&#34;尺寸长度&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;总之就是有误差，这种情况下，一般取平均值来作为线段的长度：&lt;/p&gt;
&lt;p&gt;$$
\bar{x}=\frac{10.2+10.3+9.8+9.9+9.8}{5}=10
$$&lt;/p&gt;
&lt;p&gt;换一种思路来思考刚才的问题，首先，把测试得到的值画在笛卡尔坐标系中，分别记作 $y_i$：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s1.ax1x.com/2020/10/11/0cYe5d.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其次，把要猜测的线段长度的真实值用平行于横轴的直线来表示（因为是猜测的，所以用虚线来画），记作 $y$：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s1.ax1x.com/2020/10/11/0cYnPA.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;每个点都向 $y$ 做垂线，垂线的长度就是 $|y-y_i|$，也可以理解为测量值和真实值之间的误差：&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s1.ax1x.com/2020/10/11/0cY3qS.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;因为误差是长度，还要取绝对值，计算起来麻烦，就干脆用平方来代表误差：&lt;/p&gt;
&lt;p&gt;$$
\left|y-y_{i}\right| \rightarrow\left(y-y_{i}\right)^{2}
$$&lt;/p&gt;
&lt;p&gt;总的误差的平方就是：&lt;/p&gt;
&lt;p&gt;$$
\epsilon=\sum\left(y-y_{i}\right)^{2}
$$&lt;/p&gt;
&lt;p&gt;因为 $y$ 是猜测的，所以可以不断变换，自然，总的误差\epsilon 也是在不断变化的。法国数学家，阿德里安-馬里·勒讓德（1752－1833，这个头像有点抽象）提出让总的误差的平方最小的 y 就是真值，这是基于，如果误差是随机的，应该围绕真值上下波动：&lt;/p&gt;
&lt;p&gt;$$
\epsilon=\sum\left(y-y_{i}\right)^{2} \text { 最小 } \Longrightarrow \text { 真值 } y
$$&lt;/p&gt;
&lt;p&gt;这是一个二次函数，对其求导，导数为 0 的时候取得最小值：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\frac{d}{d y} \epsilon &amp;amp;=\frac{d}{d y} \sum\left(y-y_{i}\right)^{2}=2 \sum\left(y-y_{i}\right) \
&amp;amp;=2\left(\left(y-y_{1}\right)+\left(y-y_{2}\right)+\left(y-y_{3}\right)+\left(y-y_{4}\right)+\left(y-y_{5}\right)\right)=0
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;进而：&lt;/p&gt;
&lt;p&gt;$$
5 y=y_{1}+y_{2}+y_{3}+y_{4}+y_{5} \Longrightarrow y=\frac{y_{1}+y_{2}+y_{3}+y_{4}+y_{5}}{5}
$$&lt;/p&gt;
&lt;p&gt;以下这种方法：&lt;/p&gt;
&lt;p&gt;$$
\epsilon=\sum\left(y-y_{i}\right)^{2} \text { 最小 } \Longrightarrow \text { 真值 } y
$$&lt;/p&gt;
&lt;p&gt;就是最小二乘法，所谓“二乘”就是平方的意思，台湾直接翻译为最小平方法。&lt;/p&gt;
&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.matongxue.com/madocs/818.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.matongxue.com/madocs/818.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

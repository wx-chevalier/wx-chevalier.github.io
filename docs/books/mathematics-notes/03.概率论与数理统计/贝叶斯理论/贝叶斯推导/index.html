<!doctype html><html lang=zh><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=google-site-verification content="google69a5cccb61297807"><meta name=baidu-site-verification content="cqmZHEleVh"><meta name=description content="Bayesian Inference Let X1X1 be the vector of observable random variables. Let X2X2 be the vector of latent random variables. Let ΘΘ be the vector of parameters. f(x2,θ|x1)=f(x1|x2,θ)f(x2|θ)f(θ)f(x1) 极大似然估计 Maximum Likelihood Estimation 假设有一堆独立同分布数据 X1,…,Xn，其 PDF 为 p(x"><link rel=alternate hreflang=zh href=https://ng-tech.icu/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/><meta name=theme-color content="#0a55a7"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.5/themes/satellite-min.css integrity="sha256-TehzF/2QvNKhGQrrNpoOb2Ck4iGZ1J/DI4pkd2oUsBc=" crossorigin=anonymous><link rel=stylesheet href=/css/wowchemy.63df6ae9fc2b4cc71b83f1774d780209.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-40NYXJ8823"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-40NYXJ8823")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?56df1177bce405601b0ecdd7208f75c6",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0f7d075e895d6f5f1f5fdbc1e33dc138_10087_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://ng-tech.icu/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wx-chevalier"><meta property="twitter:creator" content="@wx-chevalier"><meta property="og:site_name" content="Next-gen Tech Edu"><meta property="og:url" content="https://ng-tech.icu/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/"><meta property="og:title" content="贝叶斯推导 | Next-gen Tech Edu"><meta property="og:description" content="Bayesian Inference Let X1X1 be the vector of observable random variables. Let X2X2 be the vector of latent random variables. Let ΘΘ be the vector of parameters. f(x2,θ|x1)=f(x1|x2,θ)f(x2|θ)f(θ)f(x1) 极大似然估计 Maximum Likelihood Estimation 假设有一堆独立同分布数据 X1,…,Xn，其 PDF 为 p(x"><meta property="og:image" content="https://ng-tech.icu/media/sharing.png"><meta property="twitter:image" content="https://ng-tech.icu/media/sharing.png"><meta property="og:locale" content="zh"><title>贝叶斯推导 | Next-gen Tech Edu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=57dd0a35e34a12717afcb1b7ad6e06b5><button onclick=topFunction() id=backTopBtn title="Go to top"><i class="fa-solid fa-circle-up" aria-hidden=true></i></button>
<script src=/js/wowchemy-init.min.14a0ed61c6dbd594b9c75193b25be179.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class="col-6 search-title"><p>搜索</p></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=关闭><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div><div id=search-common-queries></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Next-gen Tech Edu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/books-gallery><span>笔记（万篇）</span></a></li><li class=nav-item><a class=nav-link href=/#knowledge-map><span>知识图谱</span></a></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>实验室</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/galaxy-home/gh-craft><span>Craft 方块世界</span></a>
<a class=dropdown-item href=/galaxy-home/glossary-cards><span>3D 知识卡牌</span></a></div></li><style>.dropdown-item{display:inline-flex}</style><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>其他阅读渠道</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230218234451.png></img><span>知乎</span></a>
<a class=dropdown-item href=https://segmentfault.com/blog/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113556.png></img><span>SegmentFault</span></a>
<a class=dropdown-item href=https://zhuanlan.zhihu.com/wxyyxc1992><img style=width:16px;height:16px;display:inline-block;margin-right:8px src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230219113519.png></img><span>掘金</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/wx-chevalier aria-label=GitHub><i class="fa-brands fa-github" aria-hidden=true></i></a></li><div></div><style>@media only screen and (max-width:600px){.jimmysong-template{display:none!important}}</style><li class=jimmysong-template style=color:#fff;font-size:12px><a href=https://jimmysong.io style=color:#fff>By Jimmy Song's Template</a></li></ul></div></nav></header></div><div class=page-body><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><div class="container-xl docs"><div class="row flex-xl-nowrap"><div class=docs-sidebar><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">贝叶斯理论</span>
<span><i class="fas fa-chevron-down"></i></span></div></button>
<button class="form-control sidebar-search js-search d-none d-md-flex">
<i class="fas fa-search pr-2"></i>
<span class=sidebar-search-text>搜索...</span>
<span class=sidebar-search-shortcut>/</span></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li style=display:inline-flex><a style=cursor:pointer onclick=window.history.back()><i class="fas fa-arrow-left pr-1"></i>
Back</a>
<span>|</span>
<a href=/books/><i class="fa-solid fa-house" style=margin-right:4px></i>
Books</a></li></ul><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id7ecc77f293ef0281037d77bb6df75f9a")' href=#id7ecc77f293ef0281037d77bb6df75f9a aria-expanded=false aria-controls=id7ecc77f293ef0281037d77bb6df75f9a aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/>03.概率论与数理统计</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id7ecc77f293ef0281037d77bb6df75f9a aria-expanded=false aria-controls=id7ecc77f293ef0281037d77bb6df75f9a><i class="fa-solid fa-angle-down" id=caret-id7ecc77f293ef0281037d77bb6df75f9a></i></a></div><ul class="nav docs-sidenav collapse show" id=id7ecc77f293ef0281037d77bb6df75f9a><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id7eb3ed66a77ebb70e02fa9533f1bad3b")' href=#id7eb3ed66a77ebb70e02fa9533f1bad3b aria-expanded=false aria-controls=id7eb3ed66a77ebb70e02fa9533f1bad3b aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/>99.参考资料</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id7eb3ed66a77ebb70e02fa9533f1bad3b aria-expanded=false aria-controls=id7eb3ed66a77ebb70e02fa9533f1bad3b><i class="fa-solid fa-angle-right" id=caret-id7eb3ed66a77ebb70e02fa9533f1bad3b></i></a></div><ul class="nav docs-sidenav collapse" id=id7eb3ed66a77ebb70e02fa9533f1bad3b><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id57cbf5dbd55bfffd484d4be322fd7e98")' href=#id57cbf5dbd55bfffd484d4be322fd7e98 aria-expanded=false aria-controls=id57cbf5dbd55bfffd484d4be322fd7e98 aria-hidden=false data-toggle=collapse></div></div><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/99.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%AC%94%E8%AE%B0/>概率论与数理统计笔记</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id1605bf700dd6b6a326256e97c6f9c9d1")' href=#id1605bf700dd6b6a326256e97c6f9c9d1 aria-expanded=false aria-controls=id1605bf700dd6b6a326256e97c6f9c9d1 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/>贝叶斯理论</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id1605bf700dd6b6a326256e97c6f9c9d1 aria-expanded=false aria-controls=id1605bf700dd6b6a326256e97c6f9c9d1><i class="fa-solid fa-angle-down" id=caret-id1605bf700dd6b6a326256e97c6f9c9d1></i></a></div><ul class="nav docs-sidenav collapse show" id=id1605bf700dd6b6a326256e97c6f9c9d1><li class="child level active"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/>变分贝叶斯推导</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/>朴素贝叶斯</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id42b7c8cad3f0d4d281bc9df12f962aa2")' href=#id42b7c8cad3f0d4d281bc9df12f962aa2 aria-expanded=false aria-controls=id42b7c8cad3f0d4d281bc9df12f962aa2 aria-hidden=false data-toggle=collapse></div></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id37a5e51ba5b93eb4beac88a501f19afa")' href=#id37a5e51ba5b93eb4beac88a501f19afa aria-expanded=false aria-controls=id37a5e51ba5b93eb4beac88a501f19afa aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/>常见概率分布</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id37a5e51ba5b93eb4beac88a501f19afa aria-expanded=false aria-controls=id37a5e51ba5b93eb4beac88a501f19afa><i class="fa-solid fa-angle-right" id=caret-id37a5e51ba5b93eb4beac88a501f19afa></i></a></div><ul class="nav docs-sidenav collapse" id=id37a5e51ba5b93eb4beac88a501f19afa><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E5%A4%9A%E9%A1%B9%E5%88%86%E5%B8%83/>多项分布</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83/>泊松分布</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/>正态分布</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id9b4e96e6d6ebaa810879808bb5b7e521")' href=#id9b4e96e6d6ebaa810879808bb5b7e521 aria-expanded=false aria-controls=id9b4e96e6d6ebaa810879808bb5b7e521 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/>概率论基础</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id9b4e96e6d6ebaa810879808bb5b7e521 aria-expanded=false aria-controls=id9b4e96e6d6ebaa810879808bb5b7e521><i class="fa-solid fa-angle-right" id=caret-id9b4e96e6d6ebaa810879808bb5b7e521></i></a></div><ul class="nav docs-sidenav collapse" id=id9b4e96e6d6ebaa810879808bb5b7e521><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%A6%82%E7%8E%87%E4%B8%8E%E5%88%86%E5%B8%83/>概率与分布</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE/>期望与方差</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86/>中心极限与大数定理</a></li><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/>最小二乘法</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-idf37771a0647ac20fbdb01e3945a8dfa0")' href=#idf37771a0647ac20fbdb01e3945a8dfa0 aria-expanded=false aria-controls=idf37771a0647ac20fbdb01e3945a8dfa0 aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/>概率图模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#idf37771a0647ac20fbdb01e3945a8dfa0 aria-expanded=false aria-controls=idf37771a0647ac20fbdb01e3945a8dfa0><i class="fa-solid fa-angle-right" id=caret-idf37771a0647ac20fbdb01e3945a8dfa0></i></a></div><ul class="nav docs-sidenav collapse" id=idf37771a0647ac20fbdb01e3945a8dfa0><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/>条件随机场</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id4c42eb50d1c5fdbeb38fe3651eedb41c")' href=#id4c42eb50d1c5fdbeb38fe3651eedb41c aria-expanded=false aria-controls=id4c42eb50d1c5fdbeb38fe3651eedb41c aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>马尔科夫模型</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id4c42eb50d1c5fdbeb38fe3651eedb41c aria-expanded=false aria-controls=id4c42eb50d1c5fdbeb38fe3651eedb41c><i class="fa-solid fa-angle-right" id=caret-id4c42eb50d1c5fdbeb38fe3651eedb41c></i></a></div><ul class="nav docs-sidenav collapse" id=id4c42eb50d1c5fdbeb38fe3651eedb41c><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/>隐马尔科夫模型</a></li></ul></div><div class="docs-toc-item has-child"><div class="parent-node d-flex justify-content-between" onclick='Collapse("caret-id67cf2c9dd838289da4611971ec3d0bcc")' href=#id67cf2c9dd838289da4611971ec3d0bcc aria-expanded=false aria-controls=id67cf2c9dd838289da4611971ec3d0bcc aria-hidden=false data-toggle=collapse><a class="d-inline docs-toc-link" href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/>蒙特卡洛</a>
<a class="nav-toogle d-inline level" aria-hidden=false data-toggle=collapse href=#id67cf2c9dd838289da4611971ec3d0bcc aria-expanded=false aria-controls=id67cf2c9dd838289da4611971ec3d0bcc><i class="fa-solid fa-angle-right" id=caret-id67cf2c9dd838289da4611971ec3d0bcc></i></a></div><ul class="nav docs-sidenav collapse" id=id67cf2c9dd838289da4611971ec3d0bcc><li class="child level"><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B/%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/>蒙特卡罗方法</a></li></ul></div></ul></div></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>目录</a></li></ul><nav id=TableOfContents><ul><li><a href=#极大似然估计-maximum-likelihood-estimation>极大似然估计 Maximum Likelihood Estimation</a></li><li><a href=#maximum-a-posterior-estimation--极大后验估计>Maximum A Posterior Estimation | 极大后验估计</a></li><li><a href=#贝叶斯推断-bayesian-inference>贝叶斯推断 :Bayesian Inference</a></li></ul></nav><div class="subscribe-module col-24 mt-1"><img src=https://ngte-superbed.oss-cn-beijing.aliyuncs.com/item/20230220172727.png alt=image title=王下邀月熊的微信公众号></div></div><main class="py-md-3 pl-md-3 docs-content col-xl-8" role=main><article class=article><h1>贝叶斯推导</h1><div class=article-style><h1 id=bayesian-inference>Bayesian Inference</h1><p>Let X1X1 be the vector of observable random variables. Let X2X2 be the vector of latent random variables. Let ΘΘ be the vector of parameters. f(x2,θ|x1)=f(x1|x2,θ)f(x2|θ)f(θ)f(x1)</p><h2 id=极大似然估计-maximum-likelihood-estimation>极大似然估计 Maximum Likelihood Estimation</h2><p>假设有一堆独立同分布数据 X1,…,Xn，其 PDF 为 p(x;θ)，其中 θ 为模型参数，则其似然函数为: $$L<em>n(\theta)=\prod\limits</em>{i=1}^n p(X<em>i; \theta)$$ 而极大似然估计就是要找到参数 $\theta$，使得似然函数的值最大。这意思就是找到一个参数 $\theta$，使得使用分布 p(x;θ) 来估计这一堆数据 Xi 的效果最好。为啥捏，因为假设 X 都是离散值的情况下，Ln(Xi;θ) 表达的含义是：从参数 θ 通过模型 p(x;θ) 产生这一堆数据的概率(把所有单个数据产生的概率乘起来就是产生这一堆数据的概率)。所以 p(x;θ)=Pθ(x={Xi})，那么如果当有两个参数 θ1 和 θ2 时，$P</em>{\theta<em>1}(x={X_i})>P</em>{\theta<em>2}(x={X_i})$，则说明 θ1 更好的描述了这组数据，因此要找到一个 θ 使得整似然函数的值最大！所以只要将似然函数对 θ 求导，就可以找到这样的 θ。例子：求 N 次伯努利分布的最大似然估计: $$ Bern(x|\mu)=\mu^x(1-\mu)^{1-x} \ L(X|\mu)=\prod\limits</em>{i=1}^N \mu^{X*i}(1-\mu)^{1-X_i}=\mu^S(1-\mu)^{N-S} 其中 S=\sum\limits*{i=1}^N X_i $$ 将 $log L(X|\mu)$ 对 $\mu$ 求导得到 $\frac{S}{\mu}-\frac{N-S}{1-\mu}=0$，最终得到 : $$ \hat{\mu}_N=\frac{1}{N} S=\bar{X}_N $$</p><h2 id=maximum-a-posterior-estimation--极大后验估计>Maximum A Posterior Estimation | 极大后验估计</h2><p>极大后验估计中加入了一些先验知识，它最大化的是一个后验函数。具体来说，因为贝叶斯定律:</p><p>$$
p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}
$$</p><p>那么极大后验估计就是要求</p><p>$$
\hat{\theta}<em>{MAP}=\underset{\theta}{argmax}~ p(x|\theta)p(\theta)=\underset{\theta}{argmax}{\sum\limits</em>{X_i} log ~p(X_i|\theta) + log~p(\theta)}
$$</p><p>可见，极大后验估计中相对于最大似然估计，多了 log p(θ)，也就是先验的影响。</p><h2 id=贝叶斯推断-bayesian-inference>贝叶斯推断 :Bayesian Inference</h2><p>前面的 MAP 是一个点估计，只估计似然函数达到最大点的情况下，参数 θ 的值。而贝叶斯推断通过假设关于参数 $\theta$ 的一个分布而不是直接求单个值来扩展了 MAP 算法。</p><blockquote><p>Bayesian inference extends the MAP approach by allowing a distribution over the parameter set θ instead of making a direct estimate. Not only encodes this the maximum(a posteriori) value of the data-generated parameters, but it also incorporates expectation as another parameter estimate as well as variance information as a measure of estimation quality or confidence.</p></blockquote><p>具体来说，给定数据 X 和需要求的参数 θ，贝叶斯推断需要求出一个具体的分布: $$ p(\theta|X)=P(X|\theta)P(\theta)/P(X) $$</p><ul><li>$X$: 观测数据</li><li>$\theta$: 潜变量</li></ul><p>这里和 MAP 的区别就在于，MAP 忽略了 P(X) 因为它是常量，对于 MAP 的过程：求导后再求等于 0 来获得最好的 θ，这个常量是没有用的。但是贝叶斯推断要的是整个 p(θ|X) 的分布，所以 P(X) 这个 normalisation term 是需要被求出来的。在获得具体的分布之后，所要求的参数值可以通过估计期望或方差得到。</p></div><div class=article-widget><div class="container-xl row post-nav"><div class="col-6 post-nav-item"><div class=meta-nav>下一页</div><a href=/books/mathematics-notes/03.%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E5%AF%BC/ rel=prev>变分贝叶斯推导</a></div></div></div><div class=body-footer><p>最近更新于 0001-01-01</p><section id=comments class="mb-3 pt-0"><div id=disqus_thread></div><script>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="https://ngte.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><footer class=site-footer><div class="copyright py-4 bg-footer"><div class="row justify-content-center"><div class="text-center footer-color"><p class=mb-0>© 2017-2022 NGTE all rights reserved</p></div></div></div><script type=text/javascript id=clstr_globe async src="//clustrmaps.com/globe.js?d=kgpJG5sWZQpKujBmD-uW1B54-WBPol-DuDtrB2KFjKs"></script></footer></main></div></div><script src=//unpkg.com/heti/umd/heti-addon.min.js></script>
<script>const heti=new Heti(".article");heti.autoSpacing()</script><script type=text/javascript>window.$crisp=[],window.CRISP_WEBSITE_ID="12adcc35-9621-4313-8262-62dc654b29d8",function(){setTimeout(function(){d=document,s=d.createElement("script"),s.src="https://client.crisp.chat/l.js",s.async=1,d.getElementsByTagName("head")[0].appendChild(s)},2500)}()</script></div><div class=page-footer></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.1/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script id=search-hit-algolia-template type=text/html><div class=search-hit><div class=search-hit-content><div class=search-hit-name><a href={{relpermalink}}>{{#helpers.highlight}}{ "attribute": "title" }{{/helpers.highlight}}</a></div><div class="article-metadata search-hit-type">{{type}}</div><p class=search-hit-description>{{#helpers.highlight}}{ "attribute": "summary" }{{/helpers.highlight}}</p></div></div></script><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js crossorigin=anonymous></script>
<script id=dsq-count-scr src=https://ngte.disqus.com/count.js async></script>
<script src=/zh/js/algolia-search-built.min.4387d694ca1258194aaf562b8cd1c400.js type=module></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/zh/js/wowchemy.min.d1673c7a11d1238516cbe12a1e84257f.js></script>
<script>var mybutton=document.getElementById("backTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.style.display="block":mybutton.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script src=https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin=anonymous></script>
<script>anchors.add()</script><script>(function(){"use strict";if(!document.queryCommandSupported("copy"))return;function e(e,t){e.className="highlight-copy-btn",e.textContent=t,setTimeout(function(){e.textContent="",e.className="highlight-copy-btn fa fa-copy"},1e3)}function t(e){var t=window.getSelection(),n=document.createRange();return n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n),t}function n(n){var o,s=document.createElement("button");s.className="highlight-copy-btn fa fa-copy",s.textContent="",o=n.firstElementChild,s.addEventListener("click",function(){try{var n=t(o);document.execCommand("copy"),n.removeAllRanges(),e(s,"已复制")}catch(t){console&&console.log(t),e(s,"Failed :'(")}}),n.appendChild(s)}var s=document.getElementsByClassName("highlight");Array.prototype.forEach.call(s,n)})()</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>主从复制 | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
      <atom:link href="https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/index.xml" rel="self" type="application/rss+xml" />
    <description>主从复制</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>主从复制</title>
      <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
    </image>
    
    <item>
      <title>宕机恢复</title>
      <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%AE%95%E6%9C%BA%E6%81%A2%E5%A4%8D/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%AE%95%E6%9C%BA%E6%81%A2%E5%A4%8D/</guid>
      <description>&lt;h1 id=&#34;宕机恢复&#34;&gt;宕机恢复&lt;/h1&gt;
&lt;p&gt;系统中的任何节点都可能宕机，可能因为意外的故障，也可能由于计划内的维护（例如，重启机器以安装内核安全补丁）。对运维而言，能在系统不中断服务的情况下重启单个节点好处多多。我们的目标是，即使个别节点失效，也能保持整个系统运行，并尽可能控制节点停机带来的影响。&lt;/p&gt;
&lt;h1 id=&#34;设置新从库&#34;&gt;设置新从库&lt;/h1&gt;
&lt;p&gt;有时候需要设置一个新的从库：也许是为了增加副本的数量，或替换失败的节点。如何确保新的从库拥有主库数据的精确副本？最简单地将数据文件从一个节点复制到另一个节点通常是不够的：客户端不断向数据库写入数据，数据总是在不断变化，标准的数据副本会在不同的时间点总是不一样。复制的结果可能没有任何意义。&lt;/p&gt;
&lt;p&gt;可以通过锁定数据库（使其不可用于写入）来使磁盘上的文件保持一致，但是这会违背高可用的目标。幸运的是，拉起新的从库通常并不需要停机。从概念上讲，过程如下所示：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在某个时刻获取主库的一致性快照（如果可能），而不必锁定整个数据库。大多数数据库都具有这个功能，因为它是备份必需的。对于某些场景，可能需要第三方工具，例如 MySQL 的 innobackupex。&lt;/li&gt;
&lt;li&gt;将快照复制到新的从库节点。&lt;/li&gt;
&lt;li&gt;从库连接到主库，并拉取快照之后发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。该位置有不同的名称：例如，PostgreSQL 将其称为 日志序列号（log sequence number, LSN），MySQL 将其称为 二进制日志坐标（Binlog coordinates）。&lt;/li&gt;
&lt;li&gt;当从库处理完快照之后积压的数据变更，我们说它赶上（caught up）了主库。现在它可以继续处理主库产生的数据变化了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;建立从库的实际步骤因数据库而异。在某些系统中，这个过程是完全自动化的，而在另外一些系统中，它可能是一个需要由管理员手动执行的，有点神秘的多步骤工作流。&lt;/p&gt;
&lt;h1 id=&#34;从库失效追赶恢复catch-up-recovery&#34;&gt;从库失效：追赶恢复（Catch-up Recovery）&lt;/h1&gt;
&lt;p&gt;在其本地磁盘上，每个从库记录从主库收到的数据变更。如果从库崩溃并重新启动，或者，如果主库和从库之间的网络暂时中断，则比较容易恢复：从库可以从日志中知道，在发生故障之前处理的最后一个事务。因此，从库可以连接到主库，并请求在从库断开连接时发生的所有数据变更。当应用完所有这些变化后，它就赶上了主库，并可以像以前一样继续接收数据变更流。&lt;/p&gt;
&lt;h1 id=&#34;主库失效故障切换failover&#34;&gt;主库失效：故障切换（Failover）&lt;/h1&gt;
&lt;p&gt;主库失效处理起来相当棘手：其中一个从库需要被提升为新的主库，需要重新配置客户端，以将它们的写操作发送给新的主库，其他从库需要开始拉取来自新主库的数据变更。这个过程被称为故障切换（failover）。故障切换可以手动进行（通知管理员主库挂了，并采取必要的步骤来创建新的主库）或自动进行。自动故障切换过程通常由以下步骤组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;确认主库失效。有很多事情可能会出错：崩溃，停电，网络问题等等。没有万无一失的方法来检测出现了什么问题，所以大多数系统只是简单使用 超时（Timeout）：节点频繁地相互来回传递消息，并且如果一个节点在一段时间内（例如 30 秒）没有响应，就认为它挂了（因为计划内维护而故意关闭主库不算）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由之前选定的控制器节点（controller node）来指定新的主库。主库的最佳人选通常是拥有旧主库最新数据副本的从库（最小化数据损失）。让所有的节点同意一个新的领导者，是一个共识问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重新配置系统以启用新的主库。客户端现在需要将它们的写请求发送给新主库。如果老领导回来，可能仍然认为自己是主库，没有意识到其他副本已经让它下台了。系统需要确保老领导认可新领导，成为一个从库。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值得注意的是，故障切换会出现很多大麻烦：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果使用异步复制，则新主库可能没有收到老主库宕机前最后的写入操作。在选出新主库后，如果老主库重新加入集群，新主库在此期间可能会收到冲突的写入，那这些写入该如何处理？最常见的解决方案是简单丢弃老主库未复制的写入，这很可能打破客户对于数据持久性的期望。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果数据库需要和其他外部存储相协调，那么丢弃写入内容是极其危险的操作。例如在 GitHub 的一场事故中，一个过时的 MySQL 从库被提升为主库。数据库使用自增 ID 作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的 ID 作为主键。这些主键也在 Redis 中使用，主键重用使得 MySQL 和 Redis 中数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发生某些故障时可能会出现两个节点都以为自己是主库的情况。这种情况称为 脑裂(split brain)，非常危险：如果两个主库都可以接受写操作，却没有冲突解决机制，那么数据就可能丢失或损坏。一些系统采取了安全防范措施，即所谓的屏蔽（fencing）机制：当检测到两个主库节点同时存在时会关闭其中一个节点，但设计粗糙的机制可能最后会导致两个节点都被关闭。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;主库被宣告死亡之前的正确超时应该怎么配置？在主库失效的情况下，超时时间越长，意味着恢复时间也越长。但是如果超时设置太短，又可能会出现不必要的故障切换。例如，临时负载峰值可能导致节点的响应时间超时，或网络故障可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些问题没有简单的解决方案。因此，即使软件支持自动故障切换，不少运维团队还是更愿意手动执行故障切换。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>复制日志</title>
      <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%A4%8D%E5%88%B6%E6%97%A5%E5%BF%97/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%A4%8D%E5%88%B6%E6%97%A5%E5%BF%97/</guid>
      <description>&lt;h1 id=&#34;复制日志&#34;&gt;复制日志&lt;/h1&gt;
&lt;h1 id=&#34;基于语句的复制&#34;&gt;基于语句的复制&lt;/h1&gt;
&lt;p&gt;在最简单的情况下，主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。对于关系数据库来说，这意味着每个 INSERT，UPDATE 或 DELETE 语句都被转发给每个从库，每个从库解析并执行该 SQL 语句，就像从客户端收到一样。&lt;/p&gt;
&lt;p&gt;虽然听上去很合理，但有很多问题会搞砸这种复制方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;任何调用非确定性函数（nondeterministic）的语句，可能会在每个副本上生成不同的值。例如，使用 NOW()获取当前日期时间，或使用 RAND() 获取一个随机数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果语句使用了自增列（auto increment），或者依赖于数据库中的现有数据（例如，UPDATE &amp;hellip; WHERE &amp;lt;某些条件&amp;gt;），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。当有多个并发执行的事务时，这可能成为一个限制。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有副作用的语句（例如，触发器，存储过程，用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以尝试绕过这些问题，例如，当语句被记录时，主库可以用固定的返回值替换任何不确定的函数调用，以便从库获得相同的值。但是由于边缘情况实在太多了，现在通常会选择其他的复制方法。基于语句的复制在 5.1 版本前的 MySQL 中使用。因为它相当紧凑，现在有时候也还在用。但现在在默认情况下，如果语句中存在任何不确定性，MySQL 会切换到基于行的复制 VoltDB 使用了基于语句的复制，但要求事务必须是确定性的，以此来保证安全。&lt;/p&gt;
&lt;h1 id=&#34;传输预写式日志wal&#34;&gt;传输预写式日志（WAL）&lt;/h1&gt;
&lt;p&gt;存储引擎常常会写操作都是追加到日志中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于日志结构存储引擎（类似于 SSTables 和 LSM 树），日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。&lt;/li&gt;
&lt;li&gt;对于覆写单个磁盘块的 B 树，每次修改都会先写入 预写式日志（Write Ahead Log, WAL），以便崩溃后索引可以恢复到一个一致的状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在任何一种情况下，日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：除了将日志写入磁盘之外，主库还可以通过网络将其发送给其从库。当从库应用这个日志时，它会建立和主库一模一样数据结构的副本。PostgreSQL 和 Oracle 等使用这种复制方法。&lt;/p&gt;
&lt;p&gt;这种复制方式的主要缺点是日志记录的数据非常底层：WAL 包含哪些磁盘块中的哪些字节发生了更改。这使复制与存储引擎紧密耦合。如果数据库将其存储格式从一个版本更改为另一个版本，通常不可能在主库和从库上运行不同版本的数据库软件。&lt;/p&gt;
&lt;p&gt;看上去这可能只是一个微小的实现细节，但却可能对运维产生巨大的影响。如果复制协议允许从库使用比主库更新的软件版本，则可以先升级从库，然后执行故障切换，使升级后的节点之一成为新的主库，从而执行数据库软件的零停机升级。如果复制协议不允许版本不匹配（传输 WAL 经常出现这种情况），则此类升级需要停机。&lt;/p&gt;
&lt;h1 id=&#34;逻辑日志复制基于行&#34;&gt;逻辑日志复制（基于行）&lt;/h1&gt;
&lt;p&gt;另一种方法是，复制和存储引擎使用不同的日志格式，这样可以使复制日志从存储引擎内部分离出来。这种复制日志被称为逻辑日志，以将其与存储引擎的（物理）数据表示区分开来。关系数据库的逻辑日志通常是以行的粒度描述对数据库表的写入的记录序列：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于插入的行，日志包含所有列的新值。&lt;/li&gt;
&lt;li&gt;对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。&lt;/li&gt;
&lt;li&gt;对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;修改多行的事务会生成多个这样的日志记录，后面跟着一条记录，指出事务已经提交 MySQL 的二进制日志（当配置为使用基于行的复制时）使用这种方法。由于逻辑日志与存储引擎内部分离，因此可以更容易地保持向后兼容，从而使领导者和跟随者能够运行不同版本的数据库软件甚至不同的存储引擎。对于外部应用程序来说，逻辑日志格式也更容易解析。如果要将数据库的内容发送到外部系统（如数据），这一点很有用，例如复制到数据仓库进行离线分析，或建立自定义索引和缓存这种技术被称为数据变更捕获（change data capture）。&lt;/p&gt;
&lt;h1 id=&#34;基于触发器的复制&#34;&gt;基于触发器的复制&lt;/h1&gt;
&lt;p&gt;到目前为止描述的复制方法是由数据库系统实现的，不涉及任何应用程序代码。在很多情况下，这就是你想要的。但在某些情况下需要更多的灵活性。例如，如果您只想复制数据的一个子集，或者想从一种数据库复制到另一种数据库，或者如果您需要冲突解决逻辑，则可能需要将复制移动到应用程序层。&lt;/p&gt;
&lt;p&gt;一些工具，如 Oracle Golden Gate，可以通过读取数据库日志，使得其他应用程序可以使用数据。另一种方法是使用许多关系数据库自带的功能：触发器和存储过程。&lt;/p&gt;
&lt;p&gt;触发器允许您注册在数据库系统中发生数据更改（写入事务）时自动执行的自定义应用程序代码。触发器有机会将更改记录到一个单独的表中，使用外部程序读取这个表，再加上任何业务逻辑处理，会后将数据变更复制到另一个系统去。例如，Databus for Oracle 和 Bucardo for Postgres 就是这样工作的。&lt;/p&gt;
&lt;p&gt;基于触发器的复制通常比其他复制方法具有更高的开销，并且比数据库的内置复制更容易出错，也有很多限制。然而由于其灵活性，仍然是很有用的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>复制延迟</title>
      <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F/</guid>
      <description>&lt;h1 id=&#34;复制延迟&#34;&gt;复制延迟&lt;/h1&gt;
&lt;p&gt;容忍节点故障只是需要复制的一个原因，另一个原因是可扩展性（处理比单个机器更多的请求）和延迟（让副本在地理位置上更接近用户）。基于主库的复制要求所有写入都由单个节点处理，但只读查询可以由任何副本处理。所以对于读多写少的场景（Web 上的常见模式），一个有吸引力的选择是创建很多从库，并将读请求分散到所有的从库上去。这样能减小主库的负载，并允许向最近的副本发送读请求。在这种扩展体系结构中，只需添加更多的追随者，就可以提高只读请求的服务容量。但是，这种方法实际上只适用于异步复制——如果尝试同步复制到所有追随者，则单个节点故障或网络中断将使整个系统无法写入。而且越多的节点越有可能会被关闭，所以完全同步的配置是非常不可靠的。&lt;/p&gt;
&lt;p&gt;不幸的是，当应用程序从异步从库读取时，如果从库落后，它可能会看到过时的信息。这会导致数据库中出现明显的不一致：同时对主库和从库执行相同的查询，可能得到不同的结果，因为并非所有的写入都反映在从库中。这种不一致只是一个暂时的状态——如果停止写入数据库并等待一段时间，从库最终会赶上并与主库保持一致。出于这个原因，这种效应被称为 最终一致性（eventually consistency）。“最终”一词故意含糊不清：总的来说，副本落后的程度是没有限制的。在正常的操作中，复制延迟（replication lag），即写入主库到反映至从库之间的延迟，可能仅仅是几分之一秒，在实践中并不显眼。但如果系统在接近极限的情况下运行，或网络中存在问题，延迟可以轻而易举地超过几秒，甚至几分钟。因为滞后时间太长引入的不一致性，可不仅是一个理论问题，更是应用设计中会遇到的真实问题。&lt;/p&gt;
&lt;h1 id=&#34;读己之写&#34;&gt;读己之写&lt;/h1&gt;
&lt;p&gt;许多应用让用户提交一些数据，然后查看他们提交的内容。可能是用户数据库中的记录，也可能是对讨论主题的评论，或其他类似的内容。提交新数据时，必须将其发送给领导者，但是当用户查看数据时，可以从追随者读取。如果数据经常被查看，但只是偶尔写入，这是非常合适的。但对于异步复制，问题就来了。如果用户在写入后马上就查看数据，则新数据可能尚未到达副本。对用户而言，看起来好像是刚提交的数据丢失了，用户会不高兴，可以理解。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/02/09/1fwtG6.png&#34; alt=&#34;用户写入后从旧副本中读取数据。需要写后读(read-after-write)的一致性来防止这种异常&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在这种情况下，我们需要读写一致性（read-after-write consistency），也称为 读己之写一致性（read-your-writes consistency）。这是一个保证，如果用户重新加载页面，他们总会看到他们自己提交的任何更新。它不会对其他用户的写入做出承诺：其他用户的更新可能稍等才会看到。它保证用户自己的输入已被正确保存。&lt;/p&gt;
&lt;p&gt;如何在主从复制中实现读后一致性？有各种可能的技术，这里说一些：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;读用户可能已经修改过的内容时，都从主库读；这就要求有一些方法，不用实际查询就可以知道用户是否修改了某些东西。举个例子，社交网络上的用户个人资料信息通常只能由用户本人编辑，而不能由其他人编辑。因此一个简单的规则是：从主库读取用户自己的档案，在从库读取其他用户的档案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果应用中的大部分内容都可能被用户编辑，那这种方法就没用了，因为大部分内容都必须从主库读取（扩容读就没效果了）。在这种情况下可以使用其他标准来决定是否从主库读取。例如可以跟踪上次更新的时间，在上次更新后的一分钟内，从主库读。还可以监控从库的复制延迟，防止任向任何滞后超过一分钟到底从库发出查询。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端可以记住最近一次写入的时间戳，系统需要确保从库为该用户提供任何查询时，该时间戳前的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果您的副本分布在多个数据中心（出于可用性目的与用户尽量在地理上接近），则会增加复杂性。任何需要由领导者提供服务的请求都必须路由到包含主库的数据中心。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另一种复杂的情况是：如果同一个用户从多个设备请求服务，例如桌面浏览器和移动 APP。这种情况下可能就需要提供跨设备的写后读一致性：如果用户在某个设备上输入了一些信息，然后在另一个设备上查看，则应该看到他们刚输入的信息。在这种情况下，还有一些需要考虑的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;记住用户上次更新时间戳的方法变得更加困难，因为一台设备上运行的程序不知道另一台设备上发生了什么。元数据需要一个中心存储。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果副本分布在不同的数据中心，很难保证来自不同设备的连接会路由到同一数据中心（例如，用户的台式计算机使用家庭宽带连接，而移动设备使用蜂窝数据网络，则设备的网络路线可能完全不同）。如果你的方法需要读主库，可能首先需要把来自同一用户的请求路由到同一个数据中心。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;单调读&#34;&gt;单调读&lt;/h1&gt;
&lt;p&gt;从异步从库读取第二个异常例子是，用户可能会遇到时光倒流（moving backward in time）。如果用户从不同从库进行多次读取，就可能发生这种情况。例如，下图显示了用户 2345 两次进行相同的查询，首先查询了一个延迟很小的从库，然后是一个延迟较大的从库（如果用户刷新网页，而每个请求被路由到一个随机的服务器，这种情况是很有可能的。）第一个查询返回最近由用户 1234 添加的评论，但是第二个查询不返回任何东西，因为滞后的从库还没有拉取写入内容。在效果上相比第一个查询，第二个查询是在更早的时间点来观察系统。如果第一个查询没有返回任何内容，那问题并不大，因为用户 2345 可能不知道用户 1234 最近添加了评论。但如果用户 2345 先看见用户 1234 的评论，然后又看到它消失，那么对于用户 2345，就很让人头大了。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/02/09/1f0uFI.md.png&#34; alt=&#34;用户首先从新副本读取，然后从旧副本读取。时光倒流。为了防止这种异常，我们需要单调的读取。&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;单调读（Monotonic reads）是这种异常不会发生的保证。这是一个比强一致性（strong consistency）更弱，但比最终一致性（eventually consistency）更强的保证。当读取数据时，您可能会看到一个旧值；单调读取仅意味着如果一个用户顺序地进行多次读取，则他们不会看到时间后退，即，如果先前读取到较新的数据，后续读取不会得到更旧的数据。实现单调读取的一种方式是确保每个用户总是从同一个副本进行读取（不同的用户可以从不同的副本读取）。例如，可以基于用户 ID 的哈希来选择副本，而不是随机选择副本。但是，如果该副本失败，用户的查询将需要重新路由到另一个副本。&lt;/p&gt;
&lt;h1 id=&#34;一致前缀读&#34;&gt;一致前缀读&lt;/h1&gt;
&lt;p&gt;如果某些分区的复制速度慢于其他分区，那么观察者在看到问题之前可能会看到答案。防止这种异常，需要另一种类型的保证：一致前缀读（consistent prefix reads）这个保证说：如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/02/09/1f0aYq.md.png&#34; alt=&#34;违反了因果律的例子&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这是分区（partitioned）（分片（sharded））数据库中的一个特殊问题，如果数据库总是以相同的顺序应用写入，则读取总是会看到一致的前缀，所以这种异常不会发生。但是在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序：当用户从数据库中读取数据时，可能会看到数据库的某些部分处于较旧的状态，而某些处于较新的状态。&lt;/p&gt;
&lt;p&gt;一种解决方案是，确保任何因果相关的写入都写入相同的分区。对于某些无法高效完成这种操作的应用，还有一些显式跟踪因果依赖关系的算法。&lt;/p&gt;
&lt;h1 id=&#34;复制延迟的解决方案&#34;&gt;复制延迟的解决方案&lt;/h1&gt;
&lt;p&gt;在使用最终一致的系统时，如果复制延迟增加到几分钟甚至几小时，则应该考虑应用程序的行为。如果答案是“没问题”，那很好。但如果结果对于用户来说是不好体验，那么设计系统来提供更强的保证是很重要的，例如写后读。明明是异步复制却假设复制是同步的，这是很多麻烦的根源。&lt;/p&gt;
&lt;p&gt;如前所述，应用程序可以提供比底层数据库更强有力的保证，例如通过主库进行某种读取。但在应用程序代码中处理这些问题是复杂的，容易出错。如果应用程序开发人员不必担心微妙的复制问题，并可以信赖他们的数据库“做了正确的事情”，那该多好呀。这就是事务（transaction）存在的原因：数据库通过事务提供强大的保证，所以应用程序可以更加简单。&lt;/p&gt;
&lt;p&gt;单节点事务已经存在了很长时间。然而在走向分布式（复制和分区）数据库时，许多系统放弃了事务。声称事务在性能和可用性上的代价太高，并断言在可扩展系统中最终一致性是不可避免的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>同步与异步</title>
      <link>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/distributedstorage-series/2.%E5%A4%8D%E5%88%B6/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5/</guid>
      <description>&lt;h1 id=&#34;同步复制与异步复制&#34;&gt;同步复制与异步复制&lt;/h1&gt;
&lt;p&gt;复制系统的一个重要细节是：复制是同步（synchronously）发生还是异步（asynchronously）发生，在关系型数据库中这通常是一个配置项，其他系统通常硬编码为其中一个。主从之间可以是异步复制，也可以是同步复制。例如 MySQL，在默认情况下采用异步复制。&lt;/p&gt;
&lt;p&gt;譬如网站的用户更新他们的个人头像。在某个时间点，客户向主库发送更新请求；不久之后主库就收到了请求。在某个时刻，主库又会将数据变更转发给自己的从库。最后，主库通知客户更新成功。下图显示了系统各个组件之间的通信：用户客户端，主库和两个从库。时间从左到右流动。请求或响应消息用粗箭头表示。&lt;/p&gt;
&lt;p&gt;
















  &lt;figure  &gt;
    &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
      &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://s2.ax1x.com/2020/02/08/1WsVRx.png&#34; alt=&#34;基于领导者的复制：一个同步从库和一个异步从库&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
    &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;上图中，从库 1 的复制是同步的：在向用户报告写入成功，并使结果对其他用户可见之前，主库需要等待从库 1 的确认，确保从库 1 已经收到写入操作。以及在使写入对其他客户端可见之前接收到写入。跟随者 2 的复制是异步的：主库发送消息，但不等待从库的响应。从库 2 处理消息前存在一个显著的延迟。通常情况下，复制的速度相当快：大多数数据库系统能在一秒向从库应用变更，但它们不能提供复制用时的保证。有些情况下，从库可能落后主库几分钟或更久；例如：从库正在从故障中恢复，系统在最大容量附近运行，或者如果节点间存在网络问题。&lt;/p&gt;
&lt;h1 id=&#34;同步与异步的对比&#34;&gt;同步与异步的对比&lt;/h1&gt;
&lt;p&gt;同步复制的优点是，从库保证有与主库一致的最新数据副本。异步复制容易引起数据丢失。比如主从结构中，主节点的写入请求还没有复制到从节点就挂了，当从节点被选为新的主节点之后，在这之前写入没有同步的数据就会被丢失。虽然即便采用了同步复制，也只能提供相对较弱的基本保障。其他情况譬如主接收写入请求然后发到从节点，从节点写入成功后并发送确认给主，如果此时主节点正准备发送确认信息给客户端时挂了，那么客户端就会认为提交失败，可是从节点已经提交成功了，如果这是从节点被提升为主，那么就出现问题了。&lt;/p&gt;
&lt;p&gt;同步复制的缺点是如果同步从库没有响应（比如它已经崩溃，或者出现网络故障，或其它任何原因），主库就无法处理写入操作。主库必须阻止所有写入，并等待同步副本再次可用。因此，将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。实际上，如果在数据库上启用同步复制，通常意味着其中一个跟随者是同步的，而其他的则是异步的。如果同步从库变得不可用或缓慢，则使一个异步从库同步。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。这种配置有时也被称为半同步（semi-synchronous）。&lt;/p&gt;
&lt;p&gt;在主从复制结构里，异步复制相比同步复制具备更高的吞吐量和更低延迟，因此，结合同步和异步复制是一个常见选项。比如 Kafka，根据它的声称，这是一个 CA 系统，也就是同时达到数据一致和高可用。Kafka 的复制设计同时包含异步复制和同步复制，同步复制节点组成的集合称为 ISR(In-Sync Replicas)，只有 ISR 内的所有节点都对写入确认之后，才算做写成功。当一个节点失效，Leader 会通过 ZooKeeper 感知并把它从 ISR 中移除。不过 Kafka 有一个问题，因为它声称 F 个节点可以容忍 F-1 个节点失效，这跟其他系统不同，通常类似的设计只能容忍 F/2-1 个节点失效，也就是说要确保大多数节点都能正常运行，而 Kafka 这把这个条件弱化成为只有 Leader 运行也可以。这样做是有问题的：假设 ISR 只剩下一个 Leader 在运行，如果此时 Leader 跟 ZooKeeper 的网络连接中断，就会产生一次选举，让 ISR 之外的节点(那些异步复制节点)加入 ISR，通常它会落后此前的 Leader 不少。当原先的 Leader 跟 ZooKeeper 网络连接恢复后，系统就产生脑裂，需要对 2 个 Leader 的数据做 Merge 或者舍弃，后者则会导致数据丢失。&lt;/p&gt;
&lt;p&gt;最后，通常情况下，基于领导者的复制都配置为完全异步在这种情况下，如果主库失效且不可恢复，则任何尚未复制给从库的写入都会丢失这意味着即使已经向客户端确认成功，写入也不能保证 持久（Durable）然而，一个完全异步的配置也有优点：即使所有的从库都落后了，主库也可以继续处理写入。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Flume | Next-gen Tech Edu</title>
    <link>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/</link>
      <atom:link href="https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/index.xml" rel="self" type="application/rss+xml" />
    <description>Flume</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language>
    <image>
      <url>https://ng-tech.icu/media/sharing.png</url>
      <title>Flume</title>
      <link>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/</link>
    </image>
    
    <item>
      <title>安装与配置</title>
      <link>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</guid>
      <description>&lt;h1 id=&#34;flume-安装与配置&#34;&gt;Flume 安装与配置&lt;/h1&gt;
&lt;p&gt;建议直接下载 Flume 的预编译版本，下载地址 :&lt;a href=&#34;http://www.apache.org/dyn/closer.lua/flume/1.6.0/apache-flume-1.6.0-bin.tar.gz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component Interface&lt;/th&gt;
&lt;th&gt;Type Alias&lt;/th&gt;
&lt;th&gt;Implementation Class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;*.Channel&lt;/td&gt;
&lt;td&gt;memory&lt;/td&gt;
&lt;td&gt;*.channel.MemoryChannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Channel&lt;/td&gt;
&lt;td&gt;jdbc&lt;/td&gt;
&lt;td&gt;*.channel.jdbc.JdbcChannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Channel&lt;/td&gt;
&lt;td&gt;file&lt;/td&gt;
&lt;td&gt;*.channel.file.FileChannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Channel&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;*.channel.PseudoTxnMemoryChannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Channel&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MyChannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;avro&lt;/td&gt;
&lt;td&gt;*.source.AvroSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;netcat&lt;/td&gt;
&lt;td&gt;*.source.NetcatSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;seq&lt;/td&gt;
&lt;td&gt;*.source.SequenceGeneratorSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;exec&lt;/td&gt;
&lt;td&gt;*.source.ExecSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;syslogtcp&lt;/td&gt;
&lt;td&gt;*.source.SyslogTcpSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;multiport_syslogtcp&lt;/td&gt;
&lt;td&gt;*.source.MultiportSyslogTCPSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;syslogudp&lt;/td&gt;
&lt;td&gt;*.source.SyslogUDPSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;spooldir&lt;/td&gt;
&lt;td&gt;*.source.SpoolDirectorySource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;http&lt;/td&gt;
&lt;td&gt;*.source.http.HTTPSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;thrift&lt;/td&gt;
&lt;td&gt;*.source.ThriftSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;jms&lt;/td&gt;
&lt;td&gt;*.source.jms.JMSSource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;*.source.avroLegacy.AvroLegacySource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;*.source.thriftLegacy.ThriftLegacySource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Source&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MySource&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;*.sink.NullSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;logger&lt;/td&gt;
&lt;td&gt;*.sink.LoggerSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;avro&lt;/td&gt;
&lt;td&gt;*.sink.AvroSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;hdfs&lt;/td&gt;
&lt;td&gt;*.sink.hdfs.HDFSEventSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;hbase&lt;/td&gt;
&lt;td&gt;*.sink.hbase.HBaseSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;asynchbase&lt;/td&gt;
&lt;td&gt;*.sink.hbase.AsyncHBaseSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;elasticsearch&lt;/td&gt;
&lt;td&gt;*.sink.elasticsearch.ElasticSearchSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;file_roll&lt;/td&gt;
&lt;td&gt;*.sink.RollingFileSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;irc&lt;/td&gt;
&lt;td&gt;*.sink.irc.IRCSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;thrift&lt;/td&gt;
&lt;td&gt;*.sink.ThriftSink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.Sink&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MySink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.ChannelSelector&lt;/td&gt;
&lt;td&gt;replicating&lt;/td&gt;
&lt;td&gt;*.channel.ReplicatingChannelSelector&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.ChannelSelector&lt;/td&gt;
&lt;td&gt;multiplexing&lt;/td&gt;
&lt;td&gt;*.channel.MultiplexingChannelSelector&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.ChannelSelector&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MyChannelSelector&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.SinkProcessor&lt;/td&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;*.sink.DefaultSinkProcessor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.SinkProcessor&lt;/td&gt;
&lt;td&gt;failover&lt;/td&gt;
&lt;td&gt;*.sink.FailoverSinkProcessor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.SinkProcessor&lt;/td&gt;
&lt;td&gt;load_balance&lt;/td&gt;
&lt;td&gt;*.sink.LoadBalancingSinkProcessor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.SinkProcessor&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.interceptor.Interceptor&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;*.interceptor.TimestampInterceptor$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.interceptor.Interceptor&lt;/td&gt;
&lt;td&gt;host&lt;/td&gt;
&lt;td&gt;*.interceptor.HostInterceptor$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.interceptor.Interceptor&lt;/td&gt;
&lt;td&gt;static&lt;/td&gt;
&lt;td&gt;*.interceptor.StaticInterceptor$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.interceptor.Interceptor&lt;/td&gt;
&lt;td&gt;regex_filter&lt;/td&gt;
&lt;td&gt;*.interceptor.RegexFilteringInterceptor$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.interceptor.Interceptor&lt;/td&gt;
&lt;td&gt;regex_extractor&lt;/td&gt;
&lt;td&gt;*.interceptor.RegexFilteringInterceptor$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.channel.file.encryption.KeyProvider$Builder&lt;/td&gt;
&lt;td&gt;jceksfile&lt;/td&gt;
&lt;td&gt;*.channel.file.encryption.JCEFileKeyProvider&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.channel.file.encryption.KeyProvider$Builder&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MyKeyProvider&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.channel.file.encryption.CipherProvider&lt;/td&gt;
&lt;td&gt;aesctrnopadding&lt;/td&gt;
&lt;td&gt;*.channel.file.encryption.AESCTRNoPaddingProvider&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.channel.file.encryption.CipherProvider&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MyCipherProvider&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.serialization.EventSerializer$Builder&lt;/td&gt;
&lt;td&gt;text&lt;/td&gt;
&lt;td&gt;*.serialization.BodyTextEventSerializer$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.serialization.EventSerializer$Builder&lt;/td&gt;
&lt;td&gt;avro_event&lt;/td&gt;
&lt;td&gt;*.serialization.&lt;a href=&#34;https://www.iteblog.com/archives/tag/flume&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Flume&lt;/a&gt;EventAvroEventSerializer$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;*.serialization.EventSerializer$Builder&lt;/td&gt;
&lt;td&gt;–&lt;/td&gt;
&lt;td&gt;org.example.MyEventSerializer$Builder&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;avro-sourcememory-channellogger-sink&#34;&gt;Avro Source+Memory Channel+Logger Sink&lt;/h2&gt;
&lt;p&gt;使用 Avro Source 接收外部数据源，Logger 作为 sink，即通过 Avro RPC 调用，将数据缓存在 channel 中，然后通过 Logger 打印出调用发送的数据。配置 Agent，修改配置文件 conf/flume-conf.properties，内容如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Define a memory channel called ch1 on agent1
agent1.channels.ch1.type = memory

# Define an Avro source called avro-source1 on agent1 and tell it
# to bind to 0.0.0.0:41414. Connect it to channel ch1.
agent1.sources.avro-source1.channels = ch1
agent1.sources.avro-source1.type = avro
agent1.sources.avro-source1.bind = 0.0.0.0
agent1.sources.avro-source1.port = 41414

# Define a logger sink that simply logs all events it receives
# and connect it to the other end of the same channel.
agent1.sinks.log-sink1.channel = ch1
agent1.sinks.log-sink1.type = logger

# Finally, now that we&amp;#39;ve defined all of our components, tell
# agent1 which ones we want to activate.
agent1.channels = ch1
agent1.channels.ch1.capacity = 1000
agent1.sources = avro-source1
agent1.sinks = log-sink1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;首先，启动 Agent 进程：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng agent -c ./conf/ -f conf/flume-conf.properties -Dflume.root.logger=DEBUG,console -n agent1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，启动 Avro Client，发送数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng avro-client -c ./conf/ -H 0.0.0.0 -p 41414 -F /usr/local/programs/logs/sync.log -Dflume.root.logger=DEBUG,console
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;avro-sourcememory-channelhdfs-sink&#34;&gt;Avro Source+Memory Channel+HDFS Sink&lt;/h2&gt;
&lt;p&gt;配置 Agent，修改配置文件 conf/flume-conf-hdfs.properties，内容如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Define a source, channel, sink
agent1.sources = avro-source1
agent1.channels = ch1
agent1.sinks = hdfs-sink

# Configure channel
agent1.channels.ch1.type = memory
agent1.channels.ch1.capacity = 1000000
agent1.channels.ch1.transactionCapacity = 500000

# Define an Avro source called avro-source1 on agent1 and tell it
# to bind to 0.0.0.0:41414. Connect it to channel ch1.
agent1.sources.avro-source1.channels = ch1
agent1.sources.avro-source1.type = avro
agent1.sources.avro-source1.bind = 0.0.0.0
agent1.sources.avro-source1.port = 41414

# Define a logger sink that simply logs all events it receives
# and connect it to the other end of the same channel.
agent1.sinks.hdfs-sink1.channel = ch1
agent1.sinks.hdfs-sink1.type = hdfs
agent1.sinks.hdfs-sink1.hdfs.path = hdfs://h1:8020/data/flume/
agent1.sinks.hdfs-sink1.hdfs.filePrefix = sync_file
agent1.sinks.hdfs-sink1.hdfs.fileSuffix = .log
agent1.sinks.hdfs-sink1.hdfs.rollSize = 1048576
agent1.sinks.hdfs-sink1.rollInterval = 0
agent1.sinks.hdfs-sink1.hdfs.rollCount = 0
agent1.sinks.hdfs-sink1.hdfs.batchSize = 1500
agent1.sinks.hdfs-sink1.hdfs.round = true
agent1.sinks.hdfs-sink1.hdfs.roundUnit = minute
agent1.sinks.hdfs-sink1.hdfs.threadsPoolSize = 25
agent1.sinks.hdfs-sink1.hdfs.useLocalTimeStamp = true
agent1.sinks.hdfs-sink1.hdfs.minBlockReplicas = 1
agent1.sinks.hdfs-sink1.fileType = SequenceFile
agent1.sinks.hdfs-sink1.writeFormat = TEXT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;首先，启动 Agent 进程：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng agent -c ./conf/ -f conf/flume-conf.properties -Dflume.root.logger=DEBUG,console -n agent1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后，启动 Avro Client，发送数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng avro-client -c ./conf/ -H 0.0.0.0 -p 41414 -F /usr/local/programs/logs/sync.log -Dflume.root.logger=DEBUG,console
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以查看同步到 HDFS 上的数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hdfs dfs -ls /data/flume
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果示例，如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;-rw-r--r--   3 shirdrn supergroup    1377617 2014-09-16 14:35 /data/flume/sync_file.1410849320761.log
-rw-r--r--   3 shirdrn supergroup    1378137 2014-09-16 14:35 /data/flume/sync_file.1410849320762.log
-rw-r--r--   3 shirdrn supergroup     259148 2014-09-16 14:35 /data/flume/sync_file.1410849320763.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;spooling-directory-sourcememory-channelhdfs-sink&#34;&gt;Spooling Directory Source+Memory Channel+HDFS Sink&lt;/h2&gt;
&lt;p&gt;配置 Agent，修改配置文件 flume-conf-spool.properties，内容如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Define source, channel, sink
agent1.sources = spool-source1
agent1.channels = ch1
agent1.sinks = hdfs-sink1

# Configure channel
agent1.channels.ch1.type = memory
agent1.channels.ch1.capacity = 1000000
agent1.channels.ch1.transactionCapacity = 500000

# Define and configure an Spool directory source
agent1.sources.spool-source1.channels = ch1
agent1.sources.spool-source1.type = spooldir
agent1.sources.spool-source1.spoolDir = /home/shirdrn/data/
agent1.sources.spool-source1.ignorePattern = event(_\d{4}\-\d{2}\-\d{2}_\d{2}_\d{2})?\.log(\.COMPLETED)?
agent1.sources.spool-source1.batchSize = 50
agent1.sources.spool-source1.inputCharset = UTF-8

# Define and configure a hdfs sink
agent1.sinks.hdfs-sink1.channel = ch1
agent1.sinks.hdfs-sink1.type = hdfs
agent1.sinks.hdfs-sink1.hdfs.path = hdfs://h1:8020/data/flume/
agent1.sinks.hdfs-sink1.hdfs.filePrefix = event_%y-%m-%d_%H_%M_%S
agent1.sinks.hdfs-sink1.hdfs.fileSuffix = .log
agent1.sinks.hdfs-sink1.hdfs.rollSize = 1048576
agent1.sinks.hdfs-sink1.hdfs.rollCount = 0
agent1.sinks.hdfs-sink1.hdfs.batchSize = 1500
agent1.sinks.hdfs-sink1.hdfs.round = true
agent1.sinks.hdfs-sink1.hdfs.roundUnit = minute
agent1.sinks.hdfs-sink1.hdfs.threadsPoolSize = 25
agent1.sinks.hdfs-sink1.hdfs.useLocalTimeStamp = true
agent1.sinks.hdfs-sink1.hdfs.minBlockReplicas = 1
agent1.sinks.hdfs-sink1.fileType = SequenceFile
agent1.sinks.hdfs-sink1.writeFormat = TEXT
agent1.sinks.hdfs-sink1.rollInterval = 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动 Agent 进程，执行如下命令：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng agent -c ./conf/ -f conf/flume-conf-spool.properties -Dflume.root.logger=INFO,console -n agent1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以查看 HDFS 上同步过来的数据：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;hdfs dfs -ls /data/flume
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果示例，如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:52 /data/flume/event_14-09-17_10_52_00.1410922355094.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:52 /data/flume/event_14-09-17_10_52_00.1410922355095.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:52 /data/flume/event_14-09-17_10_52_00.1410922355096.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:52 /data/flume/event_14-09-17_10_52_00.1410922355097.log
-rw-r--r--   3 shirdrn supergroup       1530 2014-09-17 10:53 /data/flume/event_14-09-17_10_52_00.1410922355098.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:53 /data/flume/event_14-09-17_10_53_00.1410922380386.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:53 /data/flume/event_14-09-17_10_53_00.1410922380387.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:53 /data/flume/event_14-09-17_10_53_00.1410922380388.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:53 /data/flume/event_14-09-17_10_53_00.1410922380389.log
-rw-r--r--   3 shirdrn supergroup    1072265 2014-09-17 10:53 /data/flume/event_14-09-17_10_53_00.1410922380390.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;exec-sourcememory-channelfile-roll-sink&#34;&gt;Exec Source+Memory Channel+File Roll Sink&lt;/h2&gt;
&lt;p&gt;配置 Agent，修改配置文件 flume-conf-file.properties，内容如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Define source, channel, sink
agent1.sources = tail-source1
agent1.channels = ch1
agent1.sinks = file-sink1

# Configure channel
agent1.channels.ch1.type = memory
agent1.channels.ch1.capacity = 1000000
agent1.channels.ch1.transactionCapacity = 500000

# Define and configure an Exec source
agent1.sources.tail-source1.channels = ch1
agent1.sources.tail-source1.type = exec
agent1.sources.tail-source1.command = tail -F /home/shirdrn/data/event.log
agent1.sources.tail-source1.shell = /bin/sh -c
agent1.sources.tail-source1.batchSize = 50

# Define and configure a File roll sink
# and connect it to the other end of the same channel.
agent1.sinks.file-sink1.channel = ch1
agent1.sinks.file-sink1.type = file_roll
agent1.sinks.file-sink1.batchSize = 100
agent1.sinks.file-sink1.serializer = TEXT
agent1.sinks.file-sink1.sink.directory = /home/shirdrn/sink_data
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动 Agent 进程，执行如下命令：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bin/flume-ng agent -c ./conf/ -f conf/flume-conf-file.properties -Dflume.root.logger=INFO,console -n agent1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以查看 File Roll Sink 对应的本地文件系统目录 /home/shirdrn/sink_data 下，示例如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;-rw-rw-r-- 1 shirdrn shirdrn 13944825 Sep 17 11:36 1410924990039-1
-rw-rw-r-- 1 shirdrn shirdrn 11288870 Sep 17 11:37 1410924990039-2
-rw-rw-r-- 1 shirdrn shirdrn        0 Sep 17 11:37 1410924990039-3
-rw-rw-r-- 1 shirdrn shirdrn 20517500 Sep 17 11:38 1410924990039-4
-rw-rw-r-- 1 shirdrn shirdrn 16343250 Sep 17 11:38 1410924990039-5
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;architecture-overview-架构概览&#34;&gt;Architecture Overview: 架构概览&lt;/h1&gt;
&lt;p&gt;Flume NG 架构，如图所示：&lt;/p&gt;
&lt;p&gt;主要有一下几个核心概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Event：一个数据单元，带有一个可选的消息头&lt;/li&gt;
&lt;li&gt;Flow：Event 从源点到达目的点的迁移的抽象&lt;/li&gt;
&lt;li&gt;Client：操作位于源点处的 Event，将其发送到 Flume Agent&lt;/li&gt;
&lt;li&gt;Agent：一个独立的 Flume 进程，包含组件 Source、Channel、Sink&lt;/li&gt;
&lt;li&gt;Source：用来消费传递到该组件的 Event&lt;/li&gt;
&lt;li&gt;Channel：中转 Event 的一个临时存储，保存有 Source 组件传递过来的 Event&lt;/li&gt;
&lt;li&gt;Sink：从 Channel 中读取并移除 Event，将 Event 传递到 Flow Pipeline 中的下一个 Agent(如果有的话)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;外部系统产生日志，直接通过 Flume 的 Agent 的 Source 组件将事件(如日志行)发送到中间临时的 channel 组件，最后传递给 Sink 组件，HDFS Sink 组件可以直接把数据存储到 HDFS 集群上。一个最基本 Flow 的配置，格式如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# list the sources, sinks and channels for the agent
&amp;lt;Agent&amp;gt;.sources = &amp;lt;Source1&amp;gt; &amp;lt;Source2&amp;gt;
&amp;lt;Agent&amp;gt;.sinks = &amp;lt;Sink1&amp;gt; &amp;lt;Sink2&amp;gt;
&amp;lt;Agent&amp;gt;.channels = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt;

# set channel for source
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.channels = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt; ...
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source2&amp;gt;.channels = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt; ...

# set channel for sink
&amp;lt;Agent&amp;gt;.sinks.&amp;lt;Sink1&amp;gt;.channel = &amp;lt;Channel1&amp;gt;
&amp;lt;Agent&amp;gt;.sinks.&amp;lt;Sink2&amp;gt;.channel = &amp;lt;Channel2&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;尖括号里面的，我们可以根据实际需求或业务来修改名称。下面详细说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;Agent&amp;gt;&lt;/code&gt; 表示配置一个 Agent 的名称，一个 Agent 肯定有一个名称。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;Source1&amp;gt; &amp;lt;Source2&amp;gt;&lt;/code&gt; 是 Agent 的 Source 组件的名称，消费传递过来的 Event。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt;&lt;/code&gt; 是 Agent 的 Channel 组件的名称。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;Sink1&amp;gt; &amp;lt;Sink2&amp;gt;&lt;/code&gt; 是 Agent 的 Sink 组件的名称，从 Channel 中消费(移除)Event。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面配置内容中，第一组中配置 Source、Sink、Channel，它们的值可以有 1 个或者多个；第二组中配置 Source 将把数据存储(Put )到 哪一个 Channel 中，可以存储到 1 个或多个 Channel 中，同一个 Source 将数据存储到多个 Channel 中，实际上是 Replication；第三组中配置 Sink 从哪一个 Channel 中取(Task )数据，一个 Sink 只能从一个 Channel 中取数据。&lt;/p&gt;
&lt;h2 id=&#34;flow-pipeline&#34;&gt;Flow Pipeline&lt;/h2&gt;
&lt;h3 id=&#34;多个-agent-顺序连接&#34;&gt;多个 Agent 顺序连接&lt;/h3&gt;
&lt;p&gt;可以将多个 Agent 顺序连接起来，将最初的数据源经过收集，存储到最终的存储系统中。这是最简单的情况，一般情况下，应该控制这种顺序连接的 Agent 的数量，因为数据流经的路径变长了，如果不考虑 failover 的话，出现故障将影响整个 Flow 上的 Agent 收集服务。&lt;/p&gt;
&lt;h3 id=&#34;多个-agent-的数据汇聚到同一个-agent&#34;&gt;多个 Agent 的数据汇聚到同一个 Agent&lt;/h3&gt;
&lt;p&gt;这种情况应用的场景比较多，比如要收集 Web 网站的用户行为日志，Web 网站为了可用性使用的负载均衡的集群模式，每个节点都产生用户行为日志，可以为每 个节点都配置一个 Agent 来单独收集日志数据，然后多个 Agent 将数据最终汇聚到一个用来存储数据存储系统，如 HDFS 上。&lt;/p&gt;
&lt;h3 id=&#34;多路multiplexing--agent&#34;&gt;多路(Multiplexing ) Agent&lt;/h3&gt;
&lt;p&gt;。&lt;/p&gt;
&lt;h4 id=&#34;replication&#34;&gt;Replication&lt;/h4&gt;
&lt;p&gt;Replication 方式，可以将 最前端的数据源复制多份，分别传递到多个 channel 中，每个 channel 接收到的数据都是相同的，配置格式，如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# List the sources, sinks and channels for the agent
&amp;lt;Agent&amp;gt;.sources = &amp;lt;Source1&amp;gt;
&amp;lt;Agent&amp;gt;.sinks = &amp;lt;Sink1&amp;gt; &amp;lt;Sink2&amp;gt;
&amp;lt;Agent&amp;gt;.channels = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt;

# set list of channels for source (separated by space)
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.channels = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt;

# set channel for sinks
&amp;lt;Agent&amp;gt;.sinks.&amp;lt;Sink1&amp;gt;.channel = &amp;lt;Channel1&amp;gt;
&amp;lt;Agent&amp;gt;.sinks.&amp;lt;Sink2&amp;gt;.channel = &amp;lt;Channel2&amp;gt;

&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.type = replicating
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面指定了 selector 的 type 的值为 replication，其他的配置没有指定，使用的 Replication 方式，Source1 会将数据分 别存储到 Channel1 和 Channel2，这两个 channel 里面存储的数据是相同的，然后数据被传递到 Sink1 和 Sink2。&lt;/p&gt;
&lt;h4 id=&#34;multiplexing&#34;&gt;Multiplexing&lt;/h4&gt;
&lt;p&gt;Multiplexing 方式，selector 可以根据 header 的值来确定数据传递到哪一个 channel，配置格式，如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Mapping for multiplexing selector
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.type = multiplexing
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.header = &amp;lt;someHeader&amp;gt;
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.mapping.&amp;lt;Value1&amp;gt; = &amp;lt;Channel1&amp;gt;
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.mapping.&amp;lt;Value2&amp;gt; = &amp;lt;Channel1&amp;gt; &amp;lt;Channel2&amp;gt;
&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.mapping.&amp;lt;Value3&amp;gt; = &amp;lt;Channel2&amp;gt;
#...

&amp;lt;Agent&amp;gt;.sources.&amp;lt;Source1&amp;gt;.selector.default = &amp;lt;Channel2&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面 selector 的 type 的值为 multiplexing，同时配置 selector 的 header 信息，还配置了多个 selector 的 mapping 的值，即 header 的值：如果 header 的值为 Value1、Value2，数据从 Source1 路由到 Channel1；如果 header 的值为 Value2、Value3，数据从 Source1 路由到 Channel2。&lt;/p&gt;
&lt;h3 id=&#34;load-balance-负载均衡&#34;&gt;Load Balance: 负载均衡&lt;/h3&gt;
&lt;p&gt;Load balancing Sink Processor 能够实现 load balance 功能，上图 Agent1 是一个路由节点，负责将 Channel 暂存的 Event 均衡到对应的多个 Sink 组件上，而每个 Sink 组件分别连 接到一个独立的 Agent 上，示例配置，如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = k1 k2 k3
a1.sinkgroups.g1.processor.type = load_balance
a1.sinkgroups.g1.processor.backoff = true
a1.sinkgroups.g1.processor.selector = round_robin
a1.sinkgroups.g1.processor.selector.maxTimeOut=10000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Failover Sink Processor 能够实现 failover 功能，具体流程类似 load balance，但是内部处理机制与 load balance 完全不同：Failover Sink Processor 维护一个优先级 Sink 组件列表，只要有一个 Sink 组件可用，Event 就被传递到下一个组件。如果一个 Sink 能够成功处理 Event，则会加入到一个 Pool 中，否则会被移出 Pool 并计算失败次数，设置一个惩罚因子，示例配置如下所示：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = k1 k2 k3
a1.sinkgroups.g1.processor.type = failover
a1.sinkgroups.g1.processor.priority.k1 = 5
a1.sinkgroups.g1.processor.priority.k2 = 7
a1.sinkgroups.g1.processor.priority.k3 = 6
a1.sinkgroups.g1.processor.maxpenalty = 20000
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>组件类型</title>
      <link>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/%E7%BB%84%E4%BB%B6%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ng-tech.icu/books/devops-series/%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88/flume/%E7%BB%84%E4%BB%B6%E7%B1%BB%E5%9E%8B/</guid>
      <description>&lt;h1 id=&#34;flume-中的组件类型&#34;&gt;Flume 中的组件类型&lt;/h1&gt;
&lt;h1 id=&#34;source&#34;&gt;Source&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Source 类型&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;说明&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Avro Source&lt;/td&gt;
&lt;td&gt;支持 Avro 协议(实际上是 Avro RPC)，内置支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Thrift Source&lt;/td&gt;
&lt;td&gt;支持 Thrift 协议，内置支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exec Source&lt;/td&gt;
&lt;td&gt;基于 Unix 的 command 在标准输出上生产数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;JMS Source&lt;/td&gt;
&lt;td&gt;从 JMS 系统(消息、主题)中读取数据，ActiveMQ 已经测试过&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spooling Directory Source&lt;/td&gt;
&lt;td&gt;监控指定目录内数据变更&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Twitter 1% firehose Source&lt;/td&gt;
&lt;td&gt;通过 API 持续下载 Twitter 数据，试验性质&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netcat Source&lt;/td&gt;
&lt;td&gt;监控某个端口，将流经端口的每一个文本行数据作为 Event 输入&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sequence Generator Source&lt;/td&gt;
&lt;td&gt;序列生成器数据源，生产序列数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Syslog Sources&lt;/td&gt;
&lt;td&gt;读取 syslog 数据，产生 Event，支持 UDP 和 TCP 两种协议&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HTTP Source&lt;/td&gt;
&lt;td&gt;基于 HTTP POST 或 GET 方式的数据源，支持 JSON、BLOB 表示形式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Legacy Sources&lt;/td&gt;
&lt;td&gt;兼容老的 Flume OG 中 Source(0.9.x 版本)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;channel&#34;&gt;Channel&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Channel 类型&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;说明&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Memory Channel&lt;/td&gt;
&lt;td&gt;Event 数据存储在内存中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;JDBC Channel&lt;/td&gt;
&lt;td&gt;Event 数据存储在持久化存储中，当前 Flume Channel 内置支持 Derby&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File Channel&lt;/td&gt;
&lt;td&gt;Event 数据存储在磁盘文件中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spillable Memory Channel&lt;/td&gt;
&lt;td&gt;Event 数据存储在内存中和磁盘上，当内存队列满了，会持久化到磁盘文件(当前试验性的，不建议生产环境使用)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pseudo Transaction Channel&lt;/td&gt;
&lt;td&gt;测试用途&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Custom Channel&lt;/td&gt;
&lt;td&gt;自定义 Channel 实现&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;sink&#34;&gt;Sink&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Sink 类型&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;说明&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;HDFS Sink&lt;/td&gt;
&lt;td&gt;数据写入 HDFS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logger Sink&lt;/td&gt;
&lt;td&gt;数据写入日志文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Avro Sink&lt;/td&gt;
&lt;td&gt;数据被转换成 Avro Event，然后发送到配置的 RPC 端口上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Thrift Sink&lt;/td&gt;
&lt;td&gt;数据被转换成 Thrift Event，然后发送到配置的 RPC 端口上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IRC Sink&lt;/td&gt;
&lt;td&gt;数据在 IRC 上进行回放&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;File Roll Sink&lt;/td&gt;
&lt;td&gt;存储数据到本地文件系统&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Null Sink&lt;/td&gt;
&lt;td&gt;丢弃到所有数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HBase Sink&lt;/td&gt;
&lt;td&gt;数据写入 HBase 数据库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Morphline Solr Sink&lt;/td&gt;
&lt;td&gt;数据发送到 Solr 搜索服务器(集群)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ElasticSearch Sink&lt;/td&gt;
&lt;td&gt;数据发送到 Elastic Search 搜索服务器(集群)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kite Dataset Sink&lt;/td&gt;
&lt;td&gt;写数据到 Kite Dataset，试验性质的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Custom Sink&lt;/td&gt;
&lt;td&gt;自定义 Sink 实现&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>

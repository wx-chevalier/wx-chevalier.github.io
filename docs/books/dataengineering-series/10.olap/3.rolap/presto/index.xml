<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Presto | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/dataengineering-series/10.olap/3.rolap/presto/</link><atom:link href="https://ng-tech.icu/books/dataengineering-series/10.olap/3.rolap/presto/index.xml" rel="self" type="application/rss+xml"/><description>Presto</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>Presto</title><link>https://ng-tech.icu/books/dataengineering-series/10.olap/3.rolap/presto/</link></image><item><title>部署与控制</title><link>https://ng-tech.icu/books/dataengineering-series/10.olap/3.rolap/presto/%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/10.olap/3.rolap/presto/%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%8E%A7%E5%88%B6/</guid><description>&lt;h1 id="presto">Presto&lt;/h1>
&lt;p>Facebook 拥有世界上最大的数据仓库之一，这些数据被一系列不同种类的程序所使用，包括传统的数据批处理程序、基于图论的数据分析、机器学习、和实时性的数据分析。在以前，Facebook 的科学家和分析师一直依靠 Hive 来做数据分析。但 Hive 使用 MapReduce 作为底层计算框架，是专为批处理设计的。但随着数据越来越多，使用 Hive 进行一个简单的数据查询可能要花费几分到几小时，显然不能满足交互式查询的需求。Facebook 也调研了其他比 Hive 更快的工具，但它们要么在功能有所限制要么就太简单，以至于无法操作 Facebook 庞大的数据仓库。2012 年开始试用的一些外部项目都不合适，他们决定自己开发，这就是 Presto，2013 年 Facebook 正式宣布开源 Presto。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://www.mutouxiaogui.cn/blog/wp-content/uploads/2015/11/Presto.files/image002.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Presto 主要以 Java 开发，被设计为用来专门进行高速、实时的数据分析。它支持标准的 ANSI SQL，包括复杂查询、聚合(aggregation)、连接(join)和窗口函数(window functions)。在支持基础的对于 HDFS 的查询之外，Presto 还支持对于异构数据库的查询，建立统一的抽象屏蔽层，保证了用户以通用的 SQL 语法能够忽略底层数据库差异进行统一查询。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://www.mutouxiaogui.cn/blog/wp-content/uploads/2015/11/Presto.files/image003.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="架构">架构&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://tech.meituan.com/img/presto/image1.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Presto 查询引擎是一个 Master-Slave 的架构，由一个 Coordinator 节点，一个 Discovery Server 节点，多个 Worker 节点组成，Discovery Server 通常内嵌于 Coordinator 节点中。Coordinator 负责解析 SQL 语句，生成执行计划，分发执行任务给 Worker 节点执行。Worker 节点负责实际执行查询任务。Worker 节点启动后向 Discovery Server 服务注册，Coordinator 从 Discovery Server 获得可以正常工作的 Worker 节点。如果配置了 Hive Connector，需要配置一个 Hive MetaStore 服务为 Presto 提供 Hive 元信息，Worker 节点与 HDFS 交互读取数据。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://ww4.sinaimg.cn/large/7cc829d3gw1eaf8601b8bj20k00b9wfv.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Presto 的运行模型和 Hive 或 MapReduce 有着本质的区别。Hive 将查询翻译成多阶段的 MapReduce 任务，一个接着一个地运行。每一个任务从磁盘上读取输入数据并且将中间结果输出到磁盘上。然而 Presto 引擎没有使用 MapReduce。为支持 SQL 语法，它实现了一个定制的查询、执行引擎和操作符。除了改进的调度算法之外，所有的数据处理都是在内存中进行的。不同的处理端通过网络组成处理的流水线。这样会避免不必要的磁盘读写和额外的延迟。这种流水线式的执行模型会在同一时间运行多个数据处理段，一旦数据可用的时候就会将数据从一个处理段传入到下一个处理段。这样的方式会大大的减少各种查询的端到端延迟。Presto 动态编译部分查询计划为字节码，使得 JVM 能够优化并生成本地机器码。在扩展性方面，Presto 只设计了一种简单的存储抽象，使得能够在多种数据源上进行 SQL 查询。连接器只需要提供获取元数据的接口，获得数据地址后自动访问数据。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="http://www.mutouxiaogui.cn/blog/wp-content/uploads/2015/11/Presto.files/image011.jpg" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="部署">部署&lt;/h1>
&lt;h2 id="安装">安装&lt;/h2>
&lt;h2 id="环境配置">环境配置&lt;/h2>
&lt;h3 id="节点属性">节点属性&lt;/h3>
&lt;h3 id="jvm">JVM&lt;/h3>
&lt;h3 id="日志">日志&lt;/h3>
&lt;h2 id="连接配置">连接配置&lt;/h2>
&lt;h2 id="运行">运行&lt;/h2>
&lt;h1 id="交互">交互&lt;/h1>
&lt;h2 id="命令行">命令行&lt;/h2>
&lt;h2 id="jdbc-driver">JDBC Driver&lt;/h2>
&lt;h1 id="webui">WebUI&lt;/h1></description></item></channel></rss>
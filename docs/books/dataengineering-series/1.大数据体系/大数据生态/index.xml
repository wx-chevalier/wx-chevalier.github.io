<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大数据生态 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/</link><atom:link href="https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/index.xml" rel="self" type="application/rss+xml"/><description>大数据生态</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>大数据生态</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/</link></image><item><title>不作恶</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E4%B8%8D%E4%BD%9C%E6%81%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E4%B8%8D%E4%BD%9C%E6%81%B6/</guid><description>&lt;h1 id="不作恶">不作恶&lt;/h1>
&lt;p>每个系统都服务于一个目的；我们采取的每个举措都会同时产生期望的后果与意外的后果。这个目的可能只是简单地赚钱，但其对世界的影响，可能会远远超出最初的目的。我们，建立这些系统的工程师，有责任去仔细考虑这些后果，并有意识地决定，我们希望生活在怎样的世界中。&lt;/p>
&lt;p>我们将数据当成一种抽象的东西来讨论，但请记住，许多数据集都是关于人的：他们的行为，他们的兴趣，他们的身份。对待这些数据，我们必须怀着人性与尊重。用户也是人类，人类的尊严是至关重要的。软件开发越来越多地涉及重要的道德抉择。有一些指导原则可以帮助软件工程师解决这些问题，例如 ACM 的软件工程道德规范与专业实践，但实践中很少会讨论这些，更不用说应用与强制执行了。因此，工程师和产品经理有时会对隐私与产品潜在的负面后果抱有非常傲慢的态度。&lt;/p>
&lt;p>技术本身并无好坏之分，关键在于它被如何使用，以及它如何影响人们。这对枪械这样的武器，这是成立的，而搜索引擎这样的软件系统与之类似。我认为，软件工程师仅仅专注于技术而忽视其后果是不够的：道德责任也是我们的责任。对道德推理很困难，但它太重要了，我们无法忽视。&lt;/p>
&lt;h1 id="预测性分析">预测性分析&lt;/h1>
&lt;p>譬如预测性分析是“大数据”炒作的主要内容之一。使用数据分析预测天气或疾病传播是一码事；而预测一个罪犯是否可能再犯，一个贷款申请人是否有可能违约，或者一个保险客户是否可能进行昂贵的索赔，则是另外一码事。后者会直接影响到个人的生活。当然，支付网络希望防止欺诈交易，银行希望避免不良贷款，航空公司希望避免劫机，公司希望避免雇佣效率低下或不值得信任的人。从它们的角度来看，失去商机的成本很低，而不良贷款或问题员工的成本则要高得多，因而组织希望保持谨慎也是自然而然的事情。所以如果存疑，它们通常会 Say No。&lt;/p>
&lt;p>然而，随着算法决策变得越来越普遍，被某种算法（准确地或错误地）标记为有风险的某人可能会遭受大量这种“No”的决定。系统性地被排除在工作，航旅，保险，租赁，金融服务，以及其他社会关键领域之外。这是一种对个体自由的极大约束，因此被称为“算法监狱”。在尊重人权的国家，刑事司法系统会做无罪推定（默认清白，直到被证明有罪）。另一方面，自动化系统可以系统地，任意地将一个人排除在社会参与之外，不需要任何有罪的证明，而且几乎没有申诉的机会。&lt;/p>
&lt;h2 id="偏见与歧视">偏见与歧视&lt;/h2>
&lt;p>算法做出的决定不一定比人类更好或更差。每个人都可能有偏见，即使他们主动抗拒这一点；而歧视性做法也可能已经在文化上被制度化了。人们希望根据数据做出决定，而不是通过人的主观评价与直觉，希望这样能更加公平，并给予传统体制中经常被忽视的人更好的机会。当我们开发预测性分析系统时，不是仅仅用软件通过一系列 IF ELSE 规则将人类的决策过程自动化，那些规则本身甚至都是从数据中推断出来的。但这些系统学到的模式是个黑盒：即使数据中存在一些相关性，我们可能也压根不知道为什么。如果算法的输入中存在系统性的偏见，则系统很有可能会在输出中学习并放大这种偏见。&lt;/p>
&lt;p>在许多国家，反歧视法律禁止按种族，年龄，性别，性取向，残疾，或信仰等受保护的特征区分对待不同的人。其他的个人特征可能是允许用于分析的，但是如果这些特征与受保护的特征存在关联，又会发生什么？例如在种族隔离地区中，一个人的邮政编码，甚至是他们的 IP 地址，都是很强的种族指示物。这样的话，相信一种算法可以以某种方式将有偏数据作为输入，并产生公平和公正的输出似乎是很荒谬的。然而这种观点似乎常常潜伏在数据驱动型决策的支持者中，这种态度被讽刺为“在处理偏差上，机器学习与洗钱类似”（machine learning is like money laundering for bias）。&lt;/p>
&lt;p>预测性分析系统只是基于过去进行推断；如果过去是歧视性的，它们就会将这种歧视归纳为规律。如果我们希望未来比过去更好，那么就需要道德想象力，而这是只有人类才能提供的东西。数据与模型应该是我们的工具，而不是我们的主人。&lt;/p>
&lt;h2 id="责任与问责">责任与问责&lt;/h2>
&lt;p>自动决策引发了关于责任与问责的问题。如果一个人犯了错误，他可以被追责，受决定影响的人可以申诉。算法也会犯错误，但是如果它们出错，谁来负责？当一辆自动驾驶汽车引发事故时，谁来负责？如果自动信用评分算法系统性地歧视特定种族或宗教的人，这些人是否有任何追索权？如果机器学习系统的决定要受到司法审查，你能向法官解释算法是如何做出决定的吗？&lt;/p>
&lt;p>收集关于人的数据并进行决策，信用评级机构是一个很经典的例子。不良的信用评分会使生活变得更艰难，但至少信用分通常是基于个人实际的借款历史记录，而记录中的任何错误都能被纠正（尽管机构通常会设置门槛）。然而，基于机器学习的评分算法通常会使用更宽泛的输入，并且更不透明；因而很难理解特定决策是怎样作出的，以及是否有人被不公正地，歧视性地对待。&lt;/p>
&lt;p>信用分总结了“你过去的表现如何？”，而预测性分析通常是基于“谁与你类似，以及与你类似的人过去表现的如何？”。与他人的行为画上等号意味着刻板印象，例如，根据他们居住的地方（与种族和阶级关系密切的特征）。那么那些放错位置的人怎么办？而且，如果是因为错误数据导致的错误决定，追索几乎是不可能的。&lt;/p>
&lt;p>很多数据本质上是统计性的，这意味着即使概率分布在总体上是正确的，对于个例也可能是错误的。例如，如果贵国的平均寿命是 80 岁，这并不意味着你在 80 岁生日时就会死掉。很难从平均值与概率分布中对某个特定个体的寿命作出什么判断，同样，预测系统的输出是概率性的，对于个例可能是错误的。盲目相信数据决策至高无上，这不仅仅是一种妄想，而是有切实危险的。随着数据驱动的决策变得越来越普遍，我们需要弄清楚，如何使算法更负责任且更加透明，如何避免加强现有的偏见，以及如何在它们不可避免地出错时加以修复。&lt;/p>
&lt;p>我们还需要想清楚，如何避免数据被用于害人，如何认识数据的积极潜力。例如，分析可以揭示人们生活的财务特点与社会特点。一方面，这种权力可以用来将援助与支持集中在帮助那些最需要援助的人身上。另一方面，它有时会被掠夺性企业用于识别弱势群体，并向其兜售高风险产品，比如高利贷。&lt;/p>
&lt;h2 id="反馈循环">反馈循环&lt;/h2>
&lt;p>即使是那些对人直接影响比较小的预测性应用，比如推荐系统，也有一些必须正视的难题。当服务变得善于预测用户想要看到什么内容时，它最终可能只会向人们展示他们已经同意的观点，将人们带入滋生刻板印象，误导信息，与极端思想的回音室。我们已经看到过社交媒体回音室对竞选的影响了。&lt;/p>
&lt;p>当预测性分析影响人们的生活时，自我强化的反馈循环会导致非常有害的问题。例如，考虑雇主使用信用分来评估候选人的例子。你可能是一个信用分不错的好员工，但因不可抗力的意外而陷入财务困境。由于不能按期付账单，你的信用分会受到影响，进而导致找到工作更为困难。失业使你陷入贫困，这进一步恶化了你的分数，使你更难找到工作。在数据与数学严谨性的伪装背后，隐藏的是由恶毒假设导致的恶性循环。&lt;/p>
&lt;p>我们无法预测这种反馈循环何时发生。然而通过对整个系统（不仅仅是计算机化的部分，而且还有与之互动的人）进行整体思考，许多后果是可以够预测的，一种称为系统思维（systems thinkin）的方法。我们可以尝试理解数据分析系统如何响应不同的行为，结构或特性。该系统是否加强和增大了人们之间现有的差异（例如，损不足以奉有余，富者愈富，贫者愈贫），还是试图与不公作斗争？而且即使有着最好的动机，我们也必须当心意想不到的后果。&lt;/p>
&lt;h1 id="隐私和追踪">隐私和追踪&lt;/h1>
&lt;p>除了预测性分析，即使用数据来做出关于人的自动决策，数据收集本身也存在道德问题。收集数据的组织，与被收集数据的人之间，到底属于什么关系？当系统只存储用户明确输入的数据时，是因为用户希望系统以特定方式存储和处理这些数据，系统是在为用户提供服务：用户就是客户。但是，当用户的活动被跟踪并记录，作为他们正在做的其他事情的副作用时，这种关系就没有那么清晰了。该服务不再仅仅完成用户想要它要做的事情，而是服务于它自己的利益，而这可能与用户的利益相冲突。&lt;/p>
&lt;p>追踪用户行为数据对于许多面向用户的在线服务而言，变得越来越重要：追踪用户点击了哪些搜索结果有助于提高搜索结果的排名；推荐“喜欢 X 的人也喜欢 Y”，可以帮助用户发现实用有趣的东西；A/B 测试和用户流量分析有助于改善用户界面。这些功能需要一定量的用户行为跟踪，而用户也可以从中受益。&lt;/p>
&lt;p>但不同公司有着不同的商业模式，追踪并未止步于此。如果服务是通过广告盈利的，那么广告主才是真正的客户，而用户的利益则屈居其次。跟踪的数据会变得更详细，分析变得更深入，数据会保留很长时间，以便为每个人建立详细画像，用于营销。现在，公司与被收集数据的用户之间的关系，看上去就不太一样了。公司会免费服务用户，并引诱用户尽可能多地使用服务。对用户的追踪，主要不是服务于该用户个体，而是服务于掏钱资助该服务的广告商。我认为这种关系可以用一个更具罪犯内涵的词来恰当地描述：监视（surveilance）。&lt;/p>
&lt;h2 id="监视">监视&lt;/h2>
&lt;p>让我们做一个思想实验，尝试用监视（surveillance）一词替换数据（data），再看看常见的短语是不是听起来还那么漂亮。比如：“在我们的监视驱动的组织中，我们收集实时监视流并将它们存储在我们的监视仓库中。我们的监视科学家使用高级分析和监视处理来获得新的见解。“&lt;/p>
&lt;p>这个思想实验是罕见的争议性内容，但我认为需要激烈的言辞来强调这一点。在我们尝试制造软件“吞噬世界”的过程中，我们已经建立了世界上迄今为止所见过的最伟大的大规模监视基础设施。我们正朝着万物互联迈进，我们正在迅速走近这样一个世界：每个有人居住的空间至少包含一个带互联网连接的麦克风，以智能手机，智能电视，语音控制助理设备，婴儿监视器甚至儿童玩具的形式存在，并使用基于云的语音识别。这些设备中的很多都有着可怕的安全记录。&lt;/p>
&lt;p>即使是最为极权与专制的政权，可能也只会想着在每个房间装一个麦克风，并强迫每个人始终携带能够追踪其位置与动向的设备。然而，我们显然是自愿地，甚至热情地投身于这个全域监视的世界。不同之处在于，数据是由公司，而不是由政府机构收集的。&lt;/p>
&lt;p>并不是所有的数据收集都称得上监视，但检视这一点有助于理解我们与数据收集者之间的关系。为什么我们似乎很乐意接受企业的监视呢？也许你觉得自己没有什么好隐瞒的，换句话说，你与当权阶级穿一条裤子，你不是被边缘化的少数派，也不必害怕受到迫害。不是每个人都如此幸运。或者，也许这是因为目的似乎是温和的，这不是公然胁迫，也不是强制性的，而只是更好的推荐与更个性化的营销。但是，结合上一节中对预测性分析的讨论，这种区别似乎并不是很清晰。&lt;/p>
&lt;p>我们已经看到与汽车追踪设备挂钩的汽车保险费，以及取决于需要人佩戴健身追踪设备来确定的健康保险范围。当监视被用于决定生活的重要方面时，例如保险或就业，它就开始变得不那么温和了。此外，数据分析可以揭示出令人惊讶的私密事物：例如，智能手表或健身追踪器中的运动传感器能以相当好的精度计算出你正在输入的内容（比如密码）。而分析算法只会变得越来越精确。&lt;/p>
&lt;h2 id="同意与选择的自由">同意与选择的自由&lt;/h2>
&lt;p>我们可能会断言用户是自愿选择使用服务的，尽管服务会跟踪其活动，而且他们已经同意了服务条款与隐私政策，因此他们同意数据收集。我们甚至可以声称，用户在用所提供的数据来换取有价值的服务，并且为了提供服务，追踪是必要的。毫无疑问，社交网络，搜索引擎，以及各种其他免费的在线服务对于用户来说都是有价值的，但是这个说法却存在问题。&lt;/p>
&lt;p>用户几乎不知道他们提供给我们的是什么数据，哪些数据被放进了数据库，数据又是怎样被保留与处理的，大多数隐私政策都是模棱两可的，忽悠用户而不敢打开天窗说亮话。如果用户不了解他们的数据会发生什么，就无法给出任何有意义的同意。有时来自一个用户的数据还会提到一些关于其他人的事，而其他那些人既不是该服务的用户，也没有同意任何条款。我们在本书这一部分中讨论的衍生数据集；来自整个用户群的数据，加上行为追踪与外部数据源，就恰好是用户无法（在真正意义上）理解的数据类型。&lt;/p>
&lt;p>而且从用户身上挖掘数据是一个单向过程，而不是真正的互惠关系，也不是公平的价值交换。用户对能用多少数据换来什么样的服务，既没有没有发言权也没有选择权：服务与用户之间的关系是非常不对称与单边的。这些条款是由服务提出的，而不是由用户提出的。对于不同意监视的用户，唯一真正管用的备选项，就是简单地不使用服务。但这个选择也不是真正自由的：如果一项服务如此受欢迎，以至于“被大多数人认为是基本社会参与的必要条件”，那么指望人们选择退出这项服务是不合理的，使用它事实上（de facto）是强制性的。例如，在大多数西方社会群体中，携带智能手机，使用 Facebook 进行社交，以及使用 Google 查找信息已成为常态。特别是当一项服务具有网络效应时，人们选择不使用会产生社会成本。&lt;/p>
&lt;p>因为跟踪用户而拒绝使用服务，这只是少数人才拥有的权力，他们有足够的时间与知识来了解隐私政策，并承受的起代价：错过社会参与，以及使用服务可能带来的专业机会。对于那些处境不太好的人而言，并没有真正意义上的选择：监控是不可避免的。&lt;/p>
&lt;h2 id="隐私与数据使用">隐私与数据使用&lt;/h2>
&lt;p>有时候，人们声称“隐私已死”，理由是有些用户愿意把各种关于他们生活的事情发布到社交媒体上，有时是平凡俗套，但有时是高度私密的。但这种说法是错误的，而且是对隐私（privacy）一词的误解。拥有隐私并不意味着保密一切东西；它意味着拥有选择向谁展示哪些东西的自由，要公开什么，以及要保密什么。隐私权是一项决定权：在从保密到透明的光谱上，隐私使得每个人都能决定自己想要在什么地方位于光谱上的哪个位置。这是一个人自由与自主的重要方面。&lt;/p>
&lt;p>当通过监控基础设施从人身上提取数据时，隐私权不一定受到损害，而是转移到了数据收集者手中。获取数据的公司实际上是说“相信我们会用你的数据做正确的事情”，这意味着，决定要透露什么和保密什么的权利从个体手中转移到了公司手中。这些公司反过来选择保密这些监视结果，因为揭露这些会令人毛骨悚然，并损害它们的商业模式（比其他公司更了解人）。用户的私密信息只会间接地披露，例如针对特定人群定向投放广告的工具（比如那些患有特定疾病的人群）。&lt;/p>
&lt;p>即使特定用户无法从特定广告定向的人群中以个体的形式区分出来，但他们已经失去了披露一些私密信息的能动性，例如他们是否患有某种疾病。决定向谁透露什么并不是由个体按照自己的喜好决定的，是由公司，以利润最大化为目标来行使隐私权的。&lt;/p>
&lt;p>许多公司都有一个目标，不要让人感觉到毛骨悚然，先不说它们收集数据实际上是多么具有侵犯性，让我们先关注用户感知的管理。这些用户感受经常被管理的很糟糕：例如，在事实上可能正确的一些东西，但如果会触发痛苦的回忆，用户可能并不希望被提醒。对于任何类型的数据，我们都应当考虑它出错、不可取、不合时宜的可能性，并且需要建立处理这些失效的机制。无论是“不可取”还是“不合时宜”，当然都是由人的判断决定的；除非我们明确地将算法编码设计为尊重人类的需求，否则算法会无视这些概念。作为这些系统的工程师，我们必须保持谦卑，充分规划，接受这些失效。&lt;/p>
&lt;p>允许在线服务的用户控制其隐私设置，例如控制其他用户可以看到哪些东西，是将一些控制交还给用户的第一步。但无论怎么设置，服务本身仍然可以不受限制地访问数据，并能以隐私策略允许的任何方式自由使用它。即使服务承诺不会将数据出售给第三方，它通常会授予自己不受限制的权利，以便在内部处理与分析数据，而且往往比用户公开可见的部分要深入的多。这种从个体到公司的大规模隐私权转移在历史上是史无前例的。监控一直存在，但它过去是昂贵的，手动的，不是可扩展的，自动化的。信任关系始终存在，例如患者与其医生之间，或被告与其律师之间，但在这些情况下，数据的使用严格受到道德，法律和监管限制的约束。互联网服务使得在未经有意义的同意下收集大量敏感信息变得容易得多，而且无需用户理解他们的私人数据到底发生了什么。&lt;/p>
&lt;h2 id="数据资产与权力">数据资产与权力&lt;/h2>
&lt;p>由于行为数据是用户与服务交互的副产品，因此有时被称为“数据废气”，暗示数据是毫无价值的废料。从这个角度来看，行为和预测性分析可以被看作是一种从数据中提取价值的回收形式，否则这些数据就会被浪费。更准确的看法恰恰相反：从经济的角度来看，如果定向广告是服务的金主，那么关于人的行为数据就是服务的核心资产。在这种情况下，用户与之交互的应用仅仅是一种诱骗用户将更多的个人信息提供给监控基础设施的手段。在线服务中经常表现出的令人愉悦的人类创造力与社会关系，十分讽刺地被数据提取机器所滥用。&lt;/p>
&lt;p>个人数据是珍贵资产的说法因为数据中介的存在得到支持，这是阴影中的秘密行业，购买，聚合，分析，推断，以及转售私密个人数据，主要用于市场营销。初创公司按照它们的用户数量，“眼球数”，即它们的监视能力来估值。因为数据很有价值，所以很多人都想要它。当然，公司也想要它，这就是为什么它们一开始就收集数据的原因。但政府也想获得它：通过秘密交易，胁迫，法律强制，或者只是窃取。当公司破产时，收集到的个人数据就是被出售的资产之一。而且数据安全很难保护，因此经常发生令人难堪的泄漏事件。&lt;/p>
&lt;p>这些观察已经导致批评者声称，数据不仅仅是一种资产，而且是一种“有毒资产”，或者至少是“有害物质”。即使我们认为自己有能力阻止数据滥用，但每当我们收集数据时，我们都需要平衡收益以及这些数据落入恶人手中的风险：计算机系统可能会被犯罪分子或敌国特务渗透，数据可能会被内鬼泄露，公司可能会落入不择手段的管理层手中，而这些管理者有着迥然不同的价值观，或者国家可能被能毫无愧色迫使我们交出数据的政权所接管。&lt;/p>
&lt;p>俗话说，“知识就是力量”。更进一步，“在避免自己被审视的同时审视他人，是权力最重要的形式之一”。这就是极权政府想要监控的原因：这让它们有能力控制全体居民。尽管今天的科技公司并没有公开地寻求政治权力，但是它们积累的数据与知识却给它们带来了很多权力，其中大部分是在公共监督之外偷偷进行的。&lt;/p>
&lt;h2 id="回顾工业革命">回顾工业革命&lt;/h2>
&lt;p>数据是信息时代的决定性特征。互联网，数据存储，处理和软件驱动的自动化正在对全球经济和人类社会产生重大影响。我们的日常生活与社会组织在过去十年中发生了变化，而且在未来的十年中可能会继续发生根本性的变化，所以我们会想到与工业革命对比。工业革命是通过重大的技术与农业进步实现的，它带来了持续的经济增长，长期的生活水平显著提高。然而它也带来了一些严重的问题：空气污染（由于烟雾和化学过程）和水污染（工业垃圾和人类垃圾）是可怖的。工厂老板生活在纷奢之中，而城市工人经常居住在非常糟糕的住房中，并且在恶劣的条件下长时间工作。童工很常见，甚至包括矿井中危险而低薪的工作。&lt;/p>
&lt;p>制定了保护措施花费了很长的时间，例如环境保护条例，工作场所安全条例，宣布使用童工非法，以及食品卫生检查。毫无疑问，生产成本增加了，因为工厂再也不能把废物倒入河流，销售污染的食物，或者剥削工人。但是整个社会都从中受益良多，我们中很少会有人想回到这些管制条例之前的日子。就像工业革命有着黑暗面需要应对一样，我们转向信息时代的过程中，也有需要应对与解决的重大问题。我相信数据的收集与使用就是其中一个问题。用布鲁斯·施奈尔的话来说：&lt;/p>
&lt;blockquote>
&lt;p>数据是信息时代的污染问题，保护隐私是环境挑战。几乎所有的电脑都能生产信息。它堆积在周围，开始溃烂。我们如何处理它，我们如何控制它，以及如何摆脱它，是信息经济健康发展的核心议题。正如我们今天回顾工业时代的早期年代，并想知道我们的祖先在忙于建设工业世界的过程时怎么能忽略污染问题；我们的孙辈在回望信息时代的早期年代时，将会就我们如何应对数据收集和滥用的挑战来评断我们。
​ 我们应该设法让他们感到骄傲。&lt;/p>
&lt;/blockquote>
&lt;h2 id="立法和自律">立法和自律&lt;/h2>
&lt;p>数据保护法可能有助于维护个人的权利。例如，1995 年的“欧洲数据保护指示”规定，个人数据必须“为特定的，明确的和合法的目的收集，而不是以与这些目的不相符的方式进一步处理”，并且数据必须“就收集的目的而言适当，相关，不过分。“。但是，这个立法在今天的互联网环境下是否有效还是有疑问的。这些规则直接否定了大数据的哲学，即最大限度地收集数据，将其与其他数据集结合起来进行试验和探索，以便产生新的洞察。探索意味着将数据用于未曾预期的目的，这与用户同意的“特定和明确”目的相反（如果我们可以有意义地表示同意的话）。更新的规章正在制定中。&lt;/p>
&lt;p>那些收集了大量有关人的数据的公司反对监管，认为这是创新的负担与阻碍。在某种程度上，这种反对是有道理的。例如，分享医疗数据时，存在明显的隐私风险，但也有潜在的机遇：如果数据分析能够帮助我们实现更好的诊断或找到更好的治疗方法，能够阻止多少人的死亡？过度监管可能会阻止这种突破。在这种潜在机会与风险之间找出平衡是很困难的。&lt;/p>
&lt;p>从根本上说，我认为我们需要科技行业在个人数据方面的文化转变。我们应该停止将用户视作待优化的指标数据，并记住他们是值得尊重，有尊严和能动性的人。我们应当在数据收集和实际处理中自我约束，以建立和维持依赖我们软件的人们的信任。我们应当将教育终端用户视为己任，告诉他们我们是如何使用他们的数据的，而不是将他们蒙在鼓里。我们应该允许每个人保留自己的隐私，即，对自己数据的控制，而不是通过监视来窃取这种控制权。我们控制自己数据的个体权利就像是国家公园的自然环境：如果我们不去明确地保护它，关心它，它就会被破坏。这将是公地的悲剧，我们都会因此而变得更糟。无所不在的监视并非不可避免的，我们现在仍然能阻止它。&lt;/p>
&lt;p>我们究竟能做到哪一步，是一个开放的问题。首先，我们不应该永久保留数据，而是一旦不再需要就立即清除数据。清除数据与不变性的想法背道而驰，但这是可以解决该问题。我所看到的一种很有前景的方法是通过加密协议来实施访问控制，而不仅仅是通过策略。总的来说，文化与态度的改变是必要的。&lt;/p></description></item><item><title>大数据的未来</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%AA%E6%9D%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%AA%E6%9D%A5/</guid><description>&lt;h1 id="大数据的未来">大数据的未来&lt;/h1>
&lt;p>随着大数据的消逝，我们进入到了后大数据时代，包括多云时代、机器学习时代以及实时和无处不在的上下文时代。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>多云时代恰恰表明日益需要基于现有的各种应用系统跨多云支持应用软件和平台，也日益需要支持持续交付和业务连续性。“某项任务有一个应用软件”这种观念导致了企业中每个员工平均有一个 SaaS 应用软件的业务环境，这意味着每家大企业在为数千个 SaaS 应用软件支持数据和流量。后端容器化这个趋势导致支持按需和峰值使用环境的存储和工作负载环境日益分散化和专业化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>机器学习时代专注于分析模型、算法、模型训练、深度学习以及算法和深度学习技术的伦理。机器学习需要处理创建干净数据供分析所用所需的大量相同工作，但还需要另外的数学、业务和伦理上下文以创建持久的长期价值。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>实时和无处不在的上下文恰恰表明，从分析的角度和交互的角度来看，日益需要及时的更新。从分析的角度来看，公司分析处理仅仅每周更新一次或每天更新一次已不够。员工现在需要近乎实时的更新，否则有可能做出糟糕的公司决策，这些决策在制定的那一刻就已过时或落伍了。有效使用实时分析需要广泛的业务数据，以提供适当的整体上下文以及供针对数据按需执行的分析所用。无处不在还表明了交互的兴起，包括物联网提供表明环境和机械活动的更多边缘观察信息，以及仍在发展中的扩展现实（Extended Reality，包括增强现实和虚拟现实）提供身临其境的体验。为了提供这种级别的交互，必须以交互的速度分析数据，可能短至 300-500 毫秒，以提供有效的行为反馈。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>随着大数据时代走到尽头，我们现在可以少关注收集大量数据的机制，多关注处理、分析海量数据并与之实时交互方面的无数挑战。我们迈入大数据驱动的新时代时，请牢记以下几个概念。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>首先，Hadoop 在企业数据界仍占有一席之地。Amalgam Insights 预计，MapR 最终会被一家以管理 IT 软件出名的公司收购，比如 BMC、冠群或 MicroFocus；并认为 Cloudera 已采取了措施，不仅限于企业 Hadoop，以支持数据的下几个时代。但技术的步伐不可阻挡，Cloudera 的问题在于它的行动是否够快、随势而变。Cloudera 在将其企业数据平台完善成下一代洞察力和机器学习平台方面面临数字化转型挑战。过去几十年，公司能够为转型敲定时间表。现在正如我们从亚马逊、Facebook 和微软等公司看到的那样，仅仅为了活命，成功的科技公司必须准备好每十年就要转型，可能甚至牺牲掉自己的部分业务。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>其次，对多云分析和数据可视化的需求比以往任何时候都要大。谷歌和 Salesforce 刚斥资 180 亿美元收购了 Looker 和 Tableau，那些收购基本上是针对颇具规模和收入增长的公司的市场价值收购。会投入更多的巨额资金，以克服这一挑战：针对众多数据源提供分析技术，并支持与多云有关的日益分散且多样的存储、计算和集成需求。这意味着企业需要慎重地搞清楚数据集成、数据建模、分析及/或机器学习/数据科学团队可以在多大程度上应对这个挑战，因为处理和分析异构数据变得越来越困难、复杂，但要支持战略业务需求并将数据用作真正的战略优势又势必需要这么做。而仅看国内发展，企业对多云分析和数据可视化的需求也是一样剧增。2006 年成立的国产 BI 软件厂商帆软软件自 2016 年 300 人左右的团队短短三年内成长到现在的 1100 余人，据知为了应对更多的市场需求其团队还在不断扩大。这样的成长速度源自市场需求的增多和帆软对于市场需求走势的判断。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第三，机器学习和数据科学是下一代分析技术，需要各自做好新的数据管理工作。大规模创建测试数据、合成数据和掩蔽数据，以及数据沿袭、治理、参数和超参数定义以及算法假设，这些都超出了传统大数据假设的范畴。这里最重要的考量因素是，使用由于种种原因未能很好地服务于企业的数据：样本量小、缺乏数据源、数据定义不清晰、数据上下文不明确，或者算法和分类假设不准确。换句话说，不使用失实的数据。失实的数据会导致有偏见、不合规、不准确的结果，还可能导致诸多问题：比如 Nick Leeson 在 1995 年导致巴林银行（BaringsBank）垮台，或法国兴业银行因 Jerome Kerviel 精心操纵交易而蒙受 70 亿美元的交易损失。AI 现在是新的潜在“流氓交易者”，需要得到适当的治理、管理和支持。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>第四，需要将实时和无处不在的上下文既视为协作和技术上的挑战，又视为数据挑战。我们正进入这样一个世界：每个对象、流程和对话都可以用附加的上下文加以标记、标注或增强，可以实时处理数 GB 的数据，以生成简单的两个单词警报，可能就像“减慢速度”或“立即购买”这么简单。我们看到“数字孪生”（digital twin）这个概念方兴未艾：在工业界，PTC、GE 及其他产品生命周期和制造公司为设备创建数字孪生；而在销售界，Gong、Tact 和 Voicera 等公司借助额外的上下文以数字方式记录、分析和增强模拟对话。&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>大数据平台</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/</guid><description>&lt;h1 id="大数据平台">大数据平台&lt;/h1>
&lt;p>大数据平台是将互联网产品和后台的大数据系统整合起来，将应用系统产生的数据导入大数据平台，经过计算后导出给应用系统使用。大数据平台将互联网应用和大数据产品整合起来，将实时数据和离线数据打通，使数据可以实现更大规模的关联计算，挖掘出数据更大的价值，从而实现数据驱动业务。大数据平台使得大数据技术产品可以落地应用，实现了自身价值。&lt;/p>
&lt;p>总体来说：大数据平台可以分为四个部分：数据采集、数据处理、数据输出和任务调度管理。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s2.ax1x.com/2019/12/18/QH7aqS.jpg" alt="大数据平台" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="数据采集">数据采集&lt;/h1>
&lt;h2 id="数据库数据">数据库数据&lt;/h2>
&lt;p>目前比较常用的数据库导入工具有 Sqoop 和 Canal。&lt;/p>
&lt;p>Sqoop 是一个数据库批量导入导出工具，可以将关系数据库的数据批量导入到 Hadoop，也可以将 Hadoop 的数据导出到关系数据库。&lt;/p>
&lt;p>Sqoop 适合关系数据库数据的批量导入，如果想实时导入关系数据库的数据，可以选择 Canal。Canal 是阿里巴巴开源的一个 MySQLbinlog 获取工具，Binlog 是 MySQL 的事务日志，可用于 MySQL 数据库主从复制，Canal 将自己伪装成 MySQL 从库，从 MySQL 获取 Binlog。&lt;/p>
&lt;h2 id="日志数据">日志数据&lt;/h2>
&lt;p>日志是大数据平台重要数据来源之一，应用程序日志一方面记录各种程序执行状况，一方面记录用户的操作轨迹。Flume 是大数据日志收集常用的工具。Flume 最早由 Cloudera 开发，后来捐赠给 Apache 基金会作为开源项目运营。&lt;/p>
&lt;h2 id="前端程序埋点">前端程序埋点&lt;/h2>
&lt;p>所谓前端埋点，是应用前端为了进行数据统计和分析采集数据。&lt;/p>
&lt;p>用户的某些前端行为并不会产生后端请求，比如用户页面停留时间、用户浏览速度、用户点选又取消等等。这些信息对于分析用户行为等都很有价值。但是这些数据必须通过前端埋点获得，有些互联网公司会将前端埋点数据当作最主要的大数据来源，用户所有前端行为，都会埋点采集，再辅助结合其他的数据源，构建自己的大数据仓库，进而进行数据分析和挖掘。&lt;/p>
&lt;p>对于一个互联网应用，当我们提到前端的时候，可能指的是如下几类：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>App 程序，比如一个 iOS 应用或者 Android 应用，安装在用户的手机或者平板上；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PC Web 前端，使用 PC 浏览器打开；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>H5 前端，由移动设备浏览器打开；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>微信小程序，在微信内打开。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这些不同的前端使用不同的开发语言开发，运行在不同的设备上，每一类前端都需要解决自己的埋点问题。埋点的方式主要有手工埋点、自动化埋点和可视化埋点。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>手工埋点就是前端开发者手动编程将需要采集的前端数据发送到后端的数据采集系统。通常公司会开发一些前端数据上报的 SDK，前端工程师在需要埋点的地方，调用 SDK，按照接口规范传入相关参数，比如 ID、名称、页面、控件等通用参数，还有业务逻辑数据等，SDK 将这些数据通过 HTTP 的方式发送到后端服务器。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>自动化埋点则是通过一个前端程序 SDK，自动收集全部用户操作事件，然后全量上传到后端服器。自动化埋点有时候也被称作无埋点，意思是无需埋点，实际上是全埋点，即全部用户操作都埋点采集。自动化埋点的好处是开发工作量小，数据规范统一。缺点是采集的数据量大，很多数据采集来也不知道有什么用，白白浪费了计算资源，特别是对于流量敏感的移动端用户而言，因为自动化埋点采集上传花费了大量的流量，可能因此成为卸载应用的理由，这样就得不偿失了。在实践中，有时候只是针对部分用户做自动埋点，抽样一部分数据做统计分析。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>介于手工埋点和自动化埋点之间的，还有一种方案是可视化埋点。通过可视化的方式配置哪些前端操作需要埋点，根据配置采集数据。可视化埋点实际上是可以人工干预的自动化埋点。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="爬虫系统">爬虫系统&lt;/h2>
&lt;p>通过网络爬虫获取外部数据用于行业数据支撑，管理决策等。由于涉及到敏感内容，不做更多的展开。&lt;/p>
&lt;h1 id="数据处理">数据处理&lt;/h1>
&lt;p>大数据平台的核心，分为离线计算和实时计算两类。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>离线计算：由 MapReduce、Hive、Spark 等进行的计算处理。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>实时计算：由 Storm、SparkSteaming 等流式大数据引擎完成，可以在秒级甚至毫秒级时间内完成计算。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="数据输出">数据输出&lt;/h2>
&lt;p>大数据处理与计算产生的数据写入到 HDFS 中，但应用程序不会到 HDFS 中读取数据，所以必须要将 HDFS 中的数据导出到数据库中。除了给用户提供数据，大数据平台还需要在一些后台系统中给运营和决策层提供各种统计数据，这些数据也写入数据库，被相应的后台系统访问。&lt;/p>
&lt;h2 id="任务调度">任务调度&lt;/h2>
&lt;p>将上面三个部分有效整合和运转起来的是任务调度管理系统，它的主要作用是：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>合理调度各种 MapReduce、Spark 任务使资源利用最合理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>尽快执行临时的重要任务&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对作业提交、进度跟踪、数据查看等功能&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>简单的大数据平台任务调度管理系统其实就是一个类似 Crontab 的定时任务系统，按预设时间启动不同的大数据作业脚本。复杂的大数据平台任务调度还要考虑不同作业之间的依赖关系。开源的大数据调度系统有 Oozie，也可以在此基础进行扩展。&lt;/p>
&lt;h1 id="hadoop-不足">Hadoop 不足&lt;/h1>
&lt;p>虽然 Hadoop 在通过批处理支持大型存储和 ETL（提取、转换和加载）作业以及支持机器学习任务方面大有价值，但它在支持公司和大型组织用来管理日常运营的较为传统的分析工作方面并非最佳选择。Hive、Dremel 和 Spark 等工具在 Hadoop 上面使用以支持分析，但 Hadoop 从未变得足够快，无法真正取代数据仓库。&lt;/p>
&lt;p>Hadoop 还面临这样的挑战：NoSQL 数据库和对象存储提供商在解决 Hadoop 最初旨在帮助解决的部分存储和管理难题方面取得了进展。随着时间的推移，在 Hadoop 上支持业务连续性面临挑战，加上支持实时、地理空间及其他新兴的分析使用场合方面缺乏灵活性，这使得 Hadoop 面对海量数据时很难在批处理之外大有作为。&lt;/p>
&lt;p>此外，久而久之，许多公司开始发现大数据难题越来越与此有关：支持一系列广泛的数据源，并迅速调整数据模式、查询、定义和上下文，新的应用程序、平台和云基础设施供应商就体现了这一点。为了克服这个挑战，分析、集成和复制就必须变得更敏捷更快速。许多供应商纷纷创办就体现了这个挑战，包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>分析解决方案：比如 ClearStory Data、Domo、Incorta、Looker、FineBI、Microsoft Power BI、Qlik、Sisense、Tableau 和 ThoughtSpot&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据管道供应商：比如 Alooma、Attunity、Alteryx、Fivetran 和 Matillion&lt;/p>
&lt;/li>
&lt;li>
&lt;p>数据集成供应商：包括 Informatica、MuleSoft、SnapLogic、Talend 和 TIBCO（后者还凭借其 Spotfire 产品组合角逐分析领域）。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="links">Links&lt;/h1>
&lt;ul>
&lt;li>&lt;a href="https://www.freebuf.com/articles/database/221147.html?hmsr=toutiao.io&amp;amp;utm_medium=toutiao.io&amp;amp;utm_source=toutiao.io" target="_blank" rel="noopener">https://www.freebuf.com/articles/database/221147.html?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>大数据生态圈</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81%E5%9C%88/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81%E5%9C%88/</guid><description>&lt;h1 id="大数据与其他技术">大数据与其他技术&lt;/h1>
&lt;h1 id="云计算">云计算&lt;/h1>
&lt;p>说到这里，我们要回答一个很多人心里都存在的疑惑——大数据和云计算之间，到底有什么关系？
可以这么解释：数据本身是一种资产，而云计算，则是为挖掘资产价值提供合适的工具。&lt;/p>
&lt;p>从技术上，大数据是依赖于云计算的。云计算里面的海量数据存储技术、海量数据管理技术、分布式计算模型等，都是大数据技术的基础。&lt;/p>
&lt;p>云计算就像是挖掘机，大数据就是矿山。如果没有云计算，大数据的价值就发挥不出来。&lt;/p>
&lt;p>相反的，大数据的处理需求，也刺激了云计算相关技术的发展和落地。&lt;/p>
&lt;p>也就是说，如果没有大数据这座矿山，云计算这个挖掘机，很多强悍的功能都发展不起来。&lt;/p>
&lt;p>套用一句老话——云计算和大数据，两者是相辅相成的。&lt;/p>
&lt;h1 id="大数据与物联网">大数据与物联网&lt;/h1>
&lt;p>第二个问题，大数据和物联网有什么关系？&lt;/p>
&lt;p>这个问题我觉得大家应该能够很快想明白，前面其实也提到了。&lt;/p>
&lt;p>物联网就是“物与物互相连接的互联网”。物联网的感知层，产生了海量的数据，将会极大地促进大数据的发展。&lt;/p>
&lt;p>同样，大数据应用也发挥了物联网的价值，反向刺激了物联网的使用需求。越来越多的企业，发觉能够通过物联网大数据获得价值，就会愿意投资建设物联网。&lt;/p>
&lt;p>其实这个问题也可以进一步延伸为“大数据和 5G 之间的关系”。&lt;/p>
&lt;p>即将到来的 5G，通过提升连接速率，提升了“人联网”的感知，也促进了人类主动创造数据。&lt;/p>
&lt;p>另一方面，它更多是为“物联网”服务的。包括低延时、海量终端连接等，都是物联网场景的需求。&lt;/p>
&lt;p>5G 刺激物联网的发展，而物联网刺激大数据的发展。所有通信基础设施的强大，都是为大数据崛起铺平道路。&lt;/p></description></item><item><title>数据的特性</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E6%80%A7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E6%80%A7/</guid><description>&lt;h1 id="大数据">大数据&lt;/h1>
&lt;h1 id="数据的来源">数据的来源&lt;/h1>
&lt;p>数据的增长，为什么会如此之快？&lt;/p>
&lt;p>说到这里，就要回顾一下人类社会数据产生的几个重要阶段。&lt;/p>
&lt;p>大致来说，是三个重要的阶段。&lt;/p>
&lt;p>第一个阶段，就是计算机被发明之后的阶段。尤其是数据库被发明之后，使得数据管理的复杂度大大降低。各行各业开始产生了数据，从而被记录在数据库中。&lt;/p>
&lt;p>这时的数据，以结构化数据为主（待会解释什么是“结构化数据”）。数据的产生方式，也是被动的。&lt;/p>
&lt;p>第二个阶段，是伴随着互联网 2.0 时代出现的。互联网 2.0 的最重要标志，就是用户原创内容。&lt;/p>
&lt;p>随着互联网和移动通信设备的普及，人们开始使用博客、facebook、youtube 这样的社交网络，从而主动产生了大量的数据。&lt;/p>
&lt;p>第三个阶段，是感知式系统阶段。随着物联网的发展，各种各样的感知层节点开始自动产生大量的数据，例如遍布世界各个角落的传感器、摄像头。&lt;/p>
&lt;p>经过了“被动-主动-自动”这三个阶段的发展，最终导致了人类数据总量的极速膨胀。&lt;/p>
&lt;h2 id="机器数据">机器数据&lt;/h2>
&lt;p>机器数据中包含客户、用户、交易、应用程序、服务器、网络和手机设备所有活动和行为的明确记录。不仅仅包含日志。还包括配置、API 中的数据、消息队列、更改事件、诊断命令输出、工业系统呼叫详细信息记录和传感器数据等。计算机数以未知格式的阵列存储，监测和分析工具的传统集并未为多样性、速率、数据量、可变性设计。一个专为此独特类型数据设计的全新方法，必须可以快速诊断服务问题、检测复杂信息安全威胁、远程设备的健康状况和性能，以及说明合规性。&lt;/p>
&lt;blockquote>
&lt;p>每个环境都有独特的机器数据空间，以下是一些示例。&lt;/p>
&lt;/blockquote>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>数据类型&lt;/th>
&lt;th>位置&lt;/th>
&lt;th>它可以告诉您什么&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>应用日志&lt;/td>
&lt;td>本地日志文件、log4j、log4net、Weblogic、WebSphere、JBoss、.NET、PHP&lt;/td>
&lt;td>用户活动、欺诈检测、应用性能&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>业务流程日志&lt;/td>
&lt;td>业务流程管理日志&lt;/td>
&lt;td>跨渠道客户活动、购买、帐户变更以及问题报表&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>呼叫详细信息记录&lt;/td>
&lt;td>呼叫详细信息记录 (CDR)、计费数据记录、事件数据记录均由电信和网络交换机所记录&lt;/td>
&lt;td>计费、收入保证、客户保证、合作伙伴结算，营销智能&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>点击流数据&lt;/td>
&lt;td>Web 服务器、路由器、代理服务器和广告服务器&lt;/td>
&lt;td>可用性分析、数字市场营销和一般调查&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>配置文件&lt;/td>
&lt;td>系统配置文件&lt;/td>
&lt;td>如何设置基础设施、调试故障、后门攻击、”定时炸弹”病毒&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据库审计日志&lt;/td>
&lt;td>数据库日志文件、审计表&lt;/td>
&lt;td>如何根据时间修改数据库数据以及如何确定修改人&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>文件系统审计日志&lt;/td>
&lt;td>敏感数据存储在共享文件系统中&lt;/td>
&lt;td>监测并审计敏感数据读取权限&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>管理并记录 API&lt;/td>
&lt;td>通过 OPSEC Log Export API (OPSEC LEA) 和其他 VMware 和 Citrix 供应商特定 API 的 Checkpoint 防火墙&lt;/td>
&lt;td>管理数据和日志事件&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>消息队列&lt;/td>
&lt;td>JMS、RabbitMQ 和 AquaLogic&lt;/td>
&lt;td>调试复杂应用中的问题，并作为记录应用架构基础&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>操作系统度量、状态和诊断命令&lt;/td>
&lt;td>通过命令行实用程序(例如 Unix 和 Linux 上的 ps 与 iostat 以及 Windows 上的性能监视器)显示的 CPU、内存利用率和状态信息&lt;/td>
&lt;td>故障排除、分析趋势以发现潜在问题并调查安全事件&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据包/流量数据&lt;/td>
&lt;td>tcpdump 和 tcpflow 可生成 pcap 或流量数据以及其他有用的数据包级和会话级信息&lt;/td>
&lt;td>性能降级、超时、瓶颈或可疑活动可表明网络被入侵或者受到远程攻击&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SCADA 数据&lt;/td>
&lt;td>监视控制与数据采集 (SCADA)&lt;/td>
&lt;td>识别 SCADA 基础结构中的趋势、模式和异常情况，并用于实现客户价值&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>传感器数据&lt;/td>
&lt;td>传感器设备可以根据监测环境条件生成数据，例如气温、声音、压力、功率以及水位&lt;/td>
&lt;td>水位监测、机器健康状态监测和智能家居监测&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Syslog&lt;/td>
&lt;td>路由器、交换机和网络设备上的 Syslog&lt;/td>
&lt;td>故障排除、分析、安全审计&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Web 访问日志&lt;/td>
&lt;td>Web 访问日志会报告 Web 服务器处理的每个请求&lt;/td>
&lt;td>Web 市场营销分析报表&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Web 代理日志&lt;/td>
&lt;td>Web 代理记录用户通过代理发出的每个 Web 请求&lt;/td>
&lt;td>监测并调查服务条款以及数据泄露事件&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Windows 事件&lt;/td>
&lt;td>Windows 应用、安全和系统事件日志&lt;/td>
&lt;td>使用业务关键应用、安全信息和使用模式检测问题，&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>线上数据&lt;/td>
&lt;td>DNS 查找和记录，协议级信息，包括标头、内容以及流记录&lt;/td>
&lt;td>主动监测应用性能和可用性、最终客户体验、事件调查、网络、威胁检测、监控和合规性&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="大数据存储与处理">大数据存储与处理&lt;/h2>
&lt;p>大数据不仅仅意味着庞大的数据量，还意味着数据纬度之多。&lt;/p>
&lt;h2 id="数据仓库与数据治理">数据仓库与数据治理&lt;/h2>
&lt;p>随着企业应用复杂性的上升和微服务架构的流行，数据正变得越来越以应用为中心。服务之间仅在必要时以接口或者消息队列方式进行数据交互，从而避免了构建单一数据库集群来支撑不断增长的业务需要。以应用为中心的数据持久化架构，在带来可伸缩性好处的同时，也给数据的融合计算带来了障碍。&lt;/p>
&lt;p>由于数据散落在不同的数据库、消息队列、文件系统中，计算平台如果直接访问这些数据，会遇到可访问性和数据传输延迟等问题。在一些场景下，计算平台直接访问应用系统数据库会对系统吞吐造成显著影响，通常也是不被允许的。&lt;/p>
&lt;p>依赖于 ETL，Data Pipeline 与数据仓库等不同层次的解决方案。&lt;/p>
&lt;h1 id="大数据的特点">大数据的特点&lt;/h1>
&lt;p>行业里对大数据的特点，概括为 4 个 V。前面所说的庞大数据体量，就是 Volume（海量化）。除了 Volume 之外，剩下三个，分别是 Variety、Velocity、Value。&lt;/p>
&lt;h2 id="variety多样化">Variety（多样化）&lt;/h2>
&lt;p>数据的形式是多种多样的，包括数字（价格、交易数据、体重、人数等）、文本（邮件、网页等）、图像、音频、视频、位置信息（经纬度、海拔等），等等，都是数据。&lt;/p>
&lt;p>数据又分为结构化数据和非结构化数据。&lt;/p>
&lt;p>从名字可以看出，结构化数据，是指可以用预先定义的数据模型表述，或者，可以存入关系型数据库的数据。&lt;/p>
&lt;p>例如，一个班级所有人的年龄、一个超市所有商品的价格，这些都是结构化数据。&lt;/p>
&lt;p>而网页文章、邮件内容、图像、音频、视频等，都属于非结构话数据。&lt;/p>
&lt;p>在互联网领域里，非结构化数据的占比已经超过整个数据量的 80%。&lt;/p>
&lt;p>大数据，就符合这样的特点：数据形式多样化，且非结构化数据占比高。&lt;/p>
&lt;h2 id="velocity时效性">Velocity（时效性）&lt;/h2>
&lt;p>大数据还有一个特点，那就是时效性。从数据的生成到消耗，时间窗口非常小。数据的变化速率，还有处理过程，越来越快。例如变化速率，从以前的按天变化，变成现在的按秒甚至毫秒变化。&lt;/p>
&lt;p>我们还是用数字来说话：&lt;/p>
&lt;p>就在刚刚过去的这一分钟，数据世界里发生了什么？&lt;/p>
&lt;p>Email：2.04 亿封被发出&lt;/p>
&lt;p>Google：200 万次搜索请求被提交&lt;/p>
&lt;p>Youtube：2880 分钟的视频被上传&lt;/p>
&lt;p>Facebook：69.5 万条状态被更新&lt;/p>
&lt;p>Twitter：98000 条推送被发出&lt;/p>
&lt;p>12306：1840 张车票被卖出&lt;/p>
&lt;h2 id="value价值密度">Value（价值密度）&lt;/h2>
&lt;p>最后一个特点，就是价值密度。&lt;/p>
&lt;p>大数据的数据量很大，但随之带来的，就是价值密度很低，数据中真正有价值的，只是其中的很少一部分。&lt;/p>
&lt;p>例如通过监控视频寻找犯罪分子的相貌，也许几 TB 的视频文件，真正有价值的，只有几秒钟。&lt;/p></description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>999.参考资料 | Next-gen Tech Edu</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/</link><atom:link href="https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/index.xml" rel="self" type="application/rss+xml"/><description>999.参考资料</description><generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><image><url>https://ng-tech.icu/media/sharing.png</url><title>999.参考资料</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/</link></image><item><title>2021-数据产品小 Lee-数据仓库基础</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%95%B0%E6%8D%AE%E4%BA%A7%E5%93%81%E5%B0%8F-lee-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%95%B0%E6%8D%AE%E4%BA%A7%E5%93%81%E5%B0%8F-lee-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80/</guid><description>&lt;h1 id="数据仓库基础">数据仓库基础&lt;/h1>
&lt;h1 id="维度模型">维度模型&lt;/h1>
&lt;h2 id="什么是模型什么是建模">什么是模型，什么是建模？&lt;/h2>
&lt;p>什么是模型？作为数据行业从业者，如果你从来没有思考过这个问题，你一定要看下去。先看一个例子：&lt;/p>
&lt;blockquote>
&lt;p>2021 年 3 月 6 日，小明到楼下【行家】便利店买吃的，来来回回逛了几圈，虽然很饿，但又想减肥，最终拿了 1 个【柯德吉】人造肉汉堡。准备付账的时候，收银员跟他说，最近搞活动，加 4 块可以选一瓶原价 8 块的【卡石】酸奶。小明觉得很划算，于是去拿了酸奶，一共付了 12 块。&lt;/p>
&lt;/blockquote>
&lt;p>上面的这段文字，就是模型。先看看百度百科给出的模型定义：&lt;/p>
&lt;blockquote>
&lt;p>模型，是指通过主观意识借助实体或者虚拟表现构成客观阐述形态结构的一种表达目的的物件（物件并不等于物体，不局限于实体与虚拟）&lt;/p>
&lt;/blockquote>
&lt;p>简单来说，模型是映射 “事实” 的东西，构建这个东西的动作就叫做建模。上述的例子，是一种“文字模型”。而且，这个模型还可以补充更多细节，比如，采用什么方式付款、支付了多少钱。为了表达更加简洁，我们可以省略更多的信息，只记录关键信息：&lt;/p>
&lt;blockquote>
&lt;p>2021 年 3 月 6 日，小明买了，一个 柯德吉 牌人造肉汉堡，一瓶 卡石 牌酸奶（共计 ￥ 12）。&lt;/p>
&lt;/blockquote>
&lt;h2 id="范式模型为了更好地记录和更新">范式模型，为了更好地记录和更新&lt;/h2>
&lt;p>计算机的出现，也诞生了新的语言，我们也顺理成章地开始用新语言去建模。假设这个便利店用了现成的 ERP、CRM 系统，这些系统设计好了模型，数据会填充成如下的样子：&lt;/p>
&lt;p>1）订单表&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325133622.png" alt="订单表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>2）订单详情表&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325133644.png" alt="订单详情表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>3）商品详情表&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325133717.png" alt="商品详情表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据量不大，分析人员写 SQL 直接对范式模型进行查询，算账分析无所不能，小几十万数据，速度完全 OK。&lt;/p>
&lt;h2 id="维度模型为分析而生">维度模型，为分析而生&lt;/h2>
&lt;p>范式模型很好地解决了快速记录和节约存储空间。但事物都有两面性，当数据量大的时候，从范式模型中查询取数，就比较慢了。但数据量一大，就顶不住了。人类社会，但凡出现问题，总会天降猛士。Innon 和 Kimball 等人提出来新方案：为数据分析设计一套新模型。&lt;/p>
&lt;p>范式模型主要解决数据的插入和更新，维护一致性等问题，维度模型则解决大数据场景分析的问题，这两者也就是所谓的 OLTP 和 OLAP 。通过一个荒诞的例子来理解两者的区别：&lt;/p>
&lt;blockquote>
&lt;p>你家是个大家族，七大姑八大姨，平时需要打电话联系。
范式建模：每个人只存自己同辈人以及各自子女的联系方式。如果叔叔想找侄子/侄女（你），只能通过你爸爸。
维度建模：所有的亲戚联系方式都写到了一个家庭通讯录上，想找人，直接找通讯录。&lt;/p>
&lt;/blockquote>
&lt;p>这个例子现实生活不存在，主要想帮助大家理解两种模型的差异：&lt;/p>
&lt;p>1、范式模型为了应对数据频繁变更的场景，数据存得零散。为了保证数据的一致性，还要符合一定的规范，我们常见的是三范式（3NF）。
2、维度模型会将数据冗余，把一些相关的数据存到一起，方便快速查询取数。维度模型的出现，就是为了解决大数据量导致的查询慢的问题。&lt;/p>
&lt;h2 id="维度建模的四大要素">维度建模的四大要素&lt;/h2>
&lt;p>数据仓库领域的经典著作《维度建模工具箱》中，Kimball 定义了经典的维度建模的四步曲，：选定业务过程、声明粒度、确定维度、构建事实。&lt;/p>
&lt;h3 id="1业务过程">1）业务过程&lt;/h3>
&lt;p>很多数据仓库书籍都给出了业务过程的通用定义：业务过程是企业活动中的事件，如下单、支付、退款都是业务过程，业务过程是一个不可拆分的行为事件。看完定义，我们就会犯难了，什么是企业活动中的事件？打开手机付款，选择支付宝和微信，这些操作算不算业务过程？&lt;/p>
&lt;p>这里，我们真得咬文嚼字，回归场景。交易的场景，有 2 个参与方：消费者和便利店。便利店作为企业，如果它关心的结果只是消费者买了什么，买了多少，那消费者选择支付方式的事件，它完全不管，也不用记录。&lt;/p>
&lt;p>但如果用户只开通了微信支付，没开通支付宝，因为支付问题导致没法成交，那企业肯定也会关心选择支付方式这个事件以及其结果。业务过程，是不可拆分的事件，而且是基于分析目标进行选定的。理解一个词，不能脱离情景，多尝试将自己置于企业经营的情景下。&lt;/p>
&lt;p>企业里每天都有各种事情，而作为管理者的我们，最核心的关注点是什么？是从收益、成本出发，价值链条上最具影响力的事情或者事件。&lt;/p>
&lt;h3 id="2粒度">2）粒度&lt;/h3>
&lt;p>理解粒度，其实很简单：干什么样的事情，会新增一条记录。小乐支付了一笔，系统会新增一条支付记录，当我们要统计分析交易的订单数时，订单是最细的粒度。而这笔交易中，包含了两个商品，当我们要分析所有订单卖出的商品数，每个商品则变成了最细粒度。&lt;/p>
&lt;h3 id="3维度">3）维度&lt;/h3>
&lt;p>维度，就是我们要进行分析的角度。比如，在便利店场景中，一天的经营结束了，可以按品牌的维度分析，各个品牌的酸奶销售量；可以按日期维度分析，我们可以知道，周一到周日，每天的交易额如何。&lt;/p>
&lt;p>某天，当我们发现交易数据发生异常的时候，我们可以按照品牌、日期等维度进行分析，逐个排查，直到找到根本的原因。&lt;/p>
&lt;h3 id="4事实">4）事实&lt;/h3>
&lt;p>广义地来说，所有被记录下来的事情，都是事实。而维度建模中，对事实进行了细分，事实包含 2 类属性：维度、度量。维度就是上文所说的各个角度的数据，而度量，则通常是数值型的。举个例子，我们描述一个长方形，但是没描述它具体多长、多宽，其他人是没法确定这个长方形具体多大的。&lt;/p>
&lt;p>如果只有补充上它对应的维度和度量，人们才能理解。比如，长 4cm，宽 3cm。长、宽是维度，4 米、3 米则是对应维度上的度量。事实，就是描述客观事物的所有核心信息的所有数据的集合。&lt;/p>
&lt;h1 id="理解业务过程">理解业务过程&lt;/h1>
&lt;p>很多数据仓库书籍都给出了业务过程的通用定义：业务过程是企业活动中的事件，如下单、支付、退款都是业务过程，业务过程是一个不可拆分的行为事件。&lt;/p>
&lt;h2 id="如何理解企业活动">如何理解企业活动&lt;/h2>
&lt;p>同一件事情，按照不同的对象，会有两种描述。这样说很抽象，举个例子：A 公司向 B 公司进了一批货。&lt;/p>
&lt;ul>
&lt;li>A 公司的记录是：采购单。&lt;/li>
&lt;li>B 公司的记录是：销售单。&lt;/li>
&lt;/ul>
&lt;p>业务过程，是有对象主体的，其主体就是：数据仓库索要服务的对象。这个时候，我们要确定一个分析的层次，或者叫做，抽象的粒度。我们只分析企业这个层级的事情，而不分析员工级别的事情。&lt;/p>
&lt;h2 id="如何理解不可拆分">如何理解不可拆分&lt;/h2>
&lt;p>这还是要基于层级去说。假如某天有很多消费者在商店里面买了东西，便利店作为企业，如果它关心的结果只是消费者买了什么，买了多少。那消费者选择支付方式的事件，它完全不管，也不用记录。在便利店这个层级，只关心交易结果，不用关心交易过程中的具体支付方式。&lt;/p>
&lt;p>业务过程，是不可拆分的事件，基于分析目标进行选定的。但如果用户只开通了微信支付，没开通支付宝，因为支付问题导致没法成交，那企业肯定也会关心选择支付方式这个事件以及其结果。&lt;/p>
&lt;p>理解一个词，不能脱离情景，多尝试将自己置于企业经营的情景下。企业里每天都有各种事情，而作为管理者的我们，最核心的关注点是什么？企业是从收益、成本出发，关注价值链条上最具影响力的事情或者事件。&lt;/p>
&lt;h1 id="整明白粒度">整明白粒度&lt;/h1>
&lt;p>选定了分析的过程，紧接着就要声明粒度。看到书里这么说，我当时的反应是：为什么？粒度是什么？普通场景里，粒度可以理解为一个东西的大小。比如，钻石要区分颗粒度，大小不同的钻石，价格不一。而在数据分析的语境里，粒度则意味着分析的范围，分析的细致程度。&lt;/p>
&lt;p>举两个例子。&lt;/p>
&lt;ul>
&lt;li>系统的注册总人数，可以按照国家、省份来统计，这是地域层面上的不同统计粒度。&lt;/li>
&lt;li>系统的活跃用户数，可以按天、按周统计登录人数，这是时间层面上不同的统计粒度。&lt;/li>
&lt;/ul>
&lt;p>从数据表的角度来看，粒度则解释着什么情况下增加一条记录。&lt;/p>
&lt;ul>
&lt;li>按国家统计用户数，中国只会有一条记录，按省统计，中国则会有 34 条记录。&lt;/li>
&lt;li>按周统计活跃用户，一年只会有 52 行记录，按天统计，一年则有 365 或 366 条记录。&lt;/li>
&lt;/ul>
&lt;h2 id="通过实战理解粒度">通过实战理解粒度&lt;/h2>
&lt;p>公司出了新 APP，老板很关心新 APP 的用户活跃程度，于是，用户端产品经理希望做个面板，看每天有多少人登录。同时，他提了另一个需求，他希望能支持统计两个日期区间内的登录人数（两个日期是变化的）。通过例子理解：某个活动发布后，要查看不同时间区间内的累积活跃用户数，比如 1-2 号，3-5 号，以便及时调整促活的策略。&lt;/p>
&lt;p>首先，选定业务过程。这个一目了然，自然就是用户登录过程。其次，声明粒度。这里用户方希望按照不同的日期统计累积人数，那粒度是天。然后，是确定维度。这个例子里，因为要按照日期分析，最主要的维度是日期（为了简单，例子里就就先不考虑其他维度了），日期维度表设计如下：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325134802.png" alt="日期维度表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>最后，设计事实表，用户登录事实表(fact_loign）设计如下：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325134829.png" alt="事实表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="维度模型搞不定是粒度理解不到位">维度模型搞不定，是粒度理解不到位&lt;/h2>
&lt;p>构建模型，最终都是为了查出对应的指标和结果，所以维度模型通常都会跟标准的指标系统配套来使用。当我们按照标准套路，进入指标设计阶段，问题就会慢慢浮出水面了。基于事实表模型，我们很容易设计原子指标【登录人数】，其计算逻辑为：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fact_login&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">user_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>进而，我们也能设计出衍生指标【日期_登录人数】，其口径为：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">distinct&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fact_login&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">user_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fact_login&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">left&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">dim_date&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">date&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">date_key&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">fact_login&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">login_date&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">group&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">dim_date&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">date_key&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>从衍生指标这里，就能发现问题了。你会发现，group by 后的结果，是按照每天进行去重的。最终的结果，只能是统计每天范围内的累积登录人数。用户的期望是，统计某个时间区间内的累积登录人数，这个需求维度模型产生的指标没法满足。如果事实表的真实数据如下：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325135233.png" alt="事实表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>基于维度模型，系统可以生成这样的汇总表：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325135304.png" alt="汇总表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>但系统无法生成如下汇总表：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="image.png" alt="汇总表" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="粒度是搞清问题的关键">粒度是搞清问题的关键&lt;/h2>
&lt;p>让我们回归到真实场景里：登录成功，这个事件发生在一瞬间。常见的时间计量单位有年、月、天、小时、分钟、秒、毫秒、微秒等等。而系统记录某个操作，常见的记录粒度是秒。比如， 2021 年 6 月 27 号 14 : 00 : 00，小明登录了系统。如果按照秒去统计登录人数，则完全不用考虑去重，因为小明在这个粒度的计量单位里，只能登录一次。&lt;/p>
&lt;p>但秒级别的统计粒度，太细了。业务方希望从更加宏观的角度去统计和分析，例子里面，是以天为单位去统计。那这个时候，统计就要升粒度了，并且，要去重。此时，系统也是可以按照天的粒度进行去重统计的。再看看实际需求时，统计的时间区间是不固定的。即，业务方可能今天想统计 1 号到 2 号的登录人数，明天想统计 3 号到 5 号的登录人数。&lt;/p>
&lt;p>粒度不固定：1-2 号，间隔时间是 1 天，3-5 号，间隔时间则是 2 天。维度建模中，声明粒度就是要把粒度的大小定下来。不管是什么维度，都要提前把粒度定下来，这样才能实现累计去重。从技术实现的角度来看，如果查询的粒度，是一个变量，而不是一个固定值，没法提前计算，只能临时用明细表算，这就叫做即席查询。&lt;/p>
&lt;p>所以，这个需求中，维度建模只能解决前面部分的需求：按照天去重统计每天登录人数。而变化区间的去重统计，只能即席查询了。&lt;/p>
&lt;h1 id="搞懂维度">搞懂维度&lt;/h1>
&lt;h2 id="维度是什么">维度是什么&lt;/h2>
&lt;p>1）阿里 dataphin 产品简介-基本概念是这样介绍维度：&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>人们观察事物的角度，是指一种视角&lt;/strong>，是确定事物的多方位、多角度、多层次的条件和概念。&lt;/p>
&lt;/blockquote>
&lt;p>2）华为 DGC 产品介绍-基本概念如此介绍维度：&lt;/p>
&lt;blockquote>
&lt;p>维度是用于&lt;strong>观察和分析业务数据的视角&lt;/strong>，支撑对数据汇聚、钻取、切片分析，用于 SQL 中的 Group by 条件。多数维度具有层级结构，如：地理维度、时间维度。&lt;/p>
&lt;/blockquote>
&lt;p>3）再看看《&lt;a href="https://so.csdn.net/so/search?q=%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93&amp;amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">数据仓库&lt;/a>工具箱》怎么说的：&lt;/p>
&lt;blockquote>
&lt;p>维度能提供围绕&lt;strong>某一业务过程所涉及的 “谁、什么、何处、何时、为什么、如何”等背景&lt;/strong>。维度表包含 BI 应用所需要的用于过滤及分类事实的描述性属性。牢牢掌握事实表的粒度，就能够将所有可能存在的维度区分开。当与给定事实表进行关联时，任何情况下都应该使维度保持单一值。&lt;/p>
&lt;/blockquote>
&lt;p>4）再看《阿里巴巴大数据之路》怎么说的：&lt;/p>
&lt;blockquote>
&lt;p>维度是维度建模的基础和灵魂。在维度建模中，将度量称为 “事实” 将环境描述为 “维度” ，&lt;strong>维度是用于分析事实所需要的多样环境。&lt;/strong>
例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。
维度所包含的表示维度的列，称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。
&lt;strong>维度的作用一般是查询约束、分类汇总以及排序。&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;h2 id="维度和粒度的关系">维度和粒度的关系&lt;/h2>
&lt;p>1）维度有层级结构，不同层级对应不同的粒度。&lt;/p>
&lt;p>地理维度有不同的层级：国家、省/自治州/直辖市、市、县，时间维度也有不同的层级和粒度：年度、季度、月度、星期、天等。正如有了要描述的事情，确定了粒度，再去找对应的维度。比如，订单系统，会记录下单的时间信息，时间维度上，粒度会细到秒。学籍系统，学生户籍信息中，要填入地区维度的信息，粒度要细化到省市。&lt;/p>
&lt;p>2）维度的组合越多，粒度越细细&lt;/p>
&lt;p>客观的世界，是多维的。描述一个客观事物，维度（通常配合相应的度量）越多，粒度越细。比如一个箱子，我们可以描述其长宽高，还可以描述颜色。不同描述维度组合越多，粒度越细，描述也越细致。&lt;/p>
&lt;p>3）随着事物的变化，描述的维度可以增加&lt;/p>
&lt;p>一个箱子会经历生产、运输、送货上门等环节，从产地送达到顾客手中。箱子被生产出来后，没有品牌、产地属性，或者说属性值为空。未经历运输过程的箱子，没有快递公司、配送员属性。但是人们可以赋予它这些维度，并且填入维度值。维度是基于人类描述客观事物的需要，被创造来的。&lt;/p>
&lt;p>4）有的维度，没有直接的数字度量&lt;/p>
&lt;p>从客观唯物主义的角度来说，某个实体的存在，长、宽、高这种比较客观的维度属性，是有确定值的。但某些主观的东西，也是需要被描述的。比如，人的帅气程度。我们就简单分两类：很帅、一般。这种主观的维度，没有绝对精确的度量值，无法直接和数字划上等号。&lt;/p>
&lt;p>但聪明的我们依然可以定性、定量地测算进而描述。比如搞投票，得分超过 90 为很帅，60-90 为一般。但这种方式，只能估算，没有四海皆准的定值，不同的人群，投票结果不同。&lt;/p>
&lt;h2 id="两个有意思的维度问题">两个有意思的维度问题&lt;/h2>
&lt;h3 id="维度的角色">维度的角色&lt;/h3>
&lt;p>维度模型里，很多人不理解什么是维度角色。包括最开始的我自己。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325140618.png" alt="维度角色" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>淘宝的业务过程大家应该很熟悉，涉及 4 个关键步骤：买家下单、买家付款、卖家发货、买家确认收货。每个过程，都会涉及一个对应的时间，即下单时间、支付时间、发货时间、确认收货时间。&lt;/p>
&lt;p>如果只分析其中的一个业务过程，比如买家下单，那只需要一个时间字段即可。但是分析完整四个过程时，如果还只有一个时间字段，那如何区分其具体含义呢？到底是下单还是支付时间，搞不清楚。&lt;/p>
&lt;p>只有一个字段，肯定不够。那必然要有 4 个时间字段。而且我们会给不同的命名，下单、支付、发货、确认收货作为时间的前缀。这样一来，咱们看的人是能理解各个数字的含义了。但不仅如此，还得让计算机系统也理解。所以，要弄一个 “维度角色”的字段来标识，以便计算机能理解。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325140737.png" alt="维度角色 SQL" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p></description></item><item><title>2021-松子-一文遍历大数据架构变迁史</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%BE%E5%AD%90-%E4%B8%80%E6%96%87%E9%81%8D%E5%8E%86%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E5%8F%98%E8%BF%81%E5%8F%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2021-%E6%9D%BE%E5%AD%90-%E4%B8%80%E6%96%87%E9%81%8D%E5%8E%86%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E5%8F%98%E8%BF%81%E5%8F%B2/</guid><description>&lt;h1 id="一文遍历大数据架构变迁史">一文遍历大数据架构变迁史&lt;/h1>
&lt;p>从现在的企业发展来看，大家的诉求重点已经从经营与分析转为数据化的精细运营。在如何做好精细化运营过程中，企业也面临着来自创新、发展、内卷等的各方面压力。随着业务量、数据量增长，大家对数据粒度需求从之前的高汇总逐渐转为过程化的细粒度明细数据，以及从 T+1 的数据转为近乎实时的数据诉求。大量的数据需求、海量的临时需求，让分析师、数据开发疲惫不堪。这些职位也变成了企业资源的瓶颈，传统 BI 中的 Report、OLAP 等工具也都无法满足互联网行业个性化的数据需求。大家开始考虑如何把需求固定为一个面向最终用户自助式、半自助的产品，来快速获取数据并分析得到结果，数据通过各类数据产品对外更有针对性的数据价值传递。&lt;/p>
&lt;p>在这十几年中，影响数据仓库、数据平台、数据中台、数据湖的演进变革的因素也很多，比如不断快速迭代的业务模式与膨胀的群体规模所带来的数据量的冲击，新的大数据处理技术的驱动。还有落地在数据中台上各种数据产品的建设，比如工具化数据产品体系、各种自助式的数据产品、平台化各种数据产品的建设。这些数据建设能力的泛化，也让更多的大众参与数据中台的建设中 ，比如一些懂 SQL 的用户以及分析师参与数据平台直接建设比重增加 。还有一些原本数据中台具备的能力也有一些逐步地被前置到业务系统进行处理。&lt;/p>
&lt;p>数据仓库在国外发展多年，于大约在 1998-1999 年传入中国。进入中国以后，发展出了很多专有名词，比如数据仓库、数据中心、数据平台、数据中台、数据湖等，从大数据架构角度来看可用三个时代九种架构来做总结，其中前四代是传统数据仓库时代的架构，后面五代是大数据架构模式。其中有两个承前启后的地方：&lt;/p>
&lt;ul>
&lt;li>一个特殊地方是，传统行业第三代架构与大数据第一代架构在架构形式上基本相似。传统行业的第三代架构可以算是用大数据处理技术重新实现了一遍。&lt;/li>
&lt;li>传统行业第四代的架构中实时部分在现代用大数据实时方式做了新的落地。&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230323161242.png" alt="大数据架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>三个时代：非互联网、互联网、移动互联网时代，每一种时代的业务特点、数据量、数据类型各不相同，自然数据架构也是有显著差异的。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>行业域&lt;/th>
&lt;th>非互联网&lt;/th>
&lt;th>互联网&lt;/th>
&lt;th>移动互联网&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>数据来源(相对于数据平台来讲)&lt;/td>
&lt;td>结构化各类数据库(DB 系统)、结构化文本、Excel 表格等，少量 word&lt;/td>
&lt;td>Web、自定义、系统的日志，各类结构化 DB 数据、长文本、视频 主要是来自网页&lt;/td>
&lt;td>除了互联网那些外还含有大量定位数据、自动化传感器、嵌入式设备、自动化设备等&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据包含信息&lt;/td>
&lt;td>CRM 客户信息、事务性 ERP/MRPII 数据、资金账务数据 等。&lt;/td>
&lt;td>除了传统企业数据信息外，还含有用户各类点击日志、社交数据、多媒体、搜索、电邮数据等等&lt;/td>
&lt;td>除了传统互联网的数据外，还含有 Gps、穿戴设备、传感器各类采集数据、自动化传感器采集数据等等&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据结构特性&lt;/td>
&lt;td>几乎都是结构化数据&lt;/td>
&lt;td>非结构化数据居多&lt;/td>
&lt;td>非结构化数据居多&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据存储/数据量&lt;/td>
&lt;td>主要以 DB 结构化存储为主，从几百兆到 百 G 级别&lt;/td>
&lt;td>文件形式、DB 形式，流方式、 从 TB 到 PB&lt;/td>
&lt;td>文件形式、流方式、DB 范式，非结构化 从 TB 到 PB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>产生周期&lt;/td>
&lt;td>慢，几天甚至周为单位&lt;/td>
&lt;td>秒或更小为单位&lt;/td>
&lt;td>秒或更小为单位&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>对消费者行为采集与还原&lt;/td>
&lt;td>粒度粗&lt;/td>
&lt;td>粒度较细&lt;/td>
&lt;td>粒度非常细&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据价值&lt;/td>
&lt;td>长期有效&lt;/td>
&lt;td>随着时间衰减&lt;/td>
&lt;td>随着时间快速衰减&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="从数据到大数据的数据架构总结">从数据到大数据的数据架构总结&lt;/h1>
&lt;p>我自己对传统数据仓库的发展，简单抽象为为五个时代、四种架构（或许也不是那么严谨）。五个时代大概，按照两位数据仓库大师 Ralph kilmball、Bill Innmon 在数据仓库建设理念上碰撞阶段来作为小的分界线：&lt;/p>
&lt;ul>
&lt;li>大概在 1991 年之前，数据仓库的实施基本采用全企业集成的模式。&lt;/li>
&lt;li>大概在 1992 年企业在数据仓库实施基本采用 EDW 的方式，Bill Innmon 博士出版了《如何构建数据仓库》，里面清晰的阐述了 EDW 架构与实施方式。&lt;/li>
&lt;li>1994-1996 年是数据集市时代，这个时代另外一种维度建模、数据集市的方式较为盛行起来，其主要代表之一 Ralph Kimball 博士出版了他的第一本书“The DataWarehouse Toolkit”（《数据仓库工具箱》），里面非常清晰的定义了数据集市、维度建模。&lt;/li>
&lt;li>大概在 1996-1997 年左右的两个架构竞争时代。&lt;/li>
&lt;li>1998-2001 年左右的合并年代。&lt;/li>
&lt;/ul>
&lt;p>在主要历史事件中提到了两位经典代表人物：Bill Innmon、Ralph kilmball。这两位在数据界可以算是元祖级别的人物。现在数据中台/平台的很多设计理念依然受到他俩 90 年代所提出方法论为依据。&lt;/p>
&lt;h2 id="经典的-bill-inmon-和-ralph-kilmball-争论">经典的 BIll Inmon 和 Ralph kilmball 争论&lt;/h2>
&lt;p>Bill Inmon 提出的遵循的是自上而下的建设原则，Ralph kilmball 提出自下而上的建设原则，两种方法拥护者会在不同场合争论哪一种方法论更有优势。两位大师对于建设方法争论要点：&lt;/p>
&lt;ol>
&lt;li>其中 Bill Inmon 的方法论：认为仅仅有数据集市是不够的，提倡先必须得从企业级的数据模型角度入手来构建。企业级模型就有较为完善的业务主题域划分、逻辑模型划分，在解决某个业务单元问题时可以很容易的选择不同数据路径来组成数据集市。后来数据仓库在千禧年传到中国后，几个大实施厂商都是遵守该原则的实施方法，也逐渐的演进成了现在大家熟悉的数据架构中关于数据层次的划分：&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Ods-&amp;gt; DW-&amp;gt; ST-&amp;gt;应用&lt;/li>
&lt;li>Ods-&amp;gt;DWD-&amp;gt;DW-&amp;gt;DM -&amp;gt;应用&lt;/li>
&lt;li>Ods-&amp;gt;DWD-&amp;gt;DWB-&amp;gt;DWS -&amp;gt;应用&lt;/li>
&lt;li>Ods-&amp;gt;DWD-&amp;gt;DW-&amp;gt;ST（ADM）-&amp;gt;应用&lt;/li>
&lt;/ul>
&lt;p>上个 10 年的国内实施数据仓库以及数据平台企业，有几家专业的厂商：IBM、Teradata、埃森哲、菲奈特 (被东南收购)、亚信等。这些厂商针对自己领域服务的客户，从方案特点等一系列角度出发，在实施中对 ODS 层、EDW、DM 等不同数据层逐步地赋予了各种不同的功能与含义。现在大家熟知的数据模型层次划分，基本上也是传承原有的 Bill Inmon 的方法论。&lt;/p>
&lt;ol start="2">
&lt;li>数据集市年代的代表人物为 Ralph kilmball，他的代表作是 《The Data Warehouse Toolkit》。这本书就是大名鼎鼎的《数据仓库工具箱》。企业级数据的建设方法主张自下而上建立数据仓库，极力推崇创建数据集市，认为数据仓库是数据集市的集合，信息总是被存储在多维模型中。这种思想从业务或部门入手，设计面向业务或部门主题数据集市。随着更多的不同业务或部门数据集市实施落地，此时企业可以根据需要来合并不同的数据集市，并逐步形成企业级的数据仓库，这种方式被称为自下而上(Botton-up)方法。这个方法在当时刚好与 Bill Innmon 的自上而下建设方法相反。&lt;/li>
&lt;/ol>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>类比&lt;/th>
&lt;th>BIll Inmon 提出的方法论&lt;/th>
&lt;th>Ralph kilmball 提出的方法论&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>建设周期&lt;/td>
&lt;td>需要花费大量时间&lt;/td>
&lt;td>建设周期短、花费较少时间&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>维护难易度&lt;/td>
&lt;td>容易维护&lt;/td>
&lt;td>维护成本高&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>建设成本&lt;/td>
&lt;td>前期投入大，后期建设成本低&lt;/td>
&lt;td>前期投入较少，后续迭代成本与之前投入差不多&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>建设周期&lt;/td>
&lt;td>周期长，见效慢&lt;/td>
&lt;td>短、平、快&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>需要的团队类型&lt;/td>
&lt;td>专业团队搭建&lt;/td>
&lt;td>比较专业团队搭建，少量人参与&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据集成需求&lt;/td>
&lt;td>全企业生命周期数据集成&lt;/td>
&lt;td>企业垂直业务领域数据集成&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>面向用户群体&lt;/td>
&lt;td>潜在的全企业用户&lt;/td>
&lt;td>业务需求部门&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>专业术语&lt;/td>
&lt;td>面向主题、随时间而变化、保留历史、数据集成&lt;/td>
&lt;td>面向具体业务部门的一份比较窄的数据快照，维度建模、雪花模型、星型模型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据模型&lt;/td>
&lt;td>准三范式设计原则&lt;/td>
&lt;td>星型结构、雪花结构&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>随着数据仓库的不断实践与迭代发展，从争吵期进入到了合并的时代，其实争吵的结果要么一方妥协，要么新的结论出现。Bill inmon 与 Ralph kilmball 的争吵没有结论，干脆提出一种新的架构包含对方，也就是后来 Bill Inmon 提出的 CIF（corporation information factory）信息工厂的架构模式，这个架构模式将 Ralph kilmball 的数据集市包含了进来，有关两种数据仓库实施方法论的争吵才逐步地平息下来。&lt;/p>
&lt;h2 id="非互联网四代架构">非互联网四代架构&lt;/h2>
&lt;h3 id="第一代-edw-架构">第一代 edw 架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324172051.png" alt="第一代 EDW" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>现在数据建设中使用到的“商业智能” 、“信息仓库”等很多专业术语、方法论，基本上是在上世纪 60 年代至 90 年代出现的。比如“维度模型”这个词是上世纪 60 年代 GM 与 Darmouth College 大学第一次提出， “DatawareHouse”、“事实” 是在上个世纪 70 年代 BIll Inmon 明确定义出来的，后来 90 年代 BIll Inmon 出版《如何构建数据仓库》一书更加体系化的与明确定义了如何构建数据仓库，这套方法在落地上形成了第一代数据仓库架构。&lt;/p>
&lt;p>在第一代的数据仓库中，清晰地定义了数据仓库(Data Warehouse) 是一个面向主题的(Subject Oriented) 、集成的( Integrate ) 、相对稳定的(Non -Volatile ) 、反映历史变化( Time Variant) 的数据集合，用于支持管理决策（Decision Marking Support）。首先，数据仓库(Data Warehouse)是用来支持决策的、面向主题的用来支撑分析型数据处理的，这里有别于企业使用的数据库。数据库、数据仓库小的区别：&lt;/p>
&lt;ul>
&lt;li>数据库系统的设计目标是事务处理。数据库系统是为记录更新和事务处理而设计，数据的访问的特点是基于主键，大量原子，隔离的小事务，并发和可恢复是关键属性，最大事务吞吐量是关键指标，因此数据库的设计都反映了这些需求。&lt;/li>
&lt;li>数据仓库的设计目标是决策支持。历史的、摘要的、聚合的数据比原始的记录重要的多。查询负载主要集中在即席查询和包含连接，聚合等复杂查询操作上。&lt;/li>
&lt;li>其次，数据仓库(Data Warehouse)是对多种异构数据源进行有效集成与处理，是按照主题的方式对数据进行重新整合，且包一般不怎么修改的历史数据，一句话总结面向主题、集成性、稳定性和时变性。&lt;/li>
&lt;/ul>
&lt;p>数据仓库(Data Warehouse)从特点上来看：&lt;/p>
&lt;ul>
&lt;li>数据仓库是面向主题的。&lt;/li>
&lt;li>数据仓库是集成的，数据仓库的数据有来自于分散的操作型数据，将所需数据从原来的数据中抽取出来，进行加工与集成，统一与综合之后才能进入数据仓库。&lt;/li>
&lt;li>数据仓库是不可更新的，数据仓库主要是为决策分析提供数据，所涉及的操作主要是数据的查询。&lt;/li>
&lt;li>数据仓库是随时间而变化的，传统的关系数据库系统比较适合处理格式化的数据，能够较好的满足商业商务处理的需求，它在商业领域取得了巨大的成功。&lt;/li>
&lt;/ul>
&lt;p>数据仓库和数据库系统的区别，一言蔽之：OLAP 和 OLTP 的区别。数据库支持是 OLTP，数据仓库支持的是 OLAP。&lt;/p>
&lt;h3 id="第二代大集市架构">第二代大集市架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324172644.png" alt="第二代大集市架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>第二代就是 Ralph kilmball 的大集市的架构。第二代架构基本可以成为总线型架构，从业务或部门入手，设计面向业务或部门主题数据集市。Kilmball 的这种构建方式可以不用考虑其它正在进行的数据类项目实施，只要快速满足当前部门的需求即可，这种实施的好处是阻力较小且路径很短。但是考虑到在实施中可能会存在多个并行的项目，是需要在数据标准化、模型阶段是需要进行维度归一化处理，需要有一套标准来定义公共维度，让不同的数据集市项目都遵守相同的标准，在后面的多个数据集市做合并时可以平滑处理。比如业务中相似的名词、不同系统的枚举值、相似的业务规则都需要做统一命名，这里在现在的中台就是全域统一 ID 之类的东西。&lt;/p>
&lt;p>主要核心：&lt;/p>
&lt;ul>
&lt;li>一致的维度，以进行集成和全面支持。一致的维度具有一致的描述性属性名称、值和含义。&lt;/li>
&lt;li>一致的事实是一致定义的；如果不是一致的业务规则，那么将为其指定一个独特的名称。业务中相似的名词、不同系统的枚举值、相似的业务规则都需要做统一命名。&lt;/li>
&lt;li>建模方式：星型模型、雪花模型。&lt;/li>
&lt;/ul>
&lt;h3 id="第三代汇总维度集市-cif20-数仓结构">第三代汇总维度集市 &amp;amp;CIF2.0 数仓结构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324173843.png" alt="汇总维度集市的标准数据仓库" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324173921.png" alt="第三代 cif 2.0 架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>CIF（corporation information factor）信息工厂（作者备注，关于 Cif 的英文版文章名字 Corporate Information Factory (CIF) Overview），Bill Inmon 认为企业的发展会随着信息资源重要性会逐步的提升，会出现一种信息处理架构，类似工厂一样能满足所有信息的需求与请求。这个信息工厂的功能包含了数据存储与处理（活跃数据、沉默数据），支持跨部门甚至跨企业的数据访问与整合，同时也要保证数据安全性等。刚好 CIF 架构模式也逐步的变成了数据仓库第三代架构。为什么把这个 CIF 架构定义成一个经典架构呢，因为 CIF 的这种架构总结了前面提到的两种架构的同时，又把架构的不同层次定义得非常明确。&lt;/p>
&lt;p>例如 CIF 2.0 主要包括集成转换层（Integrated and Transformation Layer）、操作数据存储（Operational Data Store）、数据仓库（Enterprise Data Warehouse）、数据集市（Data Mart）、探索仓库（Exploration Warehouse）等部件。Data Mart 分为后台（Back Room）和前台（Front Room）两部分。后台主要负责数据准备工作，称为数据准备区（Staging Area），前台主要负责数据展示工作，称为数据集市（Data Mart）。&lt;/p>
&lt;p>这个经典的架构在后来 2006 年~2012 年进入到这个领域的从业者，乃至现在有些互联网企业的数据平台架构也是相似的。&lt;/p>
&lt;h3 id="第四代-opdm-操作实时数仓">第四代 OPDM 操作实时数仓&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324174555.png" alt="OPDM 操作实时数仓" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>OPDM 大约是在 2011 年提出来的，严格上来说，Opdm 操作型数据集市（仓库）是实时数据仓库的一种，他更多的是面向操作型数据而非历史数据查询与分析。在这里很多人会问到什么是操作型数据？比如财务系统、CRM 系统、营销系统生产系统，通过某一种机制实时的把这些数据在各数据孤岛按照业务的某个层次有机的自动化整合在一起，提供业务监控与指导。&lt;/p>
&lt;h2 id="互联网的五代大数据处理架构">互联网的五代大数据处理架构&lt;/h2>
&lt;p>在文章的开头有提过，传统行业第三代架构与大数据第一代架构在架构形式上基本相似，只不过是通过大数据的处理技术尝试对传统第三架构进行落地的。比如说在 Hadoop&amp;amp;Hive 刚兴起的阶段，有用 SyaseIQ、Greenplum 等技术来作为大数据处理技术，后来 Hadoop&amp;amp;hive 以及 Facebook Scribe、Linkedin kafka 等逐步开源后又产生了新的适应互联网大数据的架构模式。&lt;/p>
&lt;p>后续阿里巴巴淘系的 TimeTunnel 等更多的近百种大数据处理的开源技术，进一步促进了整个大数据处理架构与技术框架的发展，我在后面会给出一个比较完善截止到目前所有技术的数据处理框架。按照大数据的使用场景、数据量、数据的类型，在架构上也基本上分为流式处理技术框架、批处理技术框架等， 所以互联网这五代的大数据处理框架基本上是围绕着批处理、流式处理以及混合型架构这三种来做演进。&lt;/p>
&lt;h3 id="第一代离线大数据统计分析技术架构">第一代离线大数据统计分析技术架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230324174903.png" alt="离线统计分析技术架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>这个结构与第三代的数据处理架构非常相似，具体如下图所示：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>数据阶段&lt;/th>
&lt;th>传统行业第三代架构&lt;/th>
&lt;th>第一代离线大数据统计架构&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>数据源&lt;/td>
&lt;td>结构化数据为主(数据库数据、内部办公数据、财务数据等)、非结构化数据很少或者是没有&lt;/td>
&lt;td>结构化数据为主(数据库数据、内部办公数据、财务数据等)、结构化数据开始多起来&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据处理&lt;/td>
&lt;td>名词：ETL 为主，在数据如中央仓库之前已经开始很多的数据转换、归一化的处理技术：Datastage、informa、Dts、C、脚本等等&lt;/td>
&lt;td>名词：ELT 为主，主要是数据采集传输与归集、很少做数据归一化以及转换处理 。主要是把数据先归集到中央库自作处理技术：kafka、Datax 等&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据中央处理&lt;/td>
&lt;td>技术：Oracle、DB2、SybaseIQ、Teradata 数据模型：维度模型、准三范式&lt;/td>
&lt;td>技术：hadoop、hive、spark 数据模型：维度模型、大宽表等&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据应用&lt;/td>
&lt;td>成型的解决方案产品：Report、OLAP、在线分析等&lt;/td>
&lt;td>成型的软件产品变少、开源技术、自助研发产品变多起来&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="第二代流式架构">第二代流式架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325140925.png" alt="流式技术架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>流式的应用场景非常广泛， 比如搜索、推荐、信息流等都是在线化的，对数据实时性的要求变更高，自然计算与使用是同步进行的。随着业务的复杂化，数据的处理逻辑更加复杂，比如各种维度交叉、关联、聚类，以及需要更多算法或机器学习。这些应用场景可以完全地分为两类：事件流、持续计算。&lt;/p>
&lt;ul>
&lt;li>事件流，就是业务相对固定，只是数据在业务的规则下不断的变化。&lt;/li>
&lt;li>持续计算，适合购物网站等场景。&lt;/li>
&lt;/ul>
&lt;p>流失处理架构比上一代离线处理框架相比省掉了原有的 ETL/ELT 过程，数据流留过数据处理通道并进行实时处理与计算，处理结果通过消息的方式推送数据消费者。流式计算框架舍弃了大数据离线批量处理模式，只有很少的数据存储，所以数据保存周期非常短。如果有历史数据场景或很复杂历史数据参与计算的场景，实现起来难度就比较大。&lt;/p>
&lt;p>现在一些场景，会把流式计算的结果数据周期性地存到批处理的数据存储区域。如果有场景需要使用历史数据，流式计算框架会把保存的历史结果用更新的方式进行加载，再做进一步处理。&lt;/p>
&lt;h3 id="第三代-lambda-大数据架构">第三代 Lambda 大数据架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325141204.png" alt="Lambda 技术架构整体" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>Lambda 架构是由 Twitter 工程师南森·马茨（Nathan Marz）提出的，是一种经典的、实施广泛的技术架构。后来出现的其他大数据处理架构也是 Lambda 架构的优化或升级版。Lambda 架构有两条数据链路，一条兼顾处理批量、离线数据结构，一条是实时流式处理技术 。&lt;/p>
&lt;ul>
&lt;li>批量离线处理流在构建时大部分还是采用一些经典的大数据统计分析方法论，在保证数据一致性、完整性的同时还会对数据按照不同应用场景进行分层。&lt;/li>
&lt;li>实时流式处理主要是增量计算，也会跑一些机器学习模型等。为了保证数据的一致性， 实时流处理结果与批量处理结果会有一个合并动作。&lt;/li>
&lt;/ul>
&lt;p>Lambda 架构主要的组成是批处理、流式处理、数据服务层这三部分。&lt;/p>
&lt;ul>
&lt;li>批处理层(Bathchlayer)：Lambda 架构核心层之一，批处理接收过来的数据，并保存到相应的数据模型中，这一层的数据主题、模型设计的方法论是继承面向统计分析离线大数据中的。而且一般都会按照比较经典的 ODS、DWD、DWB、ST/ADM 的层次结构来划分。&lt;/li>
&lt;li>流式处理层(Speed Layer)：Lambda 另一个核心层，为了解决比如各场景下数据需要一边计算一边应用以及各种维度交叉、关联的事件流与持续计算的问题，计算结果在最后与批处理层的结果做合并。&lt;/li>
&lt;li>服务层(Serving layer)：这是 Lambda 架构的最后一层，服务层的职责是获取批处理和流处理的结果，向用户提供统一查询视图服务。&lt;/li>
&lt;/ul>
&lt;p>Lamabda 架构理念从出现到发展这么多年，优缺点非常明显。比如稳定与性能上的优势，ETL 处理计算利用晚上时间来做，能复用部分实时计算的资源。劣势，两套数据流因为结果要做合并，所有的算法要实现两次，一次是批处理、一次是实时计算，最终两个结果还得做合并显得会很复杂。&lt;/p>
&lt;h3 id="kappa-大数据架构">Kappa 大数据架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325142150.png" alt="Kappa 大数据架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>在 Lamadba 架构下需要维护两套的代码，为了解决这个问题，LinkedIn 公司的 Jay Kreps 结合实际经验与个人思考提出了 Kappa 架构。Kappa 架构核心是通过改进流式计算架构的计算、存储部分来解决全量的问题，使得实时计算、批处理可以共用一套代码。Kappa 架构认为对于历史数据的重复计算几率是很小的，即使需要，可以通过启用不同的实例的方式来做重复计算。其中 Kappa 的核心思想是：&lt;/p>
&lt;ul>
&lt;li>用 Kafka 或者类似 MQ 队列系统收集各种各样的数据，需要几天的数据量就保存几天。&lt;/li>
&lt;li>当需要全量重新计算时，重新起一个流计算实例，从头开始读取数据进行处理，并输出到一个新的结果存储中。&lt;/li>
&lt;li>当新的实例做完后，停止老的流计算实例，并把一些老的结果删除。&lt;/li>
&lt;/ul>
&lt;p>Kappa 架构的优点在于将实时和离线代码统一起来，方便维护而且统一了数据口径。Kappa 架构与 Lamabda 架构相比，其优缺点是：&lt;/p>
&lt;ul>
&lt;li>Lambda 架构需要维护两套跑在批处理和实时流上的代码，两个结果还需要做 merge， Kappa 架构下只维护一套代码，在需要时候才跑全量数据。&lt;/li>
&lt;li>Kappa 架构下可以同时启动很多实例来做重复计算，有利于算法模型调整优化与结果对比，Lamabda 架构下，代码调整比较复杂。所以 kappa 架构下，技术人员只需要维护一个框架就可以，成本很小。&lt;/li>
&lt;li>kappa 每次接入新的数据类型格式是需要定制开发接入程序，接入周期会变长。&lt;/li>
&lt;li>Kappa 这种架构过度依赖于 Redis、Hbase 服务，两种存储结构又不是满足全量数据存储的，用来做全量存储会显得浪费资源。&lt;/li>
&lt;/ul>
&lt;h3 id="unified-大数据架构">Unified 大数据架构&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325142342.png" alt="Unified 大数据架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>“Unifield 架构则更激进，将机器学习和数据处理整合为一体，Unifield 在 Lambda 基础上进行升级，在流处理层新增了机器学习层。数据经过数据通道进入数据湖，新增了模型训练部分，并且将其在流式层进行使用。同时流式层不单使用模型，也包含着对模型的持续训练。”&lt;/p>
&lt;h3 id="iota-架构">IOTA 架构&lt;/h3>
&lt;p>IOTA 大数据架构是一种基于 AI 生态下的、全新的数据架构模式，这个概念由易观于 2018 年首次提出。IOTA 的整体思路是设定标准数据模型，通过边缘计算技术把所有的计算过程分散在数据产生、计算和查询过程当中，以统一的数据模型贯穿始终，从而提高整体的计算效率，同时满足计算的需要，可以使用各种 Ad-hoc Query 来查询底层数据。&lt;/p>
&lt;p>主要有几个特点：&lt;/p>
&lt;ul>
&lt;li>去 ETL 化：ETL 和相关开发一直是大数据处理的痛点，IOTA 架构通过 Common Data Model 的设计，专注在某一个具体领域的数据计算，从而可以从 SDK 端开始计算，中央端只做采集、建立索引和查询，提高整体数据分析的效率。&lt;/li>
&lt;li>Ad-hoc 即时查询：鉴于整体的计算流程机制，在手机端、智能 IOT 事件发生之时，就可以直接传送到云端进入 real time data 区，可以被前端的 Query Engine 来查询。此时用户可以使用各种各样的查询，直接查到前几秒发生的事件，而不用在等待 ETL 或者 Streaming 的数据研发和处理。&lt;/li>
&lt;li>边缘计算（Edge-Computing）：将过去统一到中央进行整体计算，分散到数据产生、存储和查询端，数据产生既符合 Common Data Model。同时，也给与 Realtime model feedback，让客户端传送数据的同时马上进行反馈，而不需要所有事件都要到中央端处理之后再进行下发。&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>大数据架构的每一代的定义与出现是有必然性的， 当然没有一个严格上的时间区分点。直接给出一个每种架构比较：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>架构&lt;/strong>&lt;/th>
&lt;th>&lt;strong>优点&lt;/strong>&lt;/th>
&lt;th>&lt;strong>缺点&lt;/strong>&lt;/th>
&lt;th>&lt;strong>适用场景&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>离线大数据统计分析技术架构&lt;/td>
&lt;td>简单，易懂，对于 BI 系统来说，基本思想没有发生变化，变化的仅仅是技术选型，用大数据架构替换掉 BI 的组件。&lt;/td>
&lt;td>对于大数据来说，没有 BI 下如此完备的 Cube 架构，虽然目前有 kylin，但是 kylin 的局限性非常明显，远远没有 BI 下的 Cube 的灵活度和稳定度，因此对业务支撑的灵活度不够，所以对于存在大量报表，或者复杂的钻取的场景，需要太多的手工定制化，同时该架构依旧以批处理为主，缺乏实时的支撑。&lt;/td>
&lt;td>数据分析需求依旧以 BI 场景为主，但是因为数据量、性能等问题无法满足日常使用。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>流式架构&lt;/td>
&lt;td>没有臃肿的 ETL 过程，数据的实效性非常高。&lt;/td>
&lt;td>对于流式架构来说，不存在批处理，因此对于数据的重播和历史统计无法很好的支撑。对于离线分析仅仅支撑窗口之内的分析。&lt;/td>
&lt;td>预警，监控，对数据有有实时性要求的场景。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lambda 架构&lt;/td>
&lt;td>既有实时又有离线，对于数据分析场景涵盖的非常到位。&lt;/td>
&lt;td>离线层和实时流虽然面临的场景不相同，但是其内部处理的逻辑却是相同，因此有大量荣誉和重复的模块存在。&lt;/td>
&lt;td>同时存在实时和离线需求的情况。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Kappa 架构&lt;/td>
&lt;td>Kappa 架构解决了 Lambda 架构里面的冗余部分，以数据可重播的超凡脱俗的思想进行了设计，整个架构非常简洁。&lt;/td>
&lt;td>虽然 Kappa 架构看起来简洁，但是实施难度相对较高，尤其是对于数据重播部分。&lt;/td>
&lt;td>和 Lambda 类似，改架构是针对 Lambda 的优化。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Unifield 架构&lt;/td>
&lt;td>Unifield 架构提供了一套数据分析和机器学习结合的架构方案，非常好的解决了机器学习如何与数据平台进行结合的问题。&lt;/td>
&lt;td>Unifield 架构实施复杂度更高，对于机器学习架构来说，从软件包到硬件部署都和数据分析平台有着非常大的差别，因此在实施过程中的难度系数更高。&lt;/td>
&lt;td>有着大量数据需要分析，同时对机器学习方便又有着非常大的需求或者有规划。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>IOTA 架构&lt;/td>
&lt;td>去 ETL 化、支持 Ad-hoc 即时查询和边缘计算。&lt;/td>
&lt;td>代码漏洞较多，通过收费方式向社区提供漏洞修复代码。&lt;/td>
&lt;td>IOTA 用于物联网设备，实现万物互联、系统自治。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h1 id="大数据处理技术栈">大数据处理技术栈&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325143204.png" alt="大数据处理技术栈" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ul>
&lt;li>按照数据采集-传输-落地到存储层，再通过调度调起计算数据处理任务把整合结果数据存到数据仓库以及相关存储区域中。&lt;/li>
&lt;li>通过管理层/ide 进行数据管理或数据开发。&lt;/li>
&lt;li>通过 OLAP 、分析、算法、可视化、微服务层对外提供数据服务与数据场景化应用。&lt;/li>
&lt;/ul>
&lt;p>这个技术栈暂时没有按照没有按照批处理、流式技术的分类的角度来分类，稍微有点遗憾。&lt;/p></description></item><item><title>2022-四月天 03-万字详解数仓分层设计架构 ODS-DWD-DWS-ADS</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E5%9B%9B%E6%9C%88%E5%A4%A9-03-%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84-ods-dwd-dws-ads/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E5%9B%9B%E6%9C%88%E5%A4%A9-03-%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84-ods-dwd-dws-ads/</guid><description>&lt;h1 id="万字详解数仓分层设计架构-ods-dwd-dws-ads">万字详解数仓分层设计架构 ODS-DWD-DWS-ADS&lt;/h1>
&lt;h1 id="数仓建模的意义为什么要对数据仓库分层">数仓建模的意义，为什么要对数据仓库分层？&lt;/h1>
&lt;p>只有数据模型将数据有序的组织和存储起来之后，大数据才能得到高性能、低成本、高效率、高质量的使用。&lt;/p>
&lt;h2 id="1分层意义">1、分层意义&lt;/h2>
&lt;p>1）清晰数据结构：每一个数据分层都有它的作用域，这样我们在使用表的时候能更方便地定位和理解。数据关系条理化：源系统间存在复杂的数据关系，比如客户信息同时存在于核心系统、信贷系统、理财系统、资金系统，取数时该如何决策呢？数据仓库会对相同主题的数据进行统一建模，把复杂的数据关系梳理成条理清晰的数据模型，使用时就可避免上述问题了。&lt;/p>
&lt;p>2）数据血缘追踪：简单来讲可以这样理解，我们最终给业务诚信的是一能直接使用的张业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围。&lt;/p>
&lt;p>3）数据复用，减少重复开发：规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算。数据的逐层加工原则，下层包含了上层数据加工所需要的全量数据，这样的加工方式避免了每个数据开发人员都重新从源系统抽取数据进行加工。通过汇总层的引人，避免了下游用户逻辑的重复计算， 节省了用户的开发时间和精力，同时也节省了计算和存储。极大地减少不必要的数据冗余，也能实现计算结果复用，极大地降低存储和计算成本。&lt;/p>
&lt;p>4）把复杂问题简单化。讲一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。&lt;/p>
&lt;p>5）屏蔽原始数据的(影响) ，屏蔽业务的影响。业务或系统发生变化时，不必改一次业务就需要重新接入数据。提高数据稳定性和连续性。屏蔽源头业务系统的复杂性：源头系统可能极为繁杂，而且表命名、字段命名 、字段含义等可能五花八门，通过 DW 层来规范和屏蔽所有这些复杂性，保证下游数据用户使用数据的便捷和规范。如果源头系统业务发生变更，相关的变更由 DW 层来处理，对下游用户透明，无须改动下游用户的代码和逻辑。&lt;/p>
&lt;p>数据仓库的可维护性：分层的设计使得某一层的问题只在该层得到解决，无须更改下一层的代码和逻辑。大数据系统需要数据模型方法来帮助更好地组织和存储数据，以便在性能、成本、效率和质量之间取得最佳平衡！&lt;/p>
&lt;h2 id="2数据仓库etl的四个操作">2、数据仓库（ETL）的四个操作&lt;/h2>
&lt;p>ETL(extractiontransformation loading)负责将分散的、异构数据源中的数据抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中。ETL 是实施数据仓库的核心和灵魂，ETL 规则的设计和实施约占整个数据仓库搭建工作量的 60%～ 80%。&lt;/p>
&lt;p>1）数据抽取(extraction)包括初始化数据装载和数据刷新：初始化数据装载主要关注的是如何建立维表、事实表，并把相应的数据放到这些数据表中；而数据刷新关注的是当源数据发生变化时如何对数据仓库中的相应数据进行追加和更新等维护(比如可以创建定时任务，或者触发器的形式进行数据的定时刷新)。&lt;/p>
&lt;p>2）数据清洗主要是针对源数据库中出现的二义性、重复、不完整、违反业务或逻辑规则等问题的数据进行统一的处理。即清洗掉不符合业务或者没用的的数据。比如通过编写 hive 或者 MR 清洗字段中长度不符合要求的数据。&lt;/p>
&lt;p>3）数据转换(transformation)主要是为了将数据清洗后的数据转换成数据仓库所需要的数据：来源于不同源系统的同一数据字段的数据字典或者数据格式可能不一样(比如 A 表中叫 id,B 表中叫 ids)，在数据仓库中需要给它们提供统一的数据字典和格式，对数据内容进行归一化；另一方面，数据仓库所需要的某些字段的内容可能是源系统所不具备的，而是需要根据源系统中多个字段的内容共同确定。&lt;/p>
&lt;p>4）数据加载（loading）是将最后上面处理完的数据导入到对应的存储空间里（hbase，mysql 等）以方便给数据集市提供，进而可视化。&lt;/p>
&lt;p>一般大公司为了数据安全和操作方便，都是自己封装的数据平台和任务调度平台，底层封装了大数据集群比如 hadoop 集群，spark 集群，sqoop,hive,zookeepr,hbase 等只提供 web 界面，并且对于不同员工加以不同权限，然后对集群进行不同的操作和调用。以数据仓库为例，将数据仓库分为逻辑上的几个层次。这样对于不同层次的数据操作，创建不同层次的任务，可以放到不同层次的任务流中进行执行（大公司一个集群通常每天的定时任务有几千个等待执行，甚至上万个，所以划分不同层次的任务流，不同层次的任务放到对应的任务流中进行执行，会更加方便管理和维护）。&lt;/p>
&lt;h2 id="3分层的误区">3、分层的误区&lt;/h2>
&lt;p>数仓层内部的划分不是为了分层而分层，分层是为了解决 ETL 任务及工作流的组织、数据的流向、读写权限的控制、不同需求的满足等各类问题。&lt;/p>
&lt;p>业界较为通行的做法将整个数仓层又划分成了 DWD、DWT、DWS、DIM、DM 等很多层。然而我们却始终说不清楚这几层之间清晰的界限是什么，或者说我们能说清楚它们之间的界限，复杂的业务场景却令我们无法真正落地执行。&lt;/p>
&lt;p>所以数据分层这块一般来说三层是最基础的，至于 DW 层如何进行切分，是根据具体的业务需求和公司场景自己去定义。&lt;/p>
&lt;h1 id="二技术架构">二、技术架构&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144117.png" alt="横向数据流架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144139.png" alt="纵向数据流架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据中台包含的内容很多，对应到具体工作中的话，它可以包含下面的这些内容：&lt;/p>
&lt;ul>
&lt;li>**系统架构：**以 Hadoop、Spark 等组件为中心的架构体系&lt;/li>
&lt;li>**数据架构：**顶层设计，主题域划分，分层设计，ODS-DW-ADS&lt;/li>
&lt;li>**数据建模：**维度建模，业务过程-确定粒度-维度-事实表&lt;/li>
&lt;li>**数据管理：**资产管理，元数据管理、质量管理、主数据管理、数据标准、数据安全管理&lt;/li>
&lt;li>**辅助系统：**调度系统、ETL 系统、监控系统&lt;/li>
&lt;li>**数据服务：**数据门户、机器学习数据挖掘、数据查询、分析、报表系统、可视化系统、数据交换分享下载&lt;/li>
&lt;/ul>
&lt;h1 id="三数仓分层架构">三、数仓分层架构&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144258.png" alt="数仓分层架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据仓库标准上可以分为四层。但是注意这种划分和命名不是唯一的，一般数仓都是四层，但是不同公司可能叫法不同。但是核心的理念都是从四层数据模型而来。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144333.png" alt="四层数据模型" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144429.png" alt="四层数据模型详解" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144445.png" alt="四层逻辑分层" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h2 id="1贴源层ods-operational-data-store">1、贴源层（ODS, Operational Data Store）&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325144550.png" alt="数据源层" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据引入层（ODS，Operational Data Store，又称数据基础层）：将原始数据几乎无处理地存放在数据仓库系统中，结构上与源系统基本保持一致，是数据仓库的数据准备区。这一层的主要职责是将基础数据同步、存储。一般来说 ODS 层的数据和源系统的数据是同构的，主要目的是简化后续数据加工处理的工作。从数据粒度上来说 ODS 层的数据粒度是细的。ODS 层的表通常包括两类，一个用于存储当前需要加载的数据，一个用于存储处理完后的历史数据。历史数据一般保存 3-6 个月后需要清除，以节省空间。但不同的项目要区别对待，如果源系统的数据量不大，可以保留更长的时间，甚至全量保存。&lt;/p>
&lt;p>注意：在这层，理应不是简单的数据接入，而是要考虑一定的数据清洗，比如异常字段的处理、字段命名规范化、时间字段的统一等，一般这些很容易会被忽略，但是却至关重要。特别是后期我们做各种特征自动生成的时候，会十分有用。&lt;/p>
&lt;p>注意：有的公司 ODS 层不会做太多数据过滤处理,会放到 DWD 层来处理。有的公司会在一开始时就在 ODS 层做数据相对精细化的过滤.这个并没有明确规定,看每个公司自己的想法和技术规范。一般企业开发时,都会对原始数据存入到 ODS 时,做一些最基本的处理。&lt;/p></description></item><item><title>2022-一文读懂数据仓库、数据平台、数据中台、数据湖的概念和区别</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%95%B0%E6%8D%AE%E6%B9%96%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E5%8C%BA%E5%88%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0%E6%95%B0%E6%8D%AE%E6%B9%96%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E5%8C%BA%E5%88%AB/</guid><description>&lt;h1 id="一文读懂数据仓库数据平台数据中台数据湖的概念和区别">一文读懂数据仓库、数据平台、数据中台、数据湖的概念和区别&lt;/h1>
&lt;h1 id="一数据仓库">一、数据仓库&lt;/h1>
&lt;h2 id="1-数据仓库概念">1. 数据仓库概念&lt;/h2>
&lt;p>数据仓库由比尔·恩门（Bill Inmon，数据仓库之父）于 1990 年提出，主要功能是将企业系统联机事务处理（OLTP）长期壁垒的大量数据，通过数据仓库理论支持所持有的数据存储结构，做有系统的分析整理。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325160922.png" alt="数据存储的演变" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>随着企业的发展，业务系统的数据不断激增，这些存储在企业业务数据库中（也就是关系型数据库 Oracle，Microsoft SQL Sever，MySQL 等）数据会随着时间的积累越来越多，会使业务数据库会有一定的负载，导致业务系统的运行效率低，且这些数据中有很大一部分是冷数据，而我们业务系统一般对我们近期的数据，也就是热数据调用的比较频繁，对冷数据使用频率较低。&lt;/p>
&lt;p>同时随着企业数据驱动业务概念的兴起，企业需要将各业务部门的业务数据提取出来进行数据分析与挖掘，辅助高层进行分析与决策，但各部门需求的数据种类千差万别，接口错综复杂，过多的数据查询脚本以及接口的接入导致业务数据库的稳定性降低。&lt;/p>
&lt;p>为了避免冷数据与历史数据的积压对我们业务数据库效能产生影响，企业需要定期将冷数据从业务数据库中转移出来存储到一个专门存放历史数据的仓库里面，各部门可以根据自身业务特性对外提供统一的数据服务，这个仓库就是数据仓库。&lt;/p>
&lt;h2 id="2-数据仓库特点">2. 数据仓库特点&lt;/h2>
&lt;p>数据仓库（Data Warehoese）的特点：面向主题的、集成的、稳定的、反映历史数据变化的。&lt;/p>
&lt;ul>
&lt;li>面向主题的：数据仓库是用来分析特点主题域的，所以说数据仓库是面向主题的。例如，电商行业的主题域通常分为交易域、会员域、商品域等。&lt;/li>
&lt;li>集成的：数据仓库集成了多个数据源，同一主题或产品相关数据可能来自不同的系统不同类型的数据库，日志文件等。&lt;/li>
&lt;li>稳定的：数据一旦进入数据仓库，则不可改变。数据仓库的历史数据是不应该被更新的，同时存储稳定性较强&lt;/li>
&lt;li>反映历史数据变化的：数据仓库保存了长期的历史数据，这点相对 OLTP 的数据库而言。因为性能考虑后者统筹保存近期的热数据。&lt;/li>
&lt;/ul>
&lt;h2 id="3-oltp-与-olap">3. OLTP 与 OLAP&lt;/h2>
&lt;p>数据处理大致可以分成两大类：联机事务处理 OLTP（on-line transaction processing）、联机分析处理 OLAP（On-Line Analytical Processing）。OLTP 是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP 是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161338.png" alt="OLTP 与 OLAP" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161429.png" alt="OLTP 与 OLAP 区别" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>OLTP 系统强调数据库内存效率，强调内存各种指标的命令率，绑定变量，并发操作等。OLAP 系统则强调数据分析，强调 SQL 执行市场，磁盘 I/O，分区等。OLAP 和数仓的关系是依赖互补的，一般以数据仓库作为基础，既从数据仓库中抽取出详细数据的一个子集并经过必要的聚集存储到 OLAP 存储中供数据分析工具读取。&lt;/p>
&lt;h2 id="4-数据仓库的作用">4. 数据仓库的作用&lt;/h2>
&lt;p>数据仓库将来自不同来源的结构化数据聚合起来，用于业务智能领域的比较和分析，数据仓库是包含多种数据的存储库，并且是高度建模的。如下图所示：各个系统的元数据通过 ETL 同步到操作性数据仓库 ODS 中，对 ODS 数据进行面向主题域建模形成 DW（数据仓库），DM 是针对某一个业务领域建立模型，具体用户（决策层）查看 DM 生成的报表。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161545.png" alt="ETL 数据切换" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>传统的数据仓库集成处理架构是 ETL，利用 ETL 平台的能力，E=从源数据库抽取数据，L=将数据清洗（不符合规则的数据）、转化（对表按照业务需求进行不同维度、不同颗粒度、不同业务规则计算进行统计），T=将加工好的表以增量、全量、不同时间加载到数据仓库。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161701.png" alt="什么是 ETL" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>大数据背景下的架构体系是 ELT 结构，其根据上层的应用需求，随时从数据中台中抽取想要的原始数据进行建模分析。ELT 是利用数据库的处理能力，E=从源数据库抽取数据，L=把数据加载到目标库的临时表中，T=对临时表中的数据进行转换，然后加载到目标库目标表中。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161737.png" alt="什么是 ELT" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>ELT 对比 ETL 的优势：&lt;/p>
&lt;ul>
&lt;li>资源利用率的提升：ELT 主要通过数据库引擎来实现系统的可扩展性（尤其是当数据加工过程在晚上时，可以充分利用数据库引擎的资源）。&lt;/li>
&lt;li>任务运行效率的提升：ELT 可以保持所有的数据始终在数据库当中，避免数据的加载和导出，从而保证效率，提高系统的可监控性。&lt;/li>
&lt;li>并行处理优化：ELT 可以根据数据的分布情况进行并行处理优化，并可以利用数据库的固有功能优化磁盘 I/O。&lt;/li>
&lt;li>可扩展性增强：ELT 的可扩展性取决于数据库引擎和其硬件服务器的可扩展性。&lt;/li>
&lt;li>性能优化：通过对相关数据库进行性能调优，ETL 过程获得 3 到 4 倍的效率提升一般不是特别困难。&lt;/li>
&lt;/ul>
&lt;p>数据仓库系统的作用能实现跨业务条线、跨系统的数据整合，为管理分析和业务决策提供统一的数据支持。数据仓库能够从根本上帮助你把公司的运营数据转化成为高价值的可以获取的信息（或知识），并且在恰当的时候通过恰当的方式把恰当的信息传递给恰当的人。以下图为例：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161829.png" alt="客户案例" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据仓库的作用主要体现在企业决策、分析、计划和响应以下几个方面：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161911.png" alt="数据仓库的主要作用" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据仓库针对实时数据处理和非结构化数据处理能力较弱，以及在业务在预警预测等方面应用有一定的限制。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325161933.png" alt="数据仓库上下架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="二数据平台">二、数据平台&lt;/h1>
&lt;h2 id="1-数据平台概念">1. 数据平台概念&lt;/h2>
&lt;p>大数据时代，数据平台一般被称之为大数据平台。&lt;/p>
&lt;ul>
&lt;li>狭义上的数据平台：是为了解决数据仓库不能处理非结构化数据和报表开发周期长的问题，所以先撇开业务需求、把企业所有的数据都抽取出来放到一起，成为一个大的数据集，其中有结构化数据、非结构化数据等。当业务方有需求的时候，再把他们需要的若干个小数据集单独提取出来，以数据集的形式提供给数据应用。&lt;/li>
&lt;li>广义的大数据平台：广义的大数据平台通常被赋予更多的使命，以处理海量数据存储、计算及不间断流数据实时计算、离线计算、智能推荐、交互式查询、数据湖构建等场景为主的一套基础设施。典型的包括基于 Hadoop 生态构建的大数据平台。提供易于部署及管理的 Hive、Spark、HBase、Flink、StarRocks、Iceberg、Alluxio 等开源大数据计算和存储引擎。&lt;/li>
&lt;/ul>
&lt;p>狭义的数据平台和传统的数据平台（数据仓库）功能一致，区别只是技术架构和数据容量方面的不同。广义上的大数据平台是数据湖的基座，提供易于部署和管理的泛 Hadoop 生态及其他存储计算引擎的 PaaS 平台，助力企业构建企业级数据湖技术架构。&lt;/p>
&lt;h1 id="三数据中台">三、数据中台&lt;/h1>
&lt;h2 id="1-数据中台概念">1. 数据中台概念&lt;/h2>
&lt;p>数据中台的起源：2015 年年中，马云带领阿里巴巴集团高管拜访了一家芬兰的小型游戏公司 Supercell。这家仅有不到 200 名员工的小型游戏公司竟创造了高达 15 亿美元的年税前利润！而 Supercell 之所以能够支持多个团队快速、敏捷地推出高质量的游戏作品，其强大的中台能力功不可没。&lt;/p>
&lt;p>因此，在拜访 Supercell 的旅程结束之后，马云决定对阿里巴巴的组织和系统架构进行整体调整，建立阿里产品技术和数据能力的强大中台，构建“大中台，小前台”的组织和业务体制。&lt;/p>
&lt;p>数据中台的主要目的：解决企业在发展过程中，由于数据激增与业务的扩大而出现的统计口径不一致、重复开发、指标开发需求响应慢、数据质量低、数据成本高等问题。通过一系列数据工具（元数据中心、数据指标中心、数仓模型中心、数据资产中心-资产质量/治理/安全、数据服务中心等），规范数据供应链的各个环节。&lt;/p>
&lt;h2 id="2-数据中台特点">2. 数据中台特点&lt;/h2>
&lt;p>数据中台特点：以一种标准的、安全的、可靠的、统一的、共享的、解耦的、服务化的方式支持前端数据的应用。&lt;/p>
&lt;h2 id="3-数据中台作用">3. 数据中台作用&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325162347.png" alt="阿里数据中台逻辑架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325162404.png" alt="数据中台产品能力图" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;p>数据中台通过对企业内外部多源异构的数据采集、建设、管理、分析和应用，使数据对内优化管理提高业务价值，对外进行数据合作让业务价值得到释放，使之成为企业数据资产管理中枢。数据中台建立后，会形成数据 API 服务，为企业和客户提供高效各种数据服务。数据中台对一个企业的数字化转型和可持续发展起着至关重要的作用。数据中台为解耦而生，企业建设数据中台的最大意义就是应用与数据之间的解耦，这样企业就可以不受限制地按需构建满足业务需求的数据应用。&lt;/p>
&lt;p>构建了开放、灵活、可扩展的企业级统一数据管理和分析平台， 将企业内、外部数据随需关联，打破了数据的系统界限。利用大数据智能分析、数据可视化等技术，实现了数据共享、日常报表自动生成、快速和智能分析，满足企业各级部门之间的数据分析应用需求。&lt;/p>
&lt;p>深度挖掘数据价值，助力企业数字化转型落地。实现了数据的目录、模型、标准、认责、安全、可视化、共享等管理，实现数据集中存储、处理、分类与管理，建立大数据分析工具库、算法服务库，实现报表生成自动化、数据分析敏捷化、数据挖掘可视化，实现数据质量评估、落地管理流程。&lt;/p>
&lt;h1 id="四数据湖">四、数据湖&lt;/h1>
&lt;h2 id="1-数据湖概念">1. 数据湖概念&lt;/h2>
&lt;p>数据湖起源：数据湖的起源，应该追溯到 2010 年 10 月，由 Pentaho 的创始人兼 CTO， James Dixon 所提出，他提出的目的就当时历史背景来看，其实是为了推广自家产品 Pentaho。当时核心要解决的问题是传统数据仓库报表分析面临的两个问题：&lt;/p>
&lt;ul>
&lt;li>只使用部分属性，这些数据只能回答预先定义好(pre-determined)的问题。&lt;/li>
&lt;li>数据被聚合了，最低层级的细节丢失了，能回答的问题被限制了。&lt;/li>
&lt;/ul>
&lt;p>而我们当前所讨论的数据湖，已经远远超过了当初 James Dixon 所定义的数据湖，各厂商之间也对数据湖有了更多的不同定义。&lt;/p>
&lt;h3 id="1aws">1）AWS&lt;/h3>
&lt;p>A data lake is a centralized repository that allows you to store all your structured and unstructured data at any scale. You can store your data as-is, without having to first structure the data, and run different types of analytics—from dashboards and visualizations to big data processing, real-time analytics, and machine learning to guide better decisions.&lt;/p>
&lt;p>“数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。您可以按原样存储数据（无需先对数据进行结构化处理），并运行不同类型的分析– 从控制面板和可视化到大数据处理、实时分析和机器学习，以指导做出更好的决策。”&lt;/p>
&lt;h3 id="2微软">2）微软&lt;/h3>
&lt;p>Azure Data Lake includes all the capabilities required to make it easy for developers, data scientists, and analysts to store data of any size, shape, and speed, and do all types of processing and analytics across platforms and languages. It removes the complexities of ingesting and storing all of your data while making it faster to get up and running with batch, streaming, and interactive analytics.&lt;/p>
&lt;p>“Azure 的数据湖包括一切使得开发者、数据科学家、分析师能更简单的存储、处理数据的能力，这些能力使得用户可以存储任意规模、任意类型、任意产生速度的数据，并且可以跨平台、跨语言的做所有类型的分析和处理。数据湖在能帮助用户加速应用数据的同时，消除了数据采集和存储的复杂性，同时也能支持批处理、流式计算、交互式分析等。”&lt;/p>
&lt;h3 id="3阿里云">3）阿里云&lt;/h3>
&lt;p>“数据湖是统一存储池，可对接多种数据输入方式，您可以存储任意规模的结构化、半结构化、非结构化数据。数据湖可无缝对接多种计算分析平台，根据业务场景不同，可以选择相应的计算引擎对数据湖中存储的数据进行数据处理与分析，从而打破孤岛，挖掘业务价值。”&lt;/p>
&lt;h2 id="2-数据湖内容">2. 数据湖内容&lt;/h2>
&lt;p>数据湖中包括来自于关系型数据库中的结构化数据（行和列）、半结构化数据（如 CSV、日志、XML、JSON）、非结构化数据（如 email、文档、PDF 等）和 二进制数据（如图像、音频、视频）。&lt;/p>
&lt;h2 id="3-数据湖的特点">3. 数据湖的特点&lt;/h2>
&lt;ul>
&lt;li>统一的数据存储，存放原始的数据。&lt;/li>
&lt;li>支持任意结构的数据存储，包括结构化、半结构化、非结构化。&lt;/li>
&lt;li>支持多种计算分析，适用多种应用场景。&lt;/li>
&lt;li>支持任意规模的数据存储与计算能力。&lt;/li>
&lt;li>目标都是为了更好，更快的发现数据价值。&lt;/li>
&lt;/ul>
&lt;h2 id="4-数据湖能够解决的问题">4. 数据湖能够解决的问题&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325162849.png" alt="数据湖整体架构" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ul>
&lt;li>最底下是分布式文件系统；&lt;/li>
&lt;li>第二层是数据加速层。数据湖架构是一个存储计算彻底分离的架构，如果所有的数据访问都远程读取文件系统上的数据，那么性能和成本开销都很大。如果能把经常访问到的一些热点数据缓存在计算节点本地，这就非常自然的实现了冷热分离，一方面能收获到不错的本地读取性能，另一方面还节省了远程访问的带宽。&lt;/li>
&lt;li>第三层就是 Table format 层，主要是把一批数据文件封装成一个有业务意义的 table，提供 ACID、snapshot、schema、partition 等表级别的语义。&lt;/li>
&lt;li>最上层就是不同计算场景的计算引擎了。开源的一般有 Spark、Flink、Hive、Presto、Hive MR 等，这一批计算引擎是可以同时访问同一张数据湖的表的。&lt;/li>
&lt;/ul>
&lt;p>数据分散，存储散乱，形成数据孤岛，无法联合数据发现更多价值。这方面来讲，其实数据湖要解决的与数据仓库是类似的问题，但又有所不同，因为它的定义里支持对半结构化、非结构化数据的管理。而传统数据仓库仅能解决结构化数据的统一管理。在这个万物互联的时代，数据的来源多种多样，随着不同应用场景，产出的数据格式也是越来越丰富，不能再仅仅局限于结构化数据。如何统一存储这些数据，就是迫切需要解决的问题。&lt;/p>
&lt;p>数据库或数据仓库的存储受限于实现原理及硬件条件，导致存储海量数据时成本过高，而为了解决这类问题就有了 HDFS/对象存储这类技术方案。数据湖场景下如果使用这类存储成本较低的技术架构，将会为企业大大节省成本。结合生命周期管理的能力，可以更好的为湖内数据分层（冷温热存放在不同的存储介质：HDD、SSD、MEM），不用纠结在是保留数据还是删除数据节省成本的问题。&lt;/p>
&lt;p>越来越多种类的数据，意味着越来越多的分析方式，传统的 SQL 方式已经无法满足分析的需求，如何通过各种语言自定义贴近自己业务的代码，如何通过机器学习挖掘更多的数据价值。&lt;/p>
&lt;p>传统数据库等在海量数据下，如规模到 PB 级别，因为技术架构的原因，已经无法满足扩展的要求或者扩展成本极高，而这种情况下通过数据湖架构下的扩展技术能力，实现成本为 0，硬件成本也可控。业务模型不定，无法预先建模。传统数据库和数据仓库，都是 Schema-on-Write 的模式，需要提前定义 Schema 信息。而在数据湖场景下，可以先保存数据，后续待分析时，再发现 Schema，也就是 Schema-on-Read。&lt;/p>
&lt;h1 id="对比">对比&lt;/h1>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325163042.png" alt="1. 数据仓库 VS 数据中台 VS 数据湖" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;ul>
&lt;li>数据中台、数据仓库和数据湖没有直接的关系；&lt;/li>
&lt;li>数据中台、数据平台、数据仓库和数据湖在某个维度上为业务产生价值的形式有不同的侧重；&lt;/li>
&lt;li>数据仓库是数据驱动业务的逻辑概念，用于支持管理决策分析，为业务提供服务的主要方式是报表；&lt;/li>
&lt;li>数据中台是企业级的逻辑概念，体现企业数据向业务价值转化的能力，为业务提供服务的主要方式是数据 API；&lt;/li>
&lt;li>数据湖是企业级的技术逻辑概念，体现企业级数据湖架构加速数据向业务价值转化的能力，为业务提供服务的主要方式是原始数据；&lt;/li>
&lt;li>数据中台、数据湖距离业务更近，能够更快速的响应业务和应用开发需求，从而为业务提供速度更快的服务；&lt;/li>
&lt;li>数据中台可以建立在数据仓库和数据平台之上，是加速企业从数据到业务价值的过程的中间层；&lt;/li>
&lt;/ul></description></item><item><title>2022-园陌-做数仓必须搞明白的各种名词及关系，吐血整理</title><link>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E5%9B%AD%E9%99%8C-%E5%81%9A%E6%95%B0%E4%BB%93%E5%BF%85%E9%A1%BB%E6%90%9E%E6%98%8E%E7%99%BD%E7%9A%84%E5%90%84%E7%A7%8D%E5%90%8D%E8%AF%8D%E5%8F%8A%E5%85%B3%E7%B3%BB%E5%90%90%E8%A1%80%E6%95%B4%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ng-tech.icu/books/dataengineering-series/1.%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB/999.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/2022-%E5%9B%AD%E9%99%8C-%E5%81%9A%E6%95%B0%E4%BB%93%E5%BF%85%E9%A1%BB%E6%90%9E%E6%98%8E%E7%99%BD%E7%9A%84%E5%90%84%E7%A7%8D%E5%90%8D%E8%AF%8D%E5%8F%8A%E5%85%B3%E7%B3%BB%E5%90%90%E8%A1%80%E6%95%B4%E7%90%86/</guid><description>&lt;blockquote>
&lt;p>&lt;a href="https://www.51cto.com/article/715015.html" target="_blank" rel="noopener">原文地址&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="做数仓必须搞明白的各种名词及关系吐血整理">做数仓必须搞明白的各种名词及关系，吐血整理&lt;/h1>
&lt;p>作为一个数据人，是不是经常被各种名词围绕，是不是对其中很多概念认知模糊。有些词虽然只有一字之差，但是它们意思完全不同，今天我们就来了解下数仓建设及数据分析时常见的一些概念含义及它们之间的关系。&lt;/p>
&lt;p>本文结构如下图所示：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://assets.ng-tech.icu/item/20230325000306.png" alt="数仓中概念术语解析" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>&lt;/p>
&lt;h1 id="数仓中常见概念解析">数仓中常见概念解析&lt;/h1>
&lt;h2 id="1实体">1.实体&lt;/h2>
&lt;p>实体是指依附的主体，就是我们分析的一个对象，比如我们分析商品的销售情况，如华为手机近半年的销售量是多少，那华为手机就是一个实体；我们分析用户的活跃度，用户就是一个实体。当然实体也可以现实中不存在的，比如虚拟的业务对象，活动，会员等都可看做一个实体。&lt;/p>
&lt;p>实体的存在是为了业务分析，作为分析的一个筛选的维度，拥有描述自己的属性，本身具有可分析的价值。&lt;/p>
&lt;h2 id="2-维度">2. 维度&lt;/h2>
&lt;p>维度就是看待问题的角度，分析业务数据，从什么角度分析，就建立什么样的维度。所以维度就是要对数据进行分析时所用的一个量，比如你要分析产品销售情况，你可以选择按商品类别来进行分析，这就构成一个维度，把所有商品类别集合在一起，就构成了维度表。&lt;/p>
&lt;h2 id="3-度量">3. 度量&lt;/h2>
&lt;p>度量是业务流程节点上的一个数值。比如销量，价格，成本等等。事实表中的度量可分为三类：完全可加，半可加，不可加。&lt;/p>
&lt;ul>
&lt;li>完全可加的度量是最灵活，最有用的，比如说销量，销售额等，可进行任意维度汇总；&lt;/li>
&lt;li>半可加的度量可以对某些维度汇总，但不能对所有维度汇总，差额是常见的半可加度量，它除了时间维度外，可以跨所有维度进行加法操作；&lt;/li>
&lt;li>还有一种是完全不可加的，例如：比率。对于这类非可加度量，一种好的方法是，尽可能存储非可加度量的完全可加分量，并在计算出最终的非可加事实前，将这些分量汇总到最终的结果集中。&lt;/li>
&lt;/ul>
&lt;h2 id="4-粒度">4. 粒度&lt;/h2>
&lt;p>粒度就是业务流程中对度量的单位，比如商品是按件记录度量，还是按批记录度量。在数仓建设中，我们说这是用户粒度的事实表，那么表中每行数据都是一个用户，无重复用户；例如还有销售粒度的表，那么表中每行都是一条销售记录。&lt;/p>
&lt;p>选择合适的粒度级别是数据仓库建设好坏的重要关键内容，在设计数据粒度时，通常需重点考虑以下因素：&lt;/p>
&lt;ol>
&lt;li>要接受的分析类型、可接受的数据最低粒度和能存储的数据量；&lt;/li>
&lt;li>粒度的层次定义越高，就越不能在该仓库中进行更细致的分析；&lt;/li>
&lt;li>如果存储资源有一定的限制，就只能采用较高的数据粒度划分；&lt;/li>
&lt;li>数据粒度划分策略一定要保证：数据的粒度确实能够满足用户的决策分析需要，这是数据粒度划分策略中最重要的一个准则。&lt;/li>
&lt;/ol>
&lt;h2 id="5-口径">5. 口径&lt;/h2>
&lt;p>口径就是取数逻辑（如何取数的），比如要取的数是 10 岁以下儿童中男孩的平均身高，这就是统计的口径。&lt;/p>
&lt;h2 id="6-指标">6. 指标&lt;/h2>
&lt;p>指标是口径的衡量值，也就是最后的结果。比如最近七天的订单量，一个促销活动的购买转化率等。一个指标具体到计算实施，主要有以下几部分组成：&lt;/p>
&lt;ul>
&lt;li>指标加工逻辑，比如 count, sum, avg&lt;/li>
&lt;li>维度，比如按部门、地域进行指标统计，对应 sql 中的 group by&lt;/li>
&lt;li>业务限定/修饰词，比如以不同的支付渠道来算对应的指标，微信支付的订单退款率，支付宝支付的订单退款率 。对应 sql 中的 where。&lt;/li>
&lt;/ul>
&lt;p>除此之外，指标本身还可以衍生、派生出更多的指标，基于这些特点，可以将指标进行分类：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>原子指标：基本业务事实，没有业务限定、没有维度。比如订单表中的订单量、订单总金额都算原子指标；业务方更关心的指标，是有实际业务含义，可以直接取数据的指标。比如店铺近 1 天订单支付金额就是一个派生指标，会被直接在产品上展示给商家看。但是这个指标却不能直接从数仓的统一中间层里取数（因为没有现成的事实字段，数仓提供的一般都是大宽表）。需要有一个桥梁连接数仓中间层和业务方的指标需求，于是便有了派生指标&lt;/p>
&lt;/li>
&lt;li>
&lt;p>派生指标：维度+修饰词+原子指标。店铺近 1 天订单支付金额中店铺是维度，近 1 天是一个时间类型的修饰词，支付金额是一个原子指标；维度：观察各项指标的角度；修饰词：维度的一个或某些值，比如维度性别下，男和女就是 2 种修饰词。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>衍生指标：比如某一个促销活动的转化率就是衍生指标，因为需要促销投放人数指标和促销订单数指标进行计算得出。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="7-标签">7. 标签&lt;/h2>
&lt;p>标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。可见标签是经过人为再加工后的结果，如网红、白富美、萝莉。对于有歧义的标签，我们内部可进行标签区分，比如：苹果，我们可以定义苹果指的是水果，苹果手机才指的是手机。&lt;/p>
&lt;h2 id="8-自然键">8. 自然键&lt;/h2>
&lt;p>由现实中已经存在的属性组成的键，它在业务概念中是唯一的，并具有一定的业务含义，比如商品 ID，员工 ID。以数仓角度看，来自于业务系统的标识符就是自然键，比如业务库中员工的编号。&lt;/p>
&lt;h2 id="9-持久键">9. 持久键&lt;/h2>
&lt;p>保持永久性不会发生变化。有时也被叫做超自然持久键。比如身份证号属于持久键。自然键和持久键区别：举个例子就明白了，比如说公司员工离职之后又重新入职，他的自然键也就是员工编号发生了变化，但是他的持久键身份证号是不变的。&lt;/p>
&lt;h2 id="10-代理键">10. 代理键&lt;/h2>
&lt;p>就是不具有业务含义的键。代理键有许多其他的称呼：无意义键、整数键、非自然键、人工键、合成键等。代理键就是简单的以按照顺序序列生产的整数表示。产品行的第 1 行代理键为 1，则下一行的代理键为 2，如此进行。代理键的作用仅仅是连接维度表和事实表。&lt;/p>
&lt;h2 id="11-退化维度">11. 退化维度&lt;/h2>
&lt;p>退化维度，就是那些看起来像是事实表的一个维度关键字，但实际上并没有对应的维度表，就是维度属性存储到事实表中，这种存储到事实表中的维度列被称为退化维度。与其他存储在维表中的维度一样，退化维度也可以用来进行事实表的过滤查询、实现聚合操作等。&lt;/p>
&lt;p>那么究竟怎么定义退化维度呢？比如说订单 id，这种量级很大的维度，没必要用一张维度表来进行存储，而我们进行数据查询或者数据过滤的时候又非常需要，所以这种就冗余在事实表里面，这种就叫退化维度，citycode 这种我们也会冗余在事实表里面，但是它有对应的维度表，所以它不是退化维度。&lt;/p>
&lt;h2 id="12-缓慢变化维">12. 缓慢变化维&lt;/h2>
&lt;p>维度建模的数据仓库中，有一个概念叫 Slowly Changing Dimensions，中文一般翻译成“缓慢变化维”，经常被简写为 SCD。缓慢变化维的提出是因为在现实世界中，维度的属性并不是静态的，它会随着时间的流逝发生缓慢的变化。这种随时间发生变化的维度我们一般称之为缓慢变化维，并且把处理维度表的历史变化信息的问题称为处理缓慢变化维的问题，有时也简称为处理 SCD 的问题。&lt;/p>
&lt;ul>
&lt;li>第一种方式是直接覆盖原值。这样处理，最容易实现，但是没有保留历史数据，无法分析历史变化信息。第一种方式通常简称为“TYPE 1”。&lt;/li>
&lt;li>第二种方式是添加维度行。这样处理，需要代理键的支持。实现方式是当有维度属性发生变化时，生成一条新的维度记录，主键是新分配的代理键，通过自然键可以和原维度记录保持关联。第二种方式通常简称为“TYPE 2”。&lt;/li>
&lt;li>第三种方式是添加属性列。这种处理的实现方式是对于需要分析历史信息的属性添加一列，来记录该属性变化前的值，而本属性字段使用 TYPE 1 来直接覆盖。这种方式的优点是可以同时分析当前及前一次变化的属性值，缺点是只保留了最后一次变化信息。第三种方式通常简称为“TYPE 3”。&lt;/li>
&lt;/ul>
&lt;p>在实际建模中，我们可以联合使用三种方式，也可以对一个维度表中的不同属性使用不同的方式，这些，都需要根据实际情况来决定，但目的都是一样的，就是能够支持方便的分析历史变化情况。&lt;/p>
&lt;h2 id="13-微型维度">13. 微型维度&lt;/h2>
&lt;p>维度建模中，有一种维度叫 minidimension，中文一般翻译成“微型维度”。微型维度的提出主要是为了解决快变超大维度。以客户维度举例来说，如果维度表中有数百万行记录或者还要多，而且这些记录中的字段又经常变化，这样的维度表一般称之为快变超大维度。对于快变超大维度，设计人员一般不会使用 TYPE 2 的缓慢变化维处理方法，因为大家都不愿意向本来就有几百万行的维度表中添加更多的行。&lt;/p>
&lt;p>这时，有一项技术可以解决这个问题。解决的方法是，将分析频率比较高或者变化频率比较大的字段提取出来，建立一个单独的维度表。这个单独的维度表就是微型维度表。微型维度表有自己的关键字，这个关键字和原客户维度表的关键字一起进入事实表。有时为了分析的方便，可以把微型维度的关键字的最新值作为外关键字进入客户维度表。这时一定要注意，这个外关键字必须做 TYPE 1 型处理。&lt;/p>
&lt;h2 id="14-下钻">14. 下钻&lt;/h2>
&lt;p>这是在数据分析中常见的概念，下钻可以理解成增加维的层次，从而可以由粗粒度到细粒度来观察数据，比如对产品销售情况分析时，可以沿着时间维从年到月到日更细粒度的观察数据。从年的维度可以下钻到月的维度、日的维度等。&lt;/p>
&lt;h2 id="15-上卷">15. 上卷&lt;/h2>
&lt;p>知道了下钻，上卷就容易理解了，它俩是相逆的操作，所以上卷可以理解为删掉维的某些层，由细粒度到粗粒度观察数据的操作或沿着维的层次向上聚合汇总数据。&lt;/p>
&lt;h2 id="16-数据集市">16. 数据集市&lt;/h2>
&lt;p>数据集市可以理解为是一种&amp;quot;小型数据仓库&amp;quot;，它只包含单个主题，且关注范围也非全局。数据集市可以分为两种:&lt;/p>
&lt;ul>
&lt;li>一种是独立数据集市，这类数据集市有自己的源数据库和 ETL 架构；&lt;/li>
&lt;li>另一种是非独立数据集市，这种数据集市没有自己的源系统，它的数据来自数据仓库。当用户或者应用程序不需要/不必要/不允许用到整个数据仓库的数据时，非独立数据集市就可以简单为用户提供一个数据仓库的子集。&lt;/li>
&lt;/ul>
&lt;h1 id="数仓概念之间的关系">数仓概念之间的关系&lt;/h1>
&lt;h2 id="实体表事实表维度表之间的关系">实体表，事实表，维度表之间的关系&lt;/h2>
&lt;p>在 Kimball 维度建模中有维度与事实，在 Inmon 范式建模中有实体与关系，如果我们分开两种建模方式看这些概念比较容易理解。但是目前也出现了不少混合建模方式，两种建模方式结合起来看，这些概念是不是容易记忆混乱，尤其事实表和实体表，它们之间到底有怎样区别与联系，先看下它们各自概念：&lt;/p>
&lt;ul>
&lt;li>维度表：维度表可以看成是用户用来分析一个事实的窗口，它里面的数据应该是对事实的各个方面描述，比如时间维度表，地域维度表，维度表是事实表的一个分析角度。&lt;/li>
&lt;li>事实表：事实表其实就是通过各种维度和一些指标值的组合来确定一个事实的，比如通过时间维度，地域组织维度，指标值可以去确定在某时某地的一些指标值怎么样的事实。事实表的每一条数据都是几条维度表的数据和指标值交汇而得到的。&lt;/li>
&lt;li>实体表：实体表就是一个实际对象的表，实体表放的数据一定是一条条客观存在的事物数据，比如说各种商品，它就是客观存在的，所以可以将其设计一个实体表。实时表只描述各个事物，并不存在具体的事实，所以也有人称实体表是无事实的事实表。&lt;/li>
&lt;/ul>
&lt;p>举个例子：比如说手机商场中有苹果手机，华为手机等各品牌各型号的手机，这些数据可以组成一个手机实体表，但是表中没有可度量的数据。某天苹果手机卖了 15 台，华为手机卖了 20 台，这些手机销售数据属于事实，组成一个事实表。这样就可以使用日期维度表和地域维度表对这个事实表进行各种维度分析。&lt;/p>
&lt;h2 id="指标与标签的区别">指标与标签的区别&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>概念不同&lt;/p>
&lt;ul>
&lt;li>指标是用来定义、评价和描述特定事物的一种标准或方式。比如：新增用户数、累计用户数、用户活跃率等是衡量用户发展情况的指标；&lt;/li>
&lt;li>标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。可见标签是经过人为再加工后的结果，如网红、白富美、萝莉。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>构成不同&lt;/p>
&lt;ul>
&lt;li>指标名称是对事物质与量两方面特点的命名；指标取值是指标在具体时间、地域、条件下的数量表现，如人的体重，指标名称是体重，指标的取值就是 120 斤；&lt;/li>
&lt;li>标签名称通常都是形容词或形容词+名词的结构，标签一般是不可量化的，通常是孤立的，除了基础类标签，通过一定算法加工出来的标签一般都没有单位和量纲。如将超过 200 斤的称为大胖子。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>分类不同&lt;/p>
&lt;ul>
&lt;li>
&lt;p>对指标的分类：&lt;/p>
&lt;ul>
&lt;li>按照指标计算逻辑，可以将指标分为原子指标、派生指标、衍生指标三种类型；&lt;/li>
&lt;li>按照对事件描述内容的不同，分为过程性指标和结果性指标；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>对标签的分类：&lt;/p>
&lt;ul>
&lt;li>按照标签的变化性分为静态标签和动态标签；&lt;/li>
&lt;li>按照标签的指代和评估指标的不同，可分为定性标签和定量标签；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>指标最擅长的应用是监测、分析、评价和建模。标签最擅长的应用是标注、刻画、分类和特征提取。特别需要指出的是，由于对结果的标注也是一种标签，所以在自然语言处理和机器学习相关的算法应用场景下，标签对于监督式学习有重要价值，只是单纯的指标难以做到的。而指标在任务分配、绩效管理等领域的作用，也是标签无法做到的。&lt;/p>
&lt;h2 id="维度和指标区别与联系">维度和指标区别与联系&lt;/h2>
&lt;p>维度就是数据的观察角度，即从哪个角度去分析问题，看待问题。指标就是从维度的基础上去衡算这个结果的值。&lt;/p>
&lt;p>维度一般是一个离散的值，比如时间维度上每一个独立的日期或地域，因此统计时，可以把维度相同记录的聚合在一起，应用聚合函数做累加、均值、最大值、最小值等聚合计算。指标就是被聚合的通计算，即聚合运算的结果，一般是一个连续的值。&lt;/p>
&lt;h2 id="自然键与代理键在数仓的使用区别">自然键与代理键在数仓的使用区别&lt;/h2>
&lt;p>数仓工具箱中说维度表的唯一主键应该是代理键而不应该是自然键。有时建模人员不愿意放弃使用自然键，因为他们希望与操作型代码查询事实表，而不希望与维度表做连接操作。然而，应该避免使用包含业务含义的多维键，因为不管我们做出任何假设最终都可能变得无效，因为我们控制不了业务库的变动。&lt;/p>
&lt;p>所以数据仓库中维度表与事实表的每个连接应该基于无实际含义的整数代理键。避免使用自然键作为维度表的主键。&lt;/p>
&lt;h2 id="数据集市与数据仓库的区别与联系">数据集市与数据仓库的区别与联系&lt;/h2>
&lt;p>数据集市就是企业级数据仓库的一个子集，它主要面向部门级业务，并且只面向某个特定的主题。为了解决灵活性与性能之间的矛盾，数据集市就是数据仓库体系结构中增加的一种小型的部门或工作组级别的数据仓库。数据集市存储为特定用户预先计算好的数据，从而满足用户对性能的需求。数据集市可以在一定程度上缓解访问数据仓库的瓶颈。&lt;/p></description></item></channel></rss>
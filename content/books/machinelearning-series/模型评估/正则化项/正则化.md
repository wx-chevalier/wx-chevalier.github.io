
---
title: 正则化
linktitle: 正则化
type: book
commentable: true
---

# Regularization:正则化

我们都知道，在进行数据挖掘或者机器学习模 型建立的时候，因为在统计学习中，假设数据满足独立同分布(i.i.d，independently and identically distributed)，即当前已产生的数据可以对未来的数据进行推测与模拟，因此都是使用历史数据建立模型，即使用已经产生的数据去训练，然后使用该 模型去拟合未来的数据。但是一般独立同分布的假设往往不成立，即数据的分布可能会发生变化(distribution drift)，并且可能当前的数据量过少，不足以对整个数据集进行分布估计，因此往往需要防止模型过拟合，提高模型泛化能力。而为了达到该目的的最常见方 法便是：正则化，
正则化(Regularization)是机器学习中一个很重要的防止过拟合的手段，它会为模型的目标函数(objective function)或代价函数(cost function)加上正则项来避免模型参数过度拟合于测试数据。而 L1 正则与 L2 正则的区别在于 L1 是权重的直接和，而 L2 是权重的平方和。
规则化符合奥卡姆剃刀(Occam's razor)原理，在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶 斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项 (regularizer)或惩罚项(penalty term)。加上正则化项之后的监督函数的目标函数为：

$$
w^* = arg min_{w} \sum_i L(y_i,f(x_i;w)) + \lambda \Omega(w)
$$

在上述表达式中，第一项$L(y_i,f(x_i;w))$即是衡量模型对第$i$个样本的预测值$f(x_i;w)$与真实的标签值$y_i$之间的误差。第二项$\lambda \Omega(w)$即是正则化项用于约束我们的模型能够尽量的简单。而 L1 正则化与 L2 正则化的差异在于：
| L2 Regularization | L1 Regularization |
| ---------------------------------------- | ---------------------------------------- |
| Computational efficient due to having analytical solutions | Computational inefficient on non-sparse cases |
| Non-sparse outputs | Sparse outputs |
| No feature selection | Built-in feature selection |

这里简要解释下上面三个比较项的含义，具体的求值与应用在下文中进行阐述：

- Computational Efficiency:计算性能
- Sparsity:稀疏度
- Built-in Feature Selection:内建的特征选择

# L1 Regularization

# L2 Regularization

    

---
title: PCA
linktitle: PCA
type: book
commentable: true
---

# PCA

PCA(Principal Component Analysis)不仅仅是对高维数据进行降维，更重要的是经过降维去除了噪声，发现了数据中的模式。PCA 把原先的 n 个特征用数目更少的 m 个特征取代，新特征是旧特征的线性组合，这些线性组合最大化样本方差，尽量使新的 m 个特征互不相关。从旧特征到新特征的映射捕获数据中的固有变异性。

根据上面对 PCA 的数学原理的解释，我们可以了解到一些 PCA 的能力和限制。PCA 本质上是将方差最大的方向作为主要特征，并且在各个正交方向上将数据“离相关”，也就是让它们在不同正交方向上没有相关性。因此，PCA 也存在一些限制，例如它可以很好的解除线性相关，但是对于高阶相关性就没有办法了，对于存在高阶相关性的数据，可以 考虑 Kernel PCA，通过 Kernel 函数将非线性相关转为线性相关，关于这点就不展开讨论了。另外，PCA 假设数据各主特征是分布在正交方向上，如果在非正交方向上 存在几个方差较大的方向，PCA 的效果就大打折扣了。

最后需要说明的是，PCA 是一种无参数技术，也就是说面对同样的数据，如果不考虑清洗，谁来做结果都一样，没有主观参数的介入，所以 PCA 便于通用实现，但是本身无法个性化的优化。

    
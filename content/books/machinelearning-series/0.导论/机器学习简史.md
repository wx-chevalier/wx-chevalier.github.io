
---
title: 机器学习简史
linktitle: 机器学习简史
type: book
commentable: true
---

# 机器学习简史

机器学习是人工智能研究发展到一定阶段的必然产物，本章仅从笔者的视角对机器学习这五十年来的发展进行一个略述，疏漏错误之处烦请指正。下面这幅漫画中就展示了一个无奈的问题，三岁幼童可以轻松解决的问题却需要最顶尖的科学家花费数十年的光阴，或许机器学习离我们在电影里看到的那样还有很长一段路要走。

知识来源于哪里？知识来源于进化、经验、文化和计算机。对于知识和计算机的关系，可以引用 Facebook 人工智能实验室负责人 Yann LeCun 的一段话：将来，世界上的大部分知识将由机器提取出来，并且将长驻与机器中。而帮助计算机获取新知识，可以通过以下五种方法来实现：

- 填充现存知识的空白

- 对大脑进行仿真

- 对进化进行模拟

- 系统性的减少不确定性

- 注意新旧知识之间的相似点

对应以上这几种知识获取的途径，我们可以认为常见的人工智能的方向有：

| 派别 | 起源 | 擅长算法 |

| -------------------- | ------ | ----------------------------- |

| 符号主义(Symbolists) | 逻辑学、哲学 | 逆演绎算法(Inverse deduction) |

| 联结主义(Connectionists) | 神经科学 | 反向传播算法(Backpropagation) |

| 进化主义(Evolutionaries) | 进化生物学 | 基因编程(Genetic programming) |

| 贝叶斯派(Bayesians) | 统计学 | 概率推理(Probabilistic inference) |

| Analogizer | 心理学 | 核机器(Kernel machines) |

# 二十世纪五十年代：推理期

二十世纪五十年代到七十年代初，人工智能研究处于”推理期“，彼时人们以为只要能赋予机器逻辑推理的能力，机器就能具有智能。这一阶段的代表性作品有 A. Newell 和 H. Simon 的“逻辑理论家”程序，该程序于 1952 年证明了罗素和怀特海的名著《数学原理》中的 38 条定理，在 1963 年证明了全部的 52 条定理。不过随着时间的发展，人们渐渐发现仅具有逻辑推理能力是远远实现不了人工智能的。

# 二十世纪七十年代中期：知识期

从二十世纪七十年代中期开始，人工智能研究进入了“知识期”，在这一时期，大量的专家系统问世，在很多应用领域取得了大量成果。在本阶段诞生的技术的一个鲜明的代表就是模式识别，它强调的是如何让一个计算机程序去做一些看起来很“智能”的事情，例如识别“3”这个数字。而且在融入了很多的智慧和直觉后，人们也的确构建了这样的一个程序。从这个时代诞生的模式识别领域最著名的书之一是由 Duda & Hart 执笔的“模式识别(Pattern Classification)”。对基础的研究者来说，仍然是一本不错的入门教材。不过对于里面的一些词汇就不要太纠结了，因为这本书已经有一定的年代了，词汇会有点过时。自定义规则、自定义决策，以及自定义“智能”程序在这个任务上，曾经都风靡一时。有趣的是笔者在下文中也会介绍如何用深度学习网络去识别手写的数字，有兴趣的朋友可以去探究下使用模式识别与深度学习相比，同样是识别手写数字上的差异。

不过，专家系统面临“知识工程瓶颈”，即由人来把知识总结出来再教给计算机是相当困难的，于是人们开始考虑如果机器能够自己学习知识，该是一件多么美妙的事。

# 二十世纪八十年代：从样例中学习

R.S.Michalski 等人将机器学习分为了“从样例中学习”、“在问题求解和规划中学习”、“通过观察和发现学习”、“从指令中学习”等类别；E.A.Feigenbaum 等人在著作《人工智能手册》中，则把机器学习划分为了“机械学习”、“示教学习”、“类比学习”和“归纳学习”。机械学习又被称为死记硬背式学习，即把外界输入的信息全部记录下来，在需要时原封不动地取出来使用，这实际上没有进行真正的学习，仅仅是在进行信息存储和检索；示教学习和类比学习类似于 R.S.Michalski 等人所说的从指令中学习和通过观察和发现学习。归纳学习则相当于从样例中学习，即从训练样本中归纳出学习结果。二十世纪八十年代以来，被研究最多、应用最广的是“从样例中学习”，也就是广泛的归纳学习，它涵盖了监督学习、无监督学习等。

## 符号主义学习

在二十世纪八十年代，从样例中学习的一大主流就是符号主义学习，其代表包括决策树和基于逻辑的学习。符号学习一个直观的流程可以参考下图：

典型的决策树学习以信息论为基础，以信息熵的最小化为目标，直接模拟了人类对概念进行判定的树形流程。基于逻辑的学习的著名代表是归纳逻辑程序设计 Inductive Logic Programming，简称 ILP，可以看做机器学习与逻辑程序设计的交叉。它使用一阶逻辑，即谓词逻辑来进行知识表示，通过修改和扩充逻辑表达式来完成对于数据的归纳。符号主义学习占据主流地位与前几十年人工智能经历的推理期和知识期密切相关，最后，可以来认识几位符号主义的代表人物：

## 连接主义学习

二十世纪九十年代中期之前，从样例中学习的另一主流技术是基于神经网络的连接主义学习。下图就是典型的神经元、神经网络与著名的 BP 算法的示例。

与符号主义学习能产生明确的概念表示不同，连接主义学习产生的是黑箱模型，因此从知识获取的角度来看，连接主义学习技术有明显弱点。然而，BP 一直是被应用的最广泛的机器学习算法之一，在很多现实问题上发挥作用。连接主义学习的最大局限是其试错性。简单来说，其学习过程设计大量的参数，而参数的设置缺乏理论指导，主要靠手工调参；夸张一点来说，参数调节上失之毫厘，学习结果可能谬以千里。

# 二十世纪九十年代中期：统计学习

二十世纪九十年代中期，统计学习闪亮登场并且迅速占据主流舞台，代表性技术是支持向量机(Support Vector Machine)以及更一般的核方法(Kernel Methods)。正是由于连接主义学习技术的局限性凸显，人们才把目光转向以统计学习理论为直接支撑的统计学习技术。

# 二十一世纪：深度学习

深度学习掀起的热潮也许大过它本身真正的贡献，在理论和技术上并没有太多的创新，只不过是由于硬件技术的革命，计算机的速度大大提高了，使得人们有可能采用原来复杂度很高的算法，从而得到比过去更精细的结果。

二十一世纪初，连接主义学习又卷土重来，掀起了以深度学习为名的热潮。所谓深度学习，狭义的说就是“很多层”的神经网络。在若干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术取得了优越性能。之前的机器学习技术在应用中要取得好的性能，对于使用者的要求较高。而深度学习技术涉及的模型复杂度非常高，以至于只要下功夫“调参”，把参数调节好，性能往往就好。深度学习虽然缺乏严格的理论基础，但是显著降低了机器学习应用者的门槛，为机器学习走向工程实践带来了便利。深度学习火热的原因有：

- 数据大了，计算能力抢了，深度学习模型拥有大量参数，若数据样本少，则很容易过拟合。

- 由于人类进入了大数据时代，数据储量与计算设备都有了大发展，才使得连接主义学习技术焕发了又一春。

    

---
title: LLM-List
linktitle: LLM-List
type: book
commentable: true
---

# LLM List

- [2023-使用 Prompts 和 Chains 让 ChatGPT 成为神奇的生产力工具！](https://github.com/howl-anderson/unlocking-the-power-of-llms): ChatGPT 诞生后，因其非常强大的又难以置信的的能力，得到了非常广泛的关注。用户将 ChatGPT 视作一种有趣且知识渊博的聊天工具。但事实上，使用合适的 Prompts 和 Chains，可以将 ChatGPT 作为一个神奇的生产力工具，能够处理各种各样复杂的任务。本仓库将详细介绍如何使用 ChatGPT 完成各种任务。

# OpenSource

- [2023-Promptable ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/cfortuner/promptable)](https://github.com/cfortuner/promptable): Promptable is library that enables you to build powerful AI applications with LLMs and Embeddings providers such as OpenAI, Hugging Face, Cohere and Anthropic. It provides a flexible and extensible API that makes it easy to compose LLMs with data and tools to build complex applications quickly and easily.

- [2023-mm-cot ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/amazon-science/mm-cot)](https://github.com/amazon-science/mm-cot): Multimodal-CoT incorporates vision features in a decoupled training framework. The framework consists of two training stages: (i) rationale generation and (ii) answer inference. Both stages share the same model architecture but differ in the input and output.

- [2023-LangChains ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/hwchase17/langchain)](https://github.com/hwchase17/langchain): Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. But using these LLMs in isolation is often not enough to create a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.

  - [LangFlow ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/logspace-ai/langflow)](https://github.com/logspace-ai/langflow): ⛓️ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.

## ChatGLM

- [2023-ChatGLM-6B ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/THUDM/ChatGLM-6B)](https://github.com/THUDM/ChatGLM-6B): ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。

## Llama

- [2023-llama-dl ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/shawwn/llama-dl)](https://github.com/shawwn/llama-dl): High-speed download of LLaMA, Facebook's 65B parameter GPT model

- [2023-LlamaIndex ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/jerryjliu/llama_index)](https://github.com/jerryjliu/llama_index): LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM's with external data.

- [2023-dalai ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/cocktailpeanut/dalai)](https://github.com/cocktailpeanut/dalai): The simplest way to run LLaMA on your local machine

- [2023-Alpaca.cpp ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/antimatter15/alpaca.cpp)](https://github.com/antimatter15/alpaca.cpp): Run a fast ChatGPT-like model locally on your device. The screencast below is not sped up and running on an M2 Macbook Air with 4GB of weights.

- [2023-Alpaca-LoRA ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/Alpaca-LoRA)](https://github.com/Alpaca-LoRA): Instruct-tuning LLaMA on consumer hardware.

- [2023-llama-rs ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/setzer22/llama-rs)](https://github.com/setzer22/llama-rs): LLaMA-rs is a Rust port of the llama.cpp project. This allows running inference for Facebook's LLaMA model on a CPU with good performance using full precision, f16 or 4-bit quantized versions of the model.

- [2023-Serge ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/nsarrazin/serge)](https://github.com/nsarrazin/serge): A chat interface based on llama.cpp for running Alpaca models. Entirely self-hosted, no API keys needed. Fits on 4GB of RAM and runs on the CPU.

## Alpaca

- [2023-deep-diver/Alpaca-LoRA-Serve ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/deep-diver/Alpaca-LoRA-Serve)](https://github.com/deep-diver/Alpaca-LoRA-Serve): This repository demonstrates Alpaca-LoRA as a Chatbot service with Alpaca-LoRA and Gradio. It comes with the following features:

- [2023-LianjiaTech/BELLE ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/LianjiaTech/BELLE)](https://github.com/LianjiaTech/BELLE): 本项目基于 Stanford Alpaca ，Stanford Alpaca 的目标是构建和开源一个基于 LLaMA 的模型。 Stanford Alpaca 的种子任务都是英语，收集的数据也都是英文，因此训练出来的模型未对中文优化。

- [2023-Chinese-alpaca-lora ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/LC1332/Chinese-alpaca-lora)](https://github.com/LC1332/Chinese-alpaca-lora): CamelBell(驼铃), tuning Chinese Data on Chinese based model GLM is now an individual repo. We may move original Luotuo into a new repo also.

    